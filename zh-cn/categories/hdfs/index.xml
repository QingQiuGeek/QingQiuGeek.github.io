<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>HDFS on 青秋博客</title>
        <link>/zh-cn/categories/hdfs/</link>
        <description>Recent content in HDFS on 青秋博客</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>青秋博客</copyright>
        <lastBuildDate>Mon, 15 Apr 2024 14:38:50 +0000</lastBuildDate><atom:link href="/zh-cn/categories/hdfs/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Hadoop入门—HDFS、MR、Yarn</title>
        <link>/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/</link>
        <pubDate>Mon, 15 Apr 2024 14:38:50 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/</guid>
        <description>&lt;h2 id=&#34;hadoop-简介&#34;&gt;&lt;a href=&#34;#hadoop-%e7%ae%80%e4%bb%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hadoop 简介
&lt;/h2&gt;&lt;hr&gt;
&lt;p&gt;狭义来说，hadoop 是 Apache 基金会开发的分布式系统基础架构，用来解决海量数据的存储和海量数据的分析计算问题。广义上来说，Hadoop 通常是指一个更广泛的概念 &amp;mdash;&amp;mdash; Hadoop 生态圈。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image.png&#34;
	width=&#34;849&#34;
	height=&#34;406&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image_hu_ae871aaf7cbe79af.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image_hu_abb20e2b328fbc6b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;209&#34;
		data-flex-basis=&#34;501px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;hadoop-三大发行版本&#34;&gt;&lt;a href=&#34;#hadoop-%e4%b8%89%e5%a4%a7%e5%8f%91%e8%a1%8c%e7%89%88%e6%9c%ac&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hadoop 三大发行版本
&lt;/h3&gt;&lt;p&gt;Apache、Cloudera、Hortonworks&lt;/p&gt;
&lt;p&gt;Apache 版本最原始（最基础）的版本，对于入门学习最好。&lt;/p&gt;
&lt;p&gt;Cloudera 在大型互联网企业中用的较多。其主要产品有 CDH、Cloudera Manager，Cloudera Support&lt;/p&gt;
&lt;h3 id=&#34;hadoop-优势&#34;&gt;&lt;a href=&#34;#hadoop-%e4%bc%98%e5%8a%bf&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hadoop 优势
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;高可靠性：&lt;/strong&gt; Hadoop 底层维护多个数据副本，所以即使 Hadoop 某个计算元素或存储出现故障，也不会导致数据的丢失。&lt;br&gt;
&lt;strong&gt;高扩展性：&lt;/strong&gt; 在集群间分配任务数据，可方便的扩展数以千计的节点。&lt;br&gt;
高效性： 在 MapReduce 的思想下，Hadoop 是并行工作的，以加快任务处理速度。&lt;br&gt;
&lt;strong&gt;高容错性：&lt;/strong&gt; 能够自动将失败的任务重新分配。&lt;/p&gt;
&lt;p&gt;**低成本：**Hadoop 不要求机器的配置达到极高的标准，大部分普通商用服务器即可满足要求，通过提供多个副本和容错机制提高集群的可靠性&lt;/p&gt;
&lt;h3 id=&#34;hadoop-基本组成&#34;&gt;&lt;a href=&#34;#hadoop-%e5%9f%ba%e6%9c%ac%e7%bb%84%e6%88%90&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hadoop 基本组成
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/fd575291df78b55069687df62b245798.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;常用-shell-命令&#34;&gt;&lt;a href=&#34;#%e5%b8%b8%e7%94%a8-shell-%e5%91%bd%e4%bb%a4&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;常用 Shell 命令
&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;hdfs dfs -ls &amp;lt;path&amp;gt;：列出指定 HDFS 路径下的文件和目录
hdfs dfs -mkdir &amp;lt;path&amp;gt;：在 HDFS 中创建新目录
hdfs dfs -put &amp;lt;localsrc&amp;gt; &amp;lt;dst&amp;gt;：将本地文件（或目录）复制到 HDFS
hdfs dfs -get &amp;lt;src&amp;gt; &amp;lt;localdst&amp;gt;：将 HDFS 上的文件（或目录）复制到本地
hdfs dfs -mv &amp;lt;src&amp;gt; &amp;lt;dst&amp;gt;：移动 HDFS 中的文件目录或重命名文件目录
hdfs dfs -cp &amp;lt;src&amp;gt; &amp;lt;dst&amp;gt;：复制 HDFS 中的文件或目录
hdfs dfs -rm &amp;lt;path&amp;gt;：删除 HDFS 中的文件
hdfs dfs -cat &amp;lt;path&amp;gt;：在控制台显示 HDFS 文件的内容
hdfs dfs -du &amp;lt;path&amp;gt;：显示 HDFS 文件或目录的大小
hdfs dfs -df &amp;lt;path&amp;gt;：显示 HDFS 的可用空间
hdfs fsck path [-files [-blocks [-location]]]
-files列出路径内的文件状态
-files -blocks输出文件块报告（几个块，几个副本）
-files -blocks -locations 输出每个block的详情
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;hdfs-分布存储&#34;&gt;&lt;a href=&#34;#hdfs-%e5%88%86%e5%b8%83%e5%ad%98%e5%82%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HDFS 分布存储
&lt;/h2&gt;&lt;hr&gt;
&lt;p&gt;HDFS 是一个分布式文件系统，具有高容错、高吞吐 量等特性，&lt;strong&gt;分布在多个集群节点上的文件系统。有 NN、DN、SNN 三种角色。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;hdfs-启停&#34;&gt;&lt;a href=&#34;#hdfs-%e5%90%af%e5%81%9c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HDFS 启停
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-1.png&#34;
	width=&#34;1296&#34;
	height=&#34;368&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-1_hu_9f50d72e4713275a.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-1_hu_e892968554c81460.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;352&#34;
		data-flex-basis=&#34;845px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;namenodenn&#34;&gt;&lt;a href=&#34;#namenodenn&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;NameNode（NN）
&lt;/h3&gt;&lt;p&gt;HDFS 的主角色，负责管理每个文件的块所在的 DataNode、整个 HDFS 文件系统、存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限）等。&lt;/p&gt;
&lt;h3 id=&#34;datanodedn&#34;&gt;&lt;a href=&#34;#datanodedn&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;DataNode（DN）
&lt;/h3&gt;&lt;p&gt;HDFS 从角色，负责处理客户端的读写请求，存储删除文件块，以及块数据校验和。&lt;/p&gt;
&lt;h3 id=&#34;secondarynamenodesnn&#34;&gt;&lt;a href=&#34;#secondarynamenodesnn&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;SecondaryNameNode（SNN）
&lt;/h3&gt;&lt;p&gt;NN 的辅助角色，帮 NN 打杂，监控 HDFS 状态的辅助后台程序，每隔一段时间获取 HDFS 元数据的快照。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可通过 9870 端口（默认 9870）访问 web 界面，查看集群各节点状态及信息&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-2.png&#34;
	width=&#34;2880&#34;
	height=&#34;1620&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-2_hu_57d3224414c2e837.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-2_hu_d5435fb5eaa6d337.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;文件写入流程&#34;&gt;&lt;a href=&#34;#%e6%96%87%e4%bb%b6%e5%86%99%e5%85%a5%e6%b5%81%e7%a8%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;文件写入流程
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-3.png&#34;
	width=&#34;1462&#34;
	height=&#34;644&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-3_hu_fbf8ea63e84c9d64.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-3_hu_cd5ef232b66b9c88.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;227&#34;
		data-flex-basis=&#34;544px&#34;
	
&gt;
发送的写入请求通过后，客户端会根据 NN 返回的信息自动把数据分块，向&lt;strong&gt;网络距离最近&lt;/strong&gt;的 DN 写入数据。同时，DN 会完成备份操作，把备份传到其他的 DN，然后由其他的 DN 再次做备份传播，直到满足设置的备份数量。当数据写入完成后，客户端会通知 NN，由 NN 完成元数据记录。
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-4.png&#34;
	width=&#34;1070&#34;
	height=&#34;1148&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-4_hu_493c72faaa0d005a.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-4_hu_ba3abf22a2a6c6b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;93&#34;
		data-flex-basis=&#34;223px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;hdfs-架构的稳定性&#34;&gt;&lt;a href=&#34;#hdfs-%e6%9e%b6%e6%9e%84%e7%9a%84%e7%a8%b3%e5%ae%9a%e6%80%a7&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HDFS 架构的稳定性
&lt;/h3&gt;&lt;h4 id=&#34;心跳机制和重新复制&#34;&gt;&lt;a href=&#34;#%e5%bf%83%e8%b7%b3%e6%9c%ba%e5%88%b6%e5%92%8c%e9%87%8d%e6%96%b0%e5%a4%8d%e5%88%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;心跳机制和重新复制
&lt;/h4&gt;&lt;p&gt;每个 DataNode 定期向 NameNode 发送心跳消息，如果超过指定时间没有收到心跳消息，则将 DataNode 标记为死亡。NameNode 不会将任何新的 IO 请求转发给标记为死亡的 DataNode，也不会 再使用这些 DataNode 上的数据。 由于数据不再可用，可能会导致某些块的复制因子小于其指定值， NameNode 会跟踪这些块，并在必要的时候进行重新复制。&lt;/p&gt;
&lt;h4 id=&#34;数据的完整性&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e6%8d%ae%e7%9a%84%e5%ae%8c%e6%95%b4%e6%80%a7&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;数据的完整性
&lt;/h4&gt;&lt;p&gt;由于存储设备故障等原因，存储在 DataNode 上的数据块也会发生损坏。为了避免读取到已经损坏的数 据而导致错误，HDFS 提供了数据完整性校验机制来保证数据的完整性，具体操作如下： 当客户端创建 HDFS 文件时，它会计算文件的每个块的 校验和 ，并将 校验和 存储在同一 HDFS 命名空 间下的单独的隐藏文件中。当客户端检索文件内容时，它会验证从每个 DataNode 接收的数据是否与存 储在关联校验和文件中的 校验和 匹配。如果匹配失败，则证明数据已经损坏，此时客户端会选择从其 他 DataNode 获取该块的其他可用副本。&lt;/p&gt;
&lt;h3 id=&#34;元数据的磁盘故障&#34;&gt;&lt;a href=&#34;#%e5%85%83%e6%95%b0%e6%8d%ae%e7%9a%84%e7%a3%81%e7%9b%98%e6%95%85%e9%9a%9c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;元数据的磁盘故障
&lt;/h3&gt;&lt;p&gt;FsImage 和 EditLog 是 HDFS 的核心数据，这些数据的意外丢失可能会导致整个 HDFS 服务不可 用。为了避免这个问题，可以配置 NameNode 使其支持 FsImage 和 EditLog 多副本同步，这样 FsImage 或 EditLog 的任何改变都会引起每个副本 FsImage 和 EditLog 的同步更新。&lt;/p&gt;
&lt;h4 id=&#34;支持快照&#34;&gt;&lt;a href=&#34;#%e6%94%af%e6%8c%81%e5%bf%ab%e7%85%a7&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;支持快照
&lt;/h4&gt;&lt;p&gt;快照支持在特定时刻存储数据副本，在数据意外损坏时，可以通过回滚操作恢复到健康的数据状态。&lt;/p&gt;
&lt;h3 id=&#34;文件读取流程&#34;&gt;&lt;a href=&#34;#%e6%96%87%e4%bb%b6%e8%af%bb%e5%8f%96%e6%b5%81%e7%a8%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;文件读取流程
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-5.png&#34;
	width=&#34;1920&#34;
	height=&#34;887&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-5_hu_4d4e26163a453731.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-5_hu_66e2c8639fa1ca70.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;216&#34;
		data-flex-basis=&#34;519px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;存储方式&#34;&gt;&lt;a href=&#34;#%e5%ad%98%e5%82%a8%e6%96%b9%e5%bc%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;存储方式
&lt;/h3&gt;&lt;h4 id=&#34;block-块和多副本&#34;&gt;&lt;a href=&#34;#block-%e5%9d%97%e5%92%8c%e5%a4%9a%e5%89%af%e6%9c%ac&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Block 块和多副本
&lt;/h4&gt;&lt;p&gt;由于文件大小不一，不利于统一管理，hdfs 设定了统一的存储单位 Block 块，Block 块是 hdfs 最小存储单位，通常每个 128MB（可修改 dfs.blocksize）。hdfs 会按照 Block 块大小把文件切分成多份存储在多个 datanode 上也就是多个服务器上，同时为了保证整个文件的完成性（防止 Block 块丢失或损坏），hdfs 会对每个 Block 块做多个备份存储在其他节点上，备份的数量默认是 3，可以在 hdfs-site.xml 中配置数量，修改后要重新分发该文件，保证每个服务器的配置文件相同！&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.replication&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;3&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;同时还可以&lt;strong&gt;临时决定&lt;/strong&gt;上传文件的副本数量：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;hdfs fs -D dfs.replication=5 -put test.tst /data/test&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;还可以修改已存在的 hdfs 文件的副本数量：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;hdfs fs -setrep [-R] 5 path
path 是指定文件路径，-R 表示对子目录也生效&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;edits-和-fsimage-文件&#34;&gt;&lt;a href=&#34;#edits-%e5%92%8c-fsimage-%e6%96%87%e4%bb%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;edits 和 fsimage 文件
&lt;/h4&gt;&lt;p&gt;hdfs 中文件被划分成一堆堆 block 块，为了方便整理记录文件和 block 的关系，namenode 基于一批 edits 文件和一个 fsimage 文件完成整个文件系统的维护管理。&lt;/p&gt;
&lt;p&gt;edits 文件是一个流水账文件，记录了 hdfs 的每一次操作以及该次操作影响的文件及其对应的 block。为了保证 edits 文件检索性能，会有多个 edits 文件，每一个 edits 文件存储到达一定数量会开启新的 edits，保证不出现超大的 edits 文件。最终所有 edits 文件会合并为一个 fsimage 文件，这个 fsimage 文件就记录了最终状态的文件操作信息。如果已经有了 fsimage，就会把全部的 edits 和已存在的 fsimage 进行新的合并，生成新的 fsimage。
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-6.png&#34;
	width=&#34;1296&#34;
	height=&#34;481&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-6_hu_52dfd5d1e1ebfb29.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-6_hu_11dd4332aaa90aaa.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;269&#34;
		data-flex-basis=&#34;646px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-7.png&#34;
	width=&#34;1069&#34;
	height=&#34;588&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-7_hu_2625dce4698b9464.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-7_hu_de1611f6402ed05e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;181&#34;
		data-flex-basis=&#34;436px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-8.png&#34;
	width=&#34;1891&#34;
	height=&#34;688&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-8_hu_52c0bd3ecacf8461.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-8_hu_cefe06dc3ddf1ff3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;274&#34;
		data-flex-basis=&#34;659px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;元数据合并及控制参数&#34;&gt;&lt;a href=&#34;#%e5%85%83%e6%95%b0%e6%8d%ae%e5%90%88%e5%b9%b6%e5%8f%8a%e6%8e%a7%e5%88%b6%e5%8f%82%e6%95%b0&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;元数据合并及控制参数
&lt;/h4&gt;&lt;p&gt;**注意！**元数据（eidts 和 fsimage）的合并不是由 NN 完成的，而是 SNN，NN 只是基于元数据对整个文件系统进行维护管理，负责元数据记录和权限审批，NN 是管理者，不是员工。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;SNN 会通过 http 从 NN 拉取 edits 和 fsimage 然后合并元数据并提供给 NN 使用&lt;/strong&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-9.png&#34;
	width=&#34;1322&#34;
	height=&#34;573&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-9_hu_fdcc81a3d0edfece.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-9_hu_c4d2baad5f67d482.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;230&#34;
		data-flex-basis=&#34;553px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;hdfs-漫画&#34;&gt;&lt;a href=&#34;#hdfs-%e6%bc%ab%e7%94%bb&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HDFS 漫画
&lt;/h3&gt;&lt;h4 id=&#34;读写数据&#34;&gt;&lt;a href=&#34;#%e8%af%bb%e5%86%99%e6%95%b0%e6%8d%ae&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;读写数据
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-10.png&#34;
	width=&#34;1121&#34;
	height=&#34;1256&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-10_hu_157753679e8ec94b.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-10_hu_128645316d4622f6.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;89&#34;
		data-flex-basis=&#34;214px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-11.png&#34;
	width=&#34;1134&#34;
	height=&#34;639&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-11_hu_5749475ab96244d1.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-11_hu_fdb712f4675e0e4c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;425px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-12.png&#34;
	width=&#34;1140&#34;
	height=&#34;696&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-12_hu_cbb94e5392c1e693.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-12_hu_3fa0523a2f6f2f2b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;163&#34;
		data-flex-basis=&#34;393px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;hdfs-故障类型和检测方法&#34;&gt;&lt;a href=&#34;#hdfs-%e6%95%85%e9%9a%9c%e7%b1%bb%e5%9e%8b%e5%92%8c%e6%a3%80%e6%b5%8b%e6%96%b9%e6%b3%95&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HDFS 故障类型和检测方法
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-13.png&#34;
	width=&#34;1194&#34;
	height=&#34;1261&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-13_hu_4b1cee605bbbf67f.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-13_hu_58e809ec424f960c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;94&#34;
		data-flex-basis=&#34;227px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-14.png&#34;
	width=&#34;1174&#34;
	height=&#34;781&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-14_hu_f1b4c4dcb189bb05.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-14_hu_ca4e5674b708f30f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;150&#34;
		data-flex-basis=&#34;360px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-15.png&#34;
	width=&#34;1032&#34;
	height=&#34;1308&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-15_hu_3c0d662c6bd6c4dc.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-15_hu_3c58c6056ad8f8ae.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;78&#34;
		data-flex-basis=&#34;189px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-16.png&#34;
	width=&#34;1032&#34;
	height=&#34;1308&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-16_hu_3c0d662c6bd6c4dc.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-16_hu_3c58c6056ad8f8ae.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;78&#34;
		data-flex-basis=&#34;189px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;mapreduce-分布式并行计算框架&#34;&gt;&lt;a href=&#34;#mapreduce-%e5%88%86%e5%b8%83%e5%bc%8f%e5%b9%b6%e8%a1%8c%e8%ae%a1%e7%ae%97%e6%a1%86%e6%9e%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;MapReduce 分布式并行计算框架
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;MapReduce 是基于 Yarn 运行的，没有 Yarn 就无法运行 MapReduce，MapReduce 有 RM、NM、AM 三种角色。&lt;/p&gt;
&lt;p&gt;MR 不适合实时计算，不适合流式计算，不适合有向图计算。&lt;/p&gt;
&lt;p&gt;可通过 8042 端口（默认 8042）访问 web 界面，查看 MR 任务的执行信息
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-17.png&#34;
	width=&#34;2880&#34;
	height=&#34;1620&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-17_hu_f4034a3b5f774256.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-17_hu_c2d144baf5c37545.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;计算模式&#34;&gt;&lt;a href=&#34;#%e8%ae%a1%e7%ae%97%e6%a8%a1%e5%bc%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;计算模式
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;MapReduce 属于分散汇总。spark、flink 属于中心调度.&lt;/strong&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-18.png&#34;
	width=&#34;2005&#34;
	height=&#34;844&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-18_hu_8fee4c51ba5bc4bc.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-18_hu_233fa6c8244e1f4c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;237&#34;
		data-flex-basis=&#34;570px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-19.png&#34;
	width=&#34;1668&#34;
	height=&#34;955&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-19_hu_e796581b28647e17.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-19_hu_a7bfd4eb965f4d88.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;174&#34;
		data-flex-basis=&#34;419px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;map-和-reduce&#34;&gt;&lt;a href=&#34;#map-%e5%92%8c-reduce&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Map 和 Reduce
&lt;/h3&gt;&lt;p&gt;Map 接口提供“分散”功能，Reduce 提供“汇总聚合”功能，用户可以通过 Java、python 等编程调用 mapreduce 接口完成开发，不过现在已经有了 Hive on MR（稍微过时），sparkSQL 等客户端。不懂编程仅用 SQL 就能完成开发，使用更方便，逐渐成为主流。&lt;/p&gt;
&lt;h3 id=&#34;mr-执行原理&#34;&gt;&lt;a href=&#34;#mr-%e6%89%a7%e8%a1%8c%e5%8e%9f%e7%90%86&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;MR 执行原理
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-20.png&#34;
	width=&#34;1403&#34;
	height=&#34;1232&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-20_hu_68e96f09be2f3bc.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-20_hu_58f862bcd0565186.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;113&#34;
		data-flex-basis=&#34;273px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;yarn-作业调度资源管理&#34;&gt;&lt;a href=&#34;#yarn-%e4%bd%9c%e4%b8%9a%e8%b0%83%e5%ba%a6%e8%b5%84%e6%ba%90%e7%ae%a1%e7%90%86&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Yarn 作业调度、资源管理
&lt;/h2&gt;&lt;p&gt;Yarn 管控整个集群的资源调度，MR 程序运行时，是在 Yarn 的监督下运行的，MR 程序会把计算任务分成若干个 map 和 reduce，然后向 Yarn 申请资源并运行任务。Yarn 有四种角色：ResourceManager（RM）、NodeManager（NM）、ProxyServer（PS）、JobHistoryServer（JHS）
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-21.png&#34;
	width=&#34;889&#34;
	height=&#34;513&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-21_hu_54781fad034c5888.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-21_hu_c4ac2a9b591cc19d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;173&#34;
		data-flex-basis=&#34;415px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;yarn-启停&#34;&gt;&lt;a href=&#34;#yarn-%e5%90%af%e5%81%9c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Yarn 启停
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-22.png&#34;
	width=&#34;1253&#34;
	height=&#34;291&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-22_hu_7b46bce3de21f748.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-22_hu_775d8f0fe7403c04.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;430&#34;
		data-flex-basis=&#34;1033px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;resourcemanager&#34;&gt;&lt;a href=&#34;#resourcemanager&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;ResourceManager
&lt;/h3&gt;&lt;p&gt;集群资源总管家，整个集群资源调度者，负责协调调度各个程序所需资源。&lt;/p&gt;
&lt;h3 id=&#34;nodemanager&#34;&gt;&lt;a href=&#34;#nodemanager&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;NodeManager
&lt;/h3&gt;&lt;p&gt;单机资源管家，单个服务器的资源调度者，负责协调调度单个服务器的资源供程序使用。同时负责该节点内所有容器的生命周期的管 理，监视资源和跟踪节点健康。具体如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;启动时向 ResourceManager 注册并定时发送心跳消息，等待 ResourceManager 的指令；
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;维护 Container 的生命周期，监控 Container 的资源使用情况；
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;管理任务运行时的相关依赖，根据 ApplicationMaster 的需要，在启动 Container 之前将需 要的程序及其依赖拷贝到本地。
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;applicationmaster&#34;&gt;&lt;a href=&#34;#applicationmaster&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;ApplicationMaster
&lt;/h3&gt;&lt;p&gt;在用户提交一个应用程序时，YARN 会启动一个轻量级的进程 ApplicationMaster 。 ApplicationMaster 负责协调来自 ResourceManager 的资源，并通过 NodeManager 监视容器内资 源的使用情况，同时还负责任务的监控与容错。具体如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;根据应用的运行状态来决定动态计算资源需求；
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;向 ResourceManager 申请资源，监控申请的资源的使用情况；
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;跟踪任务状态和进度，报告资源的使用情况和应用的进度信息；
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;负责任务的容错。
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;运行时可通过服务器的 8088 端口（默认 8088）访问 web 界面&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;jobhistoryserver&#34;&gt;&lt;a href=&#34;#jobhistoryserver&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;JobHistoryServer
&lt;/h3&gt;&lt;p&gt;记录历史运行程序的信息及产生的日志，把每个程序的运行日志统一收集到 hdfs，可通过 19888 端口访问 web 界面
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-23.png&#34;
	width=&#34;2880&#34;
	height=&#34;1620&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-23_hu_30a5329cc559fcde.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-23_hu_d5dd26fb9b003a81.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;container&#34;&gt;&lt;a href=&#34;#container&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Container
&lt;/h3&gt;&lt;p&gt;Container 是 Yarn 中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等。&lt;/p&gt;
&lt;h2 id=&#34;hadoop-一键启停&#34;&gt;&lt;a href=&#34;#hadoop-%e4%b8%80%e9%94%ae%e5%90%af%e5%81%9c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hadoop 一键启停
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-24.png&#34;
	width=&#34;1483&#34;
	height=&#34;658&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-24_hu_f5e5925f43b6c9ad.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-24_hu_e523a5cfc8834ca0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;225&#34;
		data-flex-basis=&#34;540px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
