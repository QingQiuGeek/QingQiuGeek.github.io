[{"content":" 个人理解：每个公司每个团队所掌握的擅长的技术栈不同，所做的业务不同，因此要形成一套成体系规范化的开发流程，从构建工具、开发语言、框架选型、版本管理，到部署迭代，目的在于规范开发流程，提高开发效率，减少项目出错，确保项目稳定运行及后续迭代。 参考：\nhttps://segmentfault.com/a/1190000046908475\n前端工程化与工具链全解析：模块化、代码质量与框架生态-CSDN 博客\n2025 年细讲前端工程化 万字总结！！-CSDN 博客\n前端工程化 \u0026ndash; 工程化体系详解 | EnlightenCode\n工程化 构建工具 WebPack：将应用中的各种资源（JS、CSS、图片、字体等）都看作模块，然后将它们打包成一个或多个最终文件。同时提供开发模式下的热更新（HMR），加速开发过程，但是 Webpack 的配置文件通常比较复杂，学习成本高。 Vite：现代化的构建工具，设计理念是快速开发和高效的构建，它的核心优势是采用了原生 ES 模块（ESM）作为开发模式，并且利用浏览器对 ESM 的支持，来避免传统打包工具中常见的冗长的打包时间。同时支持局部热更新，不需要全局重载，更新速度比 Webpack 更加快速和精确。 Rspack\n基于 Rust 的打包工具，Rspack 包管理工具 npm（node package manager），Node.js 的默认包管理器，package-lock.json 文件确保了不同环境中依赖的一致性。 Yarn，Facebook 提供的一个 JavaScript 包管理工具，Yarn 通过缓存和并行化安装等方式，Yarn 的安装速度通常比 npm 更快。 pnpm，更高效的 JavaScript 包管理工具，旨在解决 npm 和 Yarn 在处理大量依赖时的性能瓶颈问题。通过硬链接和全局缓存，pnpm 极大地减少了磁盘占用，尤其是在多个项目共享相同依赖的情况下。安装依赖时，不会为每个项目创建独立的依赖副本，而是通过共享缓存来节省空间。 cnpm：淘宝镜像，解决国内访问的问题 模块化 代码规范 ESLint：静态代码分析，强制统一编码风格。 Prettier：自动格式化代码，解决团队风格冲突。 版本管理 集成 Git Hooks 工具如 Husky 和 Lint-Staged\nCI/CD github Action ","date":"2025-07-28T15:15:47Z","permalink":"/zh-cn/post/2025/07/%E5%89%8D%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%8C%96%E4%B8%8E%E5%B7%A5%E5%85%B7%E9%93%BE/","title":"前端工程化与工具链"},{"content":" 提示工程指南 | Prompt Engineering Guide\n提问的智慧\n为什么要优化Prompt 通过设计有效的提示词 来指导模型执行期望任务。\n用人话就是给模型一个任务，正确的告诉它怎么做、做什么。\n几个名词 Temperature temperature 决定了下一个词的随机程度，的参数值越小，模型就会返回越确定的一个结果。参数值越大，模型会返回更随机的结果，也就是说这可能会带来更多样化或创造性的产出。\nTop_p 与 temperature 一起称为核采样，用来控制模型返回结果的确定性。如果你需要准确和事实的答案，就把参数值调低，反之调高。\n**Temperature：**控制生成文本的随机性，决定模型选择下一个词时的随机程度。\nTop_p： 控制生成文本的多样性，决定模型只考虑累积概率总和不超过 P 的词。\n举例：假设模型预测下一个词的概率分布为：\n\u0026ldquo;apple\u0026rdquo;: 0.8\n\u0026ldquo;banana\u0026rdquo;: 0.1\n\u0026ldquo;cherry\u0026rdquo;: 0.05\n\u0026ldquo;date\u0026rdquo;: 0.03\n\u0026ldquo;elderberry\u0026rdquo;: 0.02\n如果top_p=0.9，那么会考虑选择\u0026quot;apple\u0026quot; 和 \u0026ldquo;banana\u0026rdquo;，（累积概率为 0.9），忽略 \u0026ldquo;cherry\u0026rdquo;、\u0026ldquo;date\u0026rdquo; 和 \u0026ldquo;elderberry\u0026rdquo;，所以top_p是增加生成文本的多样性，temperature是控制文本生成的随机性。\nStop Sequences 终止序列，当模型生成的文本包含终止序列中的字符串时会停止生成。\nFrequency Penalty Frequency penalty 是对下一个生成的 token 进行惩罚，某个token出现的次数越多，Frequency penalty 越高，那么再次出现的可能性就越小。\nPresence Penalty presence penalty 也是对重复的 token 施加惩罚，但与 frequency penalty 不同的是，对于所有重复 token 的惩罚都是相同的。出现2次的 token 和出现 10 次的 token 会受到相同的惩罚。\n提示词要素 明确的指令（任务）、上下文、期望的输出格式或类型，比如让模型写一个函数方法，我们需要提供：方法要实现的功能（任务）、环境变量（上下文）、出入参参数及类型（出入参格式）\n提示词技巧 1.明确的指令，告诉模型要做什么\n2.避免告诉模型不要做什么，而是告诉模型要做什么\n提示技术 零样本提示 所谓零样本就是不提供范例，直接给任务，如：\n少样本提示 提供范例给模型，如：\n少样本提示的限制：即使增加样本提示数量也不足以获得较为复杂的推理问题的可靠响应。\nCOT(Chain of Thought) 思维链相较于上面的少样本提示，仅添加了推理过程，只需1个样本就获得了正确的推理结果。\n零样本COT提示 不提供样本，让模型逐步思考，最终得出正确结果：\nReAct（Reasoning and Action） 推理、行动，像人一样进行推理，拆分复杂任务，调用工具，一步步执行。\n--- ","date":"2025-07-24T22:25:14Z","permalink":"/zh-cn/post/2025/07/%E5%A4%A7%E6%A8%A1%E5%9E%8Bprompt%E4%BC%98%E5%8C%96%E5%B7%A5%E7%A8%8B/","title":"大模型Prompt优化工程"},{"content":"CAS的关键实现 在 Java 中，实现 CAS操作的一个关键类是Unsafe，位于sun.misc包下：\n1 2 3 4 5 6 A collection of methods for performing low-level, unsafe operations. Although the class and all methods are public, use of this class is limited because only trusted code can obtain instances of it. Note: It is the resposibility of the caller to make sure arguments are checked before methods of this class are called. While some rudimentary checks are performed on the input, the checks are best effort and when performance is an overriding priority, as when methods of this class are optimized by the runtime compiler, some or all checks (if any) may be elided. Hence, the caller must not rely on the checks and corresponding exceptions! 该类并不推荐开发者在应用程序中使用，而是用于 JVM 内部或一些需要极高性能和底层访问的库中。\nsun.misc.Unsafe类提供了compareAndSwapObject、compareAndSwapInt、compareAndSwapLong方法来实现的对Object、int、long类型的 CAS 操作，如：\n1 2 3 4 5 6 7 8 9 private static final jdk.internal.misc.Unsafe theInternalUnsafe = jdk.internal.misc.Unsafe.getUnsafe(); @ForceInline public final boolean compareAndSwapInt(Object o, long offset, int expected, int x) { return theInternalUnsafe.compareAndSetInt(o, offset, expected, x); } 1 其中theInternalUnsafe是jdk.internal.misc包下Unsafe的实例，它的compareAndSetInt方法则是本地方法，如下： 1 2 3 4 @HotSpotIntrinsicCandidate public final native boolean compareAndSetInt(Object o, long offset, int expected, int x); Unsafe的具体使用 在juc包的atomic包提供了一些原子操作类，这些atomic类依赖于CAS乐观锁保证原子性，以AtomicInteger核心源码为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // 获取 Unsafe 实例 private static final jdk.internal.misc.Unsafe U = jdk.internal.misc.Unsafe.getUnsafe(); private static final long valueOffset; static { try { // 获取\u0026#34;value\u0026#34;字段在AtomicInteger类中的内存偏移量 valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(\u0026#34;value\u0026#34;)); } catch (Exception ex) { throw new Error(ex); } } // 确保\u0026#34;value\u0026#34;字段的可见性 private volatile int value; // 如果当前值等于预期值，则原子地将值设置为newValue // 使用 Unsafe#compareAndSwapInt 方法进行CAS操作 public final boolean compareAndSet(int expect, int update) { return U.compareAndSwapInt(this, valueOffset, expect, update); } // 原子地将当前值加 delta 并返回旧值 public final int getAndAdd(int delta) { return U.getAndAddInt(this, valueOffset, delta); } // 原子地将当前值加 1 并返回加之前的值（旧值） // 使用 Unsafe#getAndAddInt 方法进行CAS操作。 public final int getAndIncrement() { return U.getAndAddInt(this, valueOffset, 1); } // 原子地将当前值减 1 并返回减之前的值（旧值） public final int getAndDecrement() { return U.getAndAddInt(this, valueOffset, -1); } sun.internal.misc.Unsafe类有如下方法：\n1 2 3 4 5 6 7 8 9 10 // 原子地获取并增加整数值 public final int getAndAddInt(Object o, long offset, int delta) { int v; do { // 以 volatile 方式获取对象 o 在内存偏移量 offset 处的整数值 v = getIntVolatile(o, offset); } while (!compareAndSwapInt(o, offset, v, v + delta)); // 返回旧值 return v; } CAS执行流程 线程从主存读取要修改的值存到本地线程缓存中 执行 CAS 操作，将本地线程缓存中的值与主内存中的值进行比较； 如果本地线程缓存中的值与主内存中的值相等，则将需要修改的值在本地线程缓存中修改； 如果修改成功，将修改后的值写入主内存，并返回修改结果；如果失败，则返回当前主内存中的值； 在多线程并发执行的情况下，如果多个线程同时执行 CAS 操作，只有一个线程的 CAS 操作会成功，其他线程的 CAS 操作都会失败，这也是 CAS 的原子性保证。 CAS问题 1.ABA问题\n线程读取某变量的时候值为A，再次读取的时候值仍为A，不能说明该变量是否被其他线程改过，解决思路是在变量前面追加上版本号或者时间戳 。JDK 1.5 以后的 AtomicStampedReference 类就是用来解决 ABA 问题的，其中的 compareAndSet() 方法就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。\n2.循环时间长开销大\n3.只能保证一个共享变量的原子操作 ","date":"2025-07-19T19:22:50Z","permalink":"/zh-cn/post/2025/07/java%E7%9A%84cas%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E7%9A%84aba%E9%97%AE%E9%A2%98/","title":"Java的CAS是如何实现的、ABA问题"},{"content":"传播行为 事务传播行为是为了解决业务层方法之间互相调用的事务问题。\n事务方法A被事务方法B调用，就要指定事务如何传播，是两者共用同一事务还是另起一个新事务。\n图解spring中七种事务传播行为 终于有人讲明白了_spring七种事务传播行为-CSDN博客\n1. REQUIRED\n@Transactional注解默认使用就是这个事务传播行为。\n如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。\n2. REQUIRES_NEW\n另起炉灶。 先创建一个新事务 ，如果当前存在事务则把当前事务挂起 。也就是说不管外部方法是否开启事务，Propagation.REQUIRES_NEW修饰的内部方法都会新开启自己的事务，且开启的事务相互独立，互不干扰。\n3. SUPPORTS\n有事务就蹭，没事务就裸奔。 如果当前存在事务，则加入该事务；如果当前没有事务，以非事务的方式运行。\n4. NOT_SUPPORTED\n不管有没有事务，必须裸奔。 如果当前存在事务，则把当前事务挂起，以非事务执行。如果当前没有事务，以非事务方式运行。\n5. MANDATORY（强制性）\n有事务就蹭，没事务就抛异常。 如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。（mandatory：强制性）\n6. NEVER\n如果当前存在事务，则抛出异常。如果当前没有事务，以非事务方式运行，\n7.NEST（嵌套）\n如果当前存在事务，则创建一个新事务作为当前事务的嵌套事务来运行；如果当前没有事务，则创建新事务。\n隔离级别 spring的事务隔离级别和mysql几乎一模一样。\nDEFAULT\n使用后端数据库默认隔离级别，Mysql默认是可重复读\nREAD_UNCOMMITED\n最低的隔离级别，允许读取尚未提交的数据变更，有脏读、幻读、不可重复读的问题。\nREAD_COMMITED\n允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生\nREPEATABLE_READ\n对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。\nSERIALIZABLE\n最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就不产生干扰，阻止幻读。\n--- ","date":"2025-07-19T19:20:50Z","permalink":"/zh-cn/post/2025/07/spring7%E4%B8%AA%E4%BA%8B%E5%8A%A1%E4%BC%A0%E6%92%AD%E8%A1%8C%E4%B8%BA%E5%92%8C5%E4%B8%AA%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/","title":"Spring7个事务传播行为和5个隔离级别"},{"content":" 两种方案的token、用户登录信息都存储在redis中！！\n方案一 该方案是前端把token和token有效期一起加密存储到浏览器的localStorage中，每次请求时调用前端的getTokenIsExpiry()获取token并检查token是否过期，过期则remove并跳转登录页，这样前端有个问题就是前端也要知道token的有效期，需要和后端的token有效期保持一致，而后端则提供两个拦截器，分别用来刷新token、判断是否是登录用户，这个参考了黑马外卖。\n后端 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 /** * @Author:懒大王Smile * @Date: 2024/9/14 * @Time: 18:07 * @Description: 登录拦截器 */ @Component public class LoginInterceptor implements HandlerInterceptor { /* * authorization为空和redis的token失效的都放行到登录拦截器 * */ @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler){ String requestURI = request.getRequestURI(); if (requestURI.contains(\u0026#34;/api/favicon.ico\u0026#34;) || requestURI.contains(\u0026#34;/api-docs\u0026#34;) || requestURI.contains(\u0026#34;/error\u0026#34;)) { return true; } if (UserContext.getUser() == null) { response.setStatus(401); //response.setHeader(\u0026#34;登录拦截器：\u0026#34;,\u0026#34;该请求被拦截，请登录！\u0026#34;); throw new BusinessException(ErrorCode.NOT_LOGIN_ERROR, ErrorInfo.NOT_LOGIN_ERROR); } return true; } /** * 目标 Controller 的方法执行完并且返回结果之后,视图解析器渲染视图之前执行。 * @param request * @param response * @param handler * @param ex * @throws Exception */ @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { HandlerInterceptor.super.afterCompletion(request, response, handler, ex); } } /** * @Author:懒大王Smile * @Date: 2024/9/14 * @Time: 18:24 * @Description: 该拦截器只负责刷新token（redis共享session），不负责拦截 */ @Component public class RefreshTokenInterceptor implements HandlerInterceptor { @Resource StringRedisTemplate stringRedisTemplate; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) { //前端请求时带上authorization String token = request.getHeader(\u0026#34;authorization\u0026#34;); if (StringUtils.isBlank(token)) { //未登录，直接放行，由登录拦截器拦截 return true; } //从redis获取token String tokenKey = Common.LOGIN_TOKEN_KEY + token; Map\u0026lt;Object, Object\u0026gt; map = stringRedisTemplate.opsForHash().entries(tokenKey); if (map.isEmpty()) { //redis中存储的登录态已失效，放行，让登录拦截器拦截 return true; } LoginUserVO loginUserVO = BeanUtil.fillBeanWithMap(map, new LoginUserVO(), false); //将用户信息保存到ThreadLocal中 UserContext.saveUser(loginUserVO); //刷新redis的token有效期 stringRedisTemplate.expire(tokenKey, Common.LOGIN_TOKEN_TTL, TimeUnit.MINUTES); return true; } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) { //// 移除用户,防止内存泄漏!!! UserContext.removeUser(); } } /** * @Author:懒大王Smile * @Date: 2024/9/18 * @Time: 16:48 * @Description: 拦截器配置类，注册拦截器 */ @Component @Slf4j public class InterceptorsConfig extends WebMvcConfigurationSupport { @Resource LoginInterceptor loginInterceptor; @Resource RefreshTokenInterceptor refreshTokenInterceptor; @Override protected void addInterceptors(InterceptorRegistry registry) { log.info(\u0026#34;注册自定义拦截器\u0026#34;); registry.addInterceptor(refreshTokenInterceptor) .addPathPatterns(\u0026#34;/**\u0026#34;) .excludePathPatterns( \u0026#34;/doc.html/**\u0026#34;, \u0026#34;/swagger-resources/**\u0026#34;, \u0026#34;/webjars/**\u0026#34;, \u0026#34;/ai/**\u0026#34; ).order(0); // order越小，优先级越高 registry.addInterceptor(loginInterceptor) .addPathPatterns(\u0026#34;/**\u0026#34;) .excludePathPatterns( \u0026#34;/webjars/**\u0026#34;, \u0026#34;/doc.html/**\u0026#34;, \u0026#34;/swagger-resources/**\u0026#34;, \u0026#34;/v3/api-docs/\u0026#34;, \u0026#34;/api/favicon.ico\u0026#34; ); } //没有该配置将无法使用swagger API测试 @Override protected void addResourceHandlers(ResourceHandlerRegistry registry) { registry.addResourceHandler(\u0026#34;/**\u0026#34;) .addResourceLocations(\u0026#34;classpath:/static/\u0026#34;) .addResourceLocations(\u0026#34;classpath:/META-INF/resources/\u0026#34;); } } 前端 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 requestConfig.ts //前端配置请求拦截器，实现在每个请求发出前为请求头添加token requestInterceptors: [ (config: any) =\u0026gt; { const token = getTokenIsExpiry(); if (token) { config.headers[\u0026#39;authorization\u0026#39;] = token; } return config; }, ] utils.ts // 存储token和登录态 export const setTokenWithExpiry = (loginUser: API.LoginUserVO) =\u0026gt; { const encryptLoginUser = encrypt(loginUser); localStorage.setItem(\u0026#39;loginUser\u0026#39;, encryptLoginUser); // 存储 loginUser 和过期时间 const expiryTime = new Date().getTime() + TokenTTL * 60 * 1000; // 计算过期时间,单位 min const item = { token: loginUser.token, expiry: expiryTime, }; const encryptToken = encrypt(item); localStorage.setItem(\u0026#39;authorization\u0026#39;, encryptToken); }; // 获取 token 并检查是否过期，如果过期就删除 export const getTokenIsExpiry = () =\u0026gt; { const encryptToken = localStorage.getItem(\u0026#39;authorization\u0026#39;); if (!encryptToken) { return null; // 如果没有 token，返回 null } const tokenObj = decrypt(encryptToken); const currentTime = new Date().getTime(); if (currentTime \u0026gt; tokenObj.expiry) { localStorage.removeItem(\u0026#39;authorization\u0026#39;); // 如果过期了，删除 loginUser localStorage.removeItem(\u0026#39;loginUser\u0026#39;); // 如果过期了，删除 token setTimeout(() =\u0026gt; { window.location.reload(); }, 400); history.replace(\u0026#39;/home\u0026#39;); message.info(\u0026#39;登陆凭证过期，请重新登录\u0026#39;); } return tokenObj.token; // 如果没有过期，返回 token }; 方案二 后端使用sa-token框架Sa-Token实现用户登录注销、鉴权等操作，可以方便的集成redis\nSa-token框架 如图是3343@qq.com账号连续登录三次，redis中生成的3个token及一个account-session，此时仅作登陆操作\n\u0026ldquo;authorization:login:session:3343@qq.com\u0026quot;内容如下：\n可以看到\u0026quot;terminalList\u0026quot;中记录了3次登录产生的详细的token信息\n{ \u0026quot;@class\u0026quot;: \u0026quot;cn.dev33.satoken.session.SaSession\u0026quot;, \u0026quot;id\u0026quot;: \u0026quot;authorization:login:session:3343@qq.com\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;Account-Session\u0026quot;, \u0026quot;loginType\u0026quot;: \u0026quot;login\u0026quot;, \u0026quot;loginId\u0026quot;: \u0026quot;3343@qq.com\u0026quot;, \u0026quot;token\u0026quot;: null, \u0026quot;historyTerminalCount\u0026quot;: 3, \u0026quot;createTime\u0026quot;: 1751087763506, \u0026quot;dataMap\u0026quot;: { \u0026quot;@class\u0026quot;: \u0026quot;java.util.concurrent.ConcurrentHashMap\u0026quot; }, \u0026quot;terminalList\u0026quot;: [ \u0026quot;java.util.Vector\u0026quot;, [ { \u0026quot;@class\u0026quot;: \u0026quot;cn.dev33.satoken.session.SaTerminalInfo\u0026quot;, \u0026quot;index\u0026quot;: 1, \u0026quot;tokenValue\u0026quot;: \u0026quot;9d3e2b34-a5ad-4059-bdf4-4add0c370ca0\u0026quot;, \u0026quot;deviceType\u0026quot;: \u0026quot;DEF\u0026quot;, \u0026quot;deviceId\u0026quot;: null, \u0026quot;extraData\u0026quot;: null, \u0026quot;createTime\u0026quot;: 1751087763575 }, { \u0026quot;@class\u0026quot;: \u0026quot;cn.dev33.satoken.session.SaTerminalInfo\u0026quot;, \u0026quot;index\u0026quot;: 2, \u0026quot;tokenValue\u0026quot;: \u0026quot;4a740c99-071c-4512-af02-a9519e058b4d\u0026quot;, \u0026quot;deviceType\u0026quot;: \u0026quot;DEF\u0026quot;, \u0026quot;deviceId\u0026quot;: null, \u0026quot;extraData\u0026quot;: null, \u0026quot;createTime\u0026quot;: 1751087826615 }, { \u0026quot;@class\u0026quot;: \u0026quot;cn.dev33.satoken.session.SaTerminalInfo\u0026quot;, \u0026quot;index\u0026quot;: 3, \u0026quot;tokenValue\u0026quot;: \u0026quot;36d7a224-1f8e-4605-84d7-cb5ecf594018\u0026quot;, \u0026quot;deviceType\u0026quot;: \u0026quot;DEF\u0026quot;, \u0026quot;deviceId\u0026quot;: null, \u0026quot;extraData\u0026quot;: null, \u0026quot;createTime\u0026quot;: 1751087850414 } ] ] } \u0026ldquo;authorization:login:token:4a740c99-071c-4512-af02-a9519e058b4d\u0026quot;内容如下：\n然后调用StpUtil.getTokenSession()，此时就会生成一个token-session\n{ \u0026quot;@class\u0026quot;: \u0026quot;cn.dev33.satoken.session.SaSession\u0026quot;, \u0026quot;id\u0026quot;: \u0026quot;authorization:login:token-session:36d7a224-1f8e-4605-84d7-cb5ecf594018\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;Token-Session\u0026quot;, \u0026quot;loginType\u0026quot;: \u0026quot;login\u0026quot;, \u0026quot;loginId\u0026quot;: null, \u0026quot;token\u0026quot;: \u0026quot;36d7a224-1f8e-4605-84d7-cb5ecf594018\u0026quot;, \u0026quot;historyTerminalCount\u0026quot;: 0, \u0026quot;createTime\u0026quot;: 1751088437477, \u0026quot;dataMap\u0026quot;: { \u0026quot;@class\u0026quot;: \u0026quot;java.util.concurrent.ConcurrentHashMap\u0026quot; }, \u0026quot;terminalList\u0026quot;: [ \u0026quot;java.util.Vector\u0026quot;, [ ] ] } 发现token-session和account-session结构相同，因为它们都出自同一个SaSession类\n可知在Sa-Token框架中，session分别三种，我这里只关注account和token的session，前面提到在使用同一个账号连续登陆3次时只生成了account-session，其中记录了三次的登录的token，那么这就可以实现了同一账号多端登录 ，每个端的token隔离，比如同时在PC和IOS端登录，如果token不隔离（token共享），当在其中一端注销登录时，另一端也会被迫注销登录，显然不合常理，而如果实现的token隔离，每个端都有不同的token，那么这就不会出现另一端被迫注销的情况。所以说account-session记录了同一账号多端登录的token信息，而token-session则记录了该账号在某一端的token信息，更为详细。\nsa-token设置有效期 在yml配置timeout，单位是s，同一账号先后多端登录，token过期后先删除token-session，待该账号下所有token全部过期后才删除account-session。\nsa-token自动续期 SaTokenConfig.java，在yml配置autoRenew即可开启自动续期，每次要续期时直接或间接调用getLoginId()即可。\n后端 仅需一个拦截器即可，不再需要方案一的两个拦截器。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 @Slf4j @Component public class SaTokenInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) { String requestURI = request.getRequestURI(); if (requestURI.contains(\u0026#34;/api/webjars\u0026#34;) || requestURI.contains(\u0026#34;/api/favicon.ico\u0026#34;) || requestURI.contains(\u0026#34;/api-docs\u0026#34;) || requestURI.contains(\u0026#34;/error\u0026#34;)) { return true; } //刷新token有效期（这一步已经判断了名为authorization的token是否是真实有效的，如果是伪造或过期的token则不会刷新token，报错） Long userId; try { userId = Long.valueOf(StpUtil.getLoginId().toString()); } catch (Exception e) { if(requestURI.contains(\u0026#34;/ai\u0026#34;)){ return true; } throw new RuntimeException(e); } //虽然每次可以从stpUtil.getLoginId()获取userId，但是这样要读redis，会对其造成压力，因此这里取出来放到userContext，用的时候从userContext取 UserContext.saveUser(userId); //角色校验 if(requestURI.contains(\u0026#34;/admin\u0026#34;)){ StpUtil.checkRole(UserRoleEnum.ADMIN.getRole()); } return true; } // 移除用户,防止内存泄漏!!! @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) { UserContext.removeUser(); } } 注册该拦截器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 @Slf4j @Configuration public class SaTokenConfigure implements WebMvcConfigurer { @Resource SaTokenInterceptor saTokenInterceptor; /** * 注册 Sa-Token 拦截器打开注解鉴权功能 */ @Override public void addInterceptors(InterceptorRegistry registry) { // 注册 Sa-Token 拦截器打开注解鉴权功能 log.info(\u0026#34;注册自定义拦截器\u0026#34;); registry.addInterceptor(saTokenInterceptor) .addPathPatterns(\u0026#34;/**\u0026#34;) .excludePathPatterns( \u0026#34;/user/login\u0026#34;, \u0026#34;/user/register\u0026#34;, \u0026#34;/user/getUserInfo/{uid}\u0026#34;, \u0026#34;/user/sendRegisterCode\u0026#34;, \u0026#34;/user/find/{userName}\u0026#34;, \u0026#34;/user/userInfoData\u0026#34;, \u0026#34;/passage/otherPassages/{uid}\u0026#34;, \u0026#34;/passage/topCollects\u0026#34;, \u0026#34;/passage/content/{uid}/{pid}\u0026#34;, \u0026#34;/passage/homePassageList\u0026#34;, \u0026#34;/passage/search\u0026#34;, \u0026#34;/passage/passageInfo/{pid}\u0026#34;, \u0026#34;/passage/topPassages\u0026#34;, \u0026#34;/comment/getCommentByCursor\u0026#34;, \u0026#34;/category/getCategories\u0026#34;, \u0026#34;/tag/getRandomTags\u0026#34;, \u0026#34;/doc.html/**\u0026#34; ); } /** * 注册 [Sa-Token 全局过滤器] */ @Bean public SaServletFilter getSaServletFilter() { return new SaServletFilter() // 指定 [拦截路由] 与 [放行路由] .addInclude(\u0026#34;/**\u0026#34;) // 认证函数: 每次请求执行 .setAuth(obj -\u0026gt; { SaManager.getLog().info(\u0026#34;----- 请求path={},authorization={}\u0026#34;, SaHolder.getRequest().getRequestPath(), StpUtil.getTokenValue()); // 权限校验 -- 不同模块认证不同权限 //\t这里你可以写和拦截器鉴权同样的代码，不同点在于： // 校验失败后不会进入全局异常组件，而是进入下面的 .setError 函数 // SaRouter.match(\u0026#34;/admin/**\u0026#34;, r -\u0026gt; StpUtil.checkPermission(\u0026#34;admin\u0026#34;)); }) // 异常处理函数：每次认证函数发生异常时执行此函数 .setError(e -\u0026gt; { log.warn(\u0026#34;---------- sa-token全局异常 \u0026#34;); return SaResult.error(e.getMessage()); }) // 前置函数：在每次认证函数之前执行（BeforeAuth 不受 includeList 与 excludeList 的限制，所有请求都会进入） .setBeforeAuth(r -\u0026gt; { // ---------- 设置一些安全响应头 ---------- SaHolder.getResponse() // 服务器名称 .setServer(\u0026#34;sa-server\u0026#34;) // 是否可以在iframe显示视图： DENY=不可以 | SAMEORIGIN=同域下可以 | ALLOW-FROM uri=指定域名下可以 .setHeader(\u0026#34;X-Frame-Options\u0026#34;, \u0026#34;SAMEORIGIN\u0026#34;) // 是否启用浏览器默认XSS防护： 0=禁用 | 1=启用 | 1; mode=block 启用, 并在检查到XSS攻击时，停止渲染页面 .setHeader(\u0026#34;X-XSS-Protection\u0026#34;, \u0026#34;1; mode=block\u0026#34;) // 禁用浏览器内容嗅探 .setHeader(\u0026#34;X-Content-Type-Options\u0026#34;, \u0026#34;nosniff\u0026#34;) ; }) ; } /** * 解决cors跨域 * @return */ @Bean public CorsFilter corsFilter() { //1. 添加 CORS配置信息 CorsConfiguration config = new CorsConfiguration(); //放行哪些原始域 //带上这个会报错 // config.addAllowedOrigin(\u0026#34;localhost:8000\u0026#34;); // When allowCredentials is true, allowedOrigins cannot contain the special value \u0026#34;*\u0026#34; since that cannot be set on the \u0026#34;Access-Control-Allow-Origin\u0026#34; response header. To allow credentials to a set of origins, list them explicitly or consider using \u0026#34;allowedOriginPatterns\u0026#34; instead. config.addAllowedOriginPattern(\u0026#34;*\u0026#34;); //是否发送 Cookie config.setAllowCredentials(true); //放行哪些请求方式 config.addAllowedMethod(\u0026#34;*\u0026#34;); //放行哪些原始请求头部信息 config.addAllowedHeader(\u0026#34;*\u0026#34;); //暴露哪些头部信息 //config.addExposedHeader(\u0026#34;*\u0026#34;); //2. 添加映射路径 UrlBasedCorsConfigurationSource corsConfigurationSource = new UrlBasedCorsConfigurationSource(); corsConfigurationSource.registerCorsConfiguration(\u0026#34;/**\u0026#34;, config); //3. 返回新的CorsFilter return new CorsFilter(corsConfigurationSource); } /** * 解决SaTokenContext 上下文尚未初始化的问题 * 参考: https://gitee.com/dromara/sa-token/issues/IC4XFE * @return */ @Bean public FilterRegistrationBean saTokenContextFilterForJakartaServlet() { FilterRegistrationBean bean = new FilterRegistrationBean\u0026lt;\u0026gt;(new SaTokenContextFilterForJakartaServlet()); // 配置 Filter 拦截的 URL 模式 bean.addUrlPatterns(\u0026#34;/*\u0026#34;); // 设置 Filter 的执行顺序,数值越小越先执行 bean.setOrder(Ordered.HIGHEST_PRECEDENCE); bean.setAsyncSupported(true); bean.setDispatcherTypes(EnumSet.of(DispatcherType.ASYNC, DispatcherType.REQUEST)); return bean; } } 前端 ","date":"2025-06-29T17:48:00Z","permalink":"/zh-cn/post/2025/06/%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E7%94%A8%E6%88%B7%E7%99%BB%E5%BD%95%E7%8E%A9%E6%B3%95sa-token%E6%A1%86%E6%9E%B6%E4%BD%BF%E7%94%A8/","title":"前后端分离场景下的用户登录玩法\u0026Sa-token框架使用"},{"content":"分布式事务\n1.4 w字，25 张图让你彻底掌握分布式事务原理\n单数据源事务\n单数据源事务也可以叫做单机事务或本地事务。可利用数据库提供的事务机制ACID即可保证事务一致性。 在分布式场景下，一个系统有多个子系统构成， 每个子系统有自己的数据源，此时仅靠本地事务机制就无法保证全局的事务一致性，也就无法保证数据一致性。 分布式事务模型\n事务参与者：例如每个数据库就是一个事务参与者 事务协调者：访问多个数据源的服务程序，例如 shopping-service 就是事务协调者 资源管理器（Resource Manager, RM）：通常与事务参与者同义 事务管理器（Transaction Manager, TM）：通常与事务协调者同义 在分布式事务模型中，一个 TM 管理多个 RM，即一个服务程序访问多个数据源；TM 是一个全局事务管理器，协调多方本地事务的进度，使其共同提交或回滚，最终达成一种全局的 ACID 特性。 二将军问题\nB军队被两支A军队围在山谷，A1军队将军要通知另一支A2军队，约定时间攻击B军队，因此A1军队要派信使去传递消息，但是信使要经过山谷，可能被B军队俘虏。那么如果信使没有返回A1，如下两种情况：1.信使还没到A2，被俘虏，此时A2不知道进攻时间，A1也不知道A2有没有收到通知。2.信使已告知A2，但是返回途中被俘虏，A1还是不知道A2有没有收到通知。 类似的问题在计算机网络中普遍存在，例如发送者给接受者发送一个 HTTP 请求，或者 MySQL 客户端向 MySQL 服务器发送一条插入语句，然后超时了没有得到响应。请问服务器是写入成功了还是失败了？消息发送者不知道，因此往往要重复发送消息直到收到响应。例如电商系统中订单模块调用支付模块扣款的时候，如果网络故障导致二将军问题出现，扣款请求重复发送，产生的重复扣款结果显然是不能被接受的。因此要保证一次事务中的扣款请求无论被发送多少次，接收方有且只执行一次扣款动作，这种保证机制叫做接收方的幂等性。 分布式事务解决方案 2PC 2pc是解决分布式事务的最简单的模型，分为2个阶段：\n准备阶段：事务协调者向各个事务参与者发询问请求，通知即将执行全局事务，各自做好资源准备，即各自执行本地事务到待提交阶段。各个事务参与者准备好后响应ACK或no或协调者等待超时。 提交/回滚阶段：如果所有事务参与者响应ACK，则由事务协调者通知进行全局事务最终的提交阶段。如果有一个参与者no或协调者等待超时，则要回滚阶段。 要实现 2PC，所有的参与者都要实现三个接口：\nPrepare()：TM 调用该接口询问各个本地事务是否就绪\nCommit()：TM 调用该接口要求各个本地事务提交\nRollback()：TM 调用该接口要求各个本地事务回滚\n可以将这三个接口简单地（但不严谨地）理解成 XA 协议。\nXA 协议是 X/Open 提出的分布式事务处理标准。MySQL、Oracle、DB2 这些主流数据库都实现了 XA 协议，因此都能被用于实现 2PC 事务模型。 2PC存在问题\n性能差：准备阶段要等所有事务参与者响应才能进入提交回滚阶段，这期间参与者的相关资源会被锁住，影响各个参与者的本地事务并发度； 如果准备阶段完成，协调者挂了，那么所有参与者都收不到提交或回滚指令，导致所有参与者会一直阻塞直到协调者恢复，参与者没有超时机制，导致长时间资源锁定。 3PC 3PC 的出现是为了解决 2PC 的一些问题，相比于 2PC 它在参与者中也引入了超时机制 ，并且新增了一个阶段使得参与者可以利用这一个阶段统一各自的状态。3pc分为三个阶段：\n准备阶段：协调者只是询问参与者的自身状况。 预提交阶段：和2pc的准备阶段一样。 提交阶段：提交阶段和 2PC 的一样。 TCC TCC 就是一种解决多个微服务之间的分布式事务问题的方案。TCC 是 Try、Confirm、Cancel 三个词的缩写，其本质是一个应用层面上的 2PC，分为两个阶段：\n准备阶段：协调者调用所有的每个微服务提供的 try 接口，将整个全局事务涉及到的资源锁定住，若锁定成功 try 接口向协调者返回 yes。 提交阶段：若所有的服务的 try 接口在阶段一都返回 yes，则进入提交阶段，协调者调用所有服务的 confirm 接口，各个服务进行事务提交。如果有任何一个服务的 try 接口在阶段一返回 no 或者超时，则协调者调用所有服务的 cancel 接口。 TCC有两个问题：\n既然 TCC 是一种服务层面上的 2PC，它是如何解决 2PC 无法应对宕机 问题的缺陷的呢？答案是不断重试。由于 try 操作锁住了全局事务涉及的所有资源，保证了业务操作的所有前置条件得到满足，因此无论是 confirm 阶段失败还是 cancel 阶段失败都能通过不断重试直至 confirm 或 cancel 成功（所谓成功就是所有的服务都对 confirm 或者 cancel 返回了 ACK）。 在不断重试 confirm 和 cancel 的过程中（二将军问题）有可能重复进行了 confirm 或 cancel，因此还要再保证 confirm 和 cancel 操作具有幂等性，也就是整个全局事务中，每个参与者只进行一次 confirm 或者 cancel。实现 confirm 和 cancel 操作的幂等性，有很多解决方案，例如每个参与者可以维护一个去重表（可以利用数据库表实现也可以使用内存型 KV 组件实现），记录每个全局事务（以全局事务标记 XID 区分）是否进行过 confirm 或 cancel 操作，若已经进行过，则不再重复执行。 事务状态表 类似 TCC 的事务解决方案，借助事务状态表来实现。假设要在一个分布式事务中实现调用 repo-service 扣减库存、调用 order-service 生成订单两个过程。在这种方案中，协调者 shopping-service 维护一张如下的事务状态表，初始状态为 1，每成功调用一个服务则更新一次状态，最后所有的服务调用成功，状态更新到 3\n基于消息中间件的解决方案 无论是 2PC \u0026amp; 3PC 还是 TCC、事务状态表，基本都遵守 XA 协议的思想，即这些方案本质上都是事务协调者协调各个事务参与者的本地事务的进度，使所有本地事务共同提交或回滚，最终达成一种全局的 ACID 特性。在协调的过程中，协调者需要收集各个本地事务的当前状态，并根据这些状态发出下一阶段的操作指令。\n但是这些全局事务方案由于操作繁琐、时间跨度大，或者在全局事务期间会排他地锁住相关资源，使得整个分布式系统的全局事务的并发度不会太高。这很难满足电商等高并发场景对事务吞吐量的要求。\n消息队列 RocketMQ 就支持消息事务，RocketMQ 的发送方会提供一个反查事务状态接口，如果一段时间内半消息没有收到任何操作请求，那么 Broker 会通过反查接口得知发送方事务是否执行成功，然后执行 Commit 或者 RollBack 命令。\nSeata --- ","date":"2025-03-14T12:00:00Z","permalink":"/zh-cn/post/2025/03/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/","title":"分布式事务"},{"content":" 往期推荐\nsynchronized如何实现可重入，和Lock区别-CSDN博客\nMysql索引失效的几种场景、回表、索引覆盖、索引下推-CSDN博客\n为何String不可变，String的运算符重载-CSDN博客\nString.intern()-CSDN博客\nStringBuffer和StringBuilder 两者都是继承自AbstractStringBuilder，在AbstractStringBuilder中使用了byte\n\\[ \\]实现（jdk8之前由char\n\\[ \\]实现），这里的byte[]没有使用final修饰，所以是可变的，StringBuffer 对方法加了同步锁或者对调用的方法加了同步锁，线程安全。StringBuilder没加锁，不安全。\nStringBuffer 每次都会对 StringBuffer 对象本身进行操作，而不是生成新的对象并改变对象引用，相比StringBuilder性能不高。\n字符串拼接 Java 语言本身并不支持运算符重载，\u0026quot;+\u0026ldquo;和\u0026rdquo;+=\u0026ldquo;是专门为 String 类重载过的运算符，也是 Java 中仅有的两个重载过的运算符。\n在\u0026quot;abc\u0026rdquo;+\u0026ldquo;abc\u0026quot;时，实际是通过StringBuilder 调用 append() 方法实现的，拼接完成之后调用 toString() 得到一个 String 对象 ，但是在循环内使用\u0026rdquo;+\u0026ldquo;进行字符串的拼接的话，存在比较明显的缺陷：编译器不会创建单个 StringBuilder 以复用，而是每循环一次就创建过一个 StringBuilder 对象 。而如果直接使用 StringBuilder 对象进行字符串拼接的话，就不会存在这个问题了。\n--- ","date":"2025-02-24T17:52:47Z","permalink":"/zh-cn/post/2025/02/stringbuffer%E5%92%8Cstringbuilder/","title":"StringBuffer和StringBuilder"},{"content":" spring bean作用域：\nhttps://blog.csdn.net/qq_73181349/article/details/144837669\n如何记忆Spring Bean的生命周期 - 草捏子\n大致分为四个阶段：实例化 \u0026mdash;\u0026gt; 属性赋值 \u0026mdash;\u0026gt; 初始化 \u0026mdash;\u0026gt; 销毁。\n创建 Bean 的实例 ：Bean 容器首先会找到配置文件中的 Bean 定义，然后使用 Java 反射来创建 Bean 的实例。 Bean 属性赋值/填充 ：为 Bean 设置相关属性和依赖，例如@Autowired 等注解注入的对象、@Value 注入的值、setter方法或构造函数注入依赖和值、@Resource注入的各种资源。 Bean 初始化 ： 检查 Aware 相关接口， 如果实现了某个aware接口就调用相应的方法。 比如实现了 BeanFactoryAware 接口，就调用 setBeanFactory()方法，传入 BeanFactory对象的实例。 BeanPostProcessor 前置处理，执行postProcessBeforeInitialization() 方法 如果 Bean 实现了InitializingBean接口，执行afterPropertiesSet()方法。 如果 Bean 在配置文件中的定义包含 init-method 属性，执行指定的方法。 BeanPostProcessor 后置处理，执行postProcessAfterInitialization() 方法。 销毁 Bean ：销毁并不是立马把 Bean 给销毁掉，而是把 Bean 的销毁方法先记录下来，将来需要销毁 Bean 或者销毁容器的时候，就调用这些方法去释放 Bean 所持有的资源。 如果 Bean 实现了 DisposableBean 接口，执行 destroy() 方法。 如果 Bean 在配置文件中的定义包含 destroy-method 属性，执行指定的 Bean 销毁方法。或者，也可以直接通过@PreDestroy 注解标记 Bean 销毁之前执行的方法。 doCreateBean\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // AbstractAutowireCapableBeanFactory.java protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException { // 1. 实例化 BeanWrapper instanceWrapper = null; if (instanceWrapper == null) { instanceWrapper = createBeanInstance(beanName, mbd, args); } Object exposedObject = bean; try { // 2. 属性赋值 populateBean(beanName, mbd, instanceWrapper); // 3. 初始化 exposedObject = initializeBean(beanName, exposedObject, mbd); } // 4. 销毁-注册回调接口 try { registerDisposableBeanIfNecessary(beanName, bean, mbd); } return exposedObject; } initializeBean\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 // AbstractAutowireCapableBeanFactory.java protected Object initializeBean(final String beanName, final Object bean, @Nullable RootBeanDefinition mbd) { // 3. 检查 Aware 相关接口并设置相关依赖 if (System.getSecurityManager() != null) { AccessController.doPrivileged((PrivilegedAction\u0026lt;Object\u0026gt;) () -\u0026gt; { invokeAwareMethods(beanName, bean); return null; }, getAccessControlContext()); } else { invokeAwareMethods(beanName, bean); } // 4. BeanPostProcessor 前置处理 Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) { wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); } // 5. 若实现 InitializingBean 接口，调用 afterPropertiesSet() 方法 // 6. 若配置自定义的 init-method方法，则执行 try { invokeInitMethods(beanName, wrappedBean, mbd); } catch (Throwable ex) { throw new BeanCreationException( (mbd != null ? mbd.getResourceDescription() : null), beanName, \u0026#34;Invocation of init method failed\u0026#34;, ex); } // 7. BeanPostProceesor 后置处理 if (mbd == null || !mbd.isSynthetic()) { wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); } return wrappedBean; } --- ","date":"2025-02-19T08:11:22Z","permalink":"/zh-cn/post/2025/02/spring%E7%9A%84bean%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%87%E7%A8%8B%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/","title":"Spring的bean初始化过程、生命周期"},{"content":"jdk7的ConcurrentHashMap 在JDK1.7中用的是Segment数组+链表实现的。Segment是一种可重入锁(ReentrantLock)，链表则用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组，一个Segment里包含一个链表。\nJDK1.7 的ConcurrentHashMap给每一段数据配一把锁，当一个线程访问其中该段数据的时候，会锁住该链表头节点，那么其他段的数据也能被其他线程访问，能够实现真正的并发访问。\nSegment 默认个数是 16，一旦初始化就不能改变。每个链表默认长度也是16。\nrehash ConcurrentHashMap 的扩容只会扩容到原来的两倍。老数组里的数据移动到新的数组时，位置要么不变，要么变为 index+ oldSize\njdk8的ConcurrentHashMap JDK1.7的ConcurrentHashMap底层实现是Segment数组+链表的形式，在数据量大时要遍历链表，效率低。而JDK1.8则使用了Node数组+链表/红黑树的形式。\nNode 是类似于一个 HashEntry 的结构。它的冲突再达到一定大小时会转化成红黑树，在冲突小于一定数量时又退回链表。\nConcurrentHashMap的实现(和HashMap结构一样)\nhttps://blog.csdn.net/qq_73181349/article/details/144943507\n具体实现结构如下：\nJDK1.8 ConcurrentHashMap JDK1.8 ConcurrentHashMap主要通过volatile+CAS或者\nsynchronized来实现的线程安全的。put元素时先根据key的hashcode判断对应Node容器是否为空：\n如果为空则使用volatile+CAS来初始化 如果容器不为空，则根据存储的元素计算该位置是否为空。 如果根据存储的元素计算结果为空 ，则利用CAS设置该节点； 如果根据存储的元素计算结果不为空 ，则使用synchronized ，然后，遍历桶中的数据，并替换或新增节点 到桶中，最后再判断是否需要转为红黑树，这样就能保证并发访问时的线程安全了。 也就是访问Node数组时用CAS+volatile，访问HashEntry时用CAS或synchronized。\n为什么ConcurrentHashMap的key和value不能为null ConcurrentHashMap 的 key 和 value 不能为 null 主要是为了避免二义性。null 是一个特殊的值，表示没有对象或没有引用 。如果用 null 作为键，就无法通过containsKey(key)区分这个键是否存在于 ConcurrentHashMap 中，还是根本没有这个键。同样，如果用 null 作为值，就无法区分这个值是否是真正存储在 ConcurrentHashMap 中的，还是因为找不到对应的键而返回的。\n与此形成对比的是，HashMap 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个。如果传入 null 作为参数，就会返回 hash 值为 0 的位置的值 。单线程环境下，不存在一个线程操作该 HashMap 时，其他的线程将该 HashMap 修改的情况，所以可以通过 contains(key)来做判断是否存在这个键值对，也就不存在二义性问题。\nConcurrentHashMap如何保证复合操作的原子性 复合操作是指由多个基本操作(如put、get、remove、containsKey等)组成 的操作，例如先判断某个键是否存在containsKey(key)，然后根据结果进行插入或更新put(key, value)。这种操作在执行过程中可能会被其他线程打断，导致结果不符合预期。\nConcurrentHashMap 提供了一些原子性的复合操作，如 putIfAbsent、compute、computeIfAbsent 、computeIfPresent、merge等。这些方法都可以接受一个函数作为参数，根据给定的 key 和 value 来计算一个新的 value，并且将其更新到 map 中 。\n--- ","date":"2025-02-18T08:54:49Z","permalink":"/zh-cn/post/2025/02/concurrenthashmap/","title":"ConcurrentHashMap"},{"content":"\n官方教程：https://github.com/anuraghazra/github-readme-stats/blob/master/docs/readme_cn.md\n根据官方教程，有两种玩法，第一种最简单的，不用部署项目，步骤如下：\n1.建仓库\n创建一个仓库，仓库名和自己的github账户名相同，仓库里添加一个readme.md文件，这个文件就是用来美化个人主页的，效果如上图所示。\n2.编辑readme.md文件\nreadme.md文件添加如下内容，把username=xxxxx换成github的账户名即可，然后预览md文件，应该就有效果了，具体主题等配置项可以看官方教程。\n1 ​​​​​​​![Anurag\u0026#39;s GitHub stats](https://github-readme-stats.vercel.app/api?username=xxxxx\u0026amp;show_icons=true) readme.md中还可以使用\u0026lt;img\u0026gt;、\u0026lt;p\u0026gt;等基础标签，参考：​​​​​​​​​​ ","date":"2025-02-17T10:02:16Z","permalink":"/zh-cn/post/2025/02/%E7%BE%8E%E5%8C%96%E4%B8%AA%E4%BA%BAgithub%E4%B8%BB%E9%A1%B5%E9%83%A8%E7%BD%B2github-readme-stats/","title":"美化个人github主页，部署github-readme-stats"},{"content":" 往期推荐\n符号引用和直接引用、强引用、软引用、弱引用、虚引用-CSDN博客\n已老实！再学消息队列、死信队列-CSDN博客\nsynchronized如何实现可重入，和Lock区别-CSDN博客\nMysql索引失效的几种场景、回表、索引覆盖、索引下推-CSDN博客\n1. 未启用Spring事务管理功能或bean没有被spring管理\n2. @Transactional修饰的方法非public或被final、static修饰\n3. 同类的方法A直接调用同类的事务方法B\nspring事务是通过Spring AOP实现的， 对需要spring管理事务的bean生成了代理对象，然后通过代理对象拦截了目标方法的执行，在方法前后 添加了事务的功能，所以必须通过代理对象调用 目标方法的时候，事务才会起效。如果方法A直接调用方法B则是this调用，即该类的类对象，就不是代理对象。可以通过Service 类中注入自己，或者通过AopContext.currentProxy()获取代理对象来解决。\n4. 抛出的异常类型错误\n在业务方法进行异常抛出，spring会自动对事务进行回滚，那么问题来了，抛出哪些异常spring会回滚事务呢？默认情况下，spring遇到RuntimeException和Error的事务才会回滚。因为spring认为RuntimeException和Error是不可预期的错误，而受检异常是可预期的错误，可以通过业务逻辑即可解决。\n当然也可以自定义回滚异常类型@Transactional(rollbackFor = {异常类型列表})\n5. 异常被捕获处理\nspring感知到指定异常被抛出才会进行回滚，如果在方法内部捕获处理掉异常，事务就不会回滚\n1 2 3 4 5 6 7 8 9 @Transactional public void m1(){ 事务操作1 try{ 事务操作2，内部抛出了异常 }catch(Exception e){ log.error(....) } } 正确做法是捕获处理掉异常后抛出来，如下：\n1 2 3 4 5 6 7 8 9 10 @Transactional public void m1(){ 事务操作1 try{ 事务操作2，内部抛出了异常 }catch(Exception e){ log.error(....) throw e } } 6. 事务操作和@Transactional方法不在同一线程\n1 2 3 4 5 6 @Transactional public void m1() { new Thread() { 一系列事务操作 }.start(); } 7. 事务传播行为设置不对\nspring默认事务传播行为默认是**required，事务方法A内部调用事务方法B，**如果方法A存在事务则方法B加入方法A的事务，否则创建新事务。如果非事务方法A调用事务方法B，事务传播级别为NOT_SUPPORT，因为方法A当前不存在事务，则方法B虽然有@Transactional注解，但仍然以非事务去执行。\n--- ","date":"2025-02-16T12:38:15Z","permalink":"/zh-cn/post/2025/02/spring%E4%BA%8B%E5%8A%A1%E5%A4%B1%E6%95%88%E7%9A%84%E5%87%A0%E7%A7%8D%E5%9C%BA%E6%99%AF/","title":"Spring事务失效的几种场景"},{"content":" 往期推荐\nMySQL三大日志_mysql 大事务 回滚 记录binlog吗-CSDN博客\n符号引用和直接引用、强引用、软引用、弱引用、虚引用-CSDN博客\n已老实！再学消息队列、死信队列-CSDN博客\nsynchronized如何实现可重入，和Lock区别-CSDN博客\n如何设计一个能根据任务优先级来执行的线程池-CSDN博客\n聚簇索引和二级索引 innodb使用b+树作为索引数据结构。在创建表时，InnoDB 默认会创建一个主键索引（primary key），也就是聚簇索引，而其它索引都属于二级索引。\n如果没有指明主键索引，就自动在后台创建 隐藏的 6 字节 row_id 列 作为主键索引。\n值得一提的是，InnoDB和MyISAM都支持B+树索引，但是它们数据的存储结构实现方式不同。InnoDB存储擎的B+树索引的叶子节点保存数据本身（图1），MylSAM存储引擎的B+树索引的叶子节点保存数据的物理地址（图2）；\nInnoDB存储引擎根据索引类型不同，分为聚簇索引（图1）和二级索引。区别在于，聚簇索引的叶子节点存放的是实际数据，所有完整的用户数据都存放在聚簇索引的叶子节点，而二级索引的叶子节点存放的是主键值，而不是实际数据 。如果将 name 字段设置为普通索引，那么这个二级索引长下图这样：\n回表和索引覆盖 如果使用主键索引作为条件查询 ，查询聚簇索引的叶子节点数据（图1），那么就直接在叶子节点读取到要查询的数据，比如select * from user where id=1 (id是主键索引) 如果使用二级索引字段作为条件查询 ，查询聚簇索引 的叶子节点数据，那么需要检索两颗B+树：\n先在二级索引的B+树找到对应的叶子节点，获取主键值（图3），然后用获取的主键值，在聚簇索引中的B+树检索到对应的叶子节点（图1），然后获取要查询的数据。这个过程叫做回表，如select * from user where name=\u0026ldquo;林某\u0026rdquo;（name是二级索引） 如果使用二级索引字段作为条件查询 ，查询二级索引的叶子节点数据 （图3），那么只需在二级索引的 B+ 树找到对应的叶子节点，然后读取要查询的数据，不需要用到主键索引，这个过程叫做覆盖索引。如select id from user where name=\u0026ldquo;林某\u0026rdquo;（name是二级索引，id正好存在于二级索引中） 索引失效场景 3.1 like %xx或like %xx% 因为索引 B+ 树是按照「索引值」有序排列存储的，只能根据前缀进行比较。 对索引使用左或左右模糊匹配，此时会走全表扫描\n3.2 对索引使用函数 select * from user where length(name)=3（name是二级索引），因为索引保存的是索引字段原始值，而不是经过函数计算后的值，自然就没办法走索引了而是全表扫描。\n不过，从MySQL8.0开始，索引特性增加了函数索引，可以针对函数计算后的值建立一个索引，也就是说该索引的值是函数计算后的值，所以就可以通过扫描索引来查询数据。\n3.3 对索引表达式计算 select * from from where id +1=10会走全表扫描，因为索引保存的是索引字段的原始值，而不是 id + 1 表达式计算后的值，而select * from from where id = 10 -1则会走索引查询。\n3.4 对索引隐式类型转换 如果索引字段是字符串类型，但是在条件查询中，输入的参数是整型的话就会走全表扫描，而如果反过来，索引字段是整型，查询参数是字符串，此时会走索引，**因为mysql在字符串和整型比较时会自动把字符串变成数字，**所以字符串类型的索引，在使用整型参数查询时，还得把字符串索引变成整型才行，也就相当于调用了函数。\n3.5 联合索引不满足最左匹配 对主键字段建立的索引叫做聚簇索引，对普通字段建立的索引叫做二级索引。那么**多个普通字段组合在一起创建的索引就叫做联合索引（组合索引），**在使用联合索引时要遵循最左匹配，比如创建联合索引（a,b,c），查询时where b=1；where c=3；where b=2 and c=3；这三种情况都会使联合索引失效。\n有一个比较特殊的查询条件：where a \u0026gt; 1 and c = 3 ，这属于索引截断 ，不同版本处理方式也不一样。MySQL5.5的话，前面a会走索引，在联合索引找到主键值后，开始回表，到主键索引读取数据行交给Server层，在Server层再比对c字段的值。从MySQL5.6之后，有一个索引下推 ，即在存储引擎层进行索引遍历时，对索引中包含的字段先做判断（a和c都在索引中），直接过滤掉不满足条件的记录，再返还给Server层，从而减少回表次数。\n当然回表只发生在用二级索引查询聚簇索引的数据，如果用主键索引查聚簇索引的数据就不存在回表了。 索引下推原理\n截断的字段不会在Server层进行条件判断，而是会被下推到「存储引擎层」进行条件判断（因为c字段的值是在(a,b,c)联合索引里的)，然后过滤出符合条件的数据后再返回给Server层。由于在引擎层就过滤掉大量的数据，无需再回表读取数据来进行判断，减少回表次数，从而提升了性能。\n没索引下推：存储引擎先定位到第一条a\u0026gt;1的数据，然后拿着其主键去回表，读取出数据给server层，然后server层判断是否满足c=3，来决定是否给客户端，然后存储引擎重复上面操作，反复回表。\n有索引下推: 就直接在存储引擎层过滤，减少回表操作。\n联合索引的匹配遵循 最左前缀原则 ，且 从最左列开始按顺序匹配 。当遇到第一个范围查询时，后续列的索引将不再生效；而等值查询则允许后续列继续匹配索引，直到遇到范围查询为止。\n3.6 where中使用or 在 WHERE 子句中，如果 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。因为 OR 的含义就是两个只要满足一个即可，因此只有一个条件列是索引列是没有意义的，只要有条件列不是索引列，就会进行全表扫描\n3.7 两个索引列做比较 MySQL的索引（如B+Tree索引）是按列值单独排序的。每个索引独立存储某列的值及其行位置（ROWID）。当比较两列时：\n若使用 column1 的索引，只能快速定位到 column1 的特定值，但无法直接关联到 column2 的值。同理，column2 的索引也无法关联到 column1 的值。优化器无法通过索引直接找到满足 column1 = column2 的行，只能通过全表扫描逐行比较。\n3.8 不等于比较 3.9 is not null 3.10 not in和not exists 查询条件使用not in时，如果是主键索引则走索引，如果是普通索引，则索引失效。\n3.11 order by 对索引order by导致全表排序\n","date":"2025-02-15T10:33:28Z","permalink":"/zh-cn/post/2025/02/mysql%E7%B4%A2%E5%BC%95%E5%A4%B1%E6%95%88%E7%9A%84%E5%87%A0%E7%A7%8D%E5%9C%BA%E6%99%AF%E5%9B%9E%E8%A1%A8%E7%B4%A2%E5%BC%95%E8%A6%86%E7%9B%96%E7%B4%A2%E5%BC%95%E4%B8%8B%E6%8E%A8/","title":"Mysql索引失效的几种场景、回表、索引覆盖、索引下推"},{"content":" 往期推荐\n字符串常量池-CSDN博客\nAQS\u0026mdash;抽象队列同步器、CLH锁队列-CSDN博客\n符号引用和直接引用、强引用、软引用、弱引用、虚引用-CSDN博客\n已老实！再学消息队列、死信队列-CSDN博客\n可重入 synchronized底层是利用计算机系统mutex Lock实现的。每一个可重入锁都会关联一个线程ID和一个锁状态status。\n当一个线程请求方法时，会检查锁状态。\n如果锁状态是0，代表该锁没有被占用，使用CAS操作获取锁，将线程ID替换成自己的线程D。\n如果锁状态不是0，代表有线程在访问该方法。此时，如果线程D是自己的线程D,如果是可重入锁，会将status自增1，然后获取到该锁，进而执行相应的方法；如果是非重入锁，就会进入阻塞队列等待。\n在释放锁时，\n如果是可重入锁的，每一次退出方法，就会将status减1，直至status的值为0，最后释放该锁。\n如果非可重入锁的，线程退出方法，直接就会释放该锁。\n和lock的区别 Synchronized内置的Java关键字，Lock是一个Java接口 Synchronized无法判断获取锁的状态，Lock可以判断是否获取到了锁 Synchronized会自动释放锁，Lock必须要手动释放锁！如果不释放锁，死锁 Synchronized线程1（获得锁，阻塞）、线程2（等待，傻傻的等）；Lock锁就不一定会等待下去； Synchronized可重入锁，不可以中断的，非公平；Lock，可重入锁，可以判断锁，非公平（可以自己设置）； Synchronized适合锁少量的代码同步问题，Lock适合锁大量的同步代码！ --- ","date":"2025-02-15T10:30:25Z","permalink":"/zh-cn/post/2025/02/synchronized%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%8F%AF%E9%87%8D%E5%85%A5%E5%92%8Clock%E5%8C%BA%E5%88%AB/","title":"synchronized如何实现可重入，和Lock区别"},{"content":" 往期推荐\nJava内存模型（Memory Model）-CSDN博客\nArrayList、LinkedList、HashMap、HashTable、HashSet、TreeSet-CSDN博客\nAQS\u0026mdash;抽象队列同步器-CSDN博客\nKafka入门到入土\u0026mdash;\u0026mdash;万字详解，图文并茂_图解kafka-CSDN博客\nKafka系列第三篇！10 分钟学会如何在 Spring Boot 程序中使用 Kafka 作为消息队列?\n消息队列的使用场景是什么样的？\n目录{#main-toc}\n消息队列作用{#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%BD%9C%E7%94%A8-toc}\nJMS和AMQP协议{#JMS%E5%92%8CAMQP%E5%8D%8F%E8%AE%AE-toc}\nJMS{#JMS-toc}\n五种消息类型{#%E4%BA%94%E7%A7%8D%E6%B6%88%E6%81%AF%E7%B1%BB%E5%9E%8B-toc}\n两种消息模型{#%E4%B8%A4%E7%A7%8D%E6%B6%88%E6%81%AF%E6%A8%A1%E5%9E%8B-toc}\nAMQP{#AMQP-toc}\n消息类型{#%E6%B6%88%E6%81%AF%E7%B1%BB%E5%9E%8B-toc}\n五种消息模型{#%E4%BA%94%E7%A7%8D%E6%B6%88%E6%81%AF%E6%A8%A1%E5%9E%8B-toc}\n几种消息队列{#%E5%87%A0%E7%A7%8D%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-toc}\nkafka{#kafka-toc}\nkafka的优势{#kafka%E7%9A%84%E4%BC%98%E5%8A%BF-toc}\nkafka 为什么性能比 RocketMQ 好{#kafka%20%E4%B8%BA%E4%BB%80%E4%B9%88%E6%80%A7%E8%83%BD%E6%AF%94%20RocketMQ%20%E5%A5%BD-toc}\nkafka如何保证消息有序{#kafka%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E6%9C%89%E5%BA%8F-toc}\nkafka如何保证消息不丢失{#kafka%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1-toc}\n生产者丢失消息{#%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%A2%E5%A4%B1%E6%B6%88%E6%81%AF-toc}\n消费者丢失消息{#%E6%B6%88%E8%B4%B9%E8%80%85%E4%B8%A2%E5%A4%B1%E6%B6%88%E6%81%AF%C2%A0-toc}\nkafka丢消息{#kafka%E4%B8%A2%E6%B6%88%E6%81%AF-toc}\nkafka如何保证消息不重复消费{#kafka%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E4%B8%8D%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9-toc}\nRocketMQ{#RocketMQ-toc}\nRocketMQ架构{#RocketMQ%E6%9E%B6%E6%9E%84-toc}\nRabbitMQ{#RabbitMQ-toc}\nexchange类型{#exchange%E7%B1%BB%E5%9E%8B%C2%A0-toc}\n死信队列{#%E6%AD%BB%E4%BF%A1%E9%98%9F%E5%88%97%C2%A0-toc}\n消息队列作用 {#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%BD%9C%E7%94%A8} 老生常谈，削峰限流、异步解耦、分布式事务、顺序保证、延时定时、数据流处理比如大数据、即时通讯（物联网）\n消息队列（基础篇）-4 如何利用事务消息实现分布式事务？_事务消息可以实现分布式事务-CSDN博客\n当然引入组件带来的副作用往往是数据一致性、系统复杂性、系统可用性稳定性，毕竟越复杂的东西越容易出问题。\nJMS和AMQP协议 {#JMS%E5%92%8CAMQP%E5%8D%8F%E8%AE%AE} JMS JAVA Message Service，一个java消息服务的规范，类似jdbc，有点对点、发布订阅两种模型：\n五种消息类型 {#%E4%BA%94%E7%A7%8D%E6%B6%88%E6%81%AF%E7%B1%BB%E5%9E%8B} StreamMessage：Java 原始值的数据流 MapMessage：一套名称-值对 TextMessage：一个字符串对象 ObjectMessage：一个序列化的 Java 对象 BytesMessage：一个字节的数据流 两种消息模型 {#%E4%B8%A4%E7%A7%8D%E6%B6%88%E6%81%AF%E6%A8%A1%E5%9E%8B} 点对点\n一个消息只有一个消费者，未被消费的消息在queue中保留直到被消费或超时。消费者在成功接收消息之后需向队列应答成功，以便消息队列删除当前接收的消息 发布订阅\n生产者把消息广播到一个topic，该topic可以有多个消费者消费。\n在kafka中，一个topic可以有多个分区partition，单个分区的消息是有序的，而全局的topic的多个分区的消息是无序的。这就是为什么kafka一条消息只能被同一个消费者组里面的一个消费者消费，这样就某种程度上保证了消息的不重复消费和乱序消费。 AMQP Advanced Message Queuing Protocol，一个提供统一消息服务的应用层标准 高级消息队列协议 （二进制应用层协议），是应用层协议的一个开放标准，为面向消息的中间件设计，兼容 JMS。RabbitMQ 就是基于 AMQP 协议实现的。\n消息类型 {#%E6%B6%88%E6%81%AF%E7%B1%BB%E5%9E%8B} 二进制字节数组\n五种消息模型 {#%E4%BA%94%E7%A7%8D%E6%B6%88%E6%81%AF%E6%A8%A1%E5%9E%8B} ①direct exchange；\n②fanout exchange；\n③topic change；\n④headers exchange；\n⑤system exchange;\n本质来讲，后四种和 JMS 的 pub/sub 模型没有太大差别，仅是在路由机制上做了更详细的划分；\n几种消息队列 {#%E5%87%A0%E7%A7%8D%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97} 消息中间件：Kafka、RabbitMQ、RocketMQ、ActiveMQ 四个分布式消息队列 综合对比_kafuka tcp 与 mq 队列是否类似-CSDN博客\nkafka 具体看这个：Kafka入门到入土\u0026mdash;\u0026mdash;万字详解，图文并茂_图解kafka-CSDN博客\nkafka的优势 {#kafka%E7%9A%84%E4%BC%98%E5%8A%BF} 极致的性能：\n基于 Scala 和 Java 语言开发，设计中大量使用了批量处理和异步的思想，最高可以每秒处理千万级别的消息。 生态系统兼容性：\nKafka 与 周边生态系统的兼容性是最好的没有之一，尤其在大数据(数据吞吐量大)和流计算领域。 kafka 为什么性能比 RocketMQ 好 {#kafka%20%E4%B8%BA%E4%BB%80%E4%B9%88%E6%80%A7%E8%83%BD%E6%AF%94%20RocketMQ%20%E5%A5%BD} 面试官：RocketMQ 和 Kafka 有什么区别？\n这里性能主要指吞吐量，kafka使用了sendfile零拷贝，RocketMQ 使用的是 mmap 零拷贝技术，具体可以看这个\n用户态和内核态、进程、协程及线程几种状态、DMA、零拷贝_进程和线程 用户态和内核态-CSDN博客\n为什么RocketMQ不使用sendfile呢？\n1 2 3 4 5 6 ssize_t sendfile(int out_fd, int in_fd, off_t* offset, size_t count); // num = sendfile(xxx); void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset); // buf = mmap(xxx) sendfile返回的是发送成功了几个字节数 ，具体发了什么内容，应用层根本不知道 。mmap 返回的是数据的具体内容，应用层能获取到消息内容并进行一些逻辑处理。而 RocketMQ 的一些功能，却需要了解具体这个消息内容，方便二次投递等，比如将消费失败的消息重新投递到死信队列中，如果 RocketMQ 使用 sendfile，那根本没机会获取到消息内容长什么样子，也就没办法实现一些好用的功能了。\n一句话总结就是：和 Kafka 相比，RocketMQ 在架构上做了减法，在功能上做了加法\u0026quot;\nkafka如何保证消息有序 {#kafka%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E6%9C%89%E5%BA%8F} kafka的消息存储在topic的Partition中，整体来看topic的消息是无序的，但是单个Partition的消息是有序的，每次添加消息到 Partition的时候都会采用尾加法，并为其分配一个特定的offset。因此为保证 Kafka 中消息消费的顺序，有了下面两种方法：\n1 个 Topic 只对应一个 Partition。 （推荐）发送消息的时候指定 key/Partition。 kafka如何保证消息不丢失 {#kafka%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1} 生产者丢失消息 {#%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%A2%E5%A4%B1%E6%B6%88%E6%81%AF} 生产者(Producer) 调用send方法发送消息之后，消息可能因为网络问题并没有发送过去。\n所以，我们不能默认在调用send方法发送消息之后消息发送成功了。为了确定消息是发送成功，我们要判断消息发送的结果。但是要注意的是 Kafka 生产者(Producer) 使用 send 方法发送消息实际上是异步的操作，我们可以通过 get()方法获取调用结果，但是这样也让它变为了同步操作，示例代码如下：\n1 2 3 4 5 SendResult\u0026lt;String, Object\u0026gt; sendResult = kafkaTemplate.send(topic, o).get(); if (sendResult.getRecordMetadata() != null) { logger.info(\u0026#34;生产者成功发送消息到\u0026#34; + sendResult.getProducerRecord().topic() + \u0026#34;-\u0026gt; \u0026#34; + sendRe sult.getProducerRecord().value().toString()); } 但是一般不推荐这么做！可以采用为其添加回调函数的形式，示例代码如下：\n1 2 3 ListenableFuture\u0026lt;SendResult\u0026lt;String, Object\u0026gt;\u0026gt; future = kafkaTemplate.send(topic, o); future.addCallback(result -\u0026gt; logger.info(\u0026#34;生产者成功发送消息到topic:{} partition:{}的消息\u0026#34;, result.getRecordMetadata().topic(), result.getRecordMetadata().partition()), ex -\u0026gt; logger.error(\u0026#34;生产者发送消失败，原因：{}\u0026#34;, ex.getMessage())); 另外可以为producer设置失败的重试次数和重试的时间间隔。如果多次重试失败，可以把消息加入死信队列\n消费者丢失消息 {#%E6%B6%88%E8%B4%B9%E8%80%85%E4%B8%A2%E5%A4%B1%E6%B6%88%E6%81%AF%C2%A0} 消息加入分区后会有一个offset，如果消费者拉取到了分区的某个消息之后，消费者会自动提交了 offset，此时如果消费者挂掉，那么消息并没有被消费，offset却自动提交了。一种解决方法是关闭自动提交，开启手动提交，但是如果消费完消息还没手动提交offset，消费者挂掉，那么该消息会被消费第二次甚至更多次，直到offset提交。\nkafka丢消息 {#kafka%E4%B8%A2%E6%B6%88%E6%81%AF} kafka的分区有一个多副本机制，副本之间有一个leader副本，其他副本是follower，如果leader副本突然挂掉，有些数据还未来得及同步到follower中，会消息丢失。\n解决方法有以下几种：\n设置acks=all，表示只有所有 ISR 列表（所有的可用副本）的副本全部收到消息时，生产者才会接收到来自服务器的响应。acks 的默认值即为 1，代表我们的消息被 leader 副本接收之后就算被成功发送。 设置min.insync.replicas \u0026gt; 1， 代表消息至少要被写入到 2 个副本才算是被成功发送。min.insync.replicas 的默认值为 1 ，在实际生产中应尽量避免默认值 1。 **设置 unclean.leader.election.enable = false，**各个follower的同步情况不一样，当 leader 副本发生故障时就不会从 follower 副本中和 leader 同步程度达不到要求的副本中选择出 leader ，这样降低了消息丢失的可能性。 kafka如何保证消息不重复消费 {#kafka%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E4%B8%8D%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9} 消息重复消费的根本原因是已消费的数据没有成功提交offset，在上面消费者丢失消息中已讲到。\nRocketMQ RocketMQ常见问题总结 | JavaGuide\nrocketMQ是阿里开源的消息队列，由java开发，和kafka的topic中是partition，rocketMQ的topic中是queue，queue可以分布在不同的borker中来容灾。和kafka相同，对于一个topic的一个queue，同个消费者组有一个消费者消费\nRocketMQ架构 {#RocketMQ%E6%9E%B6%E6%9E%84} NameServer、Broker、Producer、Consumer ，NameServer作用和kafka的zk相同，用来维护rocketmq的元信息，注册发现borker和路由信息管理，但是相对zk来说更为轻量\nRabbitMQ RabbitMQ常见问题总结 | JavaGuide\n基于AMQP实现，由erlang编写，在 RabbitMQ 中，消息并不是直接被投递到queue中，中间还必须经过 Exchange(交换器) 这一层，Exchange会把消息分配到对应的queue。\n生产者将消息发送给交换器时，需要一个 RoutingKey，当 BindingKey 和 RoutingKey 相匹配时，消息会被路由到对应的队列中。\nexchange类型 {#exchange%E7%B1%BB%E5%9E%8B%C2%A0} RabbitMQ 的 Exchange 有 4 种类型，不同的类型对应着不同的路由策略：direct(默认)，fanout, topic, 和 headers。\nfanout 把所有发送到该 Exchange 的消息路由到所有与它绑定的 Queue 中，不需要做任何判断操作，所以 fanout 类型是所有的交换机类型里面速度最快 的。fanout 类型常用来广播消息。 direct 把消息路由到那些 Bindingkey 与 RoutingKey 完全匹配的 Queue 中，常用在处理有优先级的任务，根据任务的优先级把消息发送到对应的队列，这样可以指派更多的资源去处理高优先级的队列。\ntopic把可以把一条消息发送到匹配的多个queue中，BindingKey和RoutingKey 为一个点号\u0026quot;．\u0026ldquo;分隔的字符串，如a.b.c，BindingKey 中还可以存在\u0026rdquo;*\u0026ldquo;和\u0026rdquo;#\u0026ldquo;做模糊匹配，\u0026rdquo;*\u0026ldquo;用于匹配1个单词，\u0026rdquo;#\u0026ldquo;匹配0或多个单词。 headers 类型的交换器不依赖路由键的匹配规则来路由消息 ，而是根据发送的消息内容中的 headers 属性进行完全匹配。 死信队列 {#%E6%AD%BB%E4%BF%A1%E9%98%9F%E5%88%97%C2%A0} 当消息在一个队列中变成死信之后，它能被重新发送到另一个交换器中，这个交换器就是 DLX，绑定 DLX 的队列就称之为死信队列。\n导致的死信的几种原因：\n消息被拒（Basic.Reject /Basic.Nack) 且 requeue = false。 消息 TTL 过期。 队列满了，无法再添加。 ","date":"2025-02-14T12:00:00Z","permalink":"/zh-cn/post/2025/02/%E5%B7%B2%E8%80%81%E5%AE%9E%E5%86%8D%E5%AD%A6%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E6%AD%BB%E4%BF%A1%E9%98%9F%E5%88%97/","title":"已老实！再学消息队列、死信队列"},{"content":" 往期推荐\nKafka入门到入土\u0026mdash;\u0026mdash;万字详解，图文并茂_图解kafka-CSDN博客\nJava内存模型（Memory Model）-CSDN博客\nArrayList、LinkedList、HashMap、HashTable、HashSet、TreeSet-CSDN博客\nAQS\u0026mdash;抽象队列同步器、CLH锁队列-CSDN博客\n参考：https://segmentfault.com/a/1190000042313862\n符号引用 以一组符号来描述所引用的目标。 符号引用可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可，符号引用和虚拟机的布局无关。 为什么要有符号引用？ java类被编译成class文件时，虚拟机并不知道所引用类的地址，所以就用符号引用来代替 ，而在链接的解析阶段 就是为了把这个符号引用转化成为真正的地址即直接引用。\n直接引用 直接引用和虚拟机的布局是相关的，不同的虚拟机对于相同的符号引用所翻译出来的直接引用一般是不同的。 直接引用可以是指向对象，类变量和类方法的指针、相对偏移量、一个间接定位到对象的句柄。 强引用 把一个对象赋给一个引用变量，如 MikeChen mikechen=new MikeChen();\n在一个方法的内部有一个强引用，这个引用保存在Java栈中，而真正的引用内容(MikeChen)保存在Java堆中。\n如果一个对象具有强引用，即使OOM垃圾回收器不会回收该对象，如果强引用对象不使用时，需要弱化从而使GC能够回收，如 mikechen=null;\n软引用（Soft） 1 2 3 软引用是一种相对强引用弱化了一些的引用，需要用java.lang.ref.SoftReference 类来实现： String str=new String(\u0026#34;abc\u0026#34;); // 强引用 SoftReference\u0026lt;String\u0026gt; softRef=new SoftReference\u0026lt;String\u0026gt;(str); 内存不足时就会回收该对象内存，gc不一定回收。\n弱引用（Weak） 不管内存是否足够，只要发生 GC，都会被回收。\n调用System.gc()方法只是起通知作用，不一定立刻gc，JVM的gc时机由JVM自己的状态决定。\n比如ThreadLocal的静态内部类Entry就继承了弱引用，ThreadLocalMap使用ThreadLocal的弱引用作为key，GC时这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，也就造成内存泄漏。\n虚引用（Phantom） 虚引用（Phantom Reference）是Java中最弱的引用类型，无法通过引用直接获取到对象实例 。虚引用主要用于跟踪对象被垃圾回收的状态。当一个对象只被虚引用关联时，其实际上并不影响对象的生命周期，也就是说，垃圾回收器随时可能回收被虚引用关联的对象。\n--- ","date":"2025-02-13T14:03:21Z","permalink":"/zh-cn/post/2025/02/%E7%AC%A6%E5%8F%B7%E5%BC%95%E7%94%A8%E5%92%8C%E7%9B%B4%E6%8E%A5%E5%BC%95%E7%94%A8%E5%BC%BA%E5%BC%95%E7%94%A8%E8%BD%AF%E5%BC%95%E7%94%A8%E5%BC%B1%E5%BC%95%E7%94%A8%E8%99%9A%E5%BC%95%E7%94%A8/","title":"符号引用和直接引用、强引用、软引用、弱引用、虚引用"},{"content":" 往期推荐\nJava内存模型（Memory Model）-CSDN博客\n扫盲，CRM、ERP、OA、MVP \u0026hellip;-CSDN博客\nArrayList、LinkedList、HashMap、HashTable、HashSet、TreeSet-CSDN博客\n参考：Java AQS 核心数据结构-CLH 锁\n什么是AQS AbstractQueuedSynchronizer，一个抽象类，用来构建锁和同步器，定义了资源获取和释放的通用流程，ReentrantLock、Semaphore皆是基于AQS实现的。\n核心思想\n线程请求的共享资源已被占用，那么该请求线程进入AQS的CLH队列进行等待，否则把请求线程设置为有效的工作线程，并将共享资源设置为占用状态，即该线程占用了共享资源。\nAQS的CLH锁队列 自旋锁即线程不断对一个原子变量CAS来尝试获取锁，若多线程同时竞争同一个原子变量，可能造成某个线程的 CAS 操作长时间失败，从而导致 \u0026ldquo;饥饿\u0026quot;问题 ，而CLH锁对自旋锁进行了改进，通过引入一个单向队列来让线程排队确保公平性，避免饥饿。\nAQS 在 CLH 锁的基础上进一步优化，形成了其内部的 CLH 队列变体，优化点如下：\n自旋+阻塞：普通的CLH锁使用纯自旋等待锁释放，大量自旋会占用CPU资源，AQS的CLH锁则会短暂自旋，失败后进入阻塞状态，等待被唤醒，减少CPU占用。 双向队列 ：普通的CLH锁是单向的，节点只知道前驱节点的状态，而当某个节点释放锁时，需要通过队列唤醒后续节点。AQS 将队列改为 双向队列 ，新增了 next 指针，使得节点不仅知道前驱节点，也可以直接唤醒后继节点，从而简化了队列操作，提高了唤醒效率。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /** * Head of the wait queue, lazily initialized. Except for * initialization, it is modified only via method setHead. Note: * If head exists, its waitStatus is guaranteed not to be * CANCELLED. */ private transient volatile Node head; /** * Tail of the wait queue, lazily initialized. Modified only via * method enq to add new wait node. */ private transient volatile Node tail; /** * The synchronization state. */ private volatile int state; Node节点各个状态含义 为什么state要用volatile修饰 使用 volatile 修饰state不是为了利用 volatile 的内存可见性，因为state本来就只会被持有线程写入，只会被队列中该线程的后驱节点对应的线程读，而且后者会轮询读取。因此，可见性问题不会影响锁的正确性。\n但要实现一个可以在多线程程序中正确执行的锁，还需要解决重排序问题 。\n在《Java 并发编程实战》一书对于重排序问题是这么描述的：在没有同步的情况下，编译器、处理器以及运行时等都可能对操作的执行顺序进行一些意想不到的调整。在缺乏足够同步的多线程程序中，要想对内存操作的执行顺序进行判断，几乎无法得到正确的结论。对于 Java synchronized 关键字提供的内置锁(又叫监视器) ，Java内存模型规范中有一条 Happens-Before（先行发生）规则：\u0026ldquo;一个监视器锁上的解锁应该发生在该监视器锁的后续锁定之前\u0026quot;也就是后面的锁在锁定之前得知道前面的锁有没有解锁，而自定义互斥锁就需要自己保证这一规则的成立，因此上述代码通过 volatile 的 Happens-Before（先行发生）规则来解决重排序问题。JMM 的 Happens-Before（先行发生）规则有一条针对 volatile 关键字的规则：\u0026ldquo;volatile 变量的写操作发生在该变量的后续读之前\u0026rdquo;。\nAQS的独占和共享 Exclusive（独占，如ReentrantLock）和Share（共享，如Semaphore/CountDownLatch）。\n一般来说，自定义同步器的共享方式要么是独占，要么是共享，他们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。但 AQS 也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。\nacquire()和release() 6.1 acquire() 1 2 3 4 5 6 7 8 9 10 public final void acquire(int arg) { if (!tryAcquire(arg) \u0026amp;\u0026amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } tryAcquire() ：尝试获取锁（模板方法），AQS 不提供具体实现，由子类实现。 acquireQueued() ：对线程进行阻塞、唤醒，并调用 tryAcquire() 方法让队列中的线程尝试获取锁。 addWaiter() ：如果获取锁失败，会将当前线程封装为 Node 节点加入到 AQS 的 CLH 变体队列中等待获取锁。 6.2 release() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public final boolean release(int arg) { // 1、尝试释放锁 if (tryRelease(arg)) { Node h = head; // 2、唤醒后继节点 if (h != null \u0026amp;\u0026amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false; } tryRelease() 方法尝试释放锁，该方法为模板方法，由自定义同步器实现。 如果 tryRelease() 返回 true ，表明线程已经没有重入次数了，锁已经被完全释放，因此需要唤醒后继节点。 以ReentrantLock讲解AQS原理 假设有 3 个线程尝试抢占 获取锁，线程分别为 T1 、 T2 和 T3。\n假设线程 T1 先获取到锁，线程 T2 排队等待获取锁。但是在线程 T2 进入队列之前，需要初始化AQS的CLH锁队列。head 节点在初始化后状态为 0 。AQS 内部初始化后的队列如下\n由于线程 T1 持有锁，因此线程 T2 会获取失败并进入队列中等待获取锁。同时会将前继节点（ head 节点）的状态由 0 更新为 SIGNAL ，表示需要对 head 节点的后继节点进行唤醒。此时，AQS 内部队列如下图所示：\n由于线程 T1 持有锁，因此线程 T3 也获取锁失败，会进入队列中等待获取锁。同时会将前继节点（线程 T2 节点）的状态由 0 更新为 SIGNAL ，表示线程 T2 节点需要对后继节点进行唤醒。此时，AQS 内部队列如下图所示：\n此时，假设线程 T1 释放锁，会唤醒后继节点 T2 。线程 T2 被唤醒后获取到锁，并且会从等待队列中退出（不是移除，因为T2还要当head）。\n--- ","date":"2025-02-12T11:02:38Z","permalink":"/zh-cn/post/2025/02/aqs---%E6%8A%BD%E8%B1%A1%E9%98%9F%E5%88%97%E5%90%8C%E6%AD%A5%E5%99%A8clh%E9%94%81%E9%98%9F%E5%88%97/","title":"AQS---抽象队列同步器、CLH锁队列"},{"content":"数组与集合区别 数组固定长度，集合动态改变\n数组可以包含基本数据类型，集合只能包含对象\n数组可以直接访问元素，集合需要通过迭代器或其他方法访问\n集合族谱 在这些集合中，仅有vector和hashtable是线程安全的，其内部方法基本都有synchronized修饰。\nArrayList 底层采用Object数组实现，实现了RandomAccess接口因此支持随机访问。插入删除操作效率慢。\nArrayList需要一份连续的内存空间。\nArrayList扩容机制 ArrayList添加元素时，若达到了内部数组指定的数量上限，会自动进行扩容：\n计算新容量，一般是原容量的1.5倍（1.5 倍，是因为 1.5 可以充分利用移位操作，减少浮点数或者运算时间和运算次数） 根据新容量创建新数组 把原来的数据拷贝到新数组中 更新ArrayList内部指向原数组的引用，指向新数组 ArrayList哪里不安全 首先，对arraylist添加一个元素，分为3步\n判断数组是否需要扩容，如果需要就调用grow方法扩容； 将数组的size位置设置值（因为数组的下标是从0开始的）； 将当前集合的大小+1 多线程插入删除下，ArrayList会暴露三个问题：\n出现null值：\n假设arraylist容量为10，线程1检查当前size=4，不需要扩容，于是在index=4进行插入，但是还没有size++，线程2又来进行插入，检查不需要扩容且size=4，于是也在index=4执行插入，然后两个线程同时执行size++，就导致实际size=6，两次插入都在index=4，而index=5的地方并没有插入数据。 索引越界异常\n还是上述例子，假设线程1检查size=9，没有到10，无需扩容，于是在index=9的地方插入，但还没有size++，线程2来检查size=9，也在index=9的地方插入，然后两个线程同时++，导致size=11。 集合的size()和实际add数量不符\nsize++不 ","date":"2025-02-11T12:00:00Z","permalink":"/zh-cn/post/2025/02/arraylistlinkedlisthashmaphashtablehashsettreeset/","title":"ArrayList、LinkedList、HashMap、HashTable、HashSet、TreeSet"},{"content":" 往期推荐\nsynchronized锁升级-CSDN博客\n字符串常量池-CSDN博客\nhttps://segmentfault.com/a/1190000045398760\n总结 JMM是jvm定义的一套规范，用来规范多线程并发时对共享资源的访问规则，如何保证多线程的可见性、原子性、有序性。JMM把内存分为线程的工作内存和主内存。\nCPU缓存 我们知道CPU是有缓存的，CPU缓存是为了解决主内存和CPU处理速度不对等的问题。其工作方式是先复制一份数据到 CPU 缓存中，当 CPU 需要用到的时候就可以直接从 CPU 缓存中读取数据，当运算完成后，再将运算得到的数据写回主内存中。但是，这样存在 内存缓存不一致性的问题 ！比如执行一个 i++ 操作的话，如果两个线程同时执行的话，假设两个线程从 CPU 缓存中读取的 i=1，两个线程做了 i++ 运算完之后再写回 Main Memory 之后 i=2，而正确结果应该是 i=3。\n那么CPU 为了解决内存缓存不一致性问题就需要定制协议规范，即内存模型，无论是 Windows 系统，还是 Linux 系统，它们都有特定的内存模型。\n指令重排 为了提升执行速度/性能，计算机在执行程序代码的时候，会对指令进行重排序，即执行代码的顺序和实际代码编写顺序不一定相同。常见的指令重排序有下面 2 种情况：\n编译器优化重排：编译器（包括 JVM、JIT 编译器等）在不改变单线程程序语义的前提下，重新安排语句的执行顺序。 指令并行重排：现代处理器采用了指令级并行技术(Instruction-Level Parallelism，ILP)来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 例：a = b + c; d = e - f ; 先加载 b、c（注意，有可能先加载 b，也有可能先加载 c ），但是在执行 add(b,c) 的时候，需要等待 b、c 装载结束才能继续执行，也就是需要增加停顿，那么后面的指令（加载 e 和 f）也会有停顿，这就降低了计算机的执行效率。为了减少停顿，我们可以在加载完 b 和 c 后把 e 和 f 也加载了，然后再去执行 add(b,c)，这样做对程序（串行）是没有影响的，但却减少了停顿。提高了效率！\n然而指令重排序可以保证串行语义一致，但无法保证多线程间的语义也一致 ，在多线程下指令重排序可能会导致一些问题。\n对于编译器优化重排和处理器的指令重排序（指令并行重排和内存系统重排都属于是处理器级别的指令重排序），处理该问题的方式不一样。\n对于编译器，通过禁止特定类型的编译器重排序的方式来禁止重排序。\n对于处理器，通过插入内存屏障或内存栅栏的方式来禁止特定类型的处理器重排序。\nJMM 一般来说，编程语言也可以直接复用操作系统层面的内存模型。不过，不同的操作系统内存模型不同。如果直接复用操作系统层面的内存模型，就可能会导致同样一套代码换了一个操作系统就无法执行了。Java 语言是跨平台的，它需要自己提供一套内存模型以屏蔽系统差异。\n所以Java 线程之间的通信由 Java 内存模型控制，同时保证了java的跨平台，定义了并发编程的规范，抽象了线程和主内存的关系，避免出现像CPU指令重排导致的多线程问题。\nJMM核心概念：\n**内存分区：**JMM 将内存分为 主内存 和 线程工作内存， 主内存就是 所有线程共享的内存区域，包括堆内存和方法区。线程工作内存就是每个线程独有的内存区域，包括局部变量、操作栈、寄存器等。 **可见性：**一个线程对共享变量的修改，其他线程能够立即看到。 **原子性：**一个操作要么全部完成，要么全部不完成，不会出现中间状态。 顺序性：程序中代码的执行顺序与代码的书写顺序一致。 3.1 JMM如何抽象线程和主内存的关系 Java 内存模型（JMM） 抽象了线程和主内存之间的关系，就比如说线程之间的共享变量必须存储在主内存中。\n在 JDK 2之前，Java 的内存模型实现是从 主存 （即共享内存）读取变量，而在当前的 Java 内存模型下，线程可以把变量保存 本地内存 （比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成数据的不一致。 什么是主内存、本地内存\n主内存：所有线程创建的实例对象都存放在主内存中，不管该实例对象是成员变量，还是局部变量，类信息、常量、静态变量都是放在主内存中。为了获取更好的运行速度，虚拟机及硬件系统可能会让工作内存优先存储于寄存器和高速缓存中。 本地内存 ：每个线程都有一个私有的本地内存，本地内存存储了该线程以读 / 写共享变量的副本。每个线程只能操作自己本地内存中的变量，无法直接访问其他线程的本地内存。如果线程间需要通信，必须通过主内存来进行。本地内存是 JMM 抽象出来的一个概念，并不真实存在，它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。 从上图来看，线程 1 与线程 2 之间如果要进行通信的话，必须要经历下面 2 个步骤：\n线程 1 把本地内存中修改过的共享变量副本的值同步到主内存中去。 线程 2 到主存中读取对应的共享变量的值。 也就是说，JMM 为共享变量提供了可见性的保障。不过多线程操作主内存的共享变量也是有线程安全问题的\n3.2 happens-before 原则 前面提到了指令重排可能会引发多线程的执行问题，为此JMM 抽象了 happens-before 原则来解决这个指令重排序问题。\nhappens-before 原则表达的意义其实并不是一个操作发生在另外一个操作的前面，它更想表达的意义是前一个操作的结果对于后一个操作是可见的，无论这两个操作是否在同一个线程里。\n举个例子：操作 1 happens-before 操作 2，即使操作 1 和操作 2 不在同一个线程内，JMM 也会保证操作 1 的结果对操作 2 是可见的。\n并发编程的三个重要特性 原子性\n一次操作或者多次操作，要么所有的操作全部都得到执行并且不会受到任何因素的干扰而中断，要么都不执行。\n在 Java 中，可以借助synchronized、各种 Lock 以及各种原子类实现原子性。\nsynchronized还可以保证可见性！\n可见性\n当一个线程对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。\n在 Java 中，可以借助synchronized、volatile 以及各种 Lock 实现可见性。\n如果我们将变量声明为 volatile ，这就指示 JVM，这个变量是共享且不稳定的，每次使用它都到主存中进行读取。\n有序性\n由于指令重排序问题，代码的执行顺序未必就是编写代码时候的顺序。\n我们上面讲重排序的时候也提到过，指令重排序可以保证串行语义一致，但是没有义务保证多线程间的语义也一致 ，所以在多线程下，指令重排序可能会导致一些问题。\n在 Java 中，volatile 关键字可以禁止指令进行重排序优化\n--- ","date":"2025-02-10T12:00:00Z","permalink":"/zh-cn/post/2025/02/java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8Bmemory-model/","title":"Java内存模型（Memory Model）"},{"content":" 往期推荐\nsynchronized锁升级-CSDN博客\n【排坑】云服务器docker部署前后端分离项目+域名解析+OSS-CSDN博客\n【大坑！已解决】docker容器jar包连不上另一个容器的mysql_docker启动jar包时无法连接mysql-CSDN博客\nJVM图文入门-CSDN博客\n【已解决】OSS配置问题_keyuewenhua.oss-cn-beijing.aliyuncs-CSDN博客\nString s=new String(\u0026ldquo;abc\u0026rdquo;)时， 虚拟机会先去字符串常量池查找有无abc这个字符串对象，如果有就不在字符串常量池创建了，直接在堆中创建一个abc字符串对象，然后将堆中这个abc的对象地址 返回赋值给变量，如果没有，则先在字符串常量池创建字符串abc，然后在堆中创建abc的字符串对象，然后将堆中这个abc的对象地址返回赋值给变量。\njava的栈上存储的是基本数据类型的变量和对象的引用，而对象本身则存储在堆上。 为什么要先在字符串常量池中创建对象，然后再在堆上创建呢？\n通常我们会用双引号的方式创建字符串对象，而不是new关键字，此时虚拟机会先在字符串常量池中查找有没有\u0026quot;abc\u0026quot;这个字符串对象，如果有，则不创建任何对象，直接将字符串常量池中这个\u0026quot;abc\u0026quot;的对象地址返回，赋给变量 s；如果没有，在字符串常量池中创建\u0026quot;abc\u0026quot;这个对象，然后将其地址返回，赋给变量 s。此时就不用在堆中创建对象了 String s = new String(\u0026ldquo;abc\u0026rdquo;); String s1 = new String(\u0026ldquo;abc\u0026rdquo;);\n这两行代码会创建三个对象，字符串常量池一个、堆上两个。\nString s = \u0026ldquo;abc\u0026rdquo;; String s1 = \u0026ldquo;abc\u0026rdquo;;\n这两行代码只会创建一个对象，就是字符串常量池中的那个。\n","date":"2025-02-07T12:00:00Z","permalink":"/zh-cn/post/2025/02/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0/","title":"字符串常量池"},{"content":" 往期推荐{#tableOfContents}\n【已解决】redisCache注解失效，没写cacheConfig_com.howbuy.cachemanagement.client.redisclient#incr-CSDN博客{#tableOfContents}\n【已解决】OSS配置问题_keyuewenhua.oss-cn-beijing.aliyuncs-CSDN博客{#tableOfContents}\n【排坑】云服务器docker部署前后端分离项目+域名解析+OSS-CSDN博客{#tableOfContents}\n微服务概念入门：Nacos、OpenFeign、Sentinel、GateWay、Seata-CSDN博客{#tableOfContents}\n字符串常量池-CSDN博客{#tableOfContents}\n目录{#main-toc}\n1. JVM8结构图{#main-toc-toc}\n2. Java性能低的主要原因{#Java%E6%80%A7%E8%83%BD%E4%BD%8E%E7%9A%84%E8%80%8C%E4%B8%BB%E8%A6%81%E5%8E%9F%E5%9B%A0-toc}\n3. 字节码文件{#%E5%AD%97%E8%8A%82%E7%A0%81%E6%96%87%E4%BB%B6-toc}\n3.1 字节码文件的组成{#%E5%AD%97%E8%8A%82%E7%A0%81%E6%96%87%E4%BB%B6%E7%9A%84%E7%BB%84%E6%88%90-toc}\n4. JVM架构{#5.%20JVM%E6%9E%B6%E6%9E%84-toc}\n4.1 类加载器ClassLoader{#%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8ClassLoader-toc}\n4.2 运行时数据区{#%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA-toc}\n程序计数器{#%E7%A8%8B%E5%BA%8F%E8%AE%A1%E6%95%B0%E5%99%A8-toc}\nJava虚拟机栈（方法栈）{#Java%E6%96%B9%E6%B3%95%E6%A0%88%EF%BC%88%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88%EF%BC%89-toc}\n本地方法栈{#%E6%9C%AC%E5%9C%B0%E6%96%B9%E6%B3%95%E6%A0%88%C2%A0-toc}\n堆{#Heap%E5%A0%86-toc}\n4.3 执行引擎{#%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E-toc}\n5. 双亲委派{#%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE-toc}\n5.1 破坏双亲委派{#%E7%A0%B4%E5%9D%8F%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE-toc}\nTomcat破坏{#Tomcat%E7%A0%B4%E5%9D%8F-toc}\nJDBC破坏{#JDBC%E7%A0%B4%E5%9D%8F%C2%A0-toc}\nJVM8结构图 {#main-toc} Java性能低的主要原因 {#Java%E6%80%A7%E8%83%BD%E4%BD%8E%E7%9A%84%E8%80%8C%E4%B8%BB%E8%A6%81%E5%8E%9F%E5%9B%A0} Java语言如果不做任何的优化，性能其实是不如C和C++语言的。主要原因是：\n在程序运行过程中，Java虚拟机需要将字节码指令实时 地解释成计算机能识别的机器码，这个过程在运行时可能会反复执行，所以效率较低。\nC和C++语言在执行过程中，只需将源代码编译成可执行文件，就包含了计算机能识别的机器码，无需在运行过程中再实时地解释，所以性能较高。\nJava为什么要选择一条执行效率比较低的方式呢？主要是为了实现跨平台的特性。Java的字节码指令，如果希望在不同平台（操作系统+硬件架构），比如在windows或者linux上运行。可以使用同一份字节码指令，交给windows和linux上的Java虚拟机进行解释，这样就可以获得不同平台上的机器码了。这样就实现了Write Once，Run Anywhere 编写一次，到处运行。\n字节码文件 {#%E5%AD%97%E8%8A%82%E7%A0%81%E6%96%87%E4%BB%B6} 我们java中说的字节码文件即 java代码编译后的.class文件，class文件可以跨平台运行在不同操作系统的JVM上。\n3.1 字节码文件的组成 {#%E5%AD%97%E8%8A%82%E7%A0%81%E6%96%87%E4%BB%B6%E7%9A%84%E7%BB%84%E6%88%90} 字节码文件总共可以分为以下几个部分：\n基础信息：魔数、字节码文件对应的Java版本号、访问标识(public final等等)、父类和接口信息\n常量池 **：**保存了字符串常量、类或接口名、字段名，主要在字节码指令中使用\n字段： 当前类或接口声明的字段信息\n**方法：**当前类或接口声明的方法信息，核心内容为方法的字节码指令\n**属性：**类的属性，比如源码的文件名、内部类的列表等\nJVM架构 {#5.%20JVM%E6%9E%B6%E6%9E%84} 根据上面的JVM图，JVM大致可分为三块： 类加载器ClassLoader、运行时数据区 、执行引擎\n4.1 类加载器ClassLoader {#%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8ClassLoader} 类加载器会通过二进制流的方式获取到字节码文件并交给Java虚拟机，虚拟机会在方法区和堆上生成对应的对象保存字节码信息。\n根加载器（启动类加载器）：\n默认加载Java安装目录/jre/lib下的类文件，比如rt.jar，tools.jar，resources.jar等。\n扩展类加载器：\n默认加载Java安装目录/jre/lib/ext下的类文件\n应用程序类加载器（系统类加载器）：\n默认加载的是项目中的类以及通过maven引入的第三方jar包中的类。\n用户自定义类加载器\n输出为null是因为根加载器的具体实现是由C或C++编写，不在java范围内。\n4.2 运行时数据区 {#%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA} 运行时数据可以划分为以下5块\n程序计数器 {#%E7%A8%8B%E5%BA%8F%E8%AE%A1%E6%95%B0%E5%99%A8} 每个线程都有一个私有的程序计数器，也就是一个指针，指向方法区中的方法字节码（用来存储指向指令的地址）。解释器会在工作的时候改变这个计数器的值来选取下一条需要执行的字节码指令。如果线程执行的是非本地方法，则程序计数器中保存的是当前需要执行的指令地址；如果线程执行的是本地方法，则程序计数器中的值是 undefined。\nJava虚拟机栈（方法栈） {#Java%E6%96%B9%E6%B3%95%E6%A0%88%EF%BC%88%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88%EF%BC%89} 栈中没有垃圾回收的，线程结束后内存会自动释放。栈主管程序运行、生命周期、线程同步。\nJava 虚拟机栈中是一个个栈帧，每个栈帧对应一个被调用的方法，当线程执行一个方法时，会创建一个对应的栈帧，并将栈帧压入栈中。当方法执行完毕后，将栈帧从栈中弹出。\n栈帧及组成{#%E6%A0%88%E5%B8%A7}\n局部变量表，局部变量表的作用是在运行过程中存放所有的局部变量\n操作数栈，操作数栈是栈帧中虚拟机在执行指令过程中用来存放临时数据的一块区域\n帧数据，帧数据主要包含动态链接、方法出口、异常表的引用\n​\nstack1的方法结束后要弹出栈，此时需要通过stack1返回下面的stack2的方法。\n本地方法栈 {#%E6%9C%AC%E5%9C%B0%E6%96%B9%E6%B3%95%E6%A0%88%C2%A0} Java虚拟机栈存储了Java方法调用时的栈帧，而本地方法栈存储的是native本地方法的栈帧\n堆 {#Heap%E5%A0%86} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class Test { public static void main(String[] args) { Student s1 = new Student(); s1.name = \u0026#34;张三\u0026#34;; s1.age = 18; s1.id = 1; s1.printTotalScore(); s1.printAverageScore(); Student s2 = new Student(); s2.name = \u0026#34;李四\u0026#34;; s2.age = 19; s2.id= 2; s2.printTotalScore(); s2.printAverageScore(); } } 这段代码中通过new关键字创建了两个Student类的对象，这两个对象会被存放在堆上。在栈上通过s1和s2两个局部变量保存堆上两个对象的地址，从而实现了引用关系的建立。\n​\n以前的Java 中\u0026quot;几乎\u0026quot;所有的对象都会在堆中分配，但随着JIT编译器的发展和逃逸技术的逐渐成熟，所有的对象都分配到堆上渐渐变得不那么\u0026quot;绝对\u0026quot;了。从 JDK 7 开始，Java 虚拟机已经默认开启逃逸分析了，意味着如果某些方法中的对象引用没有被返回或者未被外面使用（也就是未逃逸出去），那么对象可以直接在栈上分配内存。垃圾指JVM中没有任何引用指向它的对象\n逃逸分析\n逃逸分析是一种编译器优化技术，用于判断对象的作用域和生命周期。如果编译器确定一个对象不会逃逸出方法或线程的范围，它可以选择在栈上分配这个对象，而不是在堆上。这样做可以减少垃圾回收的压力，并提高性能。\n一个JVM实例只有一个堆内存，堆内存大小可以调节，类加载器读取类文件后要把类、方法、常变量放到堆内存中，保存所有引用类型的真实信息，堆内存在逻辑上分为三部分：\n新生代：伊甸区、幸存0区 from、幸存1区 to 老年代 永久代 4.3 执行引擎 {#%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E} 略\n双亲委派 {#%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE} 应用程序类加载器（又叫系统类加载器）收到类的加载请求先检查自己是否加载过该类，如果没有，将请求向上委托给自己的父类加载器（extensionLoader），如果父类加载器也没有加载过该类，该父类加载器继续向上委托给自己的父类加载器（bootstrapLoader，又叫根加载器、启动类加载器）若启动类加载器也没有加载过该类，则会根据要加载的类的全限定名尝试加载该类，若加载成功，则返回引用，若加载失败，则抛出异常，并反向委托给扩展类加载器，若仍加载失败，则继续抛出异常，并反向委托给应用程序类加载器，若仍加载失败，则报异常ClassNotFound。\n​\n​\n​\n安全性和沙箱机制\n由于java核心库和扩展库由根加载器加载，这些库中的类有更高的安全级别，而应用程序类由应用程序类加载器加载，安全级别低，双亲向上委派可以防止核心API被篡改，提高了程序安全性。\n什么是沙箱？\njava安全模型的核心就是java沙箱，沙箱是一个限制程序运行的环境，沙箱机制就是把java代码限定在jvm的特定运行范围内，严格限制代码对本地系统资源的访问（CPU、内存、文件系统、网络等），通过这样来保证代码的有效隔离，防止对本地系统造成破坏。\n避免类重复加载\n由于父类加载器加载类时会优先尝试加载，若类已经被加载过，就不会再次加载，避免了类重复加载。\n5.1 破坏双亲委派 {#%E7%A0%B4%E5%9D%8F%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE} 打破双亲委派机制历史上有三种方式，但本质上只有第一种算是真正的打破了双亲委派机制：\n自定义类加载器并且重写loadClass方法。Tomcat通过这种方式实现应用之间类隔离。\n线程上下文类加载器。利用上下文类加载器加载类，比如JDBC和JNDI等。\nOsgi框架的类加载器。历史上Osgi框架实现了一套新的类加载器机制，允许同级之间委托进行类的加载，目前很少使用。\nTomcat破坏 {#Tomcat%E7%A0%B4%E5%9D%8F} ​\nJDBC破坏 {#JDBC%E7%A0%B4%E5%9D%8F%C2%A0} JDBC中使用了DriverManager来管理项目中引入的不同数据库的驱动，比如mysql驱动、oracle驱动。DriverManager类位于rt.jar包中，由启动类加载器加载。依赖中的mysql驱动对应的类，由应用程序类加载器来加载。DriverManager属于rt.jar是启动类加载器加载的。而用户jar包中的驱动需要由应用类加载器加载，这就违反了双亲委派机制 。存疑\n​\nJDBC案例中真的打破了双亲委派机制吗？{#JDBC%E6%A1%88%E4%BE%8B%E4%B8%AD%E7%9C%9F%E7%9A%84%E6%89%93%E7%A0%B4%E4%BA%86%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%9C%BA%E5%88%B6%E5%90%97%EF%BC%9F}\n最早这个论点提出是在周志明《深入理解Java虚拟机》中，他认为打破了双亲委派机制，这种由启动类加载器加载的类，委派应用程序类加载器去加载类的方式，所以打破了双亲委派机制。\n但是如果我们分别从DriverManager以及驱动类的加载流程上分析，JDBC只是在DriverManager加载完之后，通过初始化阶段触发了驱动类的加载，类的加载依然遵循双亲委派机制。\n所以我认为这里没有打破双亲委派机制，只是用一种巧妙的方法让启动类加载器加载的类，去引发的其他类的加载。\n","date":"2025-02-06T12:00:00Z","permalink":"/zh-cn/post/2025/02/jvm%E5%9B%BE%E6%96%87%E5%85%A5%E9%97%A8/","title":"JVM图文入门"},{"content":"往期推荐\n浅谈云原生\u0026ndash;微服务、CICD、Serverless、服务网格_cicd 云原生-CSDN博客\n【排坑】云服务器docker部署前后端分离项目+域名解析+OSS-CSDN博客\n练习两年半，我的全栈博客出生了-CSDN博客\nhttps://blog.csdn.net/qq_73181349/article/details/145311064\n1.分布式基础 1.1 微服务 所谓微服务，就是把传统的单体项目的各个服务拆分出来单独部署，每个小服务 运行在自己 的进程中，他们之间通过HTTP调用进行通信。提高服务弹性、可维护性。\n1.2 ","date":"2025-02-05T16:56:07Z","permalink":"/zh-cn/post/2025/02/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8nacosopenfeignsentinelgatewayseata/","title":"微服务概念入门：Nacos、OpenFeign、Sentinel、GateWay、Seata"},{"content":"登陆注册页 首页 文章详情页 分类专栏 搜索结果页 可以根据类别、标签或者搜索框文本搜索\n创作页 这里参考了csdn的创作页\n支持多种皮肤，可以上传粘贴图片 AI页 引入了讯飞星火大模型lite版本，token不限量\n个人主页 主页也参考了csdn\n管理页 ","date":"2025-02-04T14:53:44Z","permalink":"/zh-cn/post/2025/02/%E7%BB%83%E4%B9%A0%E4%B8%A4%E5%B9%B4%E5%8D%8A%E6%88%91%E7%9A%84%E5%85%A8%E6%A0%88%E5%8D%9A%E5%AE%A2%E5%87%BA%E7%94%9F%E4%BA%86/","title":"练习两年半，我的全栈博客出生了"},{"content":" 踩坑推荐\n【大坑！已解决】docker容器jar包连不上另一个容器的mysql-CSDN博客\n【排坑】程序包jdk.nashorn.internal.ir.debug不存在-CSDN博客\n【已解决】 \\[ org.apache.catalina.core.StandardService : 173 \\] - Stopping service \\[Tomcat\\]-CSDN博客\n【已解决】redisCache注解失效，没写cacheConfig-CSDN博客\n【已解决】OSS配置问题-CSDN博客\n环境工具 阿里云服务器 Alibaba Cloud Linux 3.2104 LTS 64位 OSS 域名解析（具体就不写了，怕被DDOS🤡） 后端jar包 jdk11、springboot 2.6.13 前端umimax+antd系列 docker nginx latest redis7.2.4 etcd3.5.15 mysql8.0.35 SSH客户端 final shell mysql、redis、nginx等所有项目依赖环境全部部署在docker容器中。 mysql、redis这些，部署完记得在本地连一下看有没有问题，有问题就用docker logs看日志或者进容器改配置，服务器记得放开对应端口 ！！\n每部署完一个容器就用docker ps看一下status和port，如果是status是restarting或者port没映射上，大概率有问题，另外注意cpu和内存占用 （final shell看的很方便），有几次启动容器后cpu和内存占用爆满了，服务器都登不上了🤣\n拉取镜像慢的话可以改docker镜像配置，具体看\n","date":"2025-01-26T12:00:00Z","permalink":"/zh-cn/post/2025/01/%E6%8E%92%E5%9D%91%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8docker%E9%83%A8%E7%BD%B2%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E9%A1%B9%E7%9B%AE-%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90-oss/","title":"【排坑】云服务器docker部署前后端分离项目+域名解析+OSS"},{"content":"\nOSS SDK快速入门_对象存储(OSS)-阿里云帮助中心\n阿里官方的SDK使用方法还得配置环境变量access Key、access Secret ，我没有配置，仅把access Key和access Secret写到了yml文件读取，结果上传图片时还是出现下面的问题。\n[ ERROR ] [ com.serein.exception.GlobalExceptionHandler : 31 ] - RuntimeException com.aliyun.oss.common.auth.InvalidCredentialsException: Access key id should not be null or empty. at com.aliyun.oss.common.auth.DefaultCredentialProvider.checkCredentials(DefaultCredentialProvider.java:63) at com.aliyun.oss.common.auth.DefaultCredentialProvider.\u0026lt;init\u0026gt;(DefaultCredentialProvider.java:38) at com.aliyun.oss.common.auth.DefaultCredentialProvider.\u0026lt;init\u0026gt;(DefaultCredentialProvider.java:34) at com.aliyun.oss.OSSClientBuilder.getDefaultCredentialProvider(OSSClientBuilder.java:83) at com.aliyun.oss.OSSClientBuilder.build(OSSClientBuilder.java:38 解决方法是把BUCKET_NAME、END_POINT 、ACCESS_KEY_ID 、ACCESS_KEY_SECRET直接写死到代码中，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public static String uploadImageOSS(MultipartFile img) { OSS ossClient= new OSSClientBuilder().build(END_POINT, ACCESS_KEY_ID, ACCESS_KEY_SECRET); if (!ossClient.doesBucketExist(BUCKET_NAME)) { ossClient.createBucket(BUCKET_NAME); CreateBucketRequest createBucketRequest = new CreateBucketRequest(BUCKET_NAME); createBucketRequest.setCannedACL(CannedAccessControlList.PublicRead); ossClient.createBucket(createBucketRequest); } //filePath是存到oss的文件名，fileUrl是访问的路径 String filePath = createOSSFileName(img.getOriginalFilename()); PutObjectRequest putObjectRequest = null; try { putObjectRequest = new PutObjectRequest(BUCKET_NAME, filePath, img.getInputStream()); } catch (IOException e) { throw new RuntimeException(e); } PutObjectResult result = ossClient.putObject(putObjectRequest); return \u0026#34;https://\u0026#34; + BUCKET_NAME + \u0026#34;.\u0026#34; + END_POINT + \u0026#34;/\u0026#34; + filePath; } 然后再次上传图片就出现了下面的问题，因为前面填的是OSS内网oss-cn-beijing-internal.aliyuncs.com ，换成oss-cn-beijing.aliyuncs.com外网就ok了\n[ WARN ] [ com.aliyun.oss : 70 ] - [Client]Unable to execute HTTP request: Connect to xxxx.oss-cn-beijing-internal.aliyuncs.com:80 failed: Connection timed out: connect [ErrorCode]: SocketException [RequestId]: Unknown 然后图片成功上传到OSS了，但是外部并不能访问，如果拿着url在浏览器查看，会这样\n\u0026lt;Error\u0026gt; \u0026lt;Code\u0026gt;AccessDenied\u0026lt;/Code\u0026gt; \u0026lt;Message\u0026gt;You have no right to access this object because of bucket acl.\u0026lt;/Message\u0026gt; \u0026lt;RequestId\u0026gt;679391585E3414373911E999\u0026lt;/RequestId\u0026gt; \u0026lt;HostId\u0026gt;blog-backend.oss-cn-beijing.aliyuncs.com\u0026lt;/HostId\u0026gt; \u0026lt;EC\u0026gt;0003-00000001\u0026lt;/EC\u0026gt; \u0026lt;RecommendDoc\u0026gt;https://api.aliyun.com/troubleshoot?q=0003-00000001\u0026lt;/RecommendDoc\u0026gt; \u0026lt;/Error\u0026gt; 解决方法就是关闭公共访问，并且设置读写权限为公共读，这样编辑器就可以根据url显示出图片了\n成功渲染出图片！\n","date":"2025-01-25T16:12:01Z","permalink":"/zh-cn/post/2025/01/%E5%B7%B2%E8%A7%A3%E5%86%B3oss%E9%85%8D%E7%BD%AE%E9%97%AE%E9%A2%98/","title":"【已解决】OSS配置问题"},{"content":"环境配置 jdk11 springboot 2.6.13 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-cache\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; redis: host: 192.168.2.129 port: 6379 username: default password: 'linux02' database: 1 # 默认使用lettuce lettuce: pool: # 最大连接数，最大空闲数，最小空闲数 max-active: 5 max-idle: 2 min-idle: 2 # 缓存10min，允许缓存null值防止缓存穿透 cache: type: redis redis: time-to-live: 600 cache-null-values: true 代码 1 2 3 4 5 6 7 @Cacheable(cacheNames = BLOG_CACHE_PREFIX + \u0026#34;otherPassages\u0026#34;, key = \u0026#34;#userId\u0026#34;) @Override public List\u0026lt;PassageTitleVO\u0026gt; getOtherPassagesByUserId(Long userId) { .... .... return passageTitleVOS; } 解决 网上找了一些案例，有的不需要写cacheConfig，有些需要写，我之前就用过cacheable的注解，当时就是上面的配置，没写配置类也有效果，这次我最开始就没写，然后Cacheable注解就没效果了，最后写了个cacheConfig才解决。\n1 2 3 4 5 6 7 8 9 10 11 @Configuration @EnableCaching public class CacheConfig extends CachingConfigurerSupport { @Bean public RedisCacheManager cacheManager(RedisConnectionFactory redisConnectionFactory) { return RedisCacheManager.builder(redisConnectionFactory).build(); } } 然后又发现yml设置的过期时间没有生效，存到redis的是永不过期，又在 cacheConfig配置了过期时间，600s\n1 2 3 4 5 6 7 8 9 10 11 12 13 @Configuration @EnableCaching public class CacheConfig extends CachingConfigurerSupport { @Bean public RedisCacheManager cacheManager(RedisConnectionFactory redisConnectionFactory) { RedisCacheConfiguration redisCacheConfiguration = RedisCacheConfiguration.defaultCacheConfig() .entryTtl(Duration.ofSeconds(600)); return RedisCacheManager.builder(redisConnectionFactory).cacheDefaults(redisCacheConfiguration) .build(); } } ","date":"2025-01-25T12:00:00Z","permalink":"/zh-cn/post/2025/01/%E5%B7%B2%E8%A7%A3%E5%86%B3rediscache%E6%B3%A8%E8%A7%A3%E5%A4%B1%E6%95%88%E6%B2%A1%E5%86%99cacheconfig/","title":"【已解决】redisCache注解失效，没写cacheConfig"},{"content":" 常见的mysql日志有二进制日志 binlog（归档日志）和重做日志 redo log（事务日志）和 undo log（回滚日志）。\nredo log MySQL 中数据是以页为单位，查询一条记录会从硬盘把一页的数据加载出来 ，加载出来的数据叫数据页 ，会放入到**Buffer Pool**中。\n后续的查询都是先从 Buffer Pool 中找，没有命中再去硬盘加载，减少硬盘 IO 开销，提升性能。\n更新表数据的时候，也是先更新Buffer Pool 的数据，如果没有则先把数据读到Buffer Pool。 然后会把\u0026quot;在某个数据页上做了什么修改\u0026quot;记录到redo log buffer，接着刷盘到 redo log文件里。\n那么什么时候会进行刷盘呢？\n为什么需要redo log buffer pool基于内存，提高了mysql性能，但是内存的数据没有持久化到磁盘，mysql宕机后会数据丢失，为了防止断电导致数据丢失的问题，当有一条记录需要更新的时候，InnoDB引擎就会先更新内存（同时标记为脏页），然后将本次对这个页的修改以redo log的形式记录下\n来，这个时候更新就算完成\n","date":"2025-01-24T21:03:52Z","permalink":"/zh-cn/post/2025/01/mysql%E4%B8%89%E5%A4%A7%E6%97%A5%E5%BF%97/","title":"MySQL三大日志"},{"content":"\n1 2 @Update(\u0026#34;update blog.user set mail=#{mail} where userId=#{userId}\u0026#34;) void updateEncrypt(String mail, Long userId); org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.binding.BindingException: Parameter \u0026lsquo;mail\u0026rsquo; not found. Available parameters are \\[arg1, arg0, param1, param2\\]。\nMyBatis 没有找到 mail 参数的映射，无法正确绑定参数。\nMyBatis 默认的行为是通过位置来传递参数 （例如 arg0, arg1）。如果使用了具名参数（如 mail 和 userId），需要确保方法参数名与注解中的名称一致。有如下两种解决方法：\n1 2 3 //使用 @Param 注解来明确指定参数名 @Update(\u0026#34;UPDATE blog.user SET mail=#{mail} WHERE userId=#{userId}\u0026#34;) void updateEncrypt(@Param(\u0026#34;mail\u0026#34;) String mail, @Param(\u0026#34;userId\u0026#34;) Long userId); 1 2 3 //如果方法有多个参数，可以将这些参数封装成一个对象，然后通过该对象传递。 @Update(\u0026#34;UPDATE blog.user SET mail=#{mail} WHERE userId=#{userId}\u0026#34;) void updateEncrypt(UserUpdateRequest request); --- ","date":"2025-01-24T12:00:00Z","permalink":"/zh-cn/post/2025/01/mybatisplus-mapper%E5%B1%82%E7%BB%91%E5%AE%9A%E5%8F%82%E6%95%B0%E9%94%99%E8%AF%AF/","title":"mybatisplus Mapper层绑定参数错误"},{"content":"问题 环境：jdk11，springboot 2.6.13\n本地打好的jar包传到云服务器上，用docker build打成镜像后，docker run运行不起来，用docker logs查看日志如下，最后一行stopping service \\[Tomcat\\]，因为我run的时候还加上了restart=always参数，所以导致这个jar包一直失败又重启，cpu都干到100%🤣\n原因分析 \\[ org.apache.catalina.core.StandardService : 173 \\] - Stopping service \\[Tomcat\\]当时就去网上查了一些解决方法，包括但不限于pom文件引入日志依赖、修改日志级别为debug以得到更多报错信息都没法解决，最后打算排除内嵌tomcat换成war包试试，偶然看到idea打jar包时输出的这样的警告（之前一直没注意过🤣🤣）：\n因为我有hotkey-client的jar包是自己打的然后在pom中引进来的，并且用了**systemPath引入**，这样写在本地idea是可以运行起来，但是项目打成jar包就会stopping service。\n解决方法也简单，上面的黄色警告已经说了依赖的 systemPath 不应指向项目目录内的文件，那么就把hotkey-client jar 包install到本地仓库，不用 systemPath.，这样项目打出来的jar包就可以正常运行，效果如下：\n另外本地打好的jar包最好先在本地环境先跑一下，本地跑不起来云服务器大概率也不行\n","date":"2025-01-23T12:00:00Z","permalink":"/zh-cn/post/2025/01/%E5%B7%B2%E8%A7%A3%E5%86%B3-org.apache.catalina.core.standardservice-173-stopping-service-tomcat/","title":"【已解决】 [ org.apache.catalina.core.StandardService : 173 ] - Stopping service [Tomcat]"},{"content":"今天项目打包的时候报这样的错误，jdk8，在idea项目中明明可以找到该文件路径和代码，但是打包打不进去，\n参考了一些博客文章，\n【Maven问题】 错误: 程序包xxx 不存在 - 简书\nMaven错误：程序包java.nashorn.XXX不存在_程序包jdk.nashorn.api.scripting不存在-CSDN博客\n有一定借鉴意义但是没解决问题，idea的classpath中已经包含了nashorn，且可以运行项目，但是maven就是打不成jar包，试来试去都没怀疑maven问题🤓，没想到还真是maven的问题。\nmaven的runner配置，jre原来是jdk17，改成1.8就ok了\n","date":"2025-01-22T12:00:00Z","permalink":"/zh-cn/post/2025/01/%E6%8E%92%E5%9D%91%E7%A8%8B%E5%BA%8F%E5%8C%85jdk.nashorn.internal.ir.debug%E4%B8%8D%E5%AD%98%E5%9C%A8/","title":"【排坑】程序包jdk.nashorn.internal.ir.debug不存在"},{"content":"最终解决方案 mysq版本l8.0.35，驱动是8.0.26，com.mysql.cj.jdbc.Driver\njdbc的url：\njdbc:mysql://云服务器的主机地址（127.0.0.1和localhost都不行）:3306/hotkey_db?useUnicode=true\u0026amp;characterEncoding=utf-8\u0026amp;useSSL=true\u0026amp;autoReconnect=true\u0026amp;failOverReadOnly=false\u0026amp;serverTimezone=GMT\u0026amp;useTimezone=true\n（有些参数应该是没用的，但是懒得改了，能跑就行）\n问题场景 这两天在云服务器的docker上部署了jar包，jar包要连另一个容器的mysql，在本地测试过本地运行的jar包可以连接云服务器的mysql，但是云服务器的docker的jar包连不上。具体展示如下：jar包成功运行后登录时就会报这样的错误，执行sql查询失败，说是连不上mysql ，以下是jar包的部分日志。\n报错日志 登录时执行mysql查询失败，因为连不上mysql，用docker network 查看了网络信息，这些个容器启动时候已经在同一个docker网络了，并且在jar包的容器中可以ping通mysql的网关\nmysql连接报错\ncommunications link failure，很经典的错误，去网上查了很多解决办法，包括但不限于修改jar包的jdbc的url连接参数，比如useSSL=false、时区serverTimeZone、localhost和127.0.0.1，甚至是mysql的配置文件my.cnf，说是因为连接池连接过期的，要修改wait_timeout。结果没一个能解决问题的，后来问了一个朋友，他正好遇见过同样的问题，之前还给我说过但是我没记住🤣，他的解决方案就是把jdbc的url换成云服务器的主机地址，而非127.0.0.4或localhost。至此问题解决。\n分析 docker的每个容器之间是进程隔离的，每个容器都相当于一个独立的主机，我的jar和mysql不在同一个容器，相当于mysql和jar包不在一个主机上，那么jar包里的127.0.0.1:3306显然是连不到mysql的。\n最后又试了试，如果jar包和mysql不在同一个docker网络，也是可以正常运行的，因为jar已经通过主机地址访问到mysql了\n","date":"2025-01-21T16:35:43Z","permalink":"/zh-cn/post/2025/01/%E5%A4%A7%E5%9D%91%E5%B7%B2%E8%A7%A3%E5%86%B3docker%E5%AE%B9%E5%99%A8jar%E5%8C%85%E8%BF%9E%E4%B8%8D%E4%B8%8A%E5%8F%A6%E4%B8%80%E4%B8%AA%E5%AE%B9%E5%99%A8%E7%9A%84mysql/","title":"【大坑！已解决】docker容器jar包连不上另一个容器的mysql"},{"content":"用户态和内核态 根据进程访问资源的特点，我们可以把进程在系统上的运行分为两个级别：\n用户态(User Mode) : 用户态运行的进程可以直接读取用户程序的数据 ，拥有较低的权限。当应用程序需要执行某些需要特殊权限的操作 ，例如读写磁盘、网络通信等，就需要向操作系统发起系统调用请求，进入内核态。 内核态(Kernel Mode) ：内核态运行的进程几乎可以访问计算机的任何资源包括系统的内存空间、设备、驱动程序等，不受限制，拥有非常高的权限。当操作系统接收到进程的系统调用请求时，就会从用户态切换到内核态，执行相应的系统调用，并将结果返回给进程，最后再从内核态切换回用户态。 不过，由于切换内核态需要付出较高的开销（需要进行一系列的上下文切换和权限检查），应该尽量减少进入内核态的次数，以提高系统的性能和稳定性。\n用户态和内核态如何切换 用户态切换到内核态的 3 种方式：\n系统调用（Trap） ：用户态进程 主动 要求切换到内核态的一种方式，主要是为了使用内核态才能做的事情比如读取磁盘资源。系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现。\n中断（Interrupt） ：当外围设备完成用户请求的操作后，会向 CPU 发出相应的中断信号，这时 CPU 会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。\n异常（Exception）：当 CPU 在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。\n进程和线程 进程（Process） 是指计算机中正在运行的一个程序实例。比如打开某个应用。\n线程（Thread） 轻量级进程，多个线程可以在同一个进程中同时执行，并且共享进程的资源比如内存空间、文件句柄、网络连接等。举例：你打开的微信里就有一个线程专门用来拉取别人发你的最新的消息。\n协程 是一种用户态 的轻量级线程 ，其调度完全由用户程序控制，而不需要内核的参与。协程拥有自己的寄存器上下文和栈，但与其他协程共享堆内存。协程的切换开销非常小，因为只需要保存和恢复协程的上下文，而无需进行内核级的上下文切换。这使得协程在处理大量并发任务时具有非常高的效率。然而，协程需要程序员显式地进行调度和管理，相对于线程和进程来说，其编程模型更为复杂。\n进程的几种状态 和线程的状态很像\n创建状态(new)：进程正在被创建，尚未到就绪状态。 就绪状态(ready)：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。 运行状态(running)：进程正在处理器上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。 阻塞状态(waiting)：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。 结束状态(terminated)：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。 创建状态和就绪状态的区别：\n状态 通俗理解 线程内部发生了什么 是否能被调度 创建（NEW） 只是\u0026quot;生成了车票\u0026quot;，还没进站 已 new Thread()，但未调用 start() ，操作系统线程尚未真正创建 ❌ 调度器看不见，进不了就绪队列 就绪（RUNNABLE） 已进站，在候车大厅排队 调用了 start()，操作系统线程已建立，所有资源到位，等待 CPU 时间片 ✅ 随时可能被调度器挑中执行 DMA（direct memory access） 在没有DMA技术之前，I/O过程是这样的：\n用户进程发起read调用，切换用户态到内核态\nCPU发出I/O请求给磁盘控制器，然后返回\n磁盘控制器收到请求开始准备数据，把数据放到磁盘控制器的内部缓冲区，然后产生一个中断\nCPU收到中断信号，停下手头的工作，把磁盘控制器缓冲区的数据一次一个字节地读进自己的寄存器，然后再把寄存器里的数据写入到内存，而在数据传输的期间 CPU 是无法执行其他任务的\n由上可见整个数据传输过程中，都需要CPU亲自参与，期间cpu不能做其他事，非常拉低性能。于是有了DMA。\n传统的文件传输 进程文件传输，最简单的方式就是把磁盘文件读取出来，通过网络协议发出去。\n期间发生四次 用户态和内核态的切换，因为发生了**两次系统调用，一次是 read() ，一次是 write()，**每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。\n如何优化文件传输性能 在读取磁盘数据的时候之所以要发生上下文切换，是因为用户空间没有权限操作磁盘或网卡，需要切换到内核态来完成，而一次系统调用必然发生两次上下文切换：用户到内核、内核到用户，所以要减少上下文切换次数，就要减少系统调用次数！\n在前面我们知道了，传统的文件传输方式会历经4次数据拷贝，而且这里面，从内核\n的读缓冲区拷贝到用户的缓冲区里，再从用户的缓冲区里拷贝到socket的缓冲区里，\n这个过程是没有必要的。因为文件传输的应用场景中，在用户空间我们并不会对数据再加工，所以数据实际上可以不用搬运到用户空间，因此用户的缓冲区是没有必要存在的。\n如何实现零拷贝 mmap + write 在前面我们知道，read()系统调用的过程中会把内核缓冲区的数据拷贝到用户的缓冲区里，于是为了减少这一步开销，可以用mmap()替换read()系统调用函数。\nmmap() 系统调用函数会直接把内核缓冲区里的数据「映射」到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。\n这种方式仍然是两次系统调用，四次上下文切换，只不过少了1次拷贝。\nsendfile linux内核2.1中的sendfile是专门发送文件的系统调用函数，仅有一次系统调用，可以代替read和write两次系统调用。该系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，这样就只有 2 次上下文切换，和 3 次数据拷贝。\nlinux 内核 2.4 ，在网卡支持SG-DMA的情况下，可以用sendfile直接把文件从内核缓冲区拷贝到网卡。这才是真正的零拷贝，因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。\nPageCache 回顾前面说道文件传输过程，其中第一步都是先需要先把磁盘文件数据拷贝「内核缓冲\n区」里，这个「内核缓冲区」实际上是磁盘高速缓存(PageCache)。\nPageCache会缓存最近被访问的数据 （把磁盘数据读到缓存中），来提高读写性能。同时会进行预读，比如实际要从磁盘读取32kb数据，那么内核会把32-64kb的数据也提前读到缓存。\n","date":"2025-01-18T12:00:00Z","permalink":"/zh-cn/post/2025/01/%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E8%BF%9B%E7%A8%8B%E5%8D%8F%E7%A8%8B%E5%8F%8A%E7%BA%BF%E7%A8%8B%E5%87%A0%E7%A7%8D%E7%8A%B6%E6%80%81dma%E9%9B%B6%E6%8B%B7%E8%B4%9D/","title":"用户态和内核态、进程、协程及线程几种状态、DMA、零拷贝"},{"content":" 往期推荐\nJava io模型-CSDN博客\n如何设计一个能根据任务优先级来执行的线程池-CSDN博客\nWeb实时消息推送的几种方案_setmessageinnerhtml is not defined-CSDN博客\nyum、dnf、apt包管理工具-CSDN博客\nJava反射、静态代理、动态代理-CSDN博客 在jdk1.5版本（包含）之前，锁的状态只有两种状态：无锁状态和重量级锁状态，只要有线程访问共享资源对象，则锁直接成为重量级锁，jdk1.6版本后，对synchronized锁进行了优化，新加了\u0026quot;偏向锁\u0026quot;和\u0026quot;轻量级锁\u0026quot;，用来减少上下文的切换以提高性能，所以锁就有了4种状态。\n无锁\n对于共享资源，不涉及多线程的竞争访问。在DK1.6之后偏向锁的默认开启的，但是有一个偏向延迟，需要在VM启动之后的多少秒之后才能开启，这个可以通过VM参数进行设置，同时是否开启偏向锁也可以通过VM参数设置。 偏向锁\n共享资源首次被访问时 ，JVM会对该共享资源对象做一些设置，比如将对象头中是否偏向锁标志位置为1，对象头中的线程ID设置为当前线程ID（注意：这里是操作系统的线程ID），后续当前线程再次访问这个共享资源时，会根据偏向锁标识跟线程ID进行比对是否相同，比对成功则直接获取到锁（锁偏向于这个线程），进入临界区域 （就是被锁保护，线程间只能串行访问的代码），这也是synchronized锁的可重入功能。 轻量级锁\n当多个线程同时申请共享资源锁的访问时，这就产生了竞争，JVM会先尝试使用轻量级锁，以CAS方式 来获取锁（一般就是自旋加锁，不阻塞线程采用循环等待 的方式），成功则获取到锁，状态为轻量级锁，轻量级锁竞争失败（达到一定的自旋次数还未成功）则锁升级到重量级锁。 重量级锁\n如果共享资源锁已经被某个线程持有，此时是偏向锁状态，**未释放锁前，再有其他线程来竞争时，则会升级到重量级锁，把竞争线程挂起，**重量级锁由操作系统来实现，所以性能消耗相对较高。 synchronized 和 volatile区别 synchronized 关键字和 volatile 关键字是两个互补的而非对立的\nvolatile 关键字是线程同步的轻量级 实现，所以 volatile性能肯定比synchronized关键字要好 。但是 volatile 关键字只能用于变量 而 synchronized 关键字可以修饰方法以及代码块 。 volatile 关键字能保证数据的可见性，但不能保证数据的原子性 。synchronized 关键字两者都能保证。 volatile关键字主要用于解决变量在多个线程之间的可见性，同时防止指令重排序。而 synchronized 关键字解决的是多个线程之间访问资源的同步性。 --- ","date":"2025-01-16T12:00:00Z","permalink":"/zh-cn/post/2025/01/synchronized%E9%94%81%E5%8D%87%E7%BA%A7/","title":"synchronized锁升级"},{"content":" 往期推荐\nJava io模型-CSDN博客\n如何设计一个能根据任务优先级来执行的线程池-CSDN博客\nWeb实时消息推送的几种方案_setmessageinnerhtml is not defined-CSDN博客\nyum、dnf、apt包管理工具-CSDN博客\n概述 反射机制是在运行状态中，对于任意一个类，都能够知道这个类中的所有属性和方法，对于任意一个对象，都能够调用它的任意一个方法和属性，这种动态获取的信息以及动态调用对象的方法的功能称为Java语言的反射机制。\nSpring、mybatis、动态代理、注解都是使用了反射。 优点：可以让咱们的代码更加灵活、为各种框架提供开箱即用的功能提供了便利。\n缺点：让我们在运行时有了分析操作类的能力，这同样也增加了安全问题。比如可以无视泛型参数的安全检查（泛型参数的安全检查发生在编译时）。另外，反射的性能也要稍差点，不过，对于框架来说实际是影响不大的。\n获取Class对象的4种方式 如果我们动态获取到这些信息，我们需要依靠 Class 对象。Class 类对象将一个类的方法、变量等信息告诉运行的程序。\n知道具体类名，直接类名.class 通过对象实例instance.getClass()获取 通过 Class.forName()传入类的全路径获取 通过类加载器xxxClassLoader.loadClass()传入类路径获取 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 //定义反射类 public class TargetObject { private String value; public TargetObject() { value = \u0026#34;QingQiu\u0026#34;; } public void publicMethod(String s) { System.out.println(\u0026#34;I love \u0026#34; + s); } private void privateMethod() { System.out.println(\u0026#34;value is \u0026#34; + value); } } //使用反射操作上面的类方法及属性 public class Main { public static void main(String[] args) throws ClassNotFoundException, NoSuchMethodException, IllegalAccessException, InstantiationException, InvocationTargetException, NoSuchFieldException { /** * 获取 TargetObject 类的 Class 对象并且创建 TargetObject 类实例 */ Class\u0026lt;?\u0026gt; targetClass = Class.forName(\u0026#34;com.serein.TargetObject\u0026#34;); TargetObject targetObject = (TargetObject) targetClass.newInstance(); /** * 获取 TargetObject 类中定义的所有方法 */ Method[] methods = targetClass.getDeclaredMethods(); for (Method method : methods) { System.out.println(method.getName()); } /** * 获取指定方法并调用 */ Method publicMethod = targetClass.getDeclaredMethod(\u0026#34;publicMethod\u0026#34;, String.class); publicMethod.invoke(targetObject, \u0026#34;QingQiu\u0026#34;); /** * 获取指定参数并对参数进行修改 */ Field field = targetClass.getDeclaredField(\u0026#34;value\u0026#34;); //为了对类中的参数进行修改我们取消安全检查 field.setAccessible(true); field.set(targetObject, \u0026#34;serein\u0026#34;); /** * 调用 private 方法 */ Method privateMethod = targetClass.getDeclaredMethod(\u0026#34;privateMethod\u0026#34;); //为了调用private方法我们取消安全检查 privateMethod.setAccessible(true); privateMethod.invoke(targetObject); } } 常见的反射应用场景 加载数据库驱动 ，Class.forName(com.mysql.cj.jdbc.Driver) 加载配置文件，Spring通过xml装载Bean的过程： 将xml配置文件加载入内存 java类里面解析xml的内容，得到对应实体类的字节码字符串以及相关的属性信息 使用反射机制，根据这个字符串获得某个类的Class实例动态配置实例的属性 代理 通过代理对象来代替对真实对象的访问，这样就可以在不修改原目标对象的前提下，提供额外的功能操作，扩展目标对象的功能。比喻：活动方要请明星出席，不会直接去找明星（真实对象），而是去找其经纪人（代理对象）\n静态代理 静态代理实现步骤 定义一个接口及其实现类 创建一个代理类同样实现这个接口 将目标对象注入进代理类，然后在代理类的对应方法调用目标类中的对应方法。这样的话，我们就可以通过代理类屏蔽对目标对象的访问，并且可以在目标方法执行前后做一些自己想做的事情。 代码演示 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 //定义发送短信的接口 public interface SmsService { String send(String message); } //实现发送短信的接口 public class SmsServiceImpl implements SmsService { public String send(String message) { System.out.println(\u0026#34;send message:\u0026#34; + message); return message; } } //创建代理类并同样实现发送短信的接口 public class SmsProxy implements SmsService { private final SmsService smsService; public SmsProxy(SmsService smsService) { this.smsService = smsService; } @Override public String send(String message) { //调用方法之前，我们可以添加自己的操作 System.out.println(\u0026#34;before method send()\u0026#34;); smsService.send(message); //调用方法之后，我们同样可以添加自己的操作 System.out.println(\u0026#34;after method send()\u0026#34;); return null; } } //实际使用 public class Main { public static void main(String[] args) { SmsService smsService = new SmsServiceImpl(); SmsProxy smsProxy = new SmsProxy(smsService); smsProxy.send(\u0026#34;java\u0026#34;); } } 动态代理 JDK动态代理 在 Java 动态代理机制中 InvocationHandler 接口和 Proxy 类是核心。\nProxy 类中使用频率最高的方法是：newProxyInstance() ，这个方法主要用来生成一个代理对象。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 常用 // loader :类加载器，用于加载代理对象。 // interfaces : 被代理类实现的一些接口； // h : 实现了 InvocationHandler 接口的对象； public static Object newProxyInstance (ClassLoader loader, Class\u0026lt;?\u0026gt;[] interfaces, InvocationHandler h) //这个私有方法通常是在实现代理类时，由 JVM 或框架内部的机制调用，来处理更复杂的代理类生成逻辑。 private static Object newProxyInstance(Class\u0026lt;?\u0026gt; caller,Constructor\u0026lt;?\u0026gt; cons, InvocationHandler h) 要实现动态代理的话，还必须需要实现InvocationHandler 来自定义处理逻辑。 当我们的动态代理对象调用一个方法时，这个方法的调用就会被转发到实现InvocationHandler 接口类的 invoke 方法来调用。\n1 2 3 4 5 6 7 8 9 10 11 12 public interface InvocationHandler { /** * 当你使用代理对象调用方法的时候实际会调用到这个方法 */ public Object invoke(Object proxy, Method method, Object[] args) throws Throwable; // proxy :动态生成的代理类 // method : 与代理类对象调用的方法相对应 // args : 当前 method 方法的参数 } JDK动态代理实现步骤 定义一个接口及其实现类； 自定义 InvocationHandler 并重写invoke方法，在 invoke 方法中我们会调用原生方法（目标类的方法）并自定义一些处理逻辑； 通过 Proxy.newProxyInstance(ClassLoader loader,Class\u0026lt;?\u0026gt;[] interfaces,InvocationHandler h) 方法创建代理对象； 代码演示 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 //定义发送短信的接口 public interface SmsService { String send(String message); } //实现发送短信的接口 public class SmsServiceImpl implements SmsService { public String send(String message) { System.out.println(\u0026#34;send message:\u0026#34; + message); return message; } } //定义JDK动态代理类 public class DebugInvocationHandler implements InvocationHandler { /** * 代理类中的真实对象 */ private final Object target; public DebugInvocationHandler(Object target) { this.target = target; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws InvocationTargetException, IllegalAccessException { //调用方法之前，我们可以添加自己的操作 System.out.println(\u0026#34;before method \u0026#34; + method.getName()); //当我们的动态代理对象调用原生方法的时候，最终实际上调用到的是 invoke() 方法，然后 invoke() 方法代替我们去调用了被代理对象的原生方法。 Object result = method.invoke(target, args); //调用方法之后，我们同样可以添加自己的操作 System.out.println(\u0026#34;after method \u0026#34; + method.getName()); return result; } } //获取代理对象的工厂类 public class JdkProxyFactory { public static Object getProxy(Object target) { return Proxy.newProxyInstance( target.getClass().getClassLoader(), // 目标类的类加载器 target.getClass().getInterfaces(), // 代理需要实现的接口，可指定多个 new DebugInvocationHandler(target) // 代理对象对应的自定义 InvocationHandler ); } } //实际使用 SmsService smsService = (SmsService) JdkProxyFactory.getProxy(new SmsServiceImpl()); smsService.send(\u0026#34;java\u0026#34;); cglib动态代理 JDK动态代理通过实现接口实现代理，而CGLIB 通过继承方式实现代理。很多知名的开源框架都使用到了CGLIB， 例如 Spring 中的 AOP 模块中：如果目标对象实现了接口，则默认采用 JDK 动态代理，否则采用 CGLIB 动态代理。 在 CGLIB 动态代理机制中 MethodInterceptor 接口和 Enhancer 类是核心。\n自定义 MethodInterceptor 并重写 intercept 方法，intercept 用于拦截增强被代理类的方法。Enhancer类来动态获取被代理类，当代理类调用方法的时候，实际调用的是 MethodInterceptor 中的 intercept 方法。\n1 2 3 4 5 6 7 8 9 10 // obj : 被代理的对象（需要增强的对象） // method : 被拦截的方法（需要增强的方法） // args : 方法入参 // proxy : 用于调用原始方法 public interface MethodInterceptor extends Callback{ // 拦截被代理类中的方法 public Object intercept(Object obj, java.lang.reflect.Method method, Object[] args,MethodProxy proxy) throws Throwable; } CGLIB动态代理类使用步骤 定义一个类； 自定义 MethodInterceptor 并重写 intercept 方法，intercept 用于拦截增强被代理类的方法，和 JDK 动态代理中的 invoke 方法类似； 通过 Enhancer 类的 create()创建代理类； 代码演示 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;cglib\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cglib\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.3.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; //实现一个使用阿里云发送短信的类 public class AliSmsService { public String send(String message) { System.out.println(\u0026#34;send message:\u0026#34; + message); return message; } } //自定义 MethodInterceptor（方法拦截器） public class DebugMethodInterceptor implements MethodInterceptor { /** * @param o 被代理的对象（需要增强的对象） * @param method 被拦截的方法（需要增强的方法） * @param args 方法入参 * @param methodProxy 用于调用原始方法 */ @Override public Object intercept(Object o, Method method, Object[] args, MethodProxy methodProxy) throws Throwable { //调用方法之前，我们可以添加自己的操作 System.out.println(\u0026#34;before method \u0026#34; + method.getName()); Object object = methodProxy.invokeSuper(o, args); //调用方法之后，我们同样可以添加自己的操作 System.out.println(\u0026#34;after method \u0026#34; + method.getName()); return object; } } //获取代理类 public class CglibProxyFactory { public static Object getProxy(Class\u0026lt;?\u0026gt; clazz) { // 创建动态代理增强类 Enhancer enhancer = new Enhancer(); // 设置类加载器 enhancer.setClassLoader(clazz.getClassLoader()); // 设置被代理类 enhancer.setSuperclass(clazz); // 设置方法拦截器 enhancer.setCallback(new DebugMethodInterceptor()); // 创建代理类 return enhancer.create(); } } //实际使用 AliSmsService aliSmsService = (AliSmsService) CglibProxyFactory.getProxy(AliSmsService.class); aliSmsService.send(\u0026#34;java\u0026#34;); 看到这里似乎发现cglib也是实现了一个接口重写intercept()来增强的，那么继承 体现在哪里呢？其实在使用 CGLIB 进行代理时，CGLIB 会通过继承目标类，生成一个新的子类 Target$Proxy，并重写目标类的非 final 方法。CGLIB 会在这些重写的方法中加入代理逻辑。\n静态代理和动态代理对比 灵活性：动态代理更加灵活，不需要必须实现接口，可以直接代理实现类（cglib），并且可以不需要针对每个目标类都创建一个代理类。另外，静态代理中，接口一旦新增加方法，目标对象和代理对象都要进行修改，这是非常麻烦的！ JVM 层面：静态代理在编译时就将接口、实现类、代理类这些都变成了一个个实际的 class 文件。而动态代理是在运行时动态生成类字节码，并加载到 JVM 中的。 JDK代理和CGLIB代理对比 JDK 动态代理只能代理实现了接口的类或者直接代理接口，而 CGLIB 可以代理未实现任何接口的类。 另外， CGLIB 动态代理是通过生成一个被代理类的子类来拦截被代理类的方法调用，因此不能代理声明为 final 类型的类和方法。 就二者的效率来说，大部分情况都是 JDK 动态代理更优秀，随着 JDK 版本的升级，这个优势更加明显 ","date":"2025-01-15T15:55:11Z","permalink":"/zh-cn/post/2025/01/java%E5%8F%8D%E5%B0%84%E9%9D%99%E6%80%81%E4%BB%A3%E7%90%86%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/","title":"Java反射、静态代理、动态代理"},{"content":"Red Hat 系列 rpm (Red Hat Package Manager) Red Hat 系列 Linux 发行版（如 CentOS、RHEL、Fedora）上的软件包管理。\n支持平台：Red Hat 系列 Linux（RHEL、CentOS、Fedora）。 依赖关系 ：不自动处理依赖关系，需要用户手动管理或借助其他工具（如 yum 或 dnf）。 功能 ：rpm 是一个低级 包管理工具，主要用于安装、查询、卸载和管理 .rpm 包。它本身不处理依赖关系，通常由其他工具（如 yum 或 dnf）解决 yum (Yellowdog Updater, Modified) Red Hat 系列 Linux 发行版（如 CentOS、RHEL、Fedora）的软件包管理。\n支持平台：Red Hat 系列 Linux（RHEL、CentOS、Fedora）。 依赖关系：自动处理软件包依赖。 功能 ：yum 是一个高级的包管理工具，可以从软件仓库中自动下载和安装软件包，自动处理依赖关系和升级。它是基于 RPM 包的管理工 ","date":"2025-01-13T12:00:00Z","permalink":"/zh-cn/post/2025/01/yumdnfapt%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/","title":"yum、dnf、apt包管理工具"},{"content":" 往期推荐\n如何设计一个能根据任务优先级来执行的线程池-CSDN博客\n【泛型擦除】通过反射向List中添加不同类型的元素-CSDN博客\nJava io模型-CSDN博客\nJava异常族谱-CSDN博客 消息推送一般分为 Web 端消息推送和移动端消息推送。，分为推和拉两种形式。\n短轮询 拉的方式，最简单的实现方式就是前端写个定时器，每隔一段时间向后台请求未读消息。然而如果推送数据不会频繁变更，无论后端此时是否有新的消息产生，客户端都会进行请求，势必会对服务端造成很大压力，浪费带宽和服务器资源。而如果数据频繁变更，比如：每10s请求一次配置，如果在第11s时配置更新了，那么推送将会延迟9s，等待下一次请求，又造成数据延迟。\n长轮询 长轮询是对上边短轮询的一种改进版本，在尽可能减少对服务器资源浪费的同时，保证消息的相对实时性。长轮询在中间件中应用的很广泛，比如 Nacos 和 Apollo 配置中心，消息队列 Kafka、RocketMQ 中都有用到长轮询。\n原理：客户端发起请求后，服务端不会立即返回请求结果，而是将请求挂起等待一段时间，如果此段时间内服务端数据变更，立即响应客户端请求，若是一直无变化则等到指定的超时时间后响应请求，客户端重新发起长链接。\niframe流 在页面中插入一个隐藏的\u0026lt;iframe\u0026gt;标签，通过在src中请求消息数量 API 接口，由此在服务端和客户端之间创建一条长连接，服务端持续向iframe传输数据。\n缺点：rame 流的服务器开销很大，还不如短轮询，而且 IE、Chrome 等浏览器一直会处于 loading 状态，很不推荐！！！\n这种方式实现简单，前端只要一个\u0026lt;iframe\u0026gt;标签搞定了\n1 \u0026lt;iframe src=\u0026#34;/iframe/message\u0026#34; style=\u0026#34;display:none\u0026#34;\u0026gt;\u0026lt;/iframe\u0026gt; 后端直接组装HTML、JS返回即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Controller @RequestMapping(\u0026#34;/iframe\u0026#34;) public class IframeController { @GetMapping(path = \u0026#34;message\u0026#34;) public void message(HttpServletResponse response) throws IOException, InterruptedException { while (true) { response.setHeader(\u0026#34;Pragma\u0026#34;, \u0026#34;no-cache\u0026#34;); response.setDateHeader(\u0026#34;Expires\u0026#34;, 0); response.setHeader(\u0026#34;Cache-Control\u0026#34;, \u0026#34;no-cache,no-store\u0026#34;); response.setStatus(HttpServletResponse.SC_OK); response.getWriter().print(\u0026#34; \u0026lt;script type=\\\u0026#34;text/javascript\\\u0026#34;\u0026gt;\\n\u0026#34; + \u0026#34;parent.document.getElementById(\u0026#39;clock\u0026#39;).innerHTML = \\\u0026#34;\u0026#34; + count.get() + \u0026#34;\\\u0026#34;;\u0026#34; + \u0026#34;parent.document.getElementById(\u0026#39;count\u0026#39;).innerHTML = \\\u0026#34;\u0026#34; + count.get() + \u0026#34;\\\u0026#34;;\u0026#34; + \u0026#34;\u0026lt;/script\u0026gt;\u0026#34;); } } } SSE 服务端向客户端推送消息，其实除了可以用WebSocket（长连接、双向）这种耳熟能详的机制外，还有一种服务器发送事件(Server-Sent Events)，简称 SSE。这是一种服务器端到客户端(浏览器)的单向消息推送。 ChatGPT 就是采用的 SSE。对于需要长时间等待响应的对话场景，ChatGPT 采用了一种巧妙的策略：它会将已经计算出的数据\u0026quot;推送\u0026quot;给用户，并利用 SSE 技术在计算过程中持续返回数据。这样做的好处是可以避免用户因等待时间过长而选择关闭页面。 **SSE基于HTTP协议，**在服务器和客户端之间打开一个单向通道，服务端响应的不再是一次性的数据包而是text/event-stream类型的数据流信息，在有数据变更时从服务器流式传输到客户端，有点类似于在线视频播放，视频流会连续不断的推送到浏览器\n前端实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \u0026lt;script\u0026gt; let source = null; let userId = 7777 if (window.EventSource) { // 建立连接 source = new EventSource(\u0026#39;http://localhost:7777/sse/sub/\u0026#39;+userId); setMessageInnerHTML(\u0026#34;连接用户=\u0026#34; + userId); /** * 连接一旦建立，就会触发open事件 * 另一种写法：source.onopen = function (event) {} */ source.addEventListener(\u0026#39;open\u0026#39;, function (e) { setMessageInnerHTML(\u0026#34;建立连接。。。\u0026#34;); }, false); /** * 客户端收到服务器发来的数据 * 另一种写法：source.onmessage = function (event) {} */ source.addEventListener(\u0026#39;message\u0026#39;, function (e) { setMessageInnerHTML(e.data); }); } else { setMessageInnerHTML(\u0026#34;你的浏览器不支持SSE\u0026#34;); } \u0026lt;/script\u0026gt; 后端实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 private static Map\u0026lt;String, SseEmitter\u0026gt; sseEmitterMap = new ConcurrentHashMap\u0026lt;\u0026gt;(); /** * 创建连接 */ public static SseEmitter connect(String userId) { try { // 设置超时时间，0表示不过期。默认30秒 SseEmitter sseEmitter = new SseEmitter(0L); // 注册回调 sseEmitter.onCompletion(completionCallBack(userId)); sseEmitter.onError(errorCallBack(userId)); sseEmitter.onTimeout(timeoutCallBack(userId)); sseEmitterMap.put(userId, sseEmitter); count.getAndIncrement(); return sseEmitter; } catch (Exception e) { log.info(\u0026#34;创建新的sse连接异常，当前用户：{}\u0026#34;, userId); } return null; } /** * 给指定用户发送消息 */ public static void sendMessage(String userId, String message) { if (sseEmitterMap.containsKey(userId)) { try { sseEmitterMap.get(userId).send(message); } catch (IOException e) { log.error(\u0026#34;用户[{}]推送异常:{}\u0026#34;, userId, e.getMessage()); removeUser(userId); } } } WebSocket 基于TCP连接的双全工协议，工作流程如下：\n客户端向服务器发送一个 HTTP 请求，请求头中包含 Upgrade: websocket 和 Sec-WebSocket-Key 等字段，表示要求升级协议为 WebSocket； 服务器收到这个请求后，会进行升级协议的操作，如果支持 WebSocket，它将回复一个 HTTP 101 状态码，响应头中包含 ，Connection: Upgrade和 Sec-WebSocket-Accept: xxx 等字段、表示成功升级到 WebSocket 协议。 客户端和服务器之间建立了一个 WebSocket 连接 ，可以进行双向的数据传输，通过心跳机制 来保持 WebSocket 连接的稳定性和活跃性。数据以帧（frames）的形式进行传送，而不是传统的 HTTP 请求和响应。WebSocket 的每条消息可能会被切分成多个数据帧（最小单位）。发送端会将消息切割成多个帧发送给接收端，接收端接收消息帧，并将关联的帧重新组装成完整的消息。 **客户端或服务器可以主动发送一个关闭帧，表示要断开连接。**另一方收到后，也会回复一个关闭帧，然后双方关闭 TCP 连接。 MQTT 基于发布/订阅模式的轻量级通讯协议，通过订阅相应的主题来获取消息，是物联网中的一个标准传输协议。 TCP 协议位于传输层，MQTT 协议位于应用层，MQTT 协议构建于 TCP/IP 协议上，也就是说只要支持 TCP/IP 协议栈的地方，都可以使用 MQTT 协议。 ","date":"2025-01-09T12:00:00Z","permalink":"/zh-cn/post/2025/01/web%E5%AE%9E%E6%97%B6%E6%B6%88%E6%81%AF%E6%8E%A8%E9%80%81%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%A1%88/","title":"Web实时消息推送的几种方案"},{"content":" 不同的线程池会选用不同的阻塞队列作为任务队列，比如FixedThreadPool 使用的是LinkedBlockingQueue（有界队列），默认构造器初始的队列长度为 Integer.MAX_VALUE ，由于队列永远不会被放满，因此FixedThreadPool最多只能创建核心线程数的线程。 假如需要实现一个优先级任务线程池的话，那可以考虑使用 PriorityBlockingQueue （优先级阻塞队列）作为任务队列（ThreadPoolExecutor 的构造函数有一个 workQueue 参数可以传入任务队列）。 要想让 PriorityBlockingQueue 实现对任务的排序，传入其中的任务必须是具备排序能力的，方式有两种：\n实现 Comparable 接口 提交到线程池的任务实现 Comparable 接口，并重写 compareTo 方法来指定任务之间的优先级比较规则。\n缺点：1.任务类必须实现 Comparable 接口，硬编码不够灵活。2.如果需要多种优先级规则，任务类代码会变得复杂。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 import java.util.concurrent.*; public class PriorityTask implements Runnable, Comparable\u0026lt;PriorityTask\u0026gt; { private final int priority; private final String name; public PriorityTask(int priority, String name) { this.priority = priority; this.name = name; } @Override public void run() { System.out.println(\u0026#34;Executing task: \u0026#34; + name + \u0026#34; with priority: \u0026#34; + priority); } @Override public int compareTo(PriorityTask other) { return Integer.compare(this.priority, other.priority); // 优先级值越小，优先级越高 } } public class PriorityThreadPoolExecutor extends ThreadPoolExecutor { public PriorityThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit) { super(corePoolSize, maximumPoolSize, keepAliveTime, unit, new PriorityBlockingQueue\u0026lt;Runnable\u0026gt;()); } } //使用示例 public class Main { public static void main(String[] args) { PriorityThreadPoolExecutor executor = new PriorityThreadPoolExecutor(2, 4, 1, TimeUnit.MINUTES); executor.execute(new PriorityTask(10, \u0026#34;Low priority task\u0026#34;)); executor.execute(new PriorityTask(1, \u0026#34;High priority task\u0026#34;)); executor.execute(new PriorityTask(5, \u0026#34;Medium priority task\u0026#34;)); executor.shutdown(); } } Comparator 创建 PriorityBlockingQueue 时传入一个 Comparator 对象来指定任务之间的排序规则(推荐)。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 import java.util.concurrent.*; public class Task implements Runnable { private final int priority; private final String name; public Task(int priority, String name) { this.priority = priority; this.name = name; } @Override public void run() { System.out.println(\u0026#34;Executing task: \u0026#34; + name + \u0026#34; with priority: \u0026#34; + priority); } public int getPriority() { return priority; } } public class PriorityThreadPoolExecutor extends ThreadPoolExecutor { public PriorityThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit) { super(corePoolSize, maximumPoolSize, keepAliveTime, unit, new PriorityBlockingQueue\u0026lt;\u0026gt;(11, Comparator.comparingInt(Task::getPriority))); } } //使用示例 public class Main { public static void main(String[] args) { PriorityThreadPoolExecutor executor = new PriorityThreadPoolExecutor(2, 4, 1, TimeUnit.MINUTES); executor.execute(new Task(10, \u0026#34;Low priority task\u0026#34;)); executor.execute(new Task(1, \u0026#34;High priority task\u0026#34;)); executor.execute(new Task(5, \u0026#34;Medium priority task\u0026#34;)); executor.shutdown(); } } ","date":"2025-01-08T11:45:00Z","permalink":"/zh-cn/post/2025/01/%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E8%83%BD%E6%A0%B9%E6%8D%AE%E4%BB%BB%E5%8A%A1%E4%BC%98%E5%85%88%E7%BA%A7%E6%9D%A5%E6%89%A7%E8%A1%8C%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%B1%A0/","title":"如何设计一个能根据任务优先级来执行的线程池"},{"content":"\n为了保证操作系统的稳定性和安全性，一个进程的地址空间划分为 用户空间（User space） 和 内核空间（Kernel space ） 。\n像我们平常运行的应用程序都是运行在用户空间，只有内核空间才能进行系统态级别的资源有关的操作，比如文件管理、进程通信、内存管理等等。也就是说，我们想要进行 IO 操作，一定是要依赖内核空间的能力。并且，用户空间的程序不能直接访问内核空间。当想要执行 IO 操作时，由于没有执行这些操作的权限，只能发起系统调用请求操作系统帮忙完成。\n因此，用户进程想要执行 IO 操作的话，必须通过 系统调用 来间接访问内核空间\n我们在平常开发过程中接触最多的就是 磁盘 IO（读写文件） 和 网络 IO（网络请求和响应）。\n从应用程序的视角来看的话，我们的应用程序对操作系统的内核发起 IO 调用（系统调用），操作系统负责的内核执行具体的 IO 操作。也就是说，我们的应用程序实际上只是发起了 IO 操作的调用而已，具体 IO 的执行是由操作系统的内核来完成的。\n同步/异步、阻塞/非阻塞 同步/异步关注的是任务执行的顺序性 ，阻塞/非阻塞关注的是线程是否被挂起，有无回调。\nJava常见IO模型 同步阻塞BIO 同步阻塞 IO 模型中，应用程序发起 read 调用后，会一直阻塞，直到内核把数据拷贝到用户空间。\n同步非阻塞NIO jdk4引入，同步非阻塞 IO 模型中，应用程序会一直发起 read 调用，等待数据从内核空间拷贝到用户空间的这段时间里，线程依然是阻塞的，直到在内核把数据拷贝到用户空间。\n但是，这种 IO 模型同样存在问题：应用程序不断进行 I/O 系统调用轮询数据是否已经准备好的过程是十分消耗 CPU 资源的。\nIO多路复用 IO 多路复用模型中，线程首先发起 select 调用 ，询问内核数据是否准备就绪，等内核把数据准备好了，用户线程再发起 read 调用 。read 调用的过程（数据从内核空间 -\u0026gt; 用户空间）还是阻塞的 。IO多路复用减少无效的系统调用，减少了对 CPU 资源的消耗。\nJava 中的 NIO ，有一个非常重要的选择器 ( Selector ) 的概念，也可以被称为 多路复用器。通过它，只需要一个线程便可以管理多个客户端连接。当客户端数据到了之后，才会为其服务。\n注意！ 使用 NIO 并不一定意味着高性能，它的性能优势主要体现在高并发和高延迟的网络环境下。当连接数较少、并发程度较低或者网络传输速度较快时，NIO 的性能并不一定优于传统的 BIO 。\n到此我们发现，上述几种都不是异步IO，他们区别在于发起read请求时是否阻塞，但是在从内核空间拷贝数据到用户空间的过程中始终是阻塞的。\nBuffer 在传统的 BIO 中，数据的读写是面向流的， 分为字节流和字符流。在 Java 1.4 的 NIO 库中，所有数据都是用缓冲区处理的\nChannel channel是一个双向通道（双全工），可以同时用于读写，而inputStream流和outputStream流则是单向的\nSelector Selector（选择器） 它允许一个线程处理多个 Channel。Selector 是基于事件驱动的 I/O 多路复用模型。\n主要运作原理是：通过 Selector 注册通道的事件，Selector 会不断地轮询注册在其上的 Channel。当事件发生时，比如：某个 Channel 上面有新的 TCP 连接接入、读和写事件，这个 Channel 就处于就绪状态 ，会被 Selector 轮询出来。Selector 会将相关的 Channel 加入到就绪集合中。通过 SelectionKey 可以获取就绪 Channel 的集合，然后对这些就绪的 Channel 进行相应的 I/O 操作。\nJava NIO 核心知识总结 | JavaGuide\n零拷贝NIO 零拷贝是提升 IO 操作性能的一个常用手段，指计算机执行 IO 操作时，CPU 不需要将数据从一个存储区域复制到另一个存储区域，从而可以减少上下文切换以及 CPU 的拷贝时间。 也就是说，零拷贝主要解决操作系统在处理 I/O 操作时频繁复制数据的问题。零拷贝的常见实现技术有： mmap+write、sendfile和 sendfile + DMA gather copy 。\nJava 对零拷贝的支持：\nMappedByteBuffer 是 NIO 基于内存映射 （mmap）这种零拷⻉⽅式的提供的⼀种实现，底层实际是调用了 Linux 内核的 mmap 系统调用。它可以将一个文件或者文件的一部分映射到内存中，形成一个虚拟内存文件，这样就可以直接操作内存中的数据，而不需要通过系统调用来读写文件。 FileChannel 的transferTo()/transferFrom()是 NIO 基于发送文件（sendfile）这种零拷贝方式的提供的一种实现，底层实际是调用了 Linux 内核的 sendfile系统调用。它可以直接将文件数据从磁盘发送到网络，而不需要经过用户空间的缓冲区。 异步AIO AIO 也就是 NIO 2。Java 7 中引入了 NIO 的**改进版 NIO 2,**它是异步 IO 模型。\n异步 IO 是基于事件和回调机制实现的，也就是应用发起read操作之后会直接返回，不会堵塞在那里，当内核后台完成数据拷贝，会执行回调函数来通知应用。\n--- ","date":"2025-01-07T13:26:47Z","permalink":"/zh-cn/post/2025/01/java-io%E6%A8%A1%E5%9E%8B----bionioaioio%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E9%9B%B6%E6%8B%B7%E8%B4%9D/","title":"Java io模型----BIO、NIO、AIO、IO多路复用、零拷贝"},{"content":"\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 ArrayList\u0026lt;String\u0026gt; list= new ArrayList\u0026lt;String\u0026gt;(); //泛型擦除,输出true System.out.println(strings.getClass().equals(integers.getClass())); list.add(\u0026#34;xxx\u0026#34;); //编译时错误，无法通过编译 //strings.add(18); Class\u0026lt;? extends ArrayList\u0026gt; clazz= list.getClass(); Method add = clazz.getMethod(\u0026#34;add\u0026#34;, Object.class); //运行时可以通过 add.invoke(list,17); //输出 [xxx,17] System.out.println(strings.toString()); --- ","date":"2025-01-04T19:31:55Z","permalink":"/zh-cn/post/2025/01/%E6%B3%9B%E5%9E%8B%E6%93%A6%E9%99%A4%E9%80%9A%E8%BF%87%E5%8F%8D%E5%B0%84%E5%90%91list%E4%B8%AD%E6%B7%BB%E5%8A%A0%E4%B8%8D%E5%90%8C%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%85%83%E7%B4%A0/","title":"【泛型擦除】通过反射向List中添加不同类型的元素"},{"content":"概览 在Exception异常中，大致又分为checked Exception（非运行时异常、受检异常）和unchecked Exception（运行时异常、非受检异常）\n受检异常\n在程序编译阶段就要被检查出来并处理掉的（try~catch或者在方法外面throws），否则程序无法通过编译，比如ClassNotFound、FileNotFoundException。\n非受检异常\n可以通过编译，但是会在程序运行过程中爆露出来，比如常见的空指针、参数错误、类型转换错误 。\ntry-catch-finally try块：用于捕获异常。其后可接零个或多个 catch 块，如果没有 catch 块，则必须跟一个 finally 块。 catch块：用于处理 try 捕获到的异常。 finally 块：无论是否捕获或处理异常，finally 块里的语句都会被执行。当在 try 块或 catch 块中遇到 return 语句时，finally 语句块将在方法return之前被执行。 finally的代码在某些情况下也不是必须执行的，比如JVM终止、线程死亡。 throws和throw throws：用于在方法声明中声明可能抛出的异常类型。如果一个方法可能抛出异常，但不想在方法内部进行处理，可以使用throws关键字将异常传递（上抛）给调用者来处理，直至被catch或者抛给前端用户。 throw：手动抛出异常。可以根据需要在代码中使用throw语句主动抛出特定类型的异常比如自定义异常。 --- ","date":"2024-12-31T12:00:00Z","permalink":"/zh-cn/post/2024/12/java%E5%BC%82%E5%B8%B8%E6%97%8F%E8%B0%B1%E8%BF%90%E8%A1%8C%E6%97%B6%E5%BC%82%E5%B8%B8%E9%9D%9E%E8%BF%90%E8%A1%8C%E6%97%B6%E5%BC%82%E5%B8%B8error/","title":"Java异常族谱、运行时异常、非运行时异常、ERROR"},{"content":"\n编译型： 通过编译器将源代码一次性翻译成 可被该平台执行的机器码。一般情况下，编译语言的执行速度比较快，跨平台性差。常见的编译性语言有 C、C++、Go、Rust 等等。 解释型： 会通过解释器一句一句的将代码解释（interpret）为机器代码后再执行。解释型语言执行速度比较慢。常见的解释性语言有 Python、JavaScript、PHP 等等。 为什么说 Java 语言\u0026quot;编译与解释并存\u0026quot;？ 由 Java 编写的程序需要先经过编译步骤，生成字节码（.class 文件），这种字节码必须由 Java 解释器来解释执行。\n常用的java编译模式是JIT（即时编译）即动态编译，在程序执行期间编译，因此支持反射、动态代理等特性。（Spring生态很多就依赖的java的代理、反射特性） JDK 9 引入了一种新的编译模式 AOT 。这种编译模式会在程序被执行前就将其编译成机器码 ，属于静态编译（C、 C++，Rust，Go 等语言就是静态编译）。AOT 避免了 JIT 预热等各方面的开销，可以提高 Java 程序的启动速度，避免预热时间长。并且，AOT 还能减少内存占用和增强 Java 程序的安全性（AOT 编译后的代码不容易被反编译和修改），特别适合云原生场景。 ","date":"2024-12-31T12:00:00Z","permalink":"/zh-cn/post/2024/12/%E7%BC%96%E8%AF%91%E4%B8%8E%E8%A7%A3%E9%87%8A%E5%B9%B6%E5%AD%98%E7%9A%84java/","title":"编译与解释并存的Java"},{"content":" Java 泛型（Generics） 是 JDK 5 中引入的一个新特性。可以在编译时提供更强的类型检查 ，并且在编译后能够保留类型信息，避免了在运行时出现类型转换异常。\n泛型3种用法 泛型一般有三种使用方式:泛型类 、泛型接口 、泛型方法。\n泛型类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 //此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型 //在实例化泛型类时，必须指定T的具体类型 public class Generic\u0026lt;T\u0026gt;{ private T key; public Generic(T key) { this.key = key; } public T getKey(){ return key; } } //实例化泛型类 Generic\u0026lt;Integer\u0026gt; genericInteger = new Generic\u0026lt;Integer\u0026gt;(123456); 泛型接口 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 //泛型接口 public interface Generator\u0026lt;T\u0026gt; { public T method(); } //实现接口，不指定类型 class GeneratorImpl\u0026lt;T\u0026gt; implements Generator\u0026lt;T\u0026gt;{ @Override public T method() { return null; } } //实现泛型接口，指定类型 class GeneratorImpl implements Generator\u0026lt;String\u0026gt; { @Override public String method() { return \u0026#34;hello\u0026#34;; } } 泛型方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 //泛型方法 public static \u0026lt; E \u0026gt; void printArray( E[] inputArray ) { for ( E element : inputArray ){ System.out.printf( \u0026#34;%s \u0026#34;, element ); } System.out.println(); } //使用 //创建不同类型数组：Integer, Double 和 Character Integer[] intArray = { 1, 2, 3 }; String[] stringArray = { \u0026#34;Hello\u0026#34;, \u0026#34;World\u0026#34; }; printArray( intArray ); printArray( stringArray ); 案例：通用结果返回类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 public class BaseResponse\u0026lt;T\u0026gt; implements Serializable { private int code; private T data; private String message; public BaseResponse(int code, T data, String message) { this.code = code; this.data = data; this.message = message; } public BaseResponse(int code, T data) { this(code, data, \u0026#34;\u0026#34;); } public BaseResponse(ErrorCode errorCode) { this(errorCode.getCode(), null, errorCode.getMessage()); } } public class ResultUtil { /** * 成功 * * @param data * @param \u0026lt;T\u0026gt; * @return */ public static \u0026lt;T\u0026gt; BaseResponse\u0026lt;T\u0026gt; success(T data) { return new BaseResponse\u0026lt;\u0026gt;(200, data, \u0026#34;ok\u0026#34;); } /** * 失败 * * @param errorCode * @return */ public static BaseResponse error(ErrorCode errorCode) { return new BaseResponse\u0026lt;\u0026gt;(errorCode); } /** * 失败 * * @param errorCode * @return */ public static BaseResponse error(ErrorCode errorCode, String message) { return new BaseResponse(errorCode.getCode(), null, message); } } --- ","date":"2024-12-31T11:00:00Z","permalink":"/zh-cn/post/2024/12/java%E6%B3%9B%E5%9E%8B/","title":"Java泛型"},{"content":" String.intern() 是一个 native (本地) 方法，用来处理字符串常量池中的字符串对象引用。它的工作流程可以概括为以下两种情况：\n常量池中已有相同内容的字符串对象 ：如果字符串常量池中已经有一个与调用 intern() 方法的字符串内容相同的 String 对象，intern() 方法会直接返回常量池中该对象的引用。 常量池中没有相同内容的字符串对象 ：如果字符串常量池中还没有一个与调用 intern() 方法的字符串内容相同的对象，intern() 方法会将当前字符串对象的引用添加到字符串常量池中，并返回该引用。 总结 intern() 方法的主要作用是确保字符串引用在常量池中的唯一性。 当调用 intern() 时，如果常量池中已经存在相同内容的字符串，则返回常量池中已有对象的引用；否则，将该字符串添加到常量池并返回其引用。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 // s1 指向字符串常量池中的 \u0026#34;Java\u0026#34; 对象 String s1 = \u0026#34;Java\u0026#34;; // s2 也指向字符串常量池中的 \u0026#34;Java\u0026#34; 对象，和 s1 是同一个对象 String s2 = s1.intern(); // 在堆中创建一个新的 \u0026#34;Java\u0026#34; 对象，s3 指向它 String s3 = new String(\u0026#34;Java\u0026#34;); // s4 指向字符串常量池中的 \u0026#34;Java\u0026#34; 对象，和 s1 是同一个对象 String s4 = s3.intern(); // s1 和 s2 指向的是同一个常量池中的对象 System.out.println(s1 == s2); // true // s3 指向堆中的对象，s4 指向常量池中的对象，所以不同 System.out.println(s3 == s4); // false // s1 和 s4 都指向常量池中的同一个对象 System.out.println(s1 == s4); // true --- ","date":"2024-12-30T12:00:00Z","permalink":"/zh-cn/post/2024/12/string.intern/","title":"String.intern()"},{"content":"==和equals区别 ==用于基本数据类型，比较的是值，用于引用类型，比较的是对象的内存地址。 java中只有值传递，因此对于引用类型，实际比较的引用的内存地址的值。 equals不能用来判断基本数据类型，只能判断引用数据类型，判断两个对象是否相等。 1 2 3 4 5 6 7 8 String a = new String(\u0026#34;ab\u0026#34;); // a 为一个引用 String b = new String(\u0026#34;ab\u0026#34;); // b为另一个引用,对象的内容一样 String aa = \u0026#34;ab\u0026#34;; // 放在常量池中 String bb = \u0026#34;ab\u0026#34;; // 从常量池中查找 System.out.println(aa == bb);// true System.out.println(a == b);// false System.out.println(a.equals(b));// true System.out.println(42 == 42.0);// true hashcode 把输入的值经过哈希算法得出哈希码，即散列码，用来确定对象在哈希表的索引位置。 hashCode() 定义在 JDK 的 Object 类中，这就意味着 Java 中的任何类都包含有 hashCode() 函数。另外需要注意的是：Object 的 hashCode() 方法是本地方法，也就是用 C 语言或 C++ 实现的。 为什么JDK同时提供hashCode() 和 equals()方法 hashCode() 和 equals()都是用于比较两个对象是否相等。\n为什么 JDK 还要同时提供这两个方法呢？\n这是因为在一些容器（比如 HashMap、HashSet）中，有了 hashCode() 之后，判断元素是否在对应容器中的效率会更高（参考添加元素进HashSet的过程）！\n我们在前面也提到了添加元素进HashSet的过程，如果 HashSet 在对比的时候，同样的 hashCode 有多个对象，它会继续使用 equals() 来判断是否真的相同。也就是说 hashCode 帮助我们大大缩小了查找成本。 为什么不只提供 hashCode() 方法呢？\n这是因为两个对象的hashCode 值相等并不代表两个对象就相等。 那为什么两个对象有相同的 hashCode 值，它们也不一定是相等的？\n因为 hashCode() 所使用的哈希算法也许刚好会让多个对象传回相同的哈希值。越糟糕的哈希算法越容易碰撞，但这也与数据值域分布的特性有关（所谓哈希碰撞也就是指的是不同的对象得到相同的 hashCode )。 ","date":"2024-12-29T15:23:14Z","permalink":"/zh-cn/post/2024/12/equalshashcode/","title":"==、equals、hashcode"},{"content":"1.为何String不可变 java8之前，String的源码中是用字符数组实现的，同时使用了final和private修饰，被final修饰的结果就是变量不可修改、类不可继承、方法不可重写，被private修饰就无法对外暴露，这就是为何String不可变。 java8之后，String改成了用字节数组实现。 新版的 String 其实支持两个编码方案：Latin-1 和 UTF-16。如果字符串中包含的汉字没有超过 Latin-1 可表示范围内的字符，那就会使用 Latin-1 作为编码方案。Latin-1 编码方案下，byte 占一个字节(8 位)，char 占用 2 个字节（16），byte 相较 char 节省一半的内存空间。JDK 官方就说了绝大部分字符串对象只包含 Latin-1 可表示的字符。 2.String的运算符重载 Java 语言本身并不支持运算符重载，\u0026quot;+\u0026ldquo;和\u0026rdquo;+=\u0026ldquo;是专门为 String 类重载过的运算符，也是 Java 中仅有的两个重载过的运算符。\n1 2 3 4 String str1 = \u0026#34;he\u0026#34;; String str2 = \u0026#34;llo\u0026#34;; String str3 = \u0026#34;world\u0026#34;; String str4 = str1 + str2 + str3; 可以看出，字符串对象通过\u0026rdquo;+\u0026ldquo;的字符串拼接方式，实际上是通过 StringBuilder 调用 append() 方法实现的，拼接完成之后调用 toString() 得到一个 String 对象 。\n不过，在循环内使用\u0026rdquo;+\u0026ldquo;进行字符串的拼接的话，存在比较明显的缺陷：编译器不会创建单个 StringBuilder 以复用， 意味着每循环一次就会创建一个 StringBuilder 对象，会导致创建过多的 StringBuilder 对象。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 //在循环内使用+号每次都会创建新的StringBuilder String[] arr = {\u0026#34;he\u0026#34;, \u0026#34;llo\u0026#34;, \u0026#34;world\u0026#34;}; String s = \u0026#34;\u0026#34;; for (int i = 0; i \u0026lt; arr.length; i++) { s += arr[i]; } System.out.println(s); //避免了上述问题 String[] arr = {\u0026#34;he\u0026#34;, \u0026#34;llo\u0026#34;, \u0026#34;world\u0026#34;}; StringBuilder s = new StringBuilder(); for (String value : arr) { s.append(value); } System.out.println(s); --- ","date":"2024-12-29T14:38:34Z","permalink":"/zh-cn/post/2024/12/%E4%B8%BA%E4%BD%95string%E4%B8%8D%E5%8F%AF%E5%8F%98string%E7%9A%84%E8%BF%90%E7%AE%97%E7%AC%A6%E9%87%8D%E8%BD%BD/","title":"为何String不可变，String的运算符重载"},{"content":"\n何为事务？ 一言蔽之，事务是逻辑上的一组操作，要么都执行，要么都不执行。 原子性 （Atomicity）：事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性 （Consistency）：执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的； 隔离性 （Isolation）：并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性 （Durability）：一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 只有保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。也就是说 A、I、D 是手段，C 是目的！\n周志明的软件架构课_软件架构_分布式系统_基础设施_架构演进_单体架构_SOA架构_微服务_云原生-极客时间\n1.并发事务的问题 {#1.1%E5%B9%B6%E5%8F%91%E4%BA%8B%E5%8A%A1%E7%9A%84%E9%97%AE%E9%A2%98} 丢失修改： 在事务 1 读取一个数据时，另外事务 2 也访问了该数据，那么在事务 1 中修改了这个数据后，事务 2 也修改了这个数据。这样事务 1 的修改结果就被丢失，因此称为丢失修改。 **例：**事务 1 读取某表中的数据 A=20，事务 2 也读取 A=20。事务 1 先修改 A=A-1，事务 2 后来也修改 A=A-1，最终结果 A=19，事务 1 的修改被丢失 脏读： 事务2读取了事务1未提交的数据 **例：**事务 1 读取某表中的数据 A=20并修改 A=A-1，事务 2 读取到 A = 19,事务 1 回滚导致对 A 的修改并未提交到数据库， A 的值还是 20 不可重复读： 事务 1 多次读同一数据。在事务 1 还没有结束时，事务 2 也访问该数据。那么，在事务 1 中的两次读数据之间，由于事务 2 的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。 **例：**事务 1 读取某表中的数据 A=20，事务 2 也读取 A=20，事务 1 修改 A=A-1，事务 2 再次读取 A =19，此时读取的结果和第一次读取的结果不同 幻读： 幻读与不可重复读类似。它发生在一个事务读取了几行数据，接着另一个并发事务插入了一些数据时。在随后的查询中，第一个事务就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。 **例：**事务 2 读取某个范围的数据，事务 1 在这个范围插入了新的数据，事务 2 再次读取这个范围的数据发现相比于第一次读取的结果多了新的数据 2.并发事务控制方式 {#1.2%E5%B9%B6%E5%8F%91%E4%BA%8B%E5%8A%A1%E6%8E%A7%E5%88%B6%E6%96%B9%E5%BC%8F} MySQL 中并发事务的控制方式无非就两种：锁 和 MVCC。锁可以看作是悲观控制的模式，多版本并发控制可以看作是乐观控制的模式。\nInnoDB存储引擎对MVCC的实现 | JavaGuide\n锁 控制方式下会通过锁来显式控制共享资源而不是通过调度手段，MySQL 中主要是通过 读写锁 来实现并发控制。\n共享锁（S 锁）：又称读锁，事务在读取记录的时候获取共享锁，允许多个事务同时获取（锁兼容）。 排他锁（X 锁）：又称写锁/独占锁，事务在修改记录的时候获取排他锁，不允许多个事务同时获取。如果一个记录已经被加了排他锁，那其他事务不能再对这条记录加任何类型的锁（锁不兼容）。 MVCC 是多版本并发控制方法，即对一份数据会存储多个版本，通过事务的可见性来保证事务能看到自己应该看到的版本。通常会有一个全局的版本分配器来为每一行数据设置版本号，版本号是唯一的。 MVCC 在 MySQL 中实现所依赖的手段主要是: 隐藏字段、read view、undo log。\n3.四个事务隔离级别 {#1.3%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB} Innodb中的事务隔离级别和锁的关系 - 美团技术团队\nMySQL 的隔离级别基于锁和 MVCC 机制共同实现的。 读已提交和 可重复读 隔离级别是基于 MVCC 实现的，可串行化 隔离级别是通过锁来实现的。 读未提交 (Read Uncommitted) 特点：在该隔离级别下，一个事务可以读取另一个事务尚未提交的数据。这就会导致脏读，即一个事务读取到的可能是另一个事务未提交的修改，这些修改可能会被回滚。 问题：事务B读取到事务A修改的值，但事务A回滚后，数据实际上没有变化。发生了脏读。 读已提交 (Read Committed) 特点：在该隔离级别下，一个事务只能读取到已提交事务的数据，因此脏读不会发生。\n问题：事务A在读取两次同一数据时，第二次读取的数据可能会因其他事务的提交而发生变化 ，这就是不可重复读 。\n「读已提交」事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致 ，因为可能这期间另外一个事务修改了该记录，并提交了事务。这就是不可重复读的问题\n可重复读 (Repeatable Read) 特点：在该隔离级别下，事务会看到在事务开始时一致的数据快照，不可重复读的问题被解决。 问题：如果事务A查询范围的数据（例如某一时间段内的所有交易记录），事务B插入 的新数据可能会被事务A在第二次查询中看到，导致事务A两次查询到的数据量不一致，这就是幻读，可重复读仅解决部分幻读。 用 Read View 只能保证\u0026quot;快照读\u0026quot;不幻读；一旦事务里出现\u0026quot;当前读\u0026quot;（UPDATE/DELETE/SELECT \u0026hellip; FOR UPDATE 等），就会重新加 Next-Key Lock，这时若别的事务新插入的记录落在这个锁范围里，就可能被本事务再次看到，于是出现\u0026quot;部分幻读\u0026quot;。\n「可重复读」隔离级别是启动事务时生成一个Read View，然后整个事务期间都在用 这个Read View ，这样就保证了在事务期间读到的数据都是事务启动前的记录。解决了不可重复读和部分幻读。 串行化 (Serializable) 特点：在该隔离级别下，事务是完全隔离、串行执行。其他事务必须等当前事务完成才能开始执行，这避免了所有并发问题（脏读、不可重复读和幻读），但也大大降低了性能。 4.幻读 幻读 VS 不可重复读\n幻读重点在于数据是否存在。原本不存在的数据却真实的存在了，这便是幻读。引起幻读的原因在于另一个事务进行了INSERT操作。 不可重复读重点在于数据值是否被改变。在一个事务中对同一条记录进行查询，第一次读取到的数据和第二次读取到的数据不一致，这便是可重复读。引起不可重复读的原因在于另一个事务进行了UPDATE或者是DELETE操作。 简单来说：幻读是说数据的条数发生了变化，原本不存在的数据存在了。不可重复读是说数据的内容发生了变化，原本存在的数据的内容发生了改变。\n可重复读隔离下为什么会产生幻读\n在可重复读隔离级别下，普通的查询是快照读 ，是不会看到别的事务插入的数据的，就没有幻读 。因此，幻读在 当前读（ select \u0026hellip; for update 等语句，使用临键锁**）** 下才会出现。\nMySQL里除了普通查询是快照读，其他都是当前读，比如update、insert、delete,这些语句执行前都会查询最新版本的数据，然后再做进一步的操作。\nMySQL中如何实现可重复读\n当隔离级别为可重复读的时候，事务只在第一次 SELECT 的时候会获取一次 Read View，而后面所有的 SELECT 都会复用这个 Read View。也就是说：不管其他事务怎么修改数据，，对于A事务而言，它能看到的数据永远都是第一次SELECT时看到的数据。这显然不合理，如果其它事务插入了数据，A事务却只能看到过去的数据，读取不了当前的数据。\n解决幻读的办法\nMySQL 可重复读隔离级别，完全解决幻读了吗？ | 小林coding{#解决幻读的方法}\n**解决幻读的核心思想就是事务A在操作某张表数据的时候，另外事务B不允许新增或者删除这张表中的数据。**解决幻读的方式主要有以下几种：\n将事务隔离级别调整为 SERIALIZABLE 。\n在可重复读的事务级别下，给事务操作的这张表添加表锁。\n在可重复读的事务级别下，给事务操作的这张表添加 临键锁。\n其他情况下的幻读\n在可重复读隔离级别下，事务A第一次执行普通的select语句时生成一个数据快照，之后事务B向表中新插入了一条id=5的记录并提交（此时是当前读）。接着，事务A对id=5这条记录进行了更新操作（看不见但是能更新），在这个时刻这条新记录的trx id隐藏列的值就变成了事务A的事务id，之后事务A再使用普通select语句去查询这条记录时就可以看到这条记录了，于是就发生了幻读。\n事务A先快照读，得到数据量为3，然后事务B插入一条数据并提交事务，事务A使用当前读得到的数量就是4了，前后数据量不对。\n要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行select for update这类当前读的语句，因为它会对记录加next-key lock，从而避免其他事务插入一条新记录。\n","date":"2024-12-27T12:00:00Z","permalink":"/zh-cn/post/2024/12/mysql%E5%9B%9B%E7%A7%8D%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E6%9C%BA%E5%88%B6/","title":"MySQL四种事务隔离机制"},{"content":"Java 基本数据类型的包装类型的大部分都用到了缓存机制来提升性能。\n**Byte,Short,Integer,Long**这 4 种包装类默认创建了数值 \\[-128，127\\] 的相应类型的缓存数据，Character 创建了数值在 \\[0,127\\] 范围的缓存数据，Boolean 直接返回 True or False。\n果超出对应范围仍然会去创建新的对象，缓存的范围区间的大小只是在性能和资源之间的权衡。\n两种浮点数类型的包装类 Float,Double 并没有实现缓存机制。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public static void main( String[] args ) { Integer i1 = 128; Integer i2 = 128; System.out.println(i1 == i2);// 输出 false Integer i3 = 33; Integer i4 = 33; System.out.println(i3 == i4);// 输出 true Float i11 = 333f; Float i22 = 333f; System.out.println(i11 == i22);// 输出 false Double i5 = 1.2; Double i6 = 1.2; System.out.println(i6 == i5);// 输出 false Integer i7 = 40; Integer i8 = new Integer(40); System.out.println(i7==i8);//输出false，因为i7直接用的缓存，i8则是创建的对象，存在堆 } 装箱其实就是调用了 包装类的valueOf()方法，拆箱其实就是调用了 xxxValue()方法。\n1 2 Integer i = 10 //等价于 Integer i = Integer.valueOf(10) int n = i //等价于 int n = i.intValue(); --- ","date":"2024-12-26T22:17:09Z","permalink":"/zh-cn/post/2024/12/java%E5%8C%85%E8%A3%85%E7%B1%BB%E5%9E%8B%E7%9A%84%E7%BC%93%E5%AD%98/","title":"Java包装类型的缓存"},{"content":"目录{#main-toc}\n1.字段类型{#%E5%AD%97%E6%AE%B5%E7%B1%BB%E5%9E%8B-toc}\n1.2VARCHAR(100)和 VARCHAR(10)区别{#VARCHAR(100)%E5%92%8C%20VARCHAR(10)%E5%8C%BA%E5%88%AB-toc}\n1.3DECIMAL 和 FLOAT/DOUBLE 区别{#DECIMAL%20%E5%92%8C%20FLOAT%2FDOUBLE%20%E5%8C%BA%E5%88%AB-toc}\n1.4TEXT和BLOB{#TEXT%E5%92%8CBLOB-toc}\n1.5DATETIME 和 TIMESTAMP{#%C2%A0DATETIME%20%E5%92%8C%20TIMESTAMP-toc}\n1.6NULL和\u0026quot;\u0026ldquo;的区别{#NULL%E5%92%8C%22%22%E7%9A%84%E5%8C%BA%E5%88%AB-toc}\n1.7为什么 MySQL 不建议使用 NULL 作为列默认值？{#%E4%B8%BA%E4%BB%80%E4%B9%88%20MySQL%20%E4%B8%8D%E5%BB%BA%E8%AE%AE%E4%BD%BF%E7%94%A8%C2%A0NULL%C2%A0%E4%BD%9C%E4%B8%BA%E5%88%97%E9%BB%98%E8%AE%A4%E5%80%BC%EF%BC%9F-toc}\n1.8Boolean类型如何表示{#Boolean%E7%B1%BB%E5%9E%8B%E5%A6%82%E4%BD%95%E8%A1%A8%E7%A4%BA-toc}\n2.MySQL基础架构{#MySQL%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84-toc}\n3.MySQL存储引擎{#MySQL%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%C2%A0-toc}\n3.1MyISAM和InnoDB区别{#MyISAM%E5%92%8CInnoDB%E5%8C%BA%E5%88%AB-toc}\nMySQL是建立在关系模型基础上的关系型数据库，关系模型表明了数据库中所存储的数据之间的联系（一对一、一对多、多对多）。\n1.字段类型 {#%E5%AD%97%E6%AE%B5%E7%B1%BB%E5%9E%8B} TINYINT占1字节，INT占4字节，BIGINT占8字节。 CHAR是定长字符串，VARCHAR是变长字符串。CHAR 在存储时会在右边填充空格以达到指定的长度，检索时会去掉空格；VARCHAR 在存储时需要使用 1 或 2 个额外字节 记录字符串的长度，检索时不需要处理。CHAR（100）指的是100个字符而非字节 MySQL中字符的存储是与字符集（CHARSET）相关的，具体的字节数取决于你使用的字符集和编码。 latin1 编码（单字节编码），每个字符占用 1 字节 。utf8mb4 编码（变长编码），每个字符可能占用 1 到 4 字节，具体取决于字符的内容。 1.2VARCHAR(100)和 VARCHAR(10)区别 {#VARCHAR(100)%E5%92%8C%20VARCHAR(10)%E5%8C%BA%E5%88%AB} VARCHAR(100)和 VARCHAR(10)都是变长类型，表示能存储最多 100 个字符和 10 个字符。但二者存储相同的字符串，所占用磁盘的存储空间其实是一样的，其所占用的磁盘空间是基于实际存储的字符长度，而不是字段的最大长度。\n1.3DECIMAL 和 FLOAT/DOUBLE 区别 {#DECIMAL%20%E5%92%8C%20FLOAT%2FDOUBLE%20%E5%8C%BA%E5%88%AB} DECIMAL 是定点数，可以存储精确的小数值。\nFLOAT（4字节），DOUBLE（8字节） 是浮点数，只能存储近似的小数值。\nDECIMAL 用于存储具有精度要求的小数，例如与货币相关的数据，可以避免浮点数带来的精度损失。\n1.4TEXT和BLOB {#TEXT%E5%92%8CBLOB} TEXT可以存储更长的字符串，即长文本数据，例如博客内容。 BLOB 类型主要用于存储二进制大对象，例如图片、音视频等文件。 TEXT和BLOB缺点： 不能有默认值。 检索效率较低。 在使用临时表时无法使用内存临时表，只能在磁盘上创建临时表。 不能直接创建索引，需要指定前缀长度。 1.5DATETIME 和 TIMESTAMP {#%C2%A0DATETIME%20%E5%92%8C%20TIMESTAMP} MySQL日期类型选择建议 | JavaGuide\nDATETIME 类型没有时区信息，TIMESTAMP 和时区有关。\n1.6NULL和\u0026quot;\u0026ldquo;的区别 {#NULL%E5%92%8C%22%22%E7%9A%84%E5%8C%BA%E5%88%AB} NULL 代表一个不确定的值,就算是两个 NULL,它俩也不一定相等。例如，SELECT NULL=NULL的结果为NULL ''的长度是 0，是不占用空间的，而NULL 是需要占用空间 1.7为什么 MySQL 不建议使用 NULL 作为列默认值？ {#%E4%B8%BA%E4%BB%80%E4%B9%88%20MySQL%20%E4%B8%8D%E5%BB%BA%E8%AE%AE%E4%BD%BF%E7%94%A8%C2%A0NULL%C2%A0%E4%BD%9C%E4%B8%BA%E5%88%97%E9%BB%98%E8%AE%A4%E5%80%BC%EF%BC%9F} NULL 会影响聚合函数的结果。例如，SUM、AVG、MIN、MAX 等聚合函数会忽略 NULL 值，如果参数是某个字段名(COUNT(列名))，则会忽略 NULL 值，只统计非空值的个数。查询 NULL 值时，必须使用 IS NULL 或 IS NOT NULLl 来判断，而不能使用 =、!=、 \u0026lt;、\u0026gt; 之类的比较运算符。而''是可以使用这些比较运算符的。\n1.8Boolean类型如何表示 {#Boolean%E7%B1%BB%E5%9E%8B%E5%A6%82%E4%BD%95%E8%A1%A8%E7%A4%BA} MySQL 中没有专门的布尔类型，而是用 TINYINT(1) 类型来表示布尔值。TINYINT(1) 类型可以存储 0 或 1，分别对应 false 或 true。\n2.MySQL基础架构 {#MySQL%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84} 连接器： 身份认证和权限相关(登录 MySQL 的时候)。 查询缓存： 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。 分析器： 没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。 优化器： 按照 MySQL 认为最优的方案去执行。 执行器： 执行语句，然后从存储引擎返回数据。 执行语句之前会先判断是否有权限，如果没有权限的话，就会报错。 插件式存储引擎 ：主要负责数据的存储和读取，采用的是插件式架构，支持 InnoDB、MyISAM、Memory 等多种存储引擎。InnoDB 是 MySQL 的默认存储引擎，绝大部分场景使用 InnoDB 就是最好的选择。 3.MySQL存储引擎 {#MySQL%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%C2%A0} MySQL :: MySQL 8.0 Reference Manual :: 17 The InnoDB Storage Engine\nMySQL :: MySQL 8.0 Reference Manual :: 18 Alternative Storage Engines\nMySQL 5.5.5 之前，MyISAM 是 MySQL 的默认存储引擎。5.5.5 版本之后，InnoDB 是 MySQL 的默认存储引擎。 在上述所有引擎中，只有InnoDB引擎支持事务。 上面还提到过MySQL 存储引擎采用的是 插件式架构 ，支持多种存储引擎。存储引擎是基于表的，而不是数据库。 3.1MyISAM和InnoDB区别 {#MyISAM%E5%92%8CInnoDB%E5%8C%BA%E5%88%AB} **锁：**MyISAM 只有表级锁，而 InnoDB 支持行级锁和表级锁，默认为行级锁。对于并发操作，细粒度的行级锁性能肯定更好！\n事务：\nMyISAM 不提供事务支持。InnoDB 提供事务支持，实现了四个隔离级别，分别是：读未提交、读已提交、可重复读、可串行化。InnoDB 默认是可重读，隔离级别是可以解决幻读问题发生的（基于 MVCC 和 Next-Key Lock）。\n**外键：**MyISAM 不支持物理外键，而 InnoDB 支持物理外键。然而外键的维护对数据库性能也有一定影响，特别是分布式、高并发项目，一个字段的更新往往会引起其他字段的更新，极大拉低数据库性能，因此是不建议使用物理外键，而是逻辑外键（在代码中进行约束）\n数据恢复 ：MyISAM 不支持，而 InnoDB 支持。使用 InnoDB 的数据库在异常崩溃后，数据库重新启动的时候依赖redo.log使数据库恢复到崩溃前的状态。\n**MVCC：**MVCC 可以看作是行级锁的一个升级，可以有效减少加锁操作，提高性能。MyISAM显然是不支持MVCC的，毕竟连行级锁都没有。\n**索引：**都使用 B+Tree 作为索引结构，但是两者的实现方式不太一样。InnoDB 引擎中，其数据文件本身就是索引文件。相比 MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按 B+Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录。\n数据缓存策略和机制：InnoDB 使用缓冲池（Buffer Pool）缓存数据页和索引页，MyISAM 使用键缓存（Key Cache）仅缓存索引页而不缓存数据页。当数据库对数据做修改的时候，需要把数据页从磁盘读到buffer pool中，然后在buffer pool中进行修改 ，此时buffer pool中的数据页就与磁盘上的数据页内容不一致，如果这个时候发生DB服务重启，那么这些数据并没有同步到磁盘文件中（同步到磁盘文件是个随机IO），就会发生数据丢失，如果这个时候，能够在有一个文件，当buffer pool 中的数据页变更结束后，把相应修改记录记录到这个文件（记录日志是顺序IO），那么当DB服务进行恢复DB的时候，可以根据这个文件的记录内容，重新持久化刷新到磁盘文件，保持数据的一致性。\n性能： InnoDB 的性能比 MyISAM 更强大，不管是在读写混合模式下还是只读模式下，随着 CPU 核数的增加，InnoDB 的读写能力呈线性增长。MyISAM 因为读写不能并发，它的处理能力跟核数没关系。\n4.MySQL如何存储IP地址 可以使用字符串存储，但是存储空间相对较大（每个字符占用1字节），每个IP占用空间为7-15个字节（1.1.1.1占用7字节，100.100.100.100占用15字节）。\n对于ipv4，其实是4字节32位的数字，可以将 IP 地址转换成整形数据存储，性能更好，占用空间也更小。\nMySQL 提供了两个方法来处理 ip 地址\nINET_ATON()：把 ip 转为无符号整型 (4-8 位) INET_NTOA() :把整型的 ip 转为地址 插入数据前，先用 INET_ATON() 把 ip 地址转为整型，显示数据时，使用 INET_NTOA() 把整型的 ip 地址转为地址显示即可。\n","date":"2024-12-26T14:43:23Z","permalink":"/zh-cn/post/2024/12/mysql%E5%85%A5%E9%97%A8%E6%A6%82%E8%BF%B0/","title":"MySQL入门概述"},{"content":"qhotKey链接\n京东hotkey把热点数据默认缓存在了本地缓存caffeine中，也可以存到redis中，但是京东hotkey的SDK没有redis的实现方法，因此需要自己实现。\n官方目录结构下：分别是client客户端（要打包引入到自己的项目）、common工具包（也打包引入到自己项目），dashboard（hotkey可视化面板，自己设置端口启动即可）、sample（实现demo）、worker（也要自己设置端口并且启动，用来和etcd交流信息）\n​\nclient是hotKey客户端，需要打包引入到我们自己的项目中（在自己项目中建个lib目录），刚开始打包报错，说是找不到某些模块，把父模块clean然后install一下，再打包client模块就好了。\nclient打成jar包后，要用的是with-dependencies包，并且要改名成hotkey-client-0.0.4-SNAPSHOT.jar，因为我们自己项目的依赖名字就是hotkey-client-0.0.4-SNAPSHOT.jar\n另外client的pom文件会加载不到一个plugin，这个时候需要设置一下groupId，去中央仓库看一下就知道了： ","date":"2024-12-21T11:58:09Z","permalink":"/zh-cn/post/2024/12/etcd-%E4%BA%AC%E4%B8%9Chotkey%E6%8E%A2%E6%B5%8B%E4%BD%BF%E7%94%A8/","title":"etcd+京东hotkey探测使用"},{"content":"\n测试之后发现是因为Map\u0026lt;Long,List\u0026lt;CommentVO\u0026gt;\u0026gt;的返回值类型的锅，改成Page\u0026lt;List\u0026lt;CommentVO\u0026gt;\u0026gt;即可解决。\n前端使用的umiMAX的openapi，报错如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 \u0026#39; originalRef: BaseResponse\u0026lt;\u0026lt;boolean\u0026gt;\u0026gt;\\n\u0026#39; + \u0026#39; \u0026#34;401\u0026#34;:\\n\u0026#39; + \u0026#39; description: Unauthorized\\n\u0026#39; + \u0026#39; \u0026#34;403\u0026#34;:\\n\u0026#39; + \u0026#39; description: Forbidden\\n\u0026#39; + \u0026#39; \u0026#34;404\u0026#34;:\\n\u0026#39; + \u0026#39; description: Not Found\\n\u0026#39; + \u0026#39; deprecated: false\\n\u0026#39; + \u0026#39; x-order: \u0026#34;2147483647\u0026#34;\\n\u0026#39; + \u0026#39; \u0026#34;/api/admin/passage/reject/{passageId}\u0026#34;:\\n\u0026#39; + \u0026#39; get:\\n\u0026#39; + \u0026#39; tags:\\n\u0026#39; + \u0026#39; - admin-passage-controller\\n\u0026#39; + \u0026#39; summary: rejectPassage\\n\u0026#39; + \u0026#39; operationId: rejectPassageUsingGET\\n\u0026#39; + \u0026#39; produces:\\n\u0026#39; + \u0026#39; - \u0026#34;*/*\u0026#34;\\n\u0026#39; + \u0026#39; parameters:\\n\u0026#39; + \u0026#39; - name: passageId\\n\u0026#39; + \u0026#39; in: path\\n\u0026#39; + \u0026#39; description: passageId\\n\u0026#39; + \u0026#39; \u0026#39;... 78804 more characters, externals: [], externalRefs: {}, rewriteRefs: true, preserveMiro: true, promise: { resolve: [Function (anonymous)], reject: [Function (anonymous)] }, patches: 0, cache: {}, openapi: { openapi: \u0026#39;3.0.0\u0026#39;, info: { description: \u0026#39;无问青秋博客\u0026#39;, version: \u0026#39;v1.0\u0026#39;, title: \u0026#39;Serein博客API接口测试\u0026#39;, contact: {} }, tags: [ { name: \u0026#39;admin-category-controller\u0026#39;, \u0026#39;x-order\u0026#39;: \u0026#39;2147483647\u0026#39; }, { name: \u0026#39;admin-comment-controller\u0026#39;, \u0026#39;x-order\u0026#39;: \u0026#39;2147483647\u0026#39; }, { name: \u0026#39;admin-passage-controller\u0026#39;, \u0026#39;x-order\u0026#39;: \u0026#39;2147483647\u0026#39; }, { name: \u0026#39;admin-tag-controller\u0026#39;, \u0026#39;x-order\u0026#39;: \u0026#39;2147483647\u0026#39; }, { name: \u0026#39;admin-user-controller\u0026#39;, \u0026#39;x-order\u0026#39;: \u0026#39;2147483647\u0026#39; }, { name: \u0026#39;category-controller\u0026#39;, \u0026#39;x-order\u0026#39;: \u0026#39;2147483647\u0026#39; }, { name: \u0026#39;comment-controller\u0026#39;, \u0026#39;x-order\u0026#39;: \u0026#39;2147483647\u0026#39; }, { name: \u0026#39;passage-controller\u0026#39;, \u0026#39;x-order\u0026#39;: \u0026#39;2147483647\u0026#39; }, { name: \u0026#39;tag-controller\u0026#39;, \u0026#39;x-order\u0026#39;: \u0026#39;2147483647\u0026#39; }, { name: \u0026#39;user-controller\u0026#39;, \u0026#39;x-order\u0026#39;: \u0026#39;2147483647\u0026#39; } ], paths: { \u0026#39;/api/admin/category/addCategory\u0026#39;: { post: { tags: [Array], summary: \u0026#39;addCategory\u0026#39;, operationId: \u0026#39;addCategoryUsingPOST\u0026#39;, requestBody: [Object], responses: [Object], responsesObject: [Object], deprecated: false, \u0026#39;x-order\u0026#39;: \u0026#39;2147483647\u0026#39; } }, 前端openapi生成接口报错 preserveMiro: true, promise: { resolve: [Function (anonymous)], reject: [Function (anonymous)] }, patches: 0, cache: {}, openapi: { openapi: '3.0.0', info: { description: '无问青秋博客', version: 'v1.0', title: 'Serein博客API接口测试', contact: {} }, tags: [ { name: 'admin-category-controller', 'x-order': '2147483647' }, { name: 'admin-comment-controller', 'x-order': '2147483647' }, { name: 'admin-passage-controller', 'x-order': '2147483647' }, { name: 'admin-tag-controller', 'x-order': '2147483647' }, { name: 'admin-user-controller', 'x-order': '2147483647' }, { name: 'category-controller', 'x-order': '2147483647' }, { name: 'comment-controller', 'x-order': '2147483647' }, { name: 'passage-controller', 'x-order': '2147483647' }, { name: 'tag-controller', 'x-order': '2147483647' }, { name: 'user-controller', 'x-order': '2147483647' } ], paths: { '/api/admin/category/addCategory': { post: { tags: [Array], summary: 'addCategory', operationId: 'addCategoryUsingPOST', requestBody: [Object], responses: [Object], responsesObject: [Object], deprecated: false, 'x-order': '2147483647' } }, '/api/admin/category/delete/{categoryId}': { put: { tags: [Array], summary: 'deleteCategory', operationId: 'deleteCategoryUsingPUT', parameters: [Array], responses: [Object], responsesObject: [Object], deprecated: false, 'x-order': '2147483647' } }, '/api/admin/comment/getComments/': { post: { tags: [Array], summary: 'getComments', operationId: 'getCommentsUsingPOST', requestBody: [Object], responses: [Object], responsesObject: [Object], deprecated: false, 'x-order': '2147483647' } }, '/api/user/userInfoData': { get: { tags: [Array], summary: 'getUserInfoData', operationId: 'getUserInfoDataUsingGET', responses: [Object], responsesObject: [Object], deprecated: false, 'x-order': '2147483647' } } }, 'x-openapi': { 'x-markdownFiles': null, 'x-setting': { language: 'zh-CN', enableSwaggerModels: true, swaggerModelName: 'Swagger Models', enableReloadCacheParameter: false, enableAfterScript: true, enableDocumentManage: true, enableVersion: false, enableRequestCache: true, enableFilterMultipartApis: false, enableFilterMultipartApiMethodType: 'POST', enableHost: false, enableHostText: '', enableDynamicParameter: false, enableDebug: true, enableFooter: true, enableFooterCustom: false, enableSearch: true, enableOpenApi: true, enableHomeCustom: false, enableGroup: true, enableResponseCode: true } }, servers: [ { url: '//127.0.0.1:8081/api' } ], components: { requestBodies: { QueryPageRequest: { content: [Object], description: 'queryPageRequest', required: true }, uploadPassageCoverUsingPOST: { content: [Object], required: true } }, schemas: { AddPassageDTO: { type: 'object', properties: [Object], title: 'AddPassageDTO' }, GetUserByIdListRequest: { type: 'object', properties: [Object], title: 'GetUserByIdListRequest' }, LoginRequest: { type: 'object', properties: [Object], title: 'LoginRequest' }, LoginUserVO: { type: 'object', properties: [Object], title: 'LoginUserVO' }, Page_List_UserVO_: { type: 'object', properties: [Object], title: 'Page\u0026lt;\u0026lt;List\u0026lt;\u0026lt;UserVO\u0026gt;\u0026gt;\u0026gt;\u0026gt;' } } } }, fetch: \u0026lt;ref *1\u0026gt; [Function: fetch] { isRedirect: [Function (anonymous)], Promise: [Function: Promise], default: [Circular *1], Headers: [class Headers], Request: [class Request], Response: [class Response], FetchError: [Function: FetchError] }, resolver: { depth: 0, base: undefined, actions: [ [] ] }, refmap: {} } } Node.js v20.10.0 --- ","date":"2024-12-16T22:39:23Z","permalink":"/zh-cn/post/2024/12/%E5%89%8D%E7%AB%AFopenapi%E6%A0%B9%E6%8D%AE%E5%90%8E%E7%AB%AFswagger%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E5%89%8D%E7%AB%AF%E6%8E%A5%E5%8F%A3%E6%8A%A5%E9%94%99/","title":"前端OpenAPI根据后端Swagger自动生成前端接口报错"},{"content":" 往期推荐\n【考前预习】3.计算机网络\u0026mdash;数据链路层-CSDN博客\n【考前预习】2.计算机网络\u0026mdash;物理层-CSDN博客\n【考前预习】1.计算机网络概述-CSDN博客\n目录{#main-toc}\n1.网络层概述{#1.%E7%BD%91%E7%BB%9C%E5%B1%82%E6%A6%82%E8%BF%B0-toc}\n2.网络层提供的两种服务{#2.%E7%BD%91%E7%BB%9C%E5%B1%82%E6%8F%90%E4%BE%9B%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%9C%8D%E5%8A%A1-toc}\n3.分类编址的IPV4{#3.%E5%88%86%E7%B1%BB%E7%BC%96%E5%9D%80%E7%9A%84IPV4-toc}\n4.无分类编址的IPV4\u0026mdash;CIDR{#4.%E6%97%A0%E5%88%86%E7%B1%BB%E7%BC%96%E5%9D%80%E7%9A%84IPV4%E2%80%94CIDR-toc}\n5.IPV4地址应用规划{#5.IPV4%E5%9C%B0%E5%9D%80%E5%BA%94%E7%94%A8%E8%A7%84%E5%88%92-toc}\n5.1使用定长子网掩码划分子网{#5.1%E4%BD%BF%E7%94%A8%E5%AE%9A%E9%95%BF%E5%AD%90%E7%BD%91%E6%8E%A9%E7%A0%81%E5%88%92%E5%88%86%E5%AD%90%E7%BD%91-toc}\n​编辑5.2使用变长子网掩码划分子网{#%E2%80%8B%E7%BC%96%E8%BE%915.2%E4%BD%BF%E7%94%A8%E5%8F%98%E9%95%BF%E5%AD%90%E7%BD%91%E6%8E%A9%E7%A0%81%E5%88%92%E5%88%86%E5%AD%90%E7%BD%91-toc}\n6.IPV4和MAC地址{#6.IPV4%E5%92%8CMAC%E5%9C%B0%E5%9D%80-toc}\n​编辑7.地址解析协议ARP{#%E2%80%8B%E7%BC%96%E8%BE%917.%E5%9C%B0%E5%9D%80%E8%A7%A3%E6%9E%90%E5%8D%8F%E8%AE%AEARP-toc}\n8.IP数据报发送转发流程{#8.IP%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%8F%91%E9%80%81%E8%BD%AC%E5%8F%91%E6%B5%81%E7%A8%8B-toc}\n9.静态路由配置{#9.%E9%9D%99%E6%80%81%E8%B7%AF%E7%94%B1%E9%85%8D%E7%BD%AE-toc}\n9.1默认路由{#9.1%E9%BB%98%E8%AE%A4%E8%B7%AF%E7%94%B1-toc}\n9.2特定主机路由{#9.2%E7%89%B9%E5%AE%9A%E4%B8%BB%E6%9C%BA%E8%B7%AF%E7%94%B1-toc}\n10.路由选择分类{#10.%E8%B7%AF%E7%94%B1%E9%80%89%E6%8B%A9%E5%88%86%E7%B1%BB-toc}\n10.1路由信息协议RIP{#10.1%E8%B7%AF%E7%94%B1%E4%BF%A1%E6%81%AF%E5%8D%8F%E8%AE%AERIP-toc}\n10.2开放最短路径优先OSPF{#10.2%E5%BC%80%E6%94%BE%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E4%BC%98%E5%85%88OSPF-toc}\n10.3路由信息协议BGP{#10.3%E8%B7%AF%E7%94%B1%E4%BF%A1%E6%81%AF%E5%8D%8F%E8%AE%AEBGP-toc}\n11.路由器工作原理{#11.%E8%B7%AF%E7%94%B1%E5%99%A8%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86-toc}\n12.IP多播地址和多播组{#12.IP%E5%A4%9A%E6%92%AD%E5%9C%B0%E5%9D%80%E5%92%8C%E5%A4%9A%E6%92%AD%E7%BB%84-toc}\n13.IPV6{#13.IPV6-toc}\n1.网络层概述 2.网络层提供的两种服务 {#2.%E7%BD%91%E7%BB%9C%E5%B1%82%E6%8F%90%E4%BE%9B%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%9C%8D%E5%8A%A1} 3.分类编址的IPV4 {#3.%E5%88%86%E7%B1%BB%E7%BC%96%E5%9D%80%E7%9A%84IPV4} 4.无分类编址的IPV4\u0026mdash;CIDR {#4.%E6%97%A0%E5%88%86%E7%B1%BB%E7%BC%96%E5%9D%80%E7%9A%84IPV4%E2%80%94CIDR} ","date":"2024-12-16T12:24:02Z","permalink":"/zh-cn/post/2024/12/%E8%80%83%E5%89%8D%E9%A2%84%E4%B9%A04.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%BD%91%E7%BB%9C%E5%B1%82/","title":"【考前预习】4.计算机网络—网络层"},{"content":" 往期推荐\n【考前预习】2.计算机网络\u0026mdash;物理层-CSDN博客\n【考前预习】1.计算机网络概述-CSDN博客\n浅谈云原生\u0026ndash;微服务、CICD、Serverless、服务网格_云原生cicd-CSDN博客\n子网掩码、网络地址、广播地址、子网划分及计算_子网广播地址-CSDN博客\n浅学React和JSX-CSDN博客\n目录{#main-toc}\n1.数据链路层概述{#1.%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82%E6%A6%82%E8%BF%B0-toc}\n1.1 数据链路和帧{#1.1%20%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%92%8C%E5%B8%A7-toc}\n2.数据链路层三个基本问题{#2.%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82%E4%B8%89%E4%B8%AA%E5%9F%BA%E6%9C%AC%E9%97%AE%E9%A2%98-toc}\n2.1封装成帧{#2.1%E5%B0%81%E8%A3%85%E6%88%90%E5%B8%A7-toc}\n2.1.1帧定界{#2.1.1%E5%B8%A7%E5%AE%9A%E7%95%8C-toc}\n2.2透明传输{#2.2%E9%80%8F%E6%98%8E%E4%BC%A0%E8%BE%93-toc}\n2.2.1 实现透明传输\u0026mdash;字节填充{#2.2.1%20%E5%AE%9E%E7%8E%B0%E9%80%8F%E6%98%8E%E4%BC%A0%E8%BE%93%E2%80%94%E5%AD%97%E8%8A%82%E5%A1%AB%E5%85%85-toc}\n2.3差错检测{#2.3%E5%B7%AE%E9%94%99%E6%A3%80%E6%B5%8B-toc}\n2.3.1循环冗余检验CRC{#2.3.1%E5%BE%AA%E7%8E%AF%E5%86%97%E4%BD%99%E6%A3%80%E9%AA%8CCRC-toc}\n2.3.2生成多项式{#2.3.2%E7%94%9F%E6%88%90%E5%A4%9A%E9%A1%B9%E5%BC%8F-toc}\n2.4可靠传输{#2.4%E5%8F%AF%E9%9D%A0%E4%BC%A0%E8%BE%93-toc}\n3.点对点信道\u0026mdash;点对点协议PPP{#3.%E7%82%B9%E5%AF%B9%E7%82%B9%E4%BF%A1%E9%81%93%E2%80%94%E7%82%B9%E5%AF%B9%E7%82%B9%E5%8D%8F%E8%AE%AEPPP-toc}\n3.1PPP协议组成{#3.1PPP%E5%8D%8F%E8%AE%AE%E7%BB%84%E6%88%90-toc}\n3.2PPP协议帧格式{#3.2PPP%E5%8D%8F%E8%AE%AE%E5%B8%A7%E6%A0%BC%E5%BC%8F-toc}\n3.3透明传输实现\u0026mdash;字节填充{#3.3%E9%80%8F%E6%98%8E%E4%BC%A0%E8%BE%93%E5%AE%9E%E7%8E%B0%E2%80%94%E5%AD%97%E8%8A%82%E5%A1%AB%E5%85%85-toc}\n3.4透明传输实现\u0026mdash;零比特填充{#3.4%E9%80%8F%E6%98%8E%E4%BC%A0%E8%BE%93%E5%AE%9E%E7%8E%B0%E2%80%94%E9%9B%B6%E6%AF%94%E7%89%B9%E5%A1%AB%E5%85%85%C2%A0-toc}\n4.广播信道{#%C2%A04.%E5%B9%BF%E6%92%AD%E4%BF%A1%E9%81%93-toc}\n4.1共享信道{#4.1%E5%85%B1%E4%BA%AB%E4%BF%A1%E9%81%93-toc}\n4.2适配器的作用{#4.2%E9%80%82%E9%85%8D%E5%99%A8%E7%9A%84%E4%BD%9C%E7%94%A8-toc}\n4.3总线型网络拓扑\u0026mdash;CSMA/CD协议{#4.3%E6%80%BB%E7%BA%BF%E5%9E%8B%E7%BD%91%E7%BB%9C%E6%8B%93%E6%89%91%E2%80%94CSMA%2FCD%E5%8D%8F%E8%AE%AE-toc}\n4.4.1 截断二进制指数退避算法{#4.4.1%20%E6%88%AA%E6%96%AD%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%8C%87%E6%95%B0%E9%80%80%E9%81%BF%E7%AE%97%E6%B3%95-toc}\n4.4星形网络拓扑\u0026mdash;集线器{#4.4%E6%98%9F%E5%BD%A2%E7%BD%91%E7%BB%9C%E6%8B%93%E6%89%91%E2%80%94%E9%9B%86%E7%BA%BF%E5%99%A8-toc}\n4.5以太网信道利用率{#4.5%E4%BB%A5%E5%A4%AA%E7%BD%91%E4%BF%A1%E9%81%93%E5%88%A9%E7%94%A8%E7%8E%87-toc}\n4.6以太网MAC层{#4.6%E4%BB%A5%E5%A4%AA%E7%BD%91MAC%E5%B1%82-toc}\n4.6.1MAC的硬件地址{#4.6.1MAC%E7%9A%84%E7%A1%AC%E4%BB%B6%E5%9C%B0%E5%9D%80-toc}\n4.6.2MAC帧格式{#4.6.2MAC%E5%B8%A7%E6%A0%BC%E5%BC%8F%C2%A0-toc}\n4.7以太网扩展{#4.7%E4%BB%A5%E5%A4%AA%E7%BD%91%E6%89%A9%E5%B1%95-toc}\n5.虚拟局域网VLAN{#5.%E8%99%9A%E6%8B%9F%E5%B1%80%E5%9F%9F%E7%BD%91VLAN-toc}\n1.数据链路层概述 数据链路层属于计算机网络的低层。数据链路层使用的信道主要有以下两种类型：\n点对点信道：使用一对一的点对点通信方式。 广播信道：使用一对多的广播通信方式，因此过程比较复杂。广播信道上连接的主机很多，因此必须使用专用的共享信道协议来协调这些主机的数据发送。 局域网虽然是个网络，但我们并不把局域网放在网络层中讨论。这是因为在网络层要讨论的问题是多个网络互连的问题，是讨论分组怎样从一个网络通过路由器转发到另一个网络。\n数据链路层研究的是在同一个局域网中，分组怎样从一台主机不用路由器传送到另一台主机。\n1.1 数据链路和帧 {#1.1%20%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%92%8C%E5%B8%A7} 链路：从一个节点到相邻节点的一段物理线路。 数据链路：在链路的基础上增加必要的通信协议控制数据传输。 链路层协议数据单元：帧，链路层接收到网络层的IP数据报添加首部尾部信息封装成帧作为链路层传输单元。 点对点信道的数据链路通信步骤：\n(1)节点A的数据链路层把网络层交下来的P数据报添加首部和尾部封装成帧。\n(2)节点A把封装好的帧发送给节点B的数据链路层。\n(3)若节点B的数据链路层收到的帧无差错，则从收到的帧中提取出P数据报交给上面的网络层：否则丢弃这个帧。 2.数据链路层三个基本问题 {#2.%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82%E4%B8%89%E4%B8%AA%E5%9F%BA%E6%9C%AC%E9%97%AE%E9%A2%98} 2.1封装成帧 {#2.1%E5%B0%81%E8%A3%85%E6%88%90%E5%B8%A7} 在IP数据报头部尾部添加一些控制信息，使得接收端的数据链路层接收到物理层的比特流后能根据首部尾部标记识别到帧的开始和结束，因此帧的作用之一就是帧定界。\n最大传送单元MTU是数据部分长度上限。\n2.1.1帧定界 {#2.1.1%E5%B8%A7%E5%AE%9A%E7%95%8C} 当数据是由可打印的ASCⅡ码组成的文本文件时，帧定界可以使用特殊的帧定界符。**ASCⅡ码是7位编码，一共可组合成128个不同的ASCIⅡ码，其中可打印的有95个，而不可打印的控制字符有33个。**控制字符SOH(Start Of Header)放在一帧的最前面，表示帧的首部开始。另一个控制字符EOT(End Of Transmission)表示帧的结束。SOH和EOT都是控制字符的名称。它们的十六进制编码分别是01（二进制是00000001）和04（二进制是00000100）。SOH(或EOT)并不是S,O,H（或E,O,T)三个字符。 如果数据传送时中断，那么接收端接收到的数据就只有SOH，没有EOT，那么说明帧是不完整的，接后端链路层就会丢弃该帧，因此帧定界有一定的检错作用。 2.2透明传输 {#2.2%E9%80%8F%E6%98%8E%E4%BC%A0%E8%BE%93} 由于帧的开始和结束的标记使用专门指明的控制字符，因此传输数据中的任何8 bit的组合不能和帧定界的控制字符的比特编码一样，否则就会出现帧定界的错误。 当传送的帧是用文本文件组成的帧时(从键盘上输入)，其数据部分一定不会出现像SOH或EOT这样的帧定界控制字符。可见不管从键盘上输入什么字符都可以放在这样的帧中传输过去，这样的传输就是透明传输。 当数据部分是非ASCⅡ码的文本文件时（如二进制代码的计算机程序或图像等)，情况就不同了。如果数据中的某个字节的二进制代码恰好和SOH或EOT这种控制字符一样，数据链路层就会错误地\u0026quot;找到帧的边界\u0026quot;，把部分帧收下（误认为是个完整的帧)，而把剩下的那部分数据丢弃，这样就不是透明传输。 2.2.1 实现透明传输\u0026mdash;字节填充 {#2.2.1%20%E5%AE%9E%E7%8E%B0%E9%80%8F%E6%98%8E%E4%BC%A0%E8%BE%93%E2%80%94%E5%AD%97%E8%8A%82%E5%A1%AB%E5%85%85} 设法使数据中出现的控制字符 \u0026ldquo;SOH\u0026quot;和\u0026quot;EOT\u0026quot;在接收端不被解释为控制字符。具体的方法是：发送端的数据链路层在数据中出现控制字符\u0026quot;SOH\u0026quot;或\u0026quot;EOT\u0026quot;的前面插入一个转义字符\u0026quot;ESC\u0026rdquo; (其十六进制编码是1B,二进制是00011011)。而在接收端数据链路层在把数据送往网络层之前删除这个插入的转义字符 。这种方法称为字节填充或字符填充 。如果转义字符也出现在数据\n当中，那么解决方法仍然是在转义字符的前面插入一个转义字符 。因此，当接收端收到连续\n的两个转义字符时，就删除其中前面的一个。\n2.3差错检测 {#2.3%E5%B7%AE%E9%94%99%E6%A3%80%E6%B5%8B} 比特流在传输过程中可能出现比特差错，一段时间内，传输错误的比特占传输总比特的比率叫误码率BER，这和信噪比有一定关系。\n2.3.1循环冗余检验CRC {#2.3.1%E5%BE%AA%E7%8E%AF%E5%86%97%E4%BD%99%E6%A3%80%E9%AA%8CCRC} ","date":"2024-12-13T11:56:09Z","permalink":"/zh-cn/post/2024/12/%E8%80%83%E5%89%8D%E9%A2%84%E4%B9%A03.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/","title":"【考前预习】3.计算机网络—数据链路层"},{"content":" 往期推荐\n【考前预习】1.计算机网络概述-CSDN博客\n子网掩码、网络地址、广播地址、子网划分及计算-CSDN博客\n浅谈云原生\u0026ndash;微服务、CICD、Serverless、服务网格_云原生 serverless-CSDN博客\n一文搞懂大数据流式计算引擎Flink【万字详解，史上最全】-CSDN博客\n浅谈维度建模、数据分析模型，何为数据仓库，与数据库的区别_统一数仓 数据库用户名-CSDN博客\n目录{#main-toc}\n1.物理层基本概念{#1.%E7%89%A9%E7%90%86%E5%B1%82%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5-toc}\n2.数据通信基础知识{#2.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-toc}\n2.1信道{#2.1%E4%BF%A1%E9%81%93-toc}\n2.2信道极限容量{#2.2%E4%BF%A1%E9%81%93%E6%9E%81%E9%99%90%E5%AE%B9%E9%87%8F-toc}\n2.3物理层的传输媒体{#2.3%E7%89%A9%E7%90%86%E5%B1%82%E7%9A%84%E4%BC%A0%E8%BE%93%E5%AA%92%E4%BD%93-toc}\n2.3.1导引型传输媒体{#2.3.1%E5%AF%BC%E5%BC%95%E5%9E%8B%E4%BC%A0%E8%BE%93%E5%AA%92%E4%BD%93-toc}\n2.3.2非导引型传输媒体{#2.3.2%E9%9D%9E%E5%AF%BC%E5%BC%95%E5%9E%8B%E4%BC%A0%E8%BE%93%E5%AA%92%E4%BD%93-toc}\n2.4信道复用{#2.4%E4%BF%A1%E9%81%93%E5%A4%8D%E7%94%A8-toc}\n2.4.1频分复用FDM（频分多址）{#2.4.1%E9%A2%91%E5%88%86%E5%A4%8D%E7%94%A8FDM%EF%BC%88%E9%A2%91%E5%88%86%E5%A4%9A%E5%9D%80%EF%BC%89-toc}\n2.4.2时分复用TDM（时分多址）{#2.4.2%E6%97%B6%E5%88%86%E5%A4%8D%E7%94%A8TDM%EF%BC%88%E6%97%B6%E5%88%86%E5%A4%9A%E5%9D%80%EF%BC%89-toc}\n2.4.3统计时分复用{#2.4.3%E7%BB%9F%E8%AE%A1%E6%97%B6%E5%88%86%E5%A4%8D%E7%94%A8-toc}\n2.4.4波分复用WDM{#2.4.4%E6%B3%A2%E5%88%86%E5%A4%8D%E7%94%A8WDM-toc}\n2.4.5码分复用CDM（码分多址）{#2.4.5%E7%A0%81%E5%88%86%E5%A4%8D%E7%94%A8CDM%EF%BC%88%E7%A0%81%E5%88%86%E5%A4%9A%E5%9D%80%EF%BC%89-toc}\n3.宽带接入技术{#3.%E5%AE%BD%E5%B8%A6%E6%8E%A5%E5%85%A5%E6%8A%80%E6%9C%AF-toc}\n1.物理层基本概念 物理层考虑的是如何在连接各种计算机的传输媒体上传输数据比特流 ，而不是指具体的传输媒体。计算机网络中的硬件设备和传输媒体的种类和通信手段繁多，物理层的作用正是要尽可能地屏蔽掉这些传输媒体和通信手段的差异，使物理层上面的数据链路层感觉不到这些差异，这样就可使数据链路层只需要考虑如何完成本层的协议和服务，而不必考虑网络具体的传输媒体和通信手段是什么 。用于物理层的协议也常称为物理层规程 (procedure)。其实物理层规程就是物理层协议。只是在\u0026quot;协议\u0026quot;这个名词出现之前人们就先使用了\u0026quot;规程\u0026quot;这一名词。\n因此物理层的主要任务可以描述为确定与传输媒体的接口有关的特性：\n机械特性\n指明接口所用接线器的形状和尺寸、引脚数目和排列、固定和锁定装置等。平时常见的各种规格的接插件都有严格的标准化的规定。 电气特性\n指明在接口电缆的各条线上出现的电压的范围。 功能特性\n指明某条线上出现的某一电平的电压的意义。 过程特性\n指明对于不同功能的各种可能事件的出现顺序。 数据在计算机内部一般是并行传输，但是在通信线路上一般是串行传输。\n物理连接的方式很多（例如，可以是点对点的，也可以采用多点连接或广播连接)，而传输媒体的种类也非常之多（如架空明线、双绞线、对称电缆、同轴电缆、光缆，以及各种波段的无线信道等)。因此在学习物理层时，应将重点放在掌握基本概念上。\n2.数据通信基础知识 {#2.%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86} 数据通信系统可划分为源系统、传输系统、目的系统。通信的目的是传送消息，而数据就是运送消息的实体（使用特定的方式表示消息），信号则是数据的电 ","date":"2024-12-10T15:09:53Z","permalink":"/zh-cn/post/2024/12/%E8%80%83%E5%89%8D%E9%A2%84%E4%B9%A02.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%89%A9%E7%90%86%E5%B1%82/","title":"【考前预习】2.计算机网络—物理层"},{"content":" 往期推荐{#main-toc}\n子网掩码、网络地址、广播地址、子网划分及计算-CSDN博客\n一文搞懂大数据流式计算引擎Flink【万字详解，史上最全】-CSDN博客\n浅学React和JSX-CSDN博客\n浅谈云原生\u0026ndash;微服务、CICD、Serverless、服务网格_云原生 serverless-CSDN博客\n浅谈维度建模、数据分析模型，何为数据仓库，与数据库的区别_统一数仓 数据库用户名-CSDN博客\n1.互联网概述{#1.%E4%BA%92%E8%81%94%E7%BD%91%E6%A6%82%E8%BF%B0-toc}\n2.互联网基础结构发展的三个阶段{#2.%E4%BA%92%E8%81%94%E7%BD%91%E5%9F%BA%E7%A1%80%E7%BB%93%E6%9E%84%E5%8F%91%E5%B1%95%E7%9A%84%E4%B8%89%E4%B8%AA%E9%98%B6%E6%AE%B5-toc}\n3.互联网组成{#3.%E4%BA%92%E8%81%94%E7%BD%91%E7%BB%84%E6%88%90-toc}\n3.1边缘部分{#3.1%E8%BE%B9%E7%BC%98%E9%83%A8%E5%88%86-toc}\n3.2核心部分{#3.2%E6%A0%B8%E5%BF%83%E9%83%A8%E5%88%86-toc}\n3.2.1电路交换{#3.2.1%E7%94%B5%E8%B7%AF%E4%BA%A4%E6%8D%A2-toc}\n3.2.2分组交换{#3.2.2%E5%88%86%E7%BB%84%E4%BA%A4%E6%8D%A2-toc}\n3.2.3报文交换{#3.2.3%E6%8A%A5%E6%96%87%E4%BA%A4%E6%8D%A2-toc}\n4.计算机网络定义{#4.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AE%9A%E4%B9%89-toc}\n5.衡量计算机网络的性能{#5.%E8%A1%A1%E9%87%8F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9A%84%E6%80%A7%E8%83%BD-toc}\n5.1速率{#5.1%E9%80%9F%E7%8E%87-toc}\n5.2带宽{#5.2%E5%B8%A6%E5%AE%BD-toc}\n5.3吞吐量{#5.3%E5%90%9E%E5%90%90%E9%87%8F-toc}\n5.4时延{#5.4%E6%97%B6%E5%BB%B6-toc}\n5.5时延带宽积{#5.5%E6%97%B6%E5%BB%B6%E5%B8%A6%E5%AE%BD%E7%A7%AF-toc}\n5.6往返时间RTT{#5.6%E5%BE%80%E8%BF%94%E6%97%B6%E9%97%B4RTT-toc}\n5.7利用率{#5.7%E5%88%A9%E7%94%A8%E7%8E%87-toc}\n6.计算机网络体系结构{#6.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%C2%A0-toc}\n6.1应用层{#6.1%E5%BA%94%E7%94%A8%E5%B1%82-toc}\n6.2运输层{#6.2%E8%BF%90%E8%BE%93%E5%B1%82-toc}\n6.3网络层{#6.3%E7%BD%91%E7%BB%9C%E5%B1%82-toc}\n6.4数据链路层{#6.4%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82-toc}\n6.5物理层{#6.5%E7%89%A9%E7%90%86%E5%B1%82-toc}\n7.TCP/IP协议族{#7.TCP%2FIP%E5%8D%8F%E8%AE%AE%E6%97%8F-toc}\n1.互联网概述 计算机网络（简称网络）：由若干节点和连接这些节点的链路组成，节点可以是计算机、集线器、路由器等。 互连网（internet）：由多个路由器连接组成的范围更大的计算机网络。 互联网（Internet）：当前全球最大的开放的由众多网络连接而成的特定互连网，采用TCP/IP协议族作为通信规则，前身是美国的ARPANET（ARPANET是历史上第一个分组交换网络）。 2.互联网基础结构发展的三个阶段 {#2.%E4%BA%92%E8%81%94%E7%BD%91%E5%9F%BA%E7%A1%80%E7%BB%93%E6%9E%84%E5%8F%91%E5%B1%95%E7%9A%84%E4%B8%89%E4%B8%AA%E9%98%B6%E6%AE%B5} 第一阶段 ：单个网络**ARPANET向互连网发展的过程，**起初ARPANET只是一个单个的分组交换网，不是互连网络。1983年TCP/IP协议成为ARPANET的标准协议，使得所有使用该协议的计算机都能通过互连网通信，因此1983年也被成为互连网诞生年。 第二阶段：该阶段特点是构成了三级结构的互联网，分为主干网、地区网、校园网。 第三阶段：逐渐形成了全球范围的多层次ISP结构的互联网。所谓ISP就是互联网服务提供者，中国移动、电信就是我我国有名的ISP。ISP可以从互联网管理结构申请很多IP地址（IPV4地址是有限的）并租给用户使用。为了应对互联网数据流量急剧增长，互联网交换点IXP诞生，其作用就是允许两个同级的ISP直接相连交换分组，不需要借助父级ISP，这样就提升了数据转发速率。 3.互联网组成 {#3.%E4%BA%92%E8%81%94%E7%BD%91%E7%BB%84%E6%88%90} 互联网的拓扑结构十分复杂，可划分为两大块：边缘部分和核心部分。\n边缘部分：由所有连接在互联网上的主机组成（端系统），由用户直接使用。 核心部分：由大量网络和连接网络的路由器组成，为边缘部分提供服务（提供连通和交换）。 ","date":"2024-12-09T22:18:04Z","permalink":"/zh-cn/post/2024/12/%E8%80%83%E5%89%8D%E9%A2%84%E4%B9%A01.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%A6%82%E8%BF%B0/","title":"【考前预习】1.计算机网络概述"},{"content":" 往期推荐\n一文入门大数据准流式计算引擎Spark【万字详解，全网最新】_大数据 spark-CSDN博客\n一文搞懂大数据流式计算引擎Flink【万字详解，史上最全】-CSDN博客\n浅学React和JSX-CSDN博客\n浅谈云原生\u0026ndash;微服务、CICD、Serverless、服务网格_springboot serverless 和服务网格的区别-CSDN博客\n目录{#main-toc}\n1. IPV4地址分类及组成{#1.%20IPV4%E5%9C%B0%E5%9D%80%E5%88%86%E7%B1%BB%E5%8F%8A%E7%BB%84%E6%88%90-toc}\n2. 子网掩码{#2.%20%E5%AD%90%E7%BD%91%E6%8E%A9%E7%A0%81%C2%A0-toc}\n3. 网络地址{#3.%20%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80-toc}\n4. 广播地址{#4.%20%E5%B9%BF%E6%92%AD%E5%9C%B0%E5%9D%80-toc}\n5. 计算主机号范围及数量{#5.%20%E8%AE%A1%E7%AE%97%E4%B8%BB%E6%9C%BA%E5%8F%B7%E8%8C%83%E5%9B%B4%E5%8F%8A%E6%95%B0%E9%87%8F-toc}\n6. 子网划分{#6.%20%E5%AD%90%E7%BD%91%E5%88%92%E5%88%86%C2%A0-toc}\n6.1 为什么要子网划分{#6.1%20%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%AD%90%E7%BD%91%E5%88%92%E5%88%86-toc}\n6.2 子网划分思想{#6.2%20%E5%AD%90%E7%BD%91%E5%88%92%E5%88%86%E6%80%9D%E6%83%B3-toc}\n6.3 子网计算步骤{#6.3%20%E5%AD%90%E7%BD%91%E8%AE%A1%E7%AE%97%E6%AD%A5%E9%AA%A4-toc}\n6.3.1 确定借几位子网号{#6.3.1%20%E7%A1%AE%E5%AE%9A%E5%80%9F%E5%87%A0%E4%BD%8D%E5%AD%90%E7%BD%91%E5%8F%B7-toc}\n6.3.2 确定每个子网的子网掩码{#6.3.2%20%E7%A1%AE%E5%AE%9A%E6%AF%8F%E4%B8%AA%E5%AD%90%E7%BD%91%E7%9A%84%E5%AD%90%E7%BD%91%E6%8E%A9%E7%A0%81-toc}\n6.3.3 确定子网的网络地址{#6.3.3%C2%A0%E7%A1%AE%E5%AE%9A%E5%AD%90%E7%BD%91%E7%9A%84%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80-toc}\n6.3.4确定子网的广播地址{#6.3.4%E7%A1%AE%E5%AE%9A%E5%AD%90%E7%BD%91%E7%9A%84%E5%B9%BF%E6%92%AD%E5%9C%B0%E5%9D%80-toc}\n6.3.5 确定子网的可用IP地址范围{#6.3.5%20%E7%A1%AE%E5%AE%9A%E5%AD%90%E7%BD%91%E7%9A%84%E5%8F%AF%E7%94%A8IP%E5%9C%B0%E5%9D%80%E8%8C%83%E5%9B%B4-toc}\nIPV4地址分类及组成 IP地址=网络地址+主机地址，（又称：主机号和网络号）\n由上图可见网络号和主机号之和是32，而且此多彼少。\n例：IP地址为192.168.2.131，转换成二进制1111 1111.1010 1000.0000 0010.1000 0011，因为192为C类IP地址，那么左边24位是网络位，代表网段，右边的8位是主机号，代表该网段内的唯一一台主机。\n以C类网络为例，左边24位是网络号，每一位是0或1，因为第一字节十进制范围是192-233，也就说24位网络号变化范围是110 x xxxx.xxxx xxxx.xxxx xxxx到1110 1001.xxxx xxxx.xxxx xxxx，那么共有个网段，同理右边8位共有个主机，也就是说每个网段下可以最多254个主机。那么为什么-2呢？是因为要除掉1111 1111和0000 0000两种特殊情况（网络地址和广播地址）\n同理，A类网段数128，主机数16777214，B类网段数16384，主机数65534。\n子网掩码 {#2.%20%E5%AD%90%E7%BD%91%E6%8E%A9%E7%A0%81%C2%A0} 子网掩码的计算_子网掩码计算-CSDN博客\n子网掩码用于判断任意两台计算机的IP地址是否属于同一子网，也可以判断IP地址的网络位和主机位， 它的特征是左边全1，右边全0。\n判断方法 ：两台计算机各自的IP地址与子网掩码进行与运算得到网络地址，结果相同则说明这两台计算机是处于同一个子网，可以进行直接的通讯。 同时，我们可以根据子网掩码可以计算出广播地址、主机号范围、主机数量 通常我们会见到这样的IP地址写法：192.168.2.131/24，其中 / 右边的24即为子网掩码，/24是CIDR的简写形式，解析如下：\n24是网络位，全是1，剩余8位是主机位，全是0，那么写成二进制是：1111 1111.1111 1111.1111 1111.0000 0000，再转化成十进制：255.255.255.0，所以上述IP也可写成192.168.2.131/255.255.255.0 ，那么一般情况 下可以得到如下结果：\n|\u0026mdash;-|\u0026mdash;\u0026ndash;|\u0026mdash;\u0026ndash;|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-| | | 网络位 | 主机位 | 默认子网掩码 | | A类 | 8 | 24 | 255.0.0.0或 8 | | B类 | 16 | 16 | 255.255.0.0或 16 | | C类 | 24 | 8 | 255.255.255.0或 24 |\n注意表格中的子网掩码是默认的，分别是8、16、24，子网掩码和IP地址类别没有必然关系，并不是说A类就必须是8，B类必须是16，A类也可以是22！\n网络地址 {#3.%20%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80} 网络地址=IP地址和掩码与运算\n以16.158.165.91/22为例 ：掩码22位，即网络位占22，主机位占10\n也可以将网络地址的网络号不变，主机号全部变0取得。 广播地址 {#4.%20%E5%B9%BF%E6%92%AD%E5%9C%B0%E5%9D%80} 广播地址=掩码取反和网络地址或运算\n仍以16.158.165.91/22为例：\n也可以将网络地址的网络号不变，主机号全部变1取得。 计算主机号范围及数量 {#5.%20%E8%AE%A1%E7%AE%97%E4%B8%BB%E6%9C%BA%E5%8F%B7%E8%8C%83%E5%9B%B4%E5%8F%8A%E6%95%B0%E9%87%8F} 可用IP地址范围=\n\\[ 网络地址+1，广播地址-1 \\]\n上述案例中的可用IP地址范围：\n\\[ 16.158.164.1，16.158.167.254 \\]\n主机数量=2^主机位二进制数位-2**（不包括网络地址和广播地址）**\n案例中的数量为：2^10 -2=1024-2=1022\n子网划分 {#6.%20%E5%AD%90%E7%BD%91%E5%88%92%E5%88%86%C2%A0} 6.1 为什么要子网划分 {#6.1%20%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%AD%90%E7%BD%91%E5%88%92%E5%88%86} IPv4地址和子网掩码_哔哩哔哩_bilibili\n6.2 子网划分思想 {#6.2%20%E5%AD%90%E7%BD%91%E5%88%92%E5%88%86%E6%80%9D%E6%83%B3} 最开始我们说，IP地址=网络号+主机号，其实这是不需要子网划分 的IP地址组成，如果IP地址需要子网划分 ，那么还要从主机号中借用几位作为子网号，此时的IP地址=网络号+子网号+主机号。\n6.3 子网计算步骤 {#6.3%20%E5%AD%90%E7%BD%91%E8%AE%A1%E7%AE%97%E6%AD%A5%E9%AA%A4} 子网掩码的计算_子网掩码计算-CSDN博客十分钟理解子网划分 路由技术基础_哔哩哔哩_bilibili子网掩码的计算_子网掩码计算-CSDN博客\n例：\n6.3.1 确定借几位子网号 {#6.3.1%20%E7%A1%AE%E5%AE%9A%E5%80%9F%E5%87%A0%E4%BD%8D%E5%AD%90%E7%BD%91%E5%8F%B7} 因为上述案例中有三个部门，所以子网数\u0026gt;=3，那么要借2位子网号，可以表示4个子网（00，01，10，11），每个子网可分配主机数(减掉全0和全1)\n6.3.2 确定每个子网的子网掩码 {#6.3.2%20%E7%A1%AE%E5%AE%9A%E6%AF%8F%E4%B8%AA%E5%AD%90%E7%BD%91%E7%9A%84%E5%AD%90%E7%BD%91%E6%8E%A9%E7%A0%81} 上述C类网段掩码是24，借了2位就是26，（注意！！这里是从主机号那里借了2位作为子网号）写成二进制：1111 1111.1111 1111.1111 1111.xx00 0000，再写成十进制即是每个子网的子网掩码，xx就是00，11，01，10\n6.3.3 确定子网的网络地址 {#6.3.3%C2%A0%E7%A1%AE%E5%AE%9A%E5%AD%90%E7%BD%91%E7%9A%84%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80} 网络地址=子网掩码和IP地址与运算 ，得出每个子网的网络地址如下：\n6.3.4确定子网的广播地址 {#6.3.4%E7%A1%AE%E5%AE%9A%E5%AD%90%E7%BD%91%E7%9A%84%E5%B9%BF%E6%92%AD%E5%9C%B0%E5%9D%80} 广播地址=掩码取反和网络地址或运算\n6.3.5 确定子网的可用IP地址范围 {#6.3.5%20%E7%A1%AE%E5%AE%9A%E5%AD%90%E7%BD%91%E7%9A%84%E5%8F%AF%E7%94%A8IP%E5%9C%B0%E5%9D%80%E8%8C%83%E5%9B%B4} 可用IP地址范围=\\[ 网络地址+1，广播地址-1 \\]\n","date":"2024-10-12T22:07:11Z","permalink":"/zh-cn/post/2024/10/%E5%AD%90%E7%BD%91%E6%8E%A9%E7%A0%81%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E5%B9%BF%E6%92%AD%E5%9C%B0%E5%9D%80%E5%AD%90%E7%BD%91%E5%88%92%E5%88%86%E5%8F%8A%E8%AE%A1%E7%AE%97/","title":"子网掩码、网络地址、广播地址、子网划分及计算"},{"content":" 往期推荐\n浅学React和JSX-CSDN博客\n一文搞懂大数据流式计算引擎Flink【万字详解，史上最全】-CSDN博客\n一文入门大数据准流式计算引擎Spark【万字详解，全网最新】_大数据 spark-CSDN博客\n目录{#main-toc}\n1. 云原生概念和特点{#1.%20%E4%BA%91%E5%8E%9F%E7%94%9F%E6%A6%82%E5%BF%B5%E5%92%8C%E7%89%B9%E7%82%B9-toc}\n2. 常见云模式{#2.%20%E5%B8%B8%E8%A7%81%E4%BA%91%E6%A8%A1%E5%BC%8F-toc}\n3. 云对外提供服务的架构模式{#3.%20%E4%BA%91%E5%AF%B9%E5%A4%96%E6%8F%90%E4%BE%9B%E6%9C%8D%E5%8A%A1%E7%9A%84%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%BC%8F-toc}\n3.1 IaaS（Infrastructure-as-a-Service）{#3.1%20IaaS%EF%BC%88Infrastructure-as-a-Service%EF%BC%89-toc}\n3.2 PaaS（Platform-as-a-Service）{#3.2%20PaaS%EF%BC%88Platform-as-a-Service%EF%BC%89-toc}\n3.3 SaaS（SoftWare-as-a-Service）{#3.3%20SaaS%EF%BC%88SoftWare-as-a-Service%EF%BC%89-toc}\n3.4 FaaS（Function-as-a-Service）{#3.4%20FaaS%EF%BC%88Function-as-a-Service%EF%BC%89-toc}\n4. 云原生核心技术栈{#4.%20%E4%BA%91%E5%8E%9F%E7%94%9F%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E6%A0%88-toc}\n4.1 微服务{#4.1%20%E5%BE%AE%E6%9C%8D%E5%8A%A1-toc}\n4.2 容器技术-Docker、K8s{#4.2%20%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF-Docker%E3%80%81K8s-toc}\n4.3 DevOps\u0026amp;CICD{#4.3%20DevOps%26CICD-toc}\n4.4 Serverless{#4.4%20Serverless-toc}\n4.5 不可变基础设施{#4.5%20%E4%B8%8D%E5%8F%AF%E5%8F%98%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD-toc}\n4.6 声明式API{#4.6%20%E5%A3%B0%E6%98%8E%E5%BC%8FAPI-toc}\n4.7 Service Mesh（服务网格）{#4.7%20Service%20Mesh%EF%BC%88%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC%EF%BC%89-toc}\n4.7.1 服务网格如何工作{#4.7.1%20%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C-toc}\n4.7.2 服务网格优点{#4.7.2%20%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC%E4%BC%98%E7%82%B9%C2%A0-toc}\n4.7.3 服务网格架构{#4.7.3%20%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC%E6%9E%B6%E6%9E%84-toc}\n数据面板{#%E6%95%B0%E6%8D%AE%E9%9D%A2%E6%9D%BF-toc}\n控制面板{#%E6%8E%A7%E5%88%B6%E9%9D%A2%E6%9D%BF-toc}\n4.7.4 服务网格和k8s{#4.7.4%20%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC%E5%92%8Ck8s-toc}\n4.7.5 服务网格面临的挑战{#4.7.5%20%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC%E9%9D%A2%E4%B8%B4%E7%9A%84%E6%8C%91%E6%88%98-toc}\n4.7.6 Istio{#4.7.6%C2%A0Istio-toc}\n介绍云原生之前，我们先介绍一下CNCF，全称为Cloud Native Computing Foundation，中文译为\u0026quot;云原生计算基金会\u0026quot;。CNCF致力于培育和维护一个厂商中立的开源生态系统，来推广云原生技术。所以说，CNCF是云原生领域影响力最大最有话语权的组织。以下是CNCF对云原生的定义：\n云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。云原生的代表技术包括容器、 服务网格、微服务、不可变基础设施和声明式 API 。\n云原生概念和特点 {#1.%20%E4%BA%91%E5%8E%9F%E7%94%9F%E6%A6%82%E5%BF%B5%E5%92%8C%E7%89%B9%E7%82%B9} 概念 云原生是一种**构建和运行应用程序的方法，程序生于云端，长于云端。**从有构建应用的想法开始，到需求、设计、开发、测试、构建、打包、部署所有的软件生命周期全部都在云平台上面进行，从应用设计之初（技术选型、架构设计、编译机制）就充分考虑并符合了云的特征，在云平台以最佳姿态原型、为企业降本增效。 特点 弹性扩缩容：本地部署的传统应用无法动态扩展，往往需要冗余资源以抵抗流量高峰，而云原生应用利用云的弹性自动伸缩，应用程序快速复制扩展、部署。 快速启停：应用程序可以快速启停以应对流量变化 隔离性强：进程级别的故障隔离 CICD：持续集成、持续交付、持续部署 常见云模式 {#2.%20%E5%B8%B8%E8%A7%81%E4%BA%91%E6%A8%A1%E5%BC%8F} 公有云\n阿里云、华为云、腾讯云、百度云等等，只需购买就能使用 私有云\n自己搭建或购买的私有平台，使用对象通常是政府、金融机构和企业 混合云： 混合云的优缺点 | IBM 行业云 云对外提供服务的架构模式 {#3.%20%E4%BA%91%E5%AF%B9%E5%A4%96%E6%8F%90%E4%BE%9B%E6%9C%8D%E5%8A%A1%E7%9A%84%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%BC%8F} 3.1 IaaS（Infrastructure-as-a-Service） {#3.1%20IaaS%EF%BC%88Infrastructure-as-a-Service%EF%BC%89} 基础设施即服务\n向外提供硬件资源等基础设施，包括计算、存储、网络等等，用户可以基于基础设施进行上层应用开发部署。\n拿租房比喻就是提供毛坯房，自己装水电、置办家具。\n3.2 PaaS（Platform-as-a-Service） {#3.2%20PaaS%EF%BC%88Platform-as-a-Service%EF%BC%89} 平台即服务\n向外提供平台组件服务，如操作系统、数据库。\n拿租房比喻就是提供装好水电的房子，自己只需置办家具即可入住。\n3.3 SaaS（SoftWare-as-a-Service） {#3.3%20SaaS%EF%BC%88SoftWare-as-a-Service%EF%BC%89} 软件即服务\n直接向外提供一款成品应用型服务，屏蔽了用户对软件底层的基础设施，用户只需要拿来使用即可。如钉钉、企业微信。\n拿租房比喻就是提供装好水电、家具的房子，直接交租金就拎包入住。\n3.4 FaaS（Function-as-a-Service） {#3.4%20FaaS%EF%BC%88Function-as-a-Service%EF%BC%89} 功能即服务\nhttps://www.ibm.com/cn-zh/topics/faas\nFaaS是一种云计算服务，专注于事件驱动，在有请求时自动启动服务，没有时自动关闭服务。\nServerless和FaaS经常被\n","date":"2024-10-11T12:00:00Z","permalink":"/zh-cn/post/2024/10/%E4%BA%91%E5%8E%9F%E7%94%9F--%E5%BE%AE%E6%9C%8D%E5%8A%A1cicdsaaspaasiaas/","title":"云原生--微服务、CICD、SaaS、PaaS、IaaS"},{"content":" 往期推荐\n一文搞懂大数据流式计算引擎Flink【万字详解，史上最全】-CSDN博客\n数仓架构：离线数仓、实时数仓Lambda和Kappa、湖仓一体数据湖-CSDN博客\n一文入门大数据准流式计算引擎Spark【万字详解，全网最新】_大数据 spark-CSDN博客\n浅谈维度建模、数据分析模型，何为数据仓库，与数据库的区别_数据建模金博尔-CSDN博客\n目录{#main-toc}\n1. 真实DOM和虚拟DOM{#1.%20%E7%9C%9F%E5%AE%9EDOM%E5%92%8C%E8%99%9A%E6%8B%9FDOM-toc}\n2. JSX语法规则{#2.%20JSX%E8%AF%AD%E6%B3%95%E8%A7%84%E5%88%99-toc}\n3. 虚拟DOM中使用内联样式{#3.%20%E8%99%9A%E6%8B%9FDOM%E4%B8%AD%E4%BD%BF%E7%94%A8%E5%86%85%E8%81%94%E6%A0%B7%E5%BC%8F-toc}\n4. render渲染虚拟DOM{#4.%20render%E6%B8%B2%E6%9F%93%E8%99%9A%E6%8B%9FDOM-toc}\n5. 函数式组件和类式组件{#5.%20%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BB%84%E4%BB%B6%E5%92%8C%E7%B1%BB%E5%BC%8F%E7%BB%84%E4%BB%B6%C2%A0-toc}\n6. State状态{#6.%20State%E7%8A%B6%E6%80%81-toc}\n6.1 类的基本知识{#6.1%20%E7%B1%BB%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86-toc}\n6.2 state复杂写法{#6.2%20state%E5%A4%8D%E6%9D%82%E5%86%99%E6%B3%95-toc}\n6.3 state简单写法{#6.3%20state%E7%AE%80%E5%8D%95%E5%86%99%E6%B3%95%C2%A0-toc}\n7.Props{#7.Props-toc}\n7.1 基本使用{#7.1%20%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8-toc}\n7.2 类型限制{#7.2%20%E7%B1%BB%E5%9E%8B%E9%99%90%E5%88%B6-toc}\n8. Ref{#8.%C2%A0Ref-toc}\n8.1 字符串形式的ref{#8.1%20%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%BD%A2%E5%BC%8F%E7%9A%84ref%C2%A0-toc}\n8.2 回调函数的ref{#8.2%20%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%E7%9A%84ref-toc}\n8.3 createRef(){#8.3%20createRef()-toc}\n9. Ajax和Axios{#9.%20Ajax%E5%92%8CAxios-toc}\n9.1 前置说明{#9.1%20%E5%89%8D%E7%BD%AE%E8%AF%B4%E6%98%8E-toc}\n9.2 Ajax请求库{#9.2%20Ajax%E8%AF%B7%E6%B1%82%E5%BA%93-toc}\n9.3 Axios请求{#9.3%20Axios%E8%AF%B7%E6%B1%82%C2%A0-toc}\n9.4 Server.js代理{#9.4%20Server.js%E4%BB%A3%E7%90%86-toc}\n10. 路由{#10.%20%E8%B7%AF%E7%94%B1-toc}\n用antd做个人博客卡到前端了，迫不得已来学react，也是干上全栈了\u0026ndash; \u0026ndash;学自尚硅谷张天禹react\nReact就是js框架，可以理解为对js做了封装，那么封装后的肯定用起来更方便。\n相关JS库\nreact.js：React核心库。 react-dom.js：提供操作DOM的react扩展库。 babel.min.js：解析JSX语法代码转为JS代码的库。\n浏览器不能直接解析JSX代码, 需要babel转译为纯JS的代码才能运行。只要用了JSX，都要加上type=\u0026ldquo;text/babel\u0026rdquo;, 声明需要babel来处理。 JS库示例 ：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;1_使用jsx创建虚拟DOM\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;!-- 准备好一个\u0026#34;容器\u0026#34; --\u0026gt; \u0026lt;div id=\u0026#34;test\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;!-- 引入react核心库 --\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;../js/react.development.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!-- 引入react-dom，用于支持react操作DOM --\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;../js/react-dom.development.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!-- 引入babel，用于将jsx转为js --\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;../js/babel.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/babel\u0026#34; \u0026gt; /* 此处一定要写babel */ //1.创建虚拟DOM const VDOM = ( /* 此处一定不要写引号，因为不是字符串 */ \u0026lt;h1 id=\u0026#34;title\u0026#34;\u0026gt; \u0026lt;span\u0026gt;Hello,React\u0026lt;/span\u0026gt; \u0026lt;/h1\u0026gt; ) //2.渲染虚拟DOM到页面 ReactDOM.render(VDOM,document.getElementById(\u0026#39;test\u0026#39;)) \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 浏览器控制台可能会报如下错误：\n找不到favicon.ico的资源，那么左上角的标签页就不显示图标。解决方法是在项目中根目录下放一个同名图标即可。\n真实DOM和虚拟DOM {#1.%20%E7%9C%9F%E5%AE%9EDOM%E5%92%8C%E8%99%9A%E6%8B%9FDOM} React提供了一些API来创建虚拟DOM对象\n虚拟dom定义在\u0026lt;script type=\u0026ldquo;text/babel\u0026rdquo;\u0026gt; \u0026lt;/script\u0026gt;中！！！\n1 2 3 4 5 6 7 8 9 10 //创建虚拟dom 1.用React创建，语法：React.createElement(\u0026#39;标签名\u0026#39;,{标签属性},\u0026#39;标签内容\u0026#39;) const VDOM = React.createElement(\u0026#39;Good\u0026#39;,{id:\u0026#39;title\u0026#39;},\u0026#39;Hello JSX\u0026#39;) 2.用JSX语法创建，可以看到这样创建dom更简单 const VDOM = \u0026lt;Good id=\u0026#34;title\u0026#34;\u0026gt;Hello JSX\u0026lt;/Good\u0026gt; //创建真实dom，不常用 const DOM = document.createElement() 我们编码时基本只需要操作react的虚拟DOM相关数据, react会转换为真实DOM变化而更新界。 虚拟DOM对象最终都会被React转换为真实的DOM。 虚拟dom本质是一个Object（控制台输出VDOM instanceof Object的结果为true）。 虚拟dom内部元素少，真实dom内部元素多，因为虚拟dom是react内用，无需真实dom那么多属性。 注意！创建的虚拟dom只能有一个根标签，并且内部的标签必须闭合（有 /\u0026gt; 结束），如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 //正确的创建虚拟DOM，根标签只有一个 const VDOM = ( \u0026lt;div\u0026gt; \u0026lt;h2\u0026gt;青秋\u0026lt;/h2\u0026gt; \u0026lt;/div\u0026gt; ) //错误的创建虚拟DOM，根标签有俩div const VDOM = ( \u0026lt;div\u0026gt; \u0026lt;h2\u0026gt;青秋\u0026lt;/h2\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;h2\u0026gt;青秋\u0026lt;/h2\u0026gt; \u0026lt;/div\u0026gt; ) //必须有/\u0026gt;结束 const VDOM = ( \u0026lt;div\u0026gt; \u0026lt;h2\u0026gt;青秋\u0026lt;/h2\u0026gt; //\u0026lt;input type=\u0026#34;text\u0026#34; \u0026gt; 错误，没有闭合 \u0026lt;input type=\u0026#34;text\u0026#34;/\u0026gt; 或 \u0026lt;input type=\u0026#34;text\u0026#34;/\u0026gt; \u0026lt;/input\u0026gt; \u0026lt;/div\u0026gt; ) JSX语法规则 {#2.%20JSX%E8%AF%AD%E6%B3%95%E8%A7%84%E5%88%99} 全称是JavaScript XML，是react定义的一种类似于XML的JS扩展语法，可以把js和html写在一起，类似JSP。\nJS + XML本质是React.createElement ( component , props , \u0026hellip; children **)**方法的语法糖\n作用: 用来简化创建虚拟DOM\n写法：var VDOM = \u0026lt;h1\u0026gt; Hello JSX\u0026lt;/h1\u0026gt;\n注意：这样创建的\u0026lt;h1\u0026gt;不是字符串, 也不是HTML/XML标签，它最终产生的就是一个JS对象\n标签名和标签属性任意，可以是HTML标签属性或其它\n语法规则：\n遇到 \u0026lt; 开头的代码, 以标签的语法解析: 与html同名标签则转换为html同名元素 , 其它标签需要特别解析，如：\n1 2 3 4 5 //自定义的h1会被替换成html中同名的标签\u0026lt;h1\u0026gt; const vdom1=\u0026lt;h1\u0026gt;hello\u0026lt;/h1\u0026gt; //自定义的Good在html中不存在同名标签,浏览器控制台会报错 const vdom2=\u0026lt;good\u0026gt;hello\u0026lt;/good\u0026gt; 也就是说，定义的虚拟dom中，开头小写的标签会去html中寻找同名的元素并替换，找不到就会报上面的错误。如果是开头大写的标签，那么就是自定义的组件 ，如果写成Good，那么浏览器就会去渲染Good组件，因此Good组件需要提前定义，否则会undefined。\n遇到以 { 开头的代码，以JS语法解析，标签中的JS表达式必须用{ }包含，比如要在标签中引用自定义的变量，就要用{ }把自定义变量包裹起来，如：\n1 2 3 4 5 6 7 8 9 10 11 const myId=\u0026#34;青秋\u0026#34; const myData=\u0026#34;青秋博客\u0026#34; //1.创建虚拟DOM const VDOM = ( \u0026lt;div\u0026gt; \u0026lt;h2 id={myId}\u0026gt; \u0026lt;span\u0026gt;{myData}\u0026lt;/span\u0026gt; \u0026lt;/h2\u0026gt; \u0026lt;/div\u0026gt; ) 虚拟DOM中使用内联样式 {#3.%20%E8%99%9A%E6%8B%9FDOM%E4%B8%AD%E4%BD%BF%E7%94%A8%E5%86%85%E8%81%94%E6%A0%B7%E5%BC%8F} 在虚拟dom中使用内联样式（直接在标签中写style），需要用{{ }}包裹，其中外层的{ }代表标签里要写js表达式，内层的{ }代表要写的是一个对象。\n另外{{ }}的style属性名是小驼峰的形式，比如font-size写成fontSize。真实dom的类名是class，**虚拟dom的类名是className。**如：\n1 2 3 4 5 6 7 8 9 10 11 //真实dom内联样式 \u0026lt;div class=\u0026#34;dom\u0026#34;\u0026gt; \u0026lt;h2 style=\u0026#34;color: black;font-size: large;\u0026#34;\u0026gt;青秋博客\u0026lt;/h2\u0026gt; \u0026lt;/div\u0026gt; //虚拟DOM内联样式 const VDOM = ( \u0026lt;div className=\u0026#34;vdom\u0026#34;\u0026gt; \u0026lt;h2 style={{color:\u0026#39;white\u0026#39;,fontSize:\u0026#39;29px\u0026#39;}}\u0026gt;青秋博客\u0026lt;/h2\u0026gt; \u0026lt;/div\u0026gt; ) render渲染虚拟DOM {#4.%20render%E6%B8%B2%E6%9F%93%E8%99%9A%E6%8B%9FDOM} 语法: ReactDOM . render (\u0026lt;MyComponent/\u0026gt;,document.getElementById(\u0026rsquo;test\u0026rsquo;))\n作用: 将定义的虚拟DOM元素渲染到页面中的真实DOM中显示。\n参数说明：MyComponent**是创建的虚拟dom对象；**document.getElementById(\u0026rsquo;test\u0026rsquo;)是根据id获取的真实dom容器，是用来用来包含虚拟dom的。\n函数式组件和类式组件 {#5.%20%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BB%84%E4%BB%B6%E5%92%8C%E7%B1%BB%E5%BC%8F%E7%BB%84%E4%BB%B6%C2%A0} 简单组件\n组件名必须首字母大写！！小写则会去html中寻找同名元素\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;script type=\u0026#34;text/babel\u0026#34;\u0026gt; //1.创建函数式组件 function MyComponent(){ console.log(this); //此处的this是undefined，因为babel编译后开启了严格模式 return \u0026lt;h2\u0026gt;我是用函数定义的组件(适用于【简单组件】的定义)\u0026lt;/h2\u0026gt; } //2.渲染组件到页面 ReactDOM.render(\u0026lt;MyComponent/\u0026gt;,document.getElementById(\u0026#39;test\u0026#39;)) /* 执行了ReactDOM.render(\u0026lt;MyComponent/\u0026gt;.......之后，发生了什么？ 1.React解析组件标签，找到了MyComponent组件。 2.发现组件是使用函数定义的，随后调用该函数，将返回的虚拟DOM转为真实DOM，随后呈现在页面中。 */ \u0026lt;/script\u0026gt; 复杂组件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026lt;script type=\u0026#34;text/babel\u0026#34;\u0026gt; //1.创建类式组件 class MyComponent extends React.Component { render(){ //render是放在哪里的？------ MyComponent的原型对象上，供实例使用。 //render中的this是谁？------ MyComponent的实例对象 \u0026lt;=\u0026gt; MyComponent组件实例对象。 console.log(\u0026#39;render中的this:\u0026#39;,this); return \u0026lt;h2\u0026gt;我是用类定义的组件(适用于【复杂组件】的定义)\u0026lt;/h2\u0026gt; } } //2.渲染组件到页面 ReactDOM.render(\u0026lt;MyComponent/\u0026gt;,document.getElementById(\u0026#39;test\u0026#39;)) /* 执行了ReactDOM.render(\u0026lt;MyComponent/\u0026gt;.......之后，发生了什么？ 1.React解析组件标签，找到了MyComponent组件。 2.发现组件是使用类定义的，随后new出来该类的实例，并通过该实例调用到原型上的render方法。 3.将render返回的虚拟DOM转为真实DOM，随后呈现在页面中。 */ \u0026lt;/script\u0026gt; State状态 {#6.%20State%E7%8A%B6%E6%80%81} 6.1 类的基本知识 {#6.1%20%E7%B1%BB%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;1_类的基本知识\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; \u0026gt; /* 总结： 1.类中的构造器不是必须要写的，要对实例进行一些初始化的操作，如添加指定属性时才写。 2.如果A类继承了B类，且A类中写了构造器，那么A类构造器中的super是必须要调用的。 3.类中所定义的方法，都放在了类的原型对象上，供实例去使用。 */ //创建一个Person类 class Person { //构造器方法 constructor(name,age){ //构造器中的this是谁？------ 类的实例对象 this.name = name this.age = age } //一般方法 speak(){ //speak方法放在了哪里？------类的原型对象上，供实例使用 //通过Person实例调用speak时，speak中的this就是Person实例 console.log(`我叫${this.name}，我年龄是${this.age}`); } } //创建一个Student类，继承于Person类 class Student extends Person { constructor(name,age,grade){ super(name,age) this.grade = grade this.school = \u0026#39;门头沟大学\u0026#39; } //重写从父类继承过来的方法 speak(){ console.log(`我叫${this.name}，我年龄是${this.age},我读的是${this.grade}年级`); this.study() } study(){ //study方法放在了哪里？------类的原型对象上，供实例使用 //通过Student实例调用study时，study中的this就是Student实例 console.log(\u0026#39;我很努力的学习\u0026#39;); } } class Car { constructor(name,price){ this.name = name this.price = price // this.wheel = 4 } //类中可以直接写赋值语句,如下代码的含义是：给Car的实例对象添加一个属性，名为a，值为1 a = 1 wheel = 4 static demo = 100 } const c1 = new Car(\u0026#39;奔驰c63\u0026#39;,199) console.log(c1); console.log(Car.demo); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 状态即数据，状态变化会驱动视图变化，可以简单理解为存储数据的对象。 复杂组件即类定义组件有this，那么就有state，可以理解为一个对象的属性，可以通过constructor()传递参数，而简单组件的this是undefined就没有state一说。 render方法中的this就是组件实例对象 组件自定义的方法中this为undefined，如何解决？ 强制绑定this，通过函数对象的bind() 2.箭头函数 注意！！状态必须通过setState进行更新，不能直接更改。\n正确的：this.setState({isHot:!isHot}) 错误的：this.state.isHot = !isHot\n6.2 state复杂写法 {#6.2%20state%E5%A4%8D%E6%9D%82%E5%86%99%E6%B3%95} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 \u0026lt;script type=\u0026#34;text/babel\u0026#34;\u0026gt; //1.创建组件 class Weather extends React.Component{ //构造器调用几次？ ------------ 1次 constructor(props){ console.log(\u0026#39;constructor\u0026#39;); super(props) //初始化状态 this.state = {isHot:false,wind:\u0026#39;微风\u0026#39;} //changeWeather是自定义的，要解决changeWeather中this指向问题 //调用bind方法会生成一个新函数，然后把新函数绑定到this实例对象上并命名为change，那么this实例对象有了名为change的方法 this.change = this.changeWeather.bind(this) } //changeWeather调用几次？ ------------ 点几次调几次 changeWeather(){ //changeWeather放在哪里？ ------------ Weather的原型对象上，供实例使用 //由于changeWeather是作为onClick的回调，所以不是通过实例调用的，是直接调用 //类中的方法默认开启了局部的严格模式，所以changeWeather中的this为undefined console.log(\u0026#39;changeWeather\u0026#39;); //获取原来的isHot值 const isHot = this.state.isHot //严重注意：状态必须通过setState进行更新,且更新是一种合并，不是替换。 this.setState({isHot:!isHot}) console.log(this); //严重注意：状态(state)不可直接更改，下面这行就是直接更改！！！ //this.state.isHot = !isHot //这是错误的写法 } //render调用几次？ ------------ 1+n次 1是初始化的那次 n是状态更新的次数 render(){ console.log(\u0026#39;render\u0026#39;); //读取状态 const {isHot,wind} = this.state //render函数中调用该类的另一个函数changeWeather，需要用this调用，否则会找不到要调用的函数！！ return \u0026lt;h1 onClick={this.change}\u0026gt;今天天气很{isHot ? \u0026#39;炎热\u0026#39; : \u0026#39;凉爽\u0026#39;}，{wind}\u0026lt;/h1\u0026gt; } } //2.渲染组件到页面 ReactDOM.render(\u0026lt;Weather/\u0026gt;,document.getElementById(\u0026#39;test\u0026#39;)) \u0026lt;/script\u0026gt; 6.3 state简单写法 {#6.3%20state%E7%AE%80%E5%8D%95%E5%86%99%E6%B3%95%C2%A0} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \u0026lt;script type=\u0026#34;text/babel\u0026#34;\u0026gt; //1.创建组件 class Weather extends React.Component{ //初始化状态 state = {isHot:false,wind:\u0026#39;微风\u0026#39;} //自定义方法------------要用赋值语句的形式+箭头函数 changeWeather = ()=\u0026gt;{ const isHot = this.state.isHot this.setState({isHot:!isHot}) } render(){ const {isHot,wind} = this.state return \u0026lt;h1 onClick={this.changeWeather}\u0026gt;今天天气很{isHot ? \u0026#39;炎热\u0026#39; : \u0026#39;凉爽\u0026#39;}，{wind}\u0026lt;/h1\u0026gt; } } //2.渲染组件到页面 ReactDOM.render(\u0026lt;Weather/\u0026gt;,document.getElementById(\u0026#39;test\u0026#39;)) \u0026lt;/script\u0026gt; 7.Props props用于父组件向子组件传递数据，props只读无法修改（）\n7.1 基本使用 {#7.1%20%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026lt;script type=\u0026#34;text/babel\u0026#34;\u0026gt; //创建组件 class Person extends React.Component{ render(){ const {name,age,sex} = this.props return ( \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;姓名：{name}\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;性别：{sex}\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;年龄：{age+1}\u0026lt;/li \u0026lt;/ul\u0026gt; ) } } //渲染组件到页面 ReactDOM.render(\u0026lt;Person name=\u0026#34;jerry\u0026#34; age={19} sex=\u0026#34;男\u0026#34;/\u0026gt;,document.getElementById(\u0026#39;test1\u0026#39;)) const p = {name:\u0026#39;老刘\u0026#39;,age:18,sex:\u0026#39;女\u0026#39;} ReactDOM.render(\u0026lt;Person {...p}/\u0026gt;,document.getElementById(\u0026#39;test3\u0026#39;)) \u0026lt;/script\u0026gt; 7.2 类型限制 {#7.2%20%E7%B1%BB%E5%9E%8B%E9%99%90%E5%88%B6} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;../js/prop-types.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/babel\u0026#34;\u0026gt; //创建组件 class Person extends React.Component{ render(){ const {name,age,sex} = this.props //props是只读的 //this.props.name = \u0026#39;jack\u0026#39; //此行代码会报错，因为props是只读的 return ( \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;姓名：{name}\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;性别：{sex}\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;年龄：{age+1}\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; ) } } //对标签属性进行类型、必要性的限制 Person.propTypes = { name:PropTypes.string.isRequired, //限制name必传，且为字符串 sex:PropTypes.string,//限制sex为字符串 age:PropTypes.number,//限制age为数值 speak:PropTypes.func,//限制speak为函数 } //指定默认标签属性值 Person.defaultProps = { sex:\u0026#39;男\u0026#39;,//sex默认值为男 age:18 //age默认值为18 } //渲染组件到页面 function speak(){console.log(\u0026#39;我说话了\u0026#39;);} ReactDOM.render(\u0026lt;Person name={100} speak={speak}/\u0026gt;,document.getElementById(\u0026#39;test1\u0026#39;)) const p = {name:\u0026#39;老刘\u0026#39;,age:18,sex:\u0026#39;女\u0026#39;} ReactDOM.render(\u0026lt;Person {...p}/\u0026gt;,document.getElementById(\u0026#39;test3\u0026#39;)) \u0026lt;/script\u0026gt; 订阅-发布PubSub 订阅发布用于兄弟组件传递数据，在之前，一个父亲有两个儿子，两个儿子要通信，要借助父亲来传达消息，而现在使用发布订阅，不需要借助父亲，两个儿子可以直接通信。\n如List和Search两个兄弟组件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 import React, { Component } from \u0026#39;react\u0026#39; import PubSub from \u0026#39;pubsub-js\u0026#39; export default class List extends Component { state = { //初始化状态 users:[], //users初始值为数组 isFirst:true, //是否为第一次打开页面 isLoading:false,//标识是否处于加载中 err:\u0026#39;\u0026#39;,//存储请求相关的错误信息 } componentDidMount(){ this.token = PubSub.subscribe(\u0026#39;atguigu\u0026#39;,(_,stateObj)=\u0026gt;{ this.setState(stateObj) }) } componentWillUnmount(){ PubSub.unsubscribe(this.token) } render() { const {users,isFirst,isLoading,err} = this.state return ( \u0026lt;div className=\u0026#34;row\u0026#34;\u0026gt; { isFirst ? \u0026lt;h2\u0026gt;欢迎使用，输入关键字，随后点击搜索\u0026lt;/h2\u0026gt; : isLoading ? \u0026lt;h2\u0026gt;Loading......\u0026lt;/h2\u0026gt; : err ? \u0026lt;h2 style={{color:\u0026#39;red\u0026#39;}}\u0026gt;{err}\u0026lt;/h2\u0026gt; : users.map((userObj)=\u0026gt;{ return ( \u0026lt;div key={userObj.id} className=\u0026#34;card\u0026#34;\u0026gt; \u0026lt;a rel=\u0026#34;noreferrer\u0026#34; href={userObj.html_url} target=\u0026#34;_blank\u0026#34;\u0026gt; \u0026lt;img alt=\u0026#34;head_portrait\u0026#34; src={userObj.avatar_url} style={{width:\u0026#39;100px\u0026#39;}}/\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;p className=\u0026#34;card-text\u0026#34;\u0026gt;{userObj.login}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; ) }) } \u0026lt;/div\u0026gt; ) } } export default class Search extends Component { search = ()=\u0026gt;{ //获取用户的输入(连续解构赋值+重命名) const {keyWordElement:{value:keyWord}} = this //发送请求前通知List更新状态 PubSub.publish(\u0026#39;atguigu\u0026#39;,{isFirst:false,isLoading:true}) //发送网络请求 axios.get(`/api1/search/users?q=${keyWord}`).then( response =\u0026gt; { //请求成功后通知List更新状态 PubSub.publish(\u0026#39;atguigu\u0026#39;,{isLoading:false,users:response.data.items}) }, error =\u0026gt; { //请求失败后通知App更新状态 PubSub.publish(\u0026#39;atguigu\u0026#39;,{isLoading:false,err:error.message}) } ) } render() { return ( \u0026lt;section className=\u0026#34;jumbotron\u0026#34;\u0026gt; \u0026lt;h3 className=\u0026#34;jumbotron-heading\u0026#34;\u0026gt;搜索github用户\u0026lt;/h3\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input ref={c =\u0026gt; this.keyWordElement = c} type=\u0026#34;text\u0026#34; placeholder=\u0026#34;输入关键词点击搜索\u0026#34;/\u0026gt;\u0026amp;nbsp; \u0026lt;button onClick={this.search}\u0026gt;搜索\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/section\u0026gt; ) } } Ref {#8.%C2%A0Ref} 为自定义的标签打标识\n9.1 字符串形式的ref {#8.1%20%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%BD%A2%E5%BC%8F%E7%9A%84ref%C2%A0} string形式的 ref 存在效率问题，不推荐使用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 \u0026lt;script type=\u0026#34;text/babel\u0026#34;\u0026gt; //创建组件 class Demo extends React.Component{ //展示左侧输入框的数据 showData = ()=\u0026gt;{ const {input1} = this.refs alert(input1.value) } //展示右侧输入框的数据 showData2 = ()=\u0026gt;{ const {input2} = this.refs alert(input2.value) } render(){ return( \u0026lt;div\u0026gt; //ref相当于属性id，即标识了一个名为input1的input标签 \u0026lt;input ref=\u0026#34;input1\u0026#34; type=\u0026#34;text\u0026#34; placeholder=\u0026#34;点击按钮提示数据\u0026#34;/\u0026gt;\u0026amp;nbsp; \u0026lt;button onClick={this.showData}\u0026gt;点我提示左侧的数据\u0026lt;/button\u0026gt;\u0026amp;nbsp; \u0026lt;input ref=\u0026#34;input2\u0026#34; onBlur={this.showData2} type=\u0026#34;text\u0026#34; placeholder=\u0026#34;失去焦点提示数据\u0026#34;/\u0026gt; \u0026lt;/div\u0026gt; ) } } //渲染组件到页面 ReactDOM.render(\u0026lt;Demo a=\u0026#34;1\u0026#34; b=\u0026#34;2\u0026#34;/\u0026gt;,document.getElementById(\u0026#39;test\u0026#39;)) \u0026lt;/script\u0026gt; 9.2 回调函数的ref {#8.2%20%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%E7%9A%84ref} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 \u0026lt;script type=\u0026#34;text/babel\u0026#34;\u0026gt; //创建组件 class Demo extends React.Component{ //展示左侧输入框的数据 showData = ()=\u0026gt;{ const {input1} = this alert(input1.value) } //展示右侧输入框的数据 showData2 = ()=\u0026gt;{ const {input2} = this alert(input2.value) } render(){ return( \u0026lt;div\u0026gt; //input的ref为c，把c赋给this实例对象，即把c标识的这个input标签赋给this对象，同时把input标签命名为myinput \u0026lt;input ref={c =\u0026gt; this.myinput = c } type=\u0026#34;text\u0026#34; placeholder=\u0026#34;点击按钮提示数据\u0026#34;/\u0026gt;\u0026amp;nbsp; \u0026lt;button onClick={this.showData}\u0026gt;点我提示左侧的数据\u0026lt;/button\u0026gt;\u0026amp;nbsp; \u0026lt;input onBlur={this.showData2} ref={c =\u0026gt; this.input2 = c } type=\u0026#34;text\u0026#34; placeholder=\u0026#34;失去焦点提示数据\u0026#34;/\u0026gt;\u0026amp;nbsp; \u0026lt;/div\u0026gt; ) } } //渲染组件到页面 ReactDOM.render(\u0026lt;Demo a=\u0026#34;1\u0026#34; b=\u0026#34;2\u0026#34;/\u0026gt;,document.getElementById(\u0026#39;test\u0026#39;)) \u0026lt;/script\u0026gt; 9.3 createRef() {#8.3%20createRef()} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 \u0026lt;script type=\u0026#34;text/babel\u0026#34;\u0026gt; //创建组件 class Demo extends React.Component{ /* React.createRef调用后可以返回一个容器，该容器可以存储被ref所标识的节点,该容器是\u0026#34;专人专用\u0026#34;的 */ myRef = React.createRef() myRef2 = React.createRef() //展示左侧输入框的数据 showData = ()=\u0026gt;{ alert(this.myRef.current.value); } //展示右侧输入框的数据 showData2 = ()=\u0026gt;{ alert(this.myRef2.current.value); } render(){ return( \u0026lt;div\u0026gt; \u0026lt;input ref={this.myRef} type=\u0026#34;text\u0026#34; placeholder=\u0026#34;点击按钮提示数据\u0026#34;/\u0026gt;\u0026amp;nbsp; \u0026lt;button onClick={this.showData}\u0026gt;点我提示左侧的数据\u0026lt;/button\u0026gt;\u0026amp;nbsp; \u0026lt;input onBlur={this.showData2} ref={this.myRef2} type=\u0026#34;text\u0026#34; placeholder=\u0026#34;失去焦点提示数据\u0026#34;/\u0026gt;\u0026amp;nbsp; \u0026lt;/div\u0026gt; ) } } //渲染组件到页面 ReactDOM.render(\u0026lt;Demo a=\u0026#34;1\u0026#34; b=\u0026#34;2\u0026#34;/\u0026gt;,document.getElementById(\u0026#39;test\u0026#39;)) \u0026lt;/script\u0026gt; Ajax和Axios {#9.%20Ajax%E5%92%8CAxios} 10.1 前置说明 {#9.1%20%E5%89%8D%E7%BD%AE%E8%AF%B4%E6%98%8E} React本身只关注于界面, 并不包含发送ajax请求的代码 前端应用需要通过ajax请求与后台进行交互(json数据) react应用中需要集成第三方ajax库(或自己封装) 10.2 Ajax请求库 {#9.2%20Ajax%E8%AF%B7%E6%B1%82%E5%BA%93} jQuery: 比较重, 如果需要另外引入不建议使用 axios: 轻量级, 建议使用 封装XmlHttpRequest对象的ajax（XHR） promise风格 可以用在浏览器端和node服务器端 10.3 Axios请求 {#9.3%20Axios%E8%AF%B7%E6%B1%82%C2%A0} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 1)\tGET请求 axios.get(\u0026#39;/user?ID=12345\u0026#39;) .then(function (response) { console.log(response.data); }) .catch(function (error) { console.log(error); }); axios.get(\u0026#39;/user\u0026#39;, { params: { ID: 12345 } }) .then(function (response) { console.log(response); }) .catch(function (error) { console.log(error); }); 2)\tPOST请求 axios.post(\u0026#39;/user\u0026#39;, { firstName: \u0026#39;Fred\u0026#39;, lastName: \u0026#39;Flintstone\u0026#39; }) .then(function (response) { console.log(response); }) .catch(function (error) { console.log(error); }); 10.4 Server.js代理 {#9.4%20Server.js%E4%BB%A3%E7%90%86} 除了熟知的nginx代理，还可以用js实现代理。 代理是为了解决跨域请求，在前后端交互中，前端发给后端的请求被后端接收到，但是后端返回给前端的数据却无法被前端接收。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 export default class App extends React.Component { getStudentData = ()=\u0026gt;{ axios.get(\u0026#39;http://localhost:3000/api1/students\u0026#39;).then( response =\u0026gt; {console.log(\u0026#39;成功了\u0026#39;,response.data);}, error =\u0026gt; {console.log(\u0026#39;失败了\u0026#39;,error);} ) } getCarData = ()=\u0026gt;{ axios.get(\u0026#39;http://localhost:3000/api2/cars\u0026#39;).then( response =\u0026gt; {console.log(\u0026#39;成功了\u0026#39;,response.data);}, error =\u0026gt; {console.log(\u0026#39;失败了\u0026#39;,error);} ) } render() { return ( \u0026lt;div\u0026gt; \u0026lt;button onClick={this.getStudentData}\u0026gt;点我获取学生数据\u0026lt;/button\u0026gt; \u0026lt;button onClick={this.getCarData}\u0026gt;点我获取汽车数据\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; ) } } ================================代理=============================== //引入了 http-proxy-middleware 库，它提供了一种简单的方法来创建代理中间件。 const proxy = require(\u0026#39;http-proxy-middleware\u0026#39;) module.exports = function(app){ app.use( proxy(\u0026#39;/api1\u0026#39;,{ //遇见/api1前缀的请求，就会触发该代理配置 target:\u0026#39;http://localhost:5000\u0026#39;, //请求转发给谁 changeOrigin:true,//控制服务器收到的请求头中Host的值。Host请求标识请求来源 pathRewrite:{\u0026#39;^/api1\u0026#39;:\u0026#39;\u0026#39;} //重写请求路径(必须) }), proxy(\u0026#39;/api2\u0026#39;,{ target:\u0026#39;http://localhost:5001\u0026#39;, changeOrigin:true, pathRewrite:{\u0026#39;^/api2\u0026#39;:\u0026#39;\u0026#39;} }), ) } 路由 {#10.%20%E8%B7%AF%E7%94%B1} 哈希路由和浏览器路由\nBrowserRouter与HashRouter的区别\n1.底层原理不一样：\nBrowserRouter使用的是H5的history API，不兼容IE9及以下版本。\nHashRouter使用的是URL的哈希值。\n2.path表现形式不一样\nBrowserRouter的路径中没有#,例如：localhost:3000/demo/test\nHashRouter的路径包含#,例如：localhost:3000/#/demo/test\n3.刷新后对路由state参数的影响\n(1).BrowserRouter没有任何影响，因为state保存在history对象中。\n(2).HashRouter刷新后会导致路由state参数的丢失！！！\n4.备注：HashRouter可以用于解决一些路径错误相关的问题。\n编程式路由导航\n不需要用户触发，可以自动跳转链接\n借助this.prosp.history对象上的API对操作路由跳转、前进、后退\n-this.prosp.history.push()\n-this.prosp.history.replace()\n-this.prosp.history.goBack()\n-this.prosp.history.goForward()\n-this.prosp.history.go()\n向路由组件传参\n","date":"2024-10-08T00:35:44Z","permalink":"/zh-cn/post/2024/10/%E6%B5%85%E5%AD%A6react%E5%92%8Cjsx/","title":"浅学React和JSX"},{"content":" 往期推荐 {#%E5%BE%80%E6%9C%9F%E6%8E%A8%E8%8D%90} 一文入门大数据准流式计算引擎Spark【万字详解，全网最新】-CSDN博客\n浅谈维度建模、数据分析模型，何为数据仓库，与数据库的区别_统一数仓 数据库用户名-CSDN博客数仓架构：离线数仓、实时数仓Lambda和Kappa、湖仓一体数据湖-CSDN博客\n数仓分层ODS、DWD、DWM、DWS、DIM、DM、ADS_ods dwd dws ads dm-CSDN博客浅谈维度建模、数据分析模型，何为数据仓库，与数据库的区别_统一数仓 数据库用户名-CSDN博客\n目录{#main-toc}\n0. Flink知识图谱{#0.%20Flink%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1-toc}\n1. Flink发展{#1.%C2%A0Flink%E5%8F%91%E5%B1%95-toc}\n1.1 四代计算引擎{#1.1%20%E5%9B%9B%E4%BB%A3%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-toc}\n2. Flink简介{#2.%20Flink%E7%AE%80%E4%BB%8B-toc}\n2.1 Flink特点{#2.1%20Flink%E7%89%B9%E7%82%B9%C2%A0-toc}\n2.2 批处理和流处理{#2.2%20%E6%89%B9%E5%A4%84%E7%90%86%E5%92%8C%E6%B5%81%E5%A4%84%E7%90%86%C2%A0-toc}\n2.3 有界流和无界流{#2.3%20%E6%9C%89%E7%95%8C%E6%B5%81%E5%92%8C%E6%97%A0%E7%95%8C%E6%B5%81-toc}\n2.4 Flink和Spark Streaming{#2.4%20Flink%E5%92%8CSpark%20Streaming-toc}\n3. Flink三层核心架构{#3.%20Flink%E4%B8%89%E5%B1%82%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84-toc}\n3.1 API \u0026amp; Libraries层详解{#3.1%20API%20%26%20Libraries%E5%B1%82%E8%AF%A6%E8%A7%A3-toc}\n3.1.1 SQL\u0026amp;Table API层{#3.1.1%20SQL%26Table%20API%E5%B1%82-toc}\n3.1.2 DataStream \u0026amp; DataSet API层{#3.1.2%C2%A0DataStream%20%26%20DataSet%20API%E5%B1%82-toc}\n3.1.3 Stateful Stream Processing层{#3.1.3%C2%A0Stateful%20Stream%20Processing%E5%B1%82-toc}\n4. 三种Time概念{#4.%20%E4%B8%89%E7%A7%8DTime%E6%A6%82%E5%BF%B5-toc}\n4.1 WaterMark水印{#4.1%C2%A0WaterMark%E6%B0%B4%E5%8D%B0-toc}\n5. Windows窗口类型{#5.%20Windows%E7%AA%97%E5%8F%A3%E7%B1%BB%E5%9E%8B-toc}\n5.1 时间窗口{#5.1%20%E6%97%B6%E9%97%B4%E7%AA%97%E5%8F%A3-toc}\n5.1.1 滚动窗口Tumbling Windows{#5.1.1%20%E6%BB%9A%E5%8A%A8%E7%AA%97%E5%8F%A3Tumbling%20Windows-toc}\n5.1.2 滑动窗口Sliding Windows{#5.1.2%20%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3Sliding%20Windows-toc}\n5.1.3 会话窗口Session Windows{#5.1.3%20%E4%BC%9A%E8%AF%9D%E7%AA%97%E5%8F%A3Session%20Windows-toc}\n5.1.4 全局窗口Global Windows{#5.1.4%20%E5%85%A8%E5%B1%80%E7%AA%97%E5%8F%A3Global%20Windows-toc}\n5.2 计数窗口{#5.2%20%E8%AE%A1%E6%95%B0%E7%AA%97%E5%8F%A3-toc}\n6. 状态管理{#6.%20%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86-toc}\n6.1 状态的Flink官方定义{#6.1%C2%A0%E7%8A%B6%E6%80%81%E7%9A%84Flink%E5%AE%98%E6%96%B9%E5%AE%9A%E4%B9%89-toc}\n6.2 状态分类及状态存储类型{#6.2%C2%A0%E7%8A%B6%E6%80%81%E5%88%86%E7%B1%BB%E5%8F%8A%E7%8A%B6%E6%80%81%E5%AD%98%E5%82%A8%E7%B1%BB%E5%9E%8B-toc}\n6.2.1 算子状态{#6.2.1%20%E7%AE%97%E5%AD%90%E7%8A%B6%E6%80%81-toc}\n6.2.2 键控状态{#6.2.2%20%E9%94%AE%E6%8E%A7%E7%8A%B6%E6%80%81-toc}\n6.2.3 Broadcast State{#6.2.3%C2%A0Broadcast%20State-toc}\n6.3. 状态后端（持久化存储）{#6.3.%20%E7%8A%B6%E6%80%81%E5%90%8E%E7%AB%AF%EF%BC%88%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%EF%BC%89-toc}\n7. Flink算子{#7.%20Flink%E7%AE%97%E5%AD%90-toc}\n7.1 DataSet批处理算子{#7.1%20DataSet%E6%89%B9%E5%A4%84%E7%90%86%E7%AE%97%E5%AD%90-toc}\n7.1.1 Source算子{#7.1.1%20Source%E7%AE%97%E5%AD%90-toc}\n7.1.2 Transform 转换算子{#7.1.2%C2%A0Transform%20%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90-toc}\n7.1.3 Sink 输出算子{#7.1.3%C2%A0Sink%20%E8%BE%93%E5%87%BA%E7%AE%97%E5%AD%90-toc}\n7.2 DataStream流处理算子{#7.2%20DataStream%E6%B5%81%E5%A4%84%E7%90%86%E7%AE%97%E5%AD%90-toc}\n8. Flink容错{#8.%20Flink%E5%AE%B9%E9%94%99-toc}\n8.1 Checkpoint机制{#8.1%C2%A0Checkpoint%E6%9C%BA%E5%88%B6-toc}\n9. Flink CEP{#9.%20Flink%20CEP-toc}\n9.1 使用场景{#9.1%20%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%C2%A0-toc}\n9.2 CEP API{#9.2%C2%A0CEP%20API-toc}\n10. Flink CDC{#10.%20Flink%20CDC-toc}\n10.1 CDC种类{#10.1%20CDC%E7%A7%8D%E7%B1%BB-toc}\n11. Flink SQL{#11.%20Flink%20SQL-toc}\nFlink知识图谱 Flink发展 {#1.%C2%A0Flink%E5%8F%91%E5%B1%95} Apache Flink 诞生于柏林工业大学的一个研究性项目，原名 StratoSphere 。2014 年，由 StratoSphere 项目孵化出 Flink，并于同年捐赠 Apache，之后成为 Apache 的顶级项目。2019 年 1 年，阿里巴巴收购了 Flink 的母公司 Data Artisans，并宣布开源内部的 Blink，Blink 是阿里巴巴基于 Flink 优化后的版本，增加了大量的新功能，并在性能和稳定性上进行了各种优化，经历过阿里内部多种复杂业务的挑战和检验。同时阿里巴巴也表示会逐步将这些新功能和特性 Merge 回社区版本的 Flink 中，因此 Flink 成为目前最为火热的大数据处理框架。\n1.1 四代计算引擎 {#1.1%20%E5%9B%9B%E4%BB%A3%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E} 在国外一些社区，有很多人将大数据的计算引擎分成了 4 代，当然，也有很多人不会认同。我们先姑且这么认为和讨论。\n首先第一代的计算引擎，无疑就是 Hadoop 承载的 MapReduce。这里大家应该都 不会对 MapReduce 陌生，它将计算分为两个阶段，分别为 Map 和 Reduce。对于上层应用来说，就不得不想方设法去拆分算法，甚至于不得不在上层应用实现 多个 Job 的串联，以完成一个完整的算法，例如迭代计算 。 由于这样的弊端，催生了支持 DAG 框架的产生。 因此，支持 DAG 的框架被划分为第二代计算引擎。如 Tez 以及更上层的 Oozie。这里我们不去细究各种 DAG 实现之间的区别，不过对于当时的 Tez 和 Oozie 来说，大多还是批处理的任务。 接下来就是以 Spark 为代表的第三代的计算引擎。第三代计算引擎的特点主要 是 Job 内部的 DAG 支持（不跨越 Job），以及强调的准实时计算。在这里，很多人也会认为第三代计算引擎也能够很好的运行批处理的 Job。 随着第三代计算引擎的出现，促进了上层应用快速发展，例如各种迭代计算的性能以及对流计算和 SQL 等的支持。 Flink 的诞生就被归在了第四代。这应该主 要表现在 Flink 对流计算的支持，以及更一步的实时性上面。当然 Flink 也可 以支持 Batch 的任务，以及 DAG 的运算。 Flink简介 {#2.%20Flink%E7%AE%80%E4%BB%8B} Flink 是一个分布式、高性能、有状态的流处理框架，它能够对有界和无界的数据流进行高效的处理。Flink 的 **核心是流处理（DataStream），当然也支持批处理（DataSet），Flink 将批处理看成是流处理的一种特殊情况，即数据流是有 明确界限的。**这和 Spark Streaming 的思想是完全相反的，Spark Streaming 的核心是批处理，它将流处理看成是批处理的一种特殊情况， 即把数据流进行极小粒度的拆分，拆分为多个微批处理。 2.1 Flink特点 {#2.1%20Flink%E7%89%B9%E7%82%B9%C2%A0} 支持高吞吐、低延迟、高性能的流处理 结果准确，Flink提供了事件时间和处理时间，对乱序数据仍能提供一直准确的结果 支持高度灵活的窗口（Window）操作，支持基于 time、count、session， 以及 data-driven 的窗口操作 支持基于轻量级分布式快照（Snapshot）实现的容错 一个运行时同时支持 Batch on Streaming 处理和 Streaming 处理 Flink 在 JVM 内部实现了自己的内存管理 支持迭代计算，Spark也支持 支持程序自动优化：避免特定情况下 Shuffle、排序等昂贵操作，中间结果有必要进行缓存 2.2 批处理和流处理 {#2.2%20%E6%89%B9%E5%A4%84%E7%90%86%E5%92%8C%E6%B5%81%E5%A4%84%E7%90%86%C2%A0} 批处理\n有界、持久、大量，一般用于离线计算 流处理\n无界、实时，流处理方式无需对整个数据集执行操作，而是对通过系统传输的每个数据项执行操作，一般用于实时统计 在 Spark 生态体系中，对于批处理和流处理采用了不同的技术框架，批处理由 SparkSQL 实现，流处理由 Spark Streaming 实现，这也是大部分框架采用的策略，使用独立的处理器实现批处理和流处理，而 Flink 可以同时实现批处理和流处理，Flink 将批处理（即处理 有限的静态数据）视作一种特殊的流处理，即把数据看作是有界的 ！\n2.3 有界流和无界流 {#2.3%20%E6%9C%89%E7%95%8C%E6%B5%81%E5%92%8C%E6%97%A0%E7%95%8C%E6%B5%81} 无界数据流：\n有定义流的开始，但没有定义流的结束； 它们会无休止的产生数据 无界流的数据必须持续处理，即数据被摄取后需要立刻处理 我们不能等到所有数据都到达再处理，因为输入是无限的。 有界数据流：\n有定义流的开始，也有定义流的结束 有界流可以在摄取所有数据后再进行计算 有界流所有数据可以被排序，所以并不需要有序摄取 有界流处理通常被称为批处理。 2.4 Flink和Spark Streaming {#2.4%20Flink%E5%92%8CSpark%20Streaming} Spark本质是批处理\nSpark数据模型：Spak采用RDD模型，Spark Streaming的DStream实际上也就是一组组小批据RDD的集合 Spark运行时架构：Spark是批计算，将DAG划分为不同的stage,一个完成后才可以计算下一个 Flink以流处理为根本\nFlink数据模型：Flink基本据模型是数据流，以及事件(Event)序列 Flink运行时架构：Flink是标准的流执行模式，一个事件在一个节点处理完后可以直接发往下一个节点进行处理 Flink三层核心架构 {#3.%20Flink%E4%B8%89%E5%B1%82%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84} 下图为 Flink 技术栈的核心组成部分，由上而下分别是 API \u0026amp; Libraries 层、Runtime 核心层以及物理部署层。\n","date":"2024-09-05T23:07:21Z","permalink":"/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8Eflink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/","title":"一文搞懂大数据流式计算引擎Flink【万字详解，史上最全】"},{"content":" 往期推荐 {#%E5%BE%80%E6%9C%9F%E6%8E%A8%E8%8D%90} 浅谈维度建模、数据分析模型，何为数据仓库，与数据库的区别-CSDN博客\n数仓架构：离线数仓、实时数仓Lambda和Kappa、湖仓一体数据湖-CSDN博客\nDW层的数仓建模：范式建模、维度建模及数据分析模型、实体建模-CSDN博客\n数仓分层ODS、DWD、DWM、DWS、DIM、DM、ADS_dm ads-CSDN博客\n后续考虑，会出Spark调优、shuffle、数据倾斜优化等\n目录{#main-toc}\n往期推荐{#%E5%BE%80%E6%9C%9F%E6%8E%A8%E8%8D%90-toc}\n1. Spark简介{#1.%20Spark%E7%AE%80%E4%BB%8B-toc}\n1.1 Spark特点{#1.1%20Spark%E7%89%B9%E7%82%B9-toc}\n1.2 Spark和MR处理任务对比{#1.2%20Spark%E5%92%8CMR%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E5%AF%B9%E6%AF%94-toc}\n2. Spark组件{#2.%20Spark%E7%BB%84%E4%BB%B6-toc}\n2.1 Spark Core{#2.1%20Spark%20Core-toc}\n2.1.1 RDD算子{#2.1.1%20RDD%E7%AE%97%E5%AD%90-toc}\n2.1.1.1 为什么有RDD？{#2.1.1.1%20%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89RDD%EF%BC%9F-toc}\n2.1.1.2 RDD介绍{#2.1.1.2%20RDD%E4%BB%8B%E7%BB%8D-toc}\n2.1.2 RDD 特点{#2.1.2%20RDD%20%E7%89%B9%E7%82%B9-toc}\n2.1.3 RDD做了什么{#2.1.3%20RDD%E5%81%9A%E4%BA%86%E4%BB%80%E4%B9%88-toc}\n2.1.4 RDD的转换和行动操作{#2.1.4%20RDD%E7%9A%84%E8%BD%AC%E6%8D%A2%E5%92%8C%E8%A1%8C%E5%8A%A8%E6%93%8D%E4%BD%9C-toc}\n2.1.4.1 Transformation（转换）算子概述{#2.1.4.1%C2%A0%20Transformation%EF%BC%88%E8%BD%AC%E6%8D%A2%EF%BC%89%E7%AE%97%E5%AD%90%E6%A6%82%E8%BF%B0-toc}\n2.1.4.2 Action（行动）算子概述{#2.1.4.2%C2%A0%20Action%EF%BC%88%E8%A1%8C%E5%8A%A8%EF%BC%89%E7%AE%97%E5%AD%90%E6%A6%82%E8%BF%B0%C2%A0-toc}\n2.1.5 RDD持久化和缓存{#2.1.5%20RDD%E6%8C%81%E4%B9%85%E5%8C%96%E5%92%8C%E7%BC%93%E5%AD%98-toc}\n2.1.6 存储级别{#2.1.6%20%E5%AD%98%E5%82%A8%E7%BA%A7%E5%88%AB-toc}\n2.1.7 Checkpoint检查点机制{#2.1.7%20Checkpoint%E6%A3%80%E6%9F%A5%E7%82%B9%E6%9C%BA%E5%88%B6%C2%A0-toc}\n2.1.8 RDD宽窄依赖{#2.1.8%20RDD%E5%AE%BD%E7%AA%84%E4%BE%9D%E8%B5%96-toc}\n2.1.8.1 为什么要设计宽窄依赖{#2.1.8.1%20%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%AE%BE%E8%AE%A1%E5%AE%BD%E7%AA%84%E4%BE%9D%E8%B5%96-toc}\n2.1.8.2 DAG生成和划分Stage{#2.1.8.2%20DAG%E7%94%9F%E6%88%90%E5%92%8C%E5%88%92%E5%88%86Stage-toc}\n2.2 Spark SQL{#2.2%20Spark%20SQL-toc}\n2.2.1 Spark SQL发展（精彩）{#2.2.1%20Spark%20SQL%E5%8F%91%E5%B1%95%EF%BC%88%E7%B2%BE%E5%BD%A9%EF%BC%89-toc}\n2.2.2 Spark SQL概述{#2.2.2%20Spark%20SQL%E6%A6%82%E8%BF%B0-toc}\n2.2.3 Spark SQL特点{#2.2.3%20Spark%20SQL%E7%89%B9%E7%82%B9-toc}\n2.2.4 Spark SQL数据模型 DataFrame和Dataset{#2.2.4%20Spark%20SQL%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%20DataFrame%E5%92%8CDataset-toc}\n2.2.5 如何进行SparkSQL编程{#2.2.5%20%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8CSparkSQL%E7%BC%96%E7%A8%8B-toc}\n2.3 Spark Streaming{#2.3%20Spark%20Streaming-toc}\n2.3.1 简介{#2.3.1%20%E7%AE%80%E4%BB%8B-toc}\n2.3.2 流式计算特点{#2.3.2%20%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E7%89%B9%E7%82%B9-toc}\n2.3.3 常见流式计算和离线计算框架{#2.3.3%20%E5%B8%B8%E8%A7%81%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%92%8C%E7%A6%BB%E7%BA%BF%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6-toc}\n2.3.4 SparkStreaming的基本工作原理{#2.3.4%20SparkStreaming%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86-toc}\n2.3.5 SparkStreaming的缓存{#2.3.5%20SparkStreaming%E7%9A%84%E7%BC%93%E5%AD%98-toc}\n2.3.6 SparkStreaming的容错{#2.3.6%20SparkStreaming%E7%9A%84%E5%AE%B9%E9%94%99-toc}\n2.3.7 DStream操作{#2.3.7%20DStream%E6%93%8D%E4%BD%9C-toc}\n2.4 MLlib{#2.4%20MLlib-toc}\n2.5 Graphx{#2.5%20Graphx-toc}\nSpark多种部署模式{#Spark%E5%A4%9A%E7%A7%8D%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F-toc}\nSpark简介 {#1.%20Spark%E7%AE%80%E4%BB%8B} Spark 于 2009 年诞生于加州大学伯克利分校 AMPLab，2013 年被捐赠给 Apache 软件基金会，2014 年 2 月成为 Apache 的顶级项目。\n相对于 MapReduce 的批处理计算，Spark基于内存计算，可以带来上百倍的性能提升，因此它成为继 MapReduce 之后，最为广泛使用的分布式计算框架、大数据分析引擎。\n1.1 Spark特点 {#1.1%20Spark%E7%89%B9%E7%82%B9} 快：采用DAG执行引擎，支持循环数据流和内存计算，使得 Spark 速度更快，在内存中的速度 是Hadoop MR的百倍，在磁盘上的速度是Hadoop MR的十倍(官网数据)。 通用：Spark提供了统一的解决方案。Spark可以⽤于批处理、交互式查询（Spark SQL）、实时流处理（Spark Streaming）、机器学习（Spark MLlib）和图计算（GraphX）。这些不同类型的处理都可以在同⼀个应用中无缝使用。 易用：Spark支持Java、Python、Scala的API和超过80种⾼级算法，⽽且⽀持交互式的Python和Scala的shell。 兼容：Spark可以使⽤Hadoop的YARN和Apache Mesos作为它的资源管理和调度器，器，并且不需要任何数据迁移就可以处理所有Hadoop支持的数据，包括HDFS、HBase和Cassandra等。Spark也可以不依赖于第三⽅的资源管理和调度器，它实现了Standalone作为其内置的资源管理和调度框架。 1.2 Spark和MR处理任务对比 {#1.2%20Spark%E5%92%8CMR%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E5%AF%B9%E6%AF%94} Spark组件 {#2.%20Spark%E7%BB%84%E4%BB%B6} 2.1 Spark Core {#2.1%20Spark%20Core} Spark Core实现了 Spark 的基本功能，包含任务调度、内存管理、错误恢复、与存储系统 交互等模块。Spark Core 中还包含 了对弹性分布式数据集(resilient distributed dataset，简称RDD)的 API 定义。\n2.1.1 RDD算子 {#2.1.1%20RDD%E7%AE%97%E5%AD%90} 2.1.1.1 为什么有RDD？ {#2.1.1.1%20%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89RDD%EF%BC%9F} 在许多迭代式算法(比如机器学习、图算法等)和交互式数据挖掘中，不同计算阶段之间会重用中间结果，即一个阶段的输出结果会作为下一个阶段的输入。但是， 之前的 MapReduce 框架采用非循环式的数据流模型，把中间结果写入到 HDFS 中，带来了大量的数据复制、磁盘 IO 和序列化开销，且这些框架只能支持一些 特定的计算模式(map/reduce)，并没有提供一种通用的数据抽象。\nRDD 提供了一个抽象的数据模型，让我们不必担心底层数据的分布式特性，只需将具体的应用逻辑表达为一系列转换操作(函数) ，不同 RDD 之间的转换操作之间还可以形成依赖关系，进而实现管道化，从而避免了中间结果的存储，大大降低数据复制、磁盘 IO 和序列化开销，并且还提供了更多的 API操作！\n2.1.1.2 RDD介绍 {#2.1.1.2%20RDD%E4%BB%8B%E7%BB%8D} RDD（Resilient Distributed Dataset）叫做弹性分布式数据集，是Spark中最基本的数据抽象，是Spark计算的基石，它代表⼀个不可变、可分区、里面的元素可并行计算的集合。 RDD具有数据流模型的特点：自动容错、位置感知性调度和可伸缩性。RDD允许用户在执⾏多个查询时显式地将⼯作集缓存在内存中，后续的查询能够重⽤⼯作集，这极⼤地提升了查询速度。 MR中对数据是没有进行抽象的，而在Spark中对数据进行了抽象，提供⼀些列处理⽅法也就是 RDD，为用户屏蔽了底层对数据的复杂抽象和处理，为⽤户提供了⼀组⽅便 的数据转换与求值方法，好比Java中类的封装。 注意 : RDD本身是不存储数据，而是记录了数据的位置，数据的转换关系(调用什么方法、传入什么函数)！！！\n以下是RDD源码翻译解读：\n2.1.2 RDD 特点 {#2.1.2%20RDD%20%E7%89%B9%E7%82%B9} 弹性体现： 存储的弹性：内存与磁盘的自动切换； 容错的弹性：RDD的血统（Lineag）会记录RDD的元数据信息和转换行为 ，当RDD的部分分区数据丢失时，它可以根据这些信息来重新运算并恢复丢失的数据分区。 计算的弹性：计算出错重试机制； 分片的弹性：可根据需要重新分片； 分布式：数据存储在大数据集群不同节点上 数据集：RDD封装了计算逻辑，并不保存数据 数据抽象：RDD是⼀个抽象，需要具体实现 不可变：RDD封装的计算逻辑不可改变，想要改变只能产⽣新的RDD 可分区、并行计算 2.1.3 RDD做了什么 {#2.1.3%20RDD%E5%81%9A%E4%BA%86%E4%BB%80%E4%B9%88} 从计算的角度来讲，数据处理过程中需要计算资源（内存 \u0026amp; CPU）和计算模型（逻辑）。执⾏时，需要将计算资源\n","date":"2024-09-04T00:12:24Z","permalink":"/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8Espark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/","title":"一文入门大数据准流式计算引擎Spark【万字详解，全网最新】"},{"content":" 往期推荐 {#%E5%BE%80%E6%9C%9F%E6%8E%A8%E8%8D%90} 大数据HBase图文简介-CSDN博客\n数仓分层ODS、DWD、DWM、DWS、DIM、DM、ADS-CSDN博客\n数仓常见名词解析和名词之间的关系-CSDN博客\n数仓架构：离线数仓、实时数仓Lambda和Kappa、湖仓一体数据湖-CSDN博客\n前言 {#0.%20%E5%89%8D%E8%A8%80} 1991年，数据仓库之父 比尔·恩门 著书《Building the DataWarehouse》，要求构建数据仓库 时，遵循范式建模，即从关系型数据库中提取的范式数据，仍按范式存储到数据仓库中，这样就导致数仓中有很多小表，查询的时候必然会有很多表的关联，极大地影响查询效率和性能。 1994年，拉尔夫·金博尔 著书《The DataWarehouse Toolkit》，提出维度建模和数据集市的概念，维度建模是反范式建模，自下而上 ，然而这种方式仍有缺点：那就是每个业务平台的数据有各自的数据集市，集市之间数据隔离，存在数据不一致、重复的情况。 1998-2001年，比尔·恩门派和金博尔派合并，比尔·恩门提出CIF架构：数仓分层，不同层采用不同的建模方式，同时解决了数据不一致和查询效率低的问题。 基于以上，有了范式建模、维度建模、实体建模三种主要建模方式 0.1 浅谈维度建模 {#0.1%20%E6%B5%85%E8%B0%88%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1} 维度建模主要面向 ","date":"2024-09-01T21:34:40Z","permalink":"/zh-cn/post/2024/09/%E6%B5%85%E8%B0%88%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E4%BD%95%E4%B8%BA%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%8C%BA%E5%88%AB/","title":"浅谈维度建模、数据分析模型，何为数据仓库，与数据库的区别"},{"content":" 往期推荐 {#%E5%BE%80%E6%9C%9F%E6%8E%A8%E8%8D%90} 大数据HBase图文简介-CSDN博客\n数仓分层ODS、DWD、DWM、DWS、DIM、DM、ADS-CSDN博客\n数仓常见名词解析和名词之间的关系-CSDN博客\n=========================================================================\n目录{#main-toc}\n往期推荐{#%E5%BE%80%E6%9C%9F%E6%8E%A8%E8%8D%90-toc}\n1. 数仓架构{#0.%20%E5%89%8D%E8%A8%80-toc}\n1.1 离线数仓架构{#1.1%C2%A0%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84-toc}\n1.1.1 数据集市架构{#2.1%20%E6%95%B0%E6%8D%AE%E9%9B%86%E5%B8%82%E6%9E%B6%E6%9E%84-toc}\n1.1.1.2 独立数据集市{#2.1.1%20%E7%8B%AC%E7%AB%8B%E6%95%B0%E6%8D%AE%E9%9B%86%E5%B8%82-toc}\n1.1.1.2 从属数据集市{#2.1.2%20%E4%BB%8E%E5%B1%9E%E6%95%B0%E6%8D%AE%E9%9B%86%E5%B8%82-toc}\n1.1.2 Inmon企业信息工厂架构{#2.2%20Inmon%E4%BC%81%E4%B8%9A%E4%BF%A1%E6%81%AF%E5%B7%A5%E5%8E%82%E6%9E%B6%E6%9E%84-toc}\n1.1.3 Kimball数据仓库架构{#2.3%20Kimball%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%9E%B6%E6%9E%84-toc}\n1.1.4 混合型数据仓库架构{#2.4%20%E6%B7%B7%E5%90%88%E5%9E%8B%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%9E%B6%E6%9E%84-toc}\n1.2 实时数仓架构{#2.2%20%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%C2%A0-toc}\n1.2.1 Lambda架构{#2.2.1%20Lambda%E6%9E%B6%E6%9E%84-toc}\n1.2.1.1 传统的Lambda实时开发{#2.2.1.1%20%E4%BC%A0%E7%BB%9F%E7%9A%84Lambda%E5%AE%9E%E6%97%B6%E5%BC%80%E5%8F%91-toc}\n1.2.1.2 升级的Lambda实时开发{#2.2.1.2%C2%A0%E5%8D%87%E7%BA%A7%E7%9A%84Lambda%E5%AE%9E%E6%97%B6%E5%BC%80%E5%8F%91-toc}\n1.2.1.3 为什么Lambda架构同时存在流处理和批处理？{#1.2.1.3%C2%A0%E4%B8%BA%E4%BB%80%E4%B9%88Lambda%E6%9E%B6%E6%9E%84%E5%90%8C%E6%97%B6%E5%AD%98%E5%9C%A8%E6%B5%81%E5%A4%84%E7%90%86%E5%92%8C%E6%89%B9%E5%A4%84%E7%90%86%EF%BC%9F-toc}\n1.2.1.4 Lambda架构缺点{#1.2.1.4%20Lambda%E6%9E%B6%E6%9E%84%E7%BC%BA%E7%82%B9-toc}\n1.2.2 Kappa架构{#2.2.2%20Kappa%E6%9E%B6%E6%9E%84-toc}\n1.2.2.1 Kappa架构缺点{#1.2.2.1%20Kappa%E6%9E%B6%E6%9E%84%E7%BC%BA%E7%82%B9%C2%A0-toc}\n1.2.3 Kappa和Lambda对比{#Kappa%E5%92%8CLambda%E5%AF%B9%E6%AF%94-toc}\n1.2.4 湖仓一体\u0026mdash;数据湖{#2.2.3%20%E6%95%B0%E6%8D%AE%E6%B9%96%E5%87%BA%E7%8E%B0%E5%8E%9F%E5%9B%A0%EF%BC%9A%E6%89%B9%E6%B5%81%E4%B8%80%E4%BD%93-toc}\n=========================================================================\n数仓架构 {#0.%20%E5%89%8D%E8%A8%80} ​\n数仓架构大致分为离线数仓架构和实时数仓架构，数仓架构可以简单理解为构成数仓的各层关系，如ODS、DWM、DWD、DWS，具体分层这里不赘述。\n1.1 离线数仓架构 {#1.1%C2%A0%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84} ​\n显而易见，这种架构不能处理实时数据，那么必然会有数据的流失。\n任何事物都是随着时间的演进变得越来越完善，当然也是越来越复杂，数仓也不例外。\n离线数仓架构 包括数据集市架构、Inmon企业信息工厂架构、Kimball数据仓库架构、混合型数据仓库架构，接下来就详细说说这几种架构。\n1.1.1 数据集市架构 {#2.1%20%E6%95%B0%E6%8D%AE%E9%9B%86%E5%B8%82%E6%9E%B6%E6%9E%84} 数据集市架构重点在于集市 二字，数据集市是按主题域 组织的数据集合，用于支持部门级的决策。有两种类型的数据集市：独立数据集市 和 从属数据集市。\n1.1.1.2 独立数据集市 {#2.1.1%20%E7%8B%AC%E7%AB%8B%E6%95%B0%E6%8D%AE%E9%9B%86%E5%B8%82} 独立数据集市集中于部门所关心的单一主题域 ，数据以部门为基础，例如制造部门、人力资源部门和其他部门都各自有他们自己的数据集市。\n​\n优点：因为一个部门的业务相对于整个企业要简单，数据量也小得多，所以部门的独立数据集市周期短、见效快。 缺点：独立数据集市各自为政。从业务角度看，当部门的分析需求扩展 或者跨部门跨主题域分析 时，独立数据市场会力不从心。 当数据存在歧义 ，比如同一个产品在A部门和B部门的定义不同，将无法在部门间进行信息比较。 每个部门使用不同的技术，建立不同的ETL的过程，处理不同的事务系统，而在多个独立的数据集市之间还会存在数据的交叉与重叠，甚至会有数据不一致的情况！ 1.1.1.2 从属数据集市 {#2.1.2%20%E4%BB%8E%E5%B1%9E%E6%95%B0%E6%8D%AE%E9%9B%86%E5%B8%82} 从属数据集市的数据来源于数据仓库\n","date":"2024-09-01T00:53:40Z","permalink":"/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/","title":"数仓架构：离线数仓、实时数仓Lambda和Kappa、湖仓一体数据湖"},{"content":"官方文档 开始使用 - Ant Design Pro\n构建项目 本次使用的是3.1.0老版本\n终端运行如下命令（注意npm包的镜像源）\n1 npm i @ant-design/pro-cli@3.1.0 -g 导入项目 打开package.json文件，查看脚本和依赖\n启动start脚本，第一次启动可能出错，原因是项目的某些依赖还没有引入，此时只需在控制台运行yarn命令，它就会自动下载需要引入的依赖，如图：\n前端启动后访问\n--- ","date":"2024-08-10T23:28:45Z","permalink":"/zh-cn/post/2024/08/ant-design-pro%E5%88%9D%E4%BD%BF%E7%94%A8/","title":"Ant Design Pro初使用"},{"content":" 往期推荐 {#%E5%BE%80%E6%9C%9F%E6%8E%A8%E8%8D%90} 数仓分层ODS、DWD、DWM、DWS、DIM、DM、ADS-CSDN博客\n数仓常见名词解析和名词之间的关系-CSDN博客\n数据仓库及数仓架构概述-CSDN博客\n大数据HBase图文简介-CSDN博客\n小学生也能看懂的Redis7持久化机制\u0026ndash;RDB和AOF-CSDN博客\n目录{#main-toc}\n1. 数仓建模在哪层建{#1.%20%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E5%9C%A8%E5%93%AA%E5%B1%82%E5%BB%BA-toc}\n2. 数仓建模要怎么建（三种建模法）{#2.%20%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%A6%81%E6%80%8E%E4%B9%88%E5%BB%BA%EF%BC%88%E4%B8%89%E7%A7%8D%E5%BB%BA%E6%A8%A1%E6%B3%95%EF%BC%89-toc}\n2.1 范式建模法（Third Normal Form，3NF）{#2.1%C2%A0%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E6%B3%95%EF%BC%88Third%20Normal%20Form%EF%BC%8C3NF%EF%BC%89-toc}\n2.2 维度建模法（Dimensional Modeling）{#2.2%20%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E6%B3%95%EF%BC%88Dimensional%20Modeling%EF%BC%89-toc}\n2.2.1 维度建模模式{#2.2.1%C2%A0%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E6%A8%A1%E5%BC%8F-toc}\n2.2.1.1 星型模式{#2.2.1.1%20%E6%98%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F-toc}\n2.2.1.2 星座模式{#2.2.1.2%20%E6%98%9F%E5%BA%A7%E6%A8%A1%E5%BC%8F-toc}\n2.2.1.3 雪花模式{#2.2.1.3%C2%A0%E9%9B%AA%E8%8A%B1%E6%A8%A1%E5%BC%8F-toc}\n2.2.2 维度建模过程{#2.2.2%20%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E8%BF%87%E7%A8%8B-toc}\n2.2.2.1 选择业务过程{#2.2.2.1%20%E9%80%89%E6%8B%A9%E4%B8%9A%E5%8A%A1%E8%BF%87%E7%A8%8B-toc}\n2.2.2.2 声明粒度{#2.2.2.2%C2%A0%E5%A3%B0%E6%98%8E%E7%B2%92%E5%BA%A6-toc}\n2.2.2.1 确认维度{#2.2.2.1%20%E7%A1%AE%E8%AE%A4%E7%BB%B4%E5%BA%A6-toc}\n2.2.2.1 确认事实{#2.2.2.1%20%E7%A1%AE%E8%AE%A4%E4%BA%8B%E5%AE%9E-toc}\n2.3 实体建模法（Entity Modeling）{#2.3%C2%A0%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1%E6%B3%95%EF%BC%88Entity%20Modeling%EF%BC%89-toc}\n数仓建模即数据仓库建模，对数据仓库中的数据进行适当的联合，类似数据库分库建表，明晰数据关系，以便进行数据处理操作。（可以适当冗余，不遵循范式）\n数仓建模在哪层建 {#1.%20%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E5%9C%A8%E5%93%AA%E5%B1%82%E5%BB%BA} 以维度建模为例，建模是在数据源层的下一层进行建设，在上节的分层架构中，就是在DW层进行数仓建模，所以DW层是数仓建设的核心层！\n数仓建模要怎么建（三种建模法） {#2.%20%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%A6%81%E6%80%8E%E4%B9%88%E5%BB%BA%EF%BC%88%E4%B8%89%E7%A7%8D%E5%BB%BA%E6%A8%A1%E6%B3%95%EF%BC%89} 常见的有范式建模法、维度建模法、实体建模法等，每种方法从本质上将是从不同的角度看待业务中的问题。\n2.1 范式建模法（Third Normal Form，3NF） {#2.1%C2%A0%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E6%B3%95%EF%BC%88Third%20Normal%20Form%EF%BC%8C3NF%EF%BC%89} 范式建模法其实是我们在构建数据模型常用的一个方法，该方法主要由 Inmon 所提倡，主要解决关系型数据库的数据存储，利用的一种技术层面上的方法。目前，我们在关系型数据库中的建模 方法，大部分采用的是三范式建模法。 范式是符合某一种级别的关系模式的集合。构造数据库必须遵循一定的规则，而在关系型数据库 中这种规则就是范式，这一过程也被称为规范化。目前关系数据库有六种范式：第一范式 （1NF）、第二范式（2NF）、第三范式（3NF）、Boyce-Codd范式（BCNF）、第四范式 （4NF）和第五范式（5NF） 在数据仓库的模型设计中，一般采用第三范式 。一个符合第三范式的关系必须具有以下三个条件 : 每个属性值唯一，不具有多义性 ; 每个非主属性必须完全依赖于整个主键，而非主键的一部分 ; 每个非主属性不能依赖于其他关系中的属性，因为这样的话，这种属性应该归到其他关系中去； 据 Inmon 的观点，数据仓库模\n","date":"2024-08-02T11:00:00Z","permalink":"/zh-cn/post/2024/08/dw%E5%B1%82%E7%9A%84%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/","title":"DW层的数仓建模：范式建模、维度建模及数据分析模型、实体建模"},{"content":" 往期推荐 数仓入门：数据分析模型、数仓建模、离线实时数仓、Lambda、Kappa、湖仓一体-CSDN博客\n数仓常见名词解析和名词之间的关系-CSDN博客\n数据仓库及数仓架构概述-CSDN博客\n大数据HBase图文简介-CSDN博客\n目录{#main-toc}\n1. 数仓分层{#1.%20%E6%95%B0%E4%BB%93%E5%88%86%E5%B1%82%C2%A0-toc}\n1.1 数据源层：ODS（Operational Data Store）{#1.1%20%E6%95%B0%E6%8D%AE%E6%BA%90%E5%B1%82%EF%BC%9AODS%EF%BC%88Operational%20Data%20Store%EF%BC%89-toc}\n1.2 数据仓库层：DW（Data Warehouse）{#1.2%20%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%B1%82%EF%BC%9ADW%EF%BC%88Data%20Warehouse%EF%BC%89-toc}\n1.2.1 数据明细层：DWD（Data Warehouse Detail）{#1.2.1%20%E6%95%B0%E6%8D%AE%E6%98%8E%E7%BB%86%E5%B1%82%EF%BC%9ADWD%EF%BC%88Data%20Warehouse%20Detail%EF%BC%89-toc}\n1.2.2 数据中间层：DWM（Data WareHouse Midddle）{#1.2.2%20%E6%95%B0%E6%8D%AE%E4%B8%AD%E9%97%B4%E5%B1%82%EF%BC%9ADWM%EF%BC%88Data%20WareHouse%20Midddle%EF%BC%89-toc}\n1.2.3 数据服务层：DWS（Data WareHouse Service）{#1.2.3%20%E6%95%B0%E6%8D%AE%E6%9C%8D%E5%8A%A1%E5%B1%82%EF%BC%9ADWS%EF%BC%88Data%20WareHouse%20Service%EF%BC%89-toc}\n1.3 数据应用层：ADS（Application Data Service）{#1.3%20%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%B1%82%EF%BC%9AADS%EF%BC%88Application%20Data%20Service%EF%BC%89-toc}\n1.4 维表层：DIM（Dimension）{#1.4%20%E7%BB%B4%E8%A1%A8%E5%B1%82%EF%BC%9ADIM%EF%BC%88Dimension%EF%BC%89-toc}\n数仓分层 {#1.%20%E6%95%B0%E4%BB%93%E5%88%86%E5%B1%82%C2%A0} 那么为什么要数据仓库进行分层呢？\n用空间换时间，通过大量的预处理来提升应用系统的用户体验（效率），因此数据仓库会存在大量冗余的数据；不分层的话，如果源业务系统的业务规则发生变化将会影响整个数据清洗过程，工作量巨大。 通过数据分层管理可以简化数据清洗的过程，把一个复杂的工作拆成了多个简单的工作，把一个大的黑盒变成了一个白盒，每一层的处理逻辑都相对简单和容易理解，这样比较容易保证每一个步骤的正确性，当数据发生错误的时候，往往我们只需要溯源并局部调整某个步骤即可。 分层是以解决当前业务快速的数据支撑为目的 抽象出共性的框架并能够赋能给其他业务线，同时为业务发展提供稳定、准确的数据支撑 并能够按照已有的模型为新业务发展提供方向，也就是数据驱动和赋能 一个好的分层架构，要有以下好处： 1. 清晰数据结构\n2. 数据血缘追踪：数据ETL转化过程中的流动变化\n3. 减少重复开发，提高数据复用性\n4. 数据关系条理化\n5. 屏蔽原始数据的影响\n数仓分层要结合公司业务进行，并且需要清晰明确各层职责，一般采用如下分层结构：\n数仓建模在哪层建设呢？我们以维度建模 为例，建模是在数据源层的下一层进行建设，在上图中，就是在 DW 层进行数仓建模，所以 DW 层是数仓建设的核心层。 下面详细阐述下每层建设规范！\n1.1 数据源层：ODS（Operational Data Store） {#1.1%20%E6%95%B0%E6%8D%AE%E6%BA%90%E5%B1%82%EF%BC%9AODS%EF%BC%88Operational%20Data%20Store%EF%BC%89} ODS 层是最接近数据源的一层，又叫贴源层 ，考虑后续可能需要追溯数据 问题， 因此对于这一层就不建议做过多的数据清洗工作，原封不动地接入原始数据即可， 至于数据去噪、去重、异常值处理等过程可以放在后面的 DWD 层来做！\n1.2 数据仓库层：DW（Data Warehouse） {#1.2%20%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%B1%82%EF%BC%9ADW%EF%BC%88Data%20Warehouse%EF%BC%89} 数据仓库层是数据仓库核心层，在这里把从 ODS 层中获得的数据按照主题建立各种数据模型。该层又依次细分为DWD、DWM、DWS\n1.2.1 数据明细层：DWD（Data Warehouse Detail） {#1.2.1%20%E6%95%B0%E6%8D%AE%E6%98%8E%E7%BB%86%E5%B1%82%EF%BC%9ADWD%EF%BC%88Data%20Warehouse%20Detail%EF%BC%89} 该层一般保持和 ODS 层一样的数据粒度，并且提供一定的数据质量保证 。DWD层要做的就是将数据清理、整合、规范化，把脏数据、垃圾数据、规范不一致的、状态定义不一致的、命名不规范的数据处理掉。 同时，为了提高数据明细层的易用性，该层会采用一些维度退化手法，将维度退化至事实表中，减少事实表和维表的关联。 另外，在该层也会做一部分的数据聚合，将相同主题的数据汇集到一张表中，提高数据的可用性 。 1.2.2 数据中间层：DWM（Data WareHouse Midddle） {#1.2.2%20%E6%95%B0%E6%8D%AE%E4%B8%AD%E9%97%B4%E5%B1%82%EF%BC%9ADWM%EF%BC%88Data%20WareHouse%20Midddle%EF%BC%89} 该层会在 DWD 层的数据基础上，数据做轻度聚合 ，生成一系列的中间表 ， 提升公共指标的复用性，减少重复加工。 直观来讲，就是对通用的核心维度进行聚合操作，算出相应的统计指标。 在实际计算中，如果直接从 DWD 或者 ODS 计算出宽表的统计指标，会存在计算量太大并且维度太少的问题，因此一般的做法是，在 DWM 层先计算出多个小的中间表，然后再拼接成一张 DWS 的宽表。由于宽和窄的界限不易界定，也可以去掉 DWM 这一层，只留 DWS 层，将所有的数据再放在DWS也可。 1.2.3 数据服务层：DWS（Data WareHouse Service） {#1.2.3%20%E6%95%B0%E6%8D%AE%E6%9C%8D%E5%8A%A1%E5%B1%82%EF%BC%9ADWS%EF%BC%88Data%20WareHouse%20Service%EF%BC%89} DWS 层为公共汇总层，会进行轻度汇总 ，粒度比明细数据稍粗，基于 DWD 层上的基础数据，整合汇总成分析某一个主题域的服务数据。 DWS 层应覆 盖 80% 的应用场景。又称数据集市或宽表。 按照业务划分，如主题域流量、订单、用户等，生成字段比较多的宽表，用于提供后续的业务查询，OLAP 分析，数据分发等。 一般来讲，该层的数据表会相对比较少，一张表会涵盖比较多的业务内容，由于其字段较多，因此一般也会称该层的表为宽表。 1.3 数据集市层：DM（Data Mart） {#1.3%20%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%B1%82%EF%BC%9AADS%EF%BC%88Application%20Data%20Service%EF%BC%89} 基于DW的基础数据，整合汇总成一个个数据集市，数据集市通常是面向部门的某个主题域的报表数据。比如用户留存表、用户活跃表、商品销量表、商品营收表等等。\n1.4 维表层：DIM（Dimension） {#1.4%20%E7%BB%B4%E8%A1%A8%E5%B1%82%EF%BC%9ADIM%EF%BC%88Dimension%EF%BC%89} 如果维表过多，也可针对维表设计单独一层，维表层主要包含两部分数据：\n高基数维度数据：一般是用户资料表、商品资料表类似的资料表。数据量可能是千万级或者上亿级别。 低基数维度数据：一般是配置表，比如枚举值对应的中文含义，或者日期维表。 数据量可能是个位数或者几千几万 1.5 数据应用层：ADS（Application Data Service） 在这里，主要是提供给数据产品和数据分析使用的数据 ，一般会存放在 ES、 PostgreSql、Redis 等系统中供线上系统使用，也可能会存在 Hive 或者 Druid 中供数据分析和数据挖掘使用。比如我们经常说的报表数据，一般就放在这里。\n--- ","date":"2024-08-01T11:00:00Z","permalink":"/zh-cn/post/2024/08/%E6%95%B0%E4%BB%93%E5%88%86%E5%B1%82odsdwddwmdwsdimdmads/","title":"数仓分层ODS、DWD、DWM、DWS、DIM、DM、ADS"},{"content":" 往期推荐 大数据HBase图文简介-CSDN博客\n数据仓库及数仓架构概述-CSDN博客\n名词汇总 实体 实体是指依附的主体，就是我们分析的一个对象，比如分析华为手机近半年的销售量是多少，那华为手机就是一个实体；我们分析用户的活跃度，用户就是一个实体。 实体可以是现实中不存在的，比如虚拟的业务对象，活动，会员等都可看做一个实体。 实体的存在是为了业务分析，作为分析的一个筛选的维度，拥有描述自己的属性，本身具有可分析的价值。 维度 维度就是看待问题的角度 ，分析业务数据，从什么角度分析，就建立什么样的维度。所以维度就是要对数据进行分析时所用的一个量，比如分析产品销售情况，可以选择按商品类别来进行分析，这就构成一个维度，把所有商品类别集合在一起，就构成了维度表。\n度量 度量是业务流程节点上的一个数值 。比如分析产品销售情况，产品ID、生产时间、生产商就是维度，而销量、价格、成本这些可度量的值就是度量。\n事实表 订单金额就是度量值，因此事实表=维度+度量\n粒度 业务流程中对度量的单位，比如商品是按件记录度量，还是按批记录度量。 例如：数仓建设中，我们说这是用户粒度的事实表，那么表中每行数据都是一个用户，无重复用户；例如还有销售粒度的表，那么表中每行都是一条销售记录。 选择合适的粒度级别是数据仓库建设好坏的重要关键内容，在设计数据粒度时，通常需重点考虑以下因素： 要接受的分析类型、可接受的数据最低粒度和能存储的数据量； 粒度的层次定义越粗，就越不能在该仓库中进行更细致的分析； 如果存储资源有一定的限制，就只能采用较粗的数据粒度划分； 数据粒度划分策略一定要保证：数据的粒度确实能够满足用户的决策分析需要，这是数据粒度划分策略中最重要的一个准则； 口径 口径就是取数逻辑（如何取数的），比如要取的数是10岁以下儿童中男孩的平均身高，这就是统计的口径，类似于要统计的数据范围。\n指标 指标是口径的衡量值，也就是最后的结果。比如最近七天的订单量，一个促销活动的购买转化率等。一个指标具体到计算实施，有以下几部分组成：\n指标加工逻辑：比如count ,sum, avg 维度，比如按部门、地域进行指标统计，对应sql中的group by 业务限定/修饰词：比如以不同的支付渠道来算对应的指标，微信支付的订单退款率，支付宝支付 的订单退款率 。对应sql中的where。 除此之外，指标还可以分为如下几种：\n原子指标：基本业务事实，没有业务限定词、没有维度。比如订单表中的订单量、订单总金额都算原子指标。 业务方更关心的指标是有实际业务含义可以直接取数据的指标。比如店铺近1天订单支付金额，这就是一个派生指标，会被直接在产品上展示给商家看。 但是这个指标却不能直接从数仓的统一中间层里取数（因为没有现成的事实字段，数仓提供的一般都是大宽表）。需要有一个桥梁连接数仓中间层和业务方的指标需求，于是便有了派生指标。 派生指标：维度+修饰词+原子指标。店铺近1天订单支付金额，店铺是维度，近1天是一个时间类型的修饰词，支付金额是一个原子指标； 维度：观察各项指标的角度； 修饰词：维度的一个或某些值，比如维度性别下，男和女就是2种修饰词。 衍生指标：比如某一个促销活动的转化率就是衍生指标，因为需要促销投放人数指标和促销订单数指标进行计算得出。 标签 标签是人为设定的、根据业务场景需求，对目标对象运用一定的算法得到的高度精炼的特征标识。 可见标签是经过人为再加工后的结果，如网红、下头男、小仙女。对于有歧义的标签，我们内部可进行标签区分，比如：苹果，我们可以定义苹果指的是水果，苹果手机才指的是手机。 自然键 由现实中已经存在的属性组成的键，它在业务概念中是唯一的，并具有一定的业务含义，比如商品ID， 员工ID。\n以数仓角度看，来自于业务系统的标识符就是自然键，比如业务库中员工的编号。\n持久键 保持永久性，不发生变化。有时也被叫做超自然持久键。比如身份证号属于持久键。 自然键和持久键区别：举个例子就明白了，比如说公司员工离职之后又重新入职，他的自然键也就是员工编号发生了变化，但是他的持久键身份证号是不变的。\n代理键 不具有业务含义的键。代理键有许多其他的称呼：无意义键、整数键、非自然键、人工键、合成键等。 代理键就是简单的按照顺序序列生产的整数表示。产品行的第1行代理键为1，则下一行的代理键为 2，如此进行。代理键的作用仅仅是连接维度表和事实表。\n退化维度 退化维度，就是那些看起来像是事实表的一个维度关键字，但实际上并没有对应的维度表，**就是维度属性存储到事实表中，这种存储到事实表中的维度列被称为退化维度。**与其他存储在维表中的维度一样， 退化维度也可以用来进行事实表的过滤查询、实现聚合操作等。 那么如何定义退化维度？比如说订单ID，这种量级很大的维度，没必要用一张维度表来进行存储，而我们进行数据查询或者数据过滤的时候又非常需要，所以这种就冗余在事实表里面，这种就叫退化维度。 下钻 这是在数据分析中常见的概念，下钻可以理解成增加维的层次（升维），从而可以由粗粒度到细粒度来观察数据 ，比如对产品销售情况分析时，可以沿着时间维从年到月到日更细粒度的观察数据。从年的维度可以下钻到月的维度、日的维度等。\n上卷 知道了下钻，上卷就容易理解了，它俩是相逆的操作**（降维），所以上卷可以理解为删掉维**的某些层，由细粒度到粗粒度观察数据的操作或沿着维的层次向上聚合汇总数据。\n维度立方体 维度立方体包含了下钻和上卷的所有操作，站在多个维度角度取看待事情，那么就会有不同的结果，所以维度立方体统计可以满足任何维度需求，不过缺点是结果过多，导致程序运行速度大大降低。\n数据集市 数据集市（Data Mart），也叫数据市场，数据集市就是满足特定的部门或者用户的需求，按照多维的方式进行存储，包括定义维度、需要计算的指标、维度的层次等，生成面向决策分析需求的数据立方体。其实就是从数据仓库中抽取出来的子集。\n名词关系 实体表、事实表、维度表的联系 在Kimball维度建模中有维度与事实，在Inmon范式建模中有实体与关系，事实表和实体表之间有怎样区别与联系，先看下它们各自概念：\n维度表：维度表可以看成是用户用来分析一个事实的窗口，它里面的数据应该是对事实的各个方面描述，比如时间维度表，地域维度表，维度表是事实表的一个分析角度。 事实表：事实表=维度+度量 ，事实表其实就是通过各种维度和一些指标值的组合来确定一个事实的，比如通过时间维度、地域维度可以确定某时某地的一些指标值的事实。事实表的每一条数据都是几条维度表的数据和指标值交汇而得到的。 实体表：实体表就是一个实际对象的表，实体表放的数据一定是一条条客观存在的事物数据，比如说各种商品，它就是客观存在的，所以可以将其设计一个实体表。实时表只描述各个事物，并不存在具体的事实，所以也有人称实体表是无事实的事实表。 举个例子： 比如说手机商场中有苹果手机，华为手机等各品牌各型号的手机，这些数据可以组成一个手机实体表，但是表中没有可度量的数据。某天苹果手机卖了15台，华为手机卖了20台，这些手机销售数据属于事实，组成一个事实表。这样就可以使用日期维度表和地域维度表对这个事实表进行各种维度分析。\n指标与标签的区别 概念不同\n指标是客观的，用来定义、评价和描述特定事物的一种标准或方式 。比如：新增用户数、累计用户数、用户活跃率等是衡量用户发展情况的指标； 标签是主观的、人为设定的，根据业务场景需求，对目标对象运用一定的算法得到的高度精炼的特征标识。 可见标签是经过人为再加工后的结果，如网红、下头男、高富帅。 构成不同\n指标名称是对事物质与量两方面特点的命名；指标取值是指标在具体时间、地域、条件下的数量表现，如人的体重，指标名称是体重，指标的取值就是120斤； 标签名称通常都是形容词或形容词+名词的结构，标签一般是不可量化的，通常是孤立的，除了基础类标签，通过一定算法加工出来的标签一般都没有单位和量纲。如将超过200斤的称为大胖子。 分类不同\n对指标的分类： 按照指标计算逻辑，可以将指标分为原子指标、派生指标、衍生指标 三种类型； 按照对事件描述内容的不同，分为过程性指标和结果性指标； 对标签的分类： 按照标签的变化性分为静态标签和动态标签； 按照标签的指代和评估指标的不同，可分为定性标签和定量标签； 指标最擅长的应用是监测、分析、评价和建模。 标签最擅长的应用是标注、刻画、分类和特征提取。 特别需要指出的是，由于对结果的标注也是一种标签，所以在自然语言处理和机器学习相关 的算法应用场景下，标签对于监督式学习有重要价值，只是单纯的指标难以做到的。而指标在任 务分配、绩效管理等领域的作用，也是标签无法做到的。\n维度和指标的区别联系 维度就是数据的观察角度，即从哪个角度去分析问题，看待问题 。 指标就是从维度的基础上去衡量结果值。\n维度：一般是一个离散的值，比如时间维度上每一个独立的日期或地域，因此统计时，可以把维 度相同记录的聚合在一起，应用聚合函数做累加、均值、最大值、最小值等聚合计算。 指标：就是被聚合的通计算，即聚合运算的结果，一般是一个连续的值。 自然键与代理键在数仓的使用区别 维度表的唯一主键应该是代理键而不应该是自然键。有时建模人员不愿意放弃使用自然键，因为他们希望与操作型代码查询事实表，而不希望与维度表做连接操作。然而，应该避免使用包含业务含义的多维键，因为不管我们做出任何假设最终都可能变得无效，因为我们控制不了业务库的变动。 所以数据仓库中维度表与事实表的每个连接应该基于无实际含义的整数代理键。避免使用自然键作为维度表的主键。 数据集市和数据仓库的关系 数据集市是企业级数据仓库的一个子集，他主要面向部门级业务 ，并且只面向某个特定的主题。为了解决灵活性和性能之间的矛盾，数据集市就是数据仓库体系结构中增加的一种小型的部门或工作组级别的数据仓库。数据集市存储为特定用户预先计算好的数据，从而满足用户对性能的需求。数据集市可以在一定程度上缓解访问数据仓库的瓶颈。 数据集市和数据仓库的主要区别：数据仓库是企业级的，能为整个企业各个部门的运行提供决策支持手 段；而数据集市则是一种微型的数据仓库,它通常有更少的数据,更少的主题区域,以及更少的历史数据,因 此是部门级的，一般只能为某个局部范围内的管理人员服务，因此也称之为部门级数据仓库。 ","date":"2024-07-31T10:08:42Z","permalink":"/zh-cn/post/2024/07/%E6%95%B0%E4%BB%93%E5%B8%B8%E8%A7%81%E5%90%8D%E8%AF%8D%E8%A7%A3%E6%9E%90%E5%92%8C%E5%90%8D%E8%AF%8D%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB/","title":"数仓常见名词解析和名词之间的关系"},{"content":" 往期推荐 数据仓库及数仓架构概述-CSDN博客\n数仓常见名词解析和名词之间的关系-CSDN博客\n引言 要想明白为什么HBase的产生，就需要先了解一下 Hadoop。\nHadoop 可以通过 HDFS 来存 储结构化、半结构甚至非结构化的数据，是传统数据库的补充，是海量数据存储的最佳方法，它针对大文件的存储、批量访问和流式访问都做了优化，同时也通过多副本解决了容灾问题。\n但是 Hadoop 的缺陷在于它只能执行批处理，并且只能以顺序方式访问数据，这意味着即使是最简单的工作也必须搜索整个数据集，无法实现对数据的随机访问。实现数据的随机访问是传统的关系型数据库所擅长的，但它们却不能用于海量数据的存储。在这种情况下，必须有一种新的方案来同时解决海量数据存储和随机访问的问题，HBase 就是其中之一 (HBase，Cassandra，couchDB，Dynamo 和 MongoDB 都能存储海量数据并支持随机访问)。\n数据结构分类：\n结构化数据：即以关系型数据库表形式管理的数据； 半结构化数据：非关系模型的，有基本固定结构模式的数据，例如日志文件、XML 文档、 JSON 文档、Email 等； 非结构化数据：没有固定模式的数据，如 WORD、PDF、PPT、EXL，各种格式的图片、视 频等。 HBase简介 HBase全称Hadoop Database ，是一个基于HDFS的分布式的、面向列的开源数据库，但是这个数据库没有SQL，只提供了API，需要API编程来使用HBase，而后面提到的Phoenix才使得可以用SQL操作HBase！\nHBase有如下特点：\n容量大：一个表可以有数十亿行，上百万列，这也和它的扩展性息息相关； 面向列：数据是按照列存储，每一列都单独存放，数据即索引，在查询时可以只访问指定列的数据，有效地降低了系统的 I/O 负担； 稀疏性：空 (null) 列并不占用存储空间，表可以设计的非常稀疏 ； 易扩展：的扩展性主要体现在两个方面，一个是基于上层处理能力（RegionServer） 的扩展，一个是基于存储的扩展（HDFS）。通过横向添加 RegionSever 的机器， 进行水平扩展，提升 Hbase 上层的处理能力，提升 Hbsae 服务更多 Region 的 能力。 数据多版本：每个单元中的数据可以有多个版本，按照时间戳排序，新的数据在最上面； 采用 HDFS 作为底层存储，支持结构化、半结构化和非结构化的存储； 支持数据分片； 易于使用的 Java 客户端 API，客户端可以通过 HBase 实现对 HDFS 上数据的随机访问； HBase的表 表 schema 仅定义列族，表 ","date":"2024-07-29T11:30:00Z","permalink":"/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/","title":"大数据HBase图文简介及Phoenix"},{"content":"Lettuce和Jedis、Redisson RedisTemplate是SpringDataRedis中对JedisApi的高度封装，提供了Redis各种操作、 异常处理及序列化，支持发布订阅。\n首先我们要知道SpringData 是Spring中数据操作的模块，包括对各种数据库的集成，比如我们之前学过的Spring Data JDBC、JPA等，其中有一个模块叫做Spring Data Redis ，而RedisTemplate就是其中提供操作Redis的通用模板。\nSpring Data Redis中提供了如下的内容：\n1、对不同Redis客户端的整合（Lettuce和Jedis、Redisson）\n2、提供了RedisTemplate统一API操作Redis\n3、⽀持Redis订阅发布模型\n4、⽀持Redis哨兵和集群\n5、⽀持基于Lettuce的响应式编程（底层就是Netty）\n6、⽀持基于JDK、JSON、字符串、Spring对象的数据序列化、反序列化\n使用Spring Data Redis需要引入RedisTemplate依赖和commons-pool连接池依赖，Jedis与RedisTemplate底层使用的连接池都是commons-pool2，所以需要导入它\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-pool2\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 这⾥我们可以看⼀下spring-boot-starter-data-redis底层，发现并没有引入Jedis\n原因：\n在SpringBoot 2.x版本以后，从原来的Jedis替换成了lettuce，所以2.x以后开始默认使用Lettuce作为Redis客户端，Lettuce客户端基于Netty的NIO框架实现，只需要维持单一的连接（非阻塞式IO）即可高效支持业务端并发请求。同时，Lettuce支持的特性更加全面，其性能表现并不逊于，甚至优于Jedis。 简单理解：\nJedis：\n采用的直连，多线程操作不安全 ，如果想要避免线程安全问题，就需要使用JedisPool连接池，但是也会有一些线程过多等其他问题，类似于BIO（阻塞式IO） Lettuce：\n单线程实现，线程安全，底层采用Netty，实例可以在多个线程中进行共享，不存在线程安全问题！类似NIO Redisson：支持红锁、分布式锁等 默认的RedisTemplate测试 1 2 3 4 5 6 7 8 9 10 11 @SpringBootTest class RedisTestApplicationTests { @Autowired private RedisTemplate redisTemplate; @Test void contextLoads() { redisTemplate.opsForValue().set(\u0026#34;CSDN\u0026#34;,\u0026#34;青秋.\u0026#34;); System.out.println(redisTemplate.opsForValue().get(\u0026#34;CSDN\u0026#34;)); } } 通过指令来查看发现是乱码，这就涉及到了序列化的问题了。\n想要解决以上问题，需要了解RedisTemplate序列化的问题，首先进入RedisTemplate源码，发现需要设置key、hashKey和value、hashValue的序列化器\n再往下看有一个默认的序列化器\n也就是说，RedisTemplate默认采用的是默认的JDK序列化器，这种序列化方式会有一定的问题 比如可读性差、内存占用大\n所以总结来说，我们可以修改key和value的RedisSerializer具体实现，这⾥我们可以先看⼀下 RedisSerializer的实现类有哪些：\nJacksonJsonRedisSerializer: 序列化object对象为json字符串 Jackson2JsonRedisSerializer: 跟JacksonJsonRedisSerializer实际上是一样的 JdkSerializationRedisSerializer: 序列化java对象 GenericToStringSerializer: 可以将任何对象泛化为字符串并序列化 StringRedisSerializer: 简单的字符串序列化 各个序列化器性能测试对比 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 @Test public void testSerial(){ UserPO userPO = new UserPO(1111L,\u0026#34;小明_testRedis1\u0026#34;,25); List\u0026lt;Object\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); for(int i=0;i\u0026lt;200;i++){ list.add(userPO); } JdkSerializationRedisSerializer j = new JdkSerializationRedisSerializer(); GenericJackson2JsonRedisSerializer g = new GenericJackson2JsonRedisSerializer(); Jackson2JsonRedisSerializer j2 = new Jackson2JsonRedisSerializer(List.class); Long j_s_start = System.currentTimeMillis(); byte[] bytesJ = j.serialize(list); System.out.println(\u0026#34;JdkSerializationRedisSerializer序列化时间：\u0026#34;+(System.currentTimeMillis()-j_s_start) + \u0026#34;ms,序列化后的长度：\u0026#34; + bytesJ.length); Long j_d_start = System.currentTimeMillis(); j.deserialize(bytesJ); System.out.println(\u0026#34;JdkSerializationRedisSerializer反序列化时间：\u0026#34;+(System.currentTimeMillis()-j_d_start)); Long g_s_start = System.currentTimeMillis(); byte[] bytesG = g.serialize(list); System.out.println(\u0026#34;GenericJackson2JsonRedisSerializer序列化时间：\u0026#34;+(System.currentTimeMillis()-g_s_start) + \u0026#34;ms,序列化后的长度：\u0026#34; + bytesG.length); Long g_d_start = System.currentTimeMillis(); g.deserialize(bytesG); System.out.println(\u0026#34;GenericJackson2JsonRedisSerializer反序列化时间：\u0026#34;+(System.currentTimeMillis()-g_d_start)); Long j2_s_start = System.currentTimeMillis(); byte[] bytesJ2 = j2.serialize(list); System.out.println(\u0026#34;Jackson2JsonRedisSerializer序列化时间：\u0026#34;+(System.currentTimeMillis()-j2_s_start) + \u0026#34;ms,序列化后的长度：\u0026#34; + bytesJ2.length); Long j2_d_start = System.currentTimeMillis(); j2.deserialize(bytesJ2); System.out.println(\u0026#34;Jackson2JsonRedisSerializer反序列化时间：\u0026#34;+(System.currentTimeMillis()-j2_d_start)); } 测试结果 1 2 3 4 5 6 JdkSerializationRedisSerializer序列化时间：8ms,序列化后的长度：1325 JdkSerializationRedisSerializer反序列化时间：4 GenericJackson2JsonRedisSerializer序列化时间：52ms,序列化后的长度：17425 GenericJackson2JsonRedisSerializer反序列化时间：60 Jackson2JsonRedisSerializer序列化时间：4ms,序列化后的长度：9801 Jackson2JsonRedisSerializer反序列化时间：4 JdkSerializationRedisSerializer序列化后长度最小，Jackson2JsonRedisSerializer效率最高。 如果综合考虑效率和可读性，牺牲部分空间，推荐key使用StringRedisSerializer，保持的key简明易读；value可以使用Jackson2JsonRedisSerializer 如果空间比较敏感，效率要求不高，推荐key使用StringRedisSerializer，保持的key简明易读；value可以使用JdkSerializationRedisSerializer 自定义RedisTemplate 新建RedisConfig配置类，以下是固定模板，可以直接用\n这个模板我们采用的Json序列化Value，String序列化Key\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 @Configuration public class RedisConfig { @Bean public RedisTemplate\u0026lt;String,Object\u0026gt; redisTemplate(RedisConnectionFactory factory){ // 为了研发⽅便 key直接为String类型 RedisTemplate\u0026lt;String,Object\u0026gt; template = new RedisTemplate\u0026lt;\u0026gt;(); // 设置连接⼯⼚ template.setConnectionFactory(factory); //设置key序列化 用的string序列化 template.setKeySerializer(RedisSerializer.string()); template.setHashKeySerializer(RedisSerializer.string()); //序列化配置，通过JSON解析任意对象 GenericJackson2JsonRedisSerializer jsonRedisSerializer = new GenericJackson2JsonRedisSerializer(); //设置value序列化，采用的是Json序列化方式 template.setValueSerializer(jsonRedisSerializer); template.setHashKeySerializer(jsonRedisSerializer); template.afterPropertiesSet(); return template; } } Json序列化Value + RedisTemplate测试 1 2 3 4 5 6 7 8 9 10 @SpringBootTest class RedisTestApplicationTests { @Autowired private RedisTemplate\u0026lt;String,Object\u0026gt; redisTemplate; @Test void contextLoads() { redisTemplate.opsForValue().set(\u0026#34;CSDN\u0026#34;,\u0026#34;青秋.\u0026#34;); System.out.println(redisTemplate.opsForValue().get(\u0026#34;CSDN\u0026#34;)); } } 此时用keys * 查看，没有乱码。那么再储存一个对象试试！\n1 2 3 4 5 @Test void saveUser(){ redisTemplate.opsForValue().set(\u0026#34;stringredistemplate\u0026#34;,new User(\u0026#34;Mask\u0026#34;,20)); System.out.println(redisTemplate.opsForValue().get(\u0026#34;stringredistemplate\u0026#34;)); } 用可视化工具查看，发现JSON序列化Value后多了个@Class字段\n虽然实现了对象的序列化和反序列化，但这是因为添加了@class字段，会导致额外的内存开销，在数据量特别大的时候就会有影响，但是如果没有@class就不会实现自动序列化和反序列化。\n实际开发中，如果为了节省空间，并不会完全使用JSON序列化来处理value， 而是统一采用String序列化器，储存Java对象也是如此，这就意味着我们需要重新编写RedisTemplate，但是SpringBoot其实提供了一个String序列化器实现的StringRedisTemplate，通过它可以完成以上的需求。\nString序列化Value + StringRedisTemplate 测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @SpringBootTest class RedisTestApplicationTests { @Autowired private StringRedisTemplate stringRedisTemplate; //Json⼯具 private ObjectMapper mapper = new ObjectMapper(); @Test void StringTemplate() throws JsonProcessingException { User user = new User(\u0026#34;青秋\u0026#34;,18); //⼿动序列化 String json = mapper.writeValueAsString(user); //写⼊数据 stringRedisTemplate.opsForValue().set(\u0026#34;stringredistemplate\u0026#34;,json); //读取数据 String val = stringRedisTemplate.opsForValue().get(\u0026#34;stringredistemplate\u0026#34;); //反序列化 User u = mapper.readValue(val,User.class); System.out.println(u); } } 总结 RedisTemplate的Key和Value的序列化器可以根据需要分别设置。 RedisTemplate默认使用JdkSerializationRedisSerializer存入数据，会将数据先序列化成字节数组然后在存入Redis数据库，这种value不可读。 如果数据是Object类型，取出的时候又不想做任何的数据转换，直接从Redis里面取出一个对象，那么使用RedisTemplate是更好的选择。 当然任何情况下从Redis获取数据的时候，都会默认将数据当做字节数组转化，这样就会导致一个问题：当需要获取的数据不是以字节数组存在redis当中，而是正常的可读的字符串的时候，RedisTemplate就无法获取数据，获取到的值是NULL。这时就需要用StringRedisTempate或者专门设置RedisTemplate的序列化器！ --- ","date":"2024-07-28T11:34:59Z","permalink":"/zh-cn/post/2024/07/redistemplatestringredistemplate%E5%BA%8F%E5%88%97%E5%8C%96%E5%99%A8%E9%85%8D%E7%BD%AE/","title":"RedisTemplate、StringRedisTemplate、序列化器配置"},{"content":"Redis 是一个内存数据库 ，所以其运行效率非常高。但也存在一个问题：内存中的数据 是不持久的，若主机宕机或 Redis 关机重启，则内存中的数据全部丢失。因此 Redis 具有持久化功能 ，Redis通过数据快照或追加操作日志的形式将数据持久化到磁盘。 根据持久化使用技术的不同，Redis 的持久化分为两种：RDB 与 AOF。\n当系统重新启动时，会自动加载持久化文件，并根据文件中数据库状态描述信息将数据恢复到内存中。\n1.RDB RDB（Redis DataBase）是Redis默认开启 的持久化⽅式，是指将内存中某一时刻的数据快照全量写入到指定的 rdb 文件中 。当 Redis 启动时会自动读取rdb快照文件，将数据从硬盘载入到内存，以恢复 Redis 关机前的数据库状态。 由于RDB是生成的数据快照，因此⽣成的 RDB⽂件⾮常适合⽤于全量复制、数据备份等场景。 RDB创建数据快照的时间间隔可以通过redis.conf配置文件中的\u0026quot;save\u0026quot;配置选项进⾏设置或者通过命令即时创建快照，如\u0026quot;save 900 1\u0026quot;表示如果900秒内有⾄少1个key变化，则创建⼀个snapshots快照。 1.1 RDB持久化命令 save\n执行 save 命令可立即进行一次持久化保存。save 命令是同步保存操作，由Redis主进程执行，因此执行期间会阻塞主进程，Redis 不能处理任何读写请求。\nbgsave\n执行 bgsave 命令可立即进行一次持久化保存，主进程会 fork 出一个子进程 ，由该子进程负责完成保存过程。在子进程进行保存过程中，不会阻塞 redis-server 进程对客户端读写请求的处理。\nfork() 函数是用于在操作系统中创建新进程的系统调用。它会将当前进程的内存内容完整地复制到内存的另一个区域，从而创建一个新的子进程。\n1.2 RDB持久化过程 在进行持久化过程中，如果主进程接收到了用户写请求，则系统会将内存中发生数据修改的物理块 copy 出一个副本。等内存中的全量数据 copy 结束后，会再将 副本中的数据 copy 到 RDB 临时文件。这个副本的生成是由于**Linux 系统的写时复制技术 （Copy-On-Write）**实现的。\n2.AOF AOF 持久性记录服务器接收到的每个写操作。然后在服务器启动时再次重复执行这些操作，从⽽重建原始数据集。\n2.1 AOF持久化过程 命令追加（append）：所有的写命令会追加到 AOF 缓冲区中。\n文件写入（write） ：将 AOF 缓冲区的数据写入到 AOF 文件过程中要调用write函数（系统调用），write先把数据写到系统内核缓冲区后直接返回，此时还没写到磁盘AOF文件中（延迟写）。\n文件同步（fsync） ：AOF 缓冲区根据对应的持久化方式（ fsync 策略）向硬盘做同步操作。这一步需要调用 fsync 函数（系统调用）进行强制硬盘同步，fsync 将阻塞直到写入磁盘完成后返回，保证了数据持久化。\n文件重写（rewrite）：随着 AOF 文件越来越大，需要定期对 AOF 文件进行重写，达到压缩的目的。\n如果在 rewrite 过程中又有写操作命令追加，那么这些数据会暂时写入 aof_rewrite_buf 缓冲区。等将全部 rewrite 计算结果写入临时文件后，会先将AOF重写缓冲区 中 的数据追加 到临时文件，然后再 rename 为磁盘文件的原名称，覆盖原文件。\nwrite：写入系统内核缓冲区之后直接返回（仅仅是写到缓冲区），不会立即同步到硬盘。虽然提高了效率，但也带来了数据丢失的风险。同步硬盘操作通常依赖于系统调度机制，Linux 内核通常为 30s 同步一次，具体值取决于写出的数据量和 I/O 缓冲区的状态。\nfsync：强制刷新系统内核缓冲区（同步到磁盘），确保写磁盘操作结束才会返回。\n2.2 AOF持久化fsync策略 appendfsync always：主线程调用 write 执行写操作后，后台线程（ aof_fsync 线程）立即调用 fsync 函数同步 AOF 文件（刷盘），fsync 完成后线程返回，这样会严重降低 Redis 的性能（write + fsync）。 appendfsync everysec：主线程调用 write 执行写操作后立即返回，由后台线程（ aof_fsync 线程）每秒钟调用 fsync 函数 （系统调用）同步一次 AOF 文件（write+fsync，fsync间隔为 1 秒） appendfsync no：主线程调用 write 执行写操作后立即返回，让操作系统决定何时进行同步，Linux 下一般为 30 秒一次（write但不fsync，fsync 的时机由操作系统决定）。 为了兼顾数据和写入性能，可以考虑 appendfsync everysec 选项 ，让 Redis 每秒同步一次 AOF 文件。\n2.3 AOF文件拆分 从Redis7.0发布看Redis的过去与未来\n从 Redis 7.0.0 开始，Redis 使用了 Multi Part AOF 机制。顾名思义，Multi Part AOF 就是将原来的单个 AOF 文件拆分成多个 AOF 文件。在 Multi Part AOF 中，AOF 文件被分为三种类型，分别为：\nBASE：表示基础 AOF 文件，它一般由子进程通过重写产生，该文件最多只有一个。 INCR：表示增量 AOF 文件，它一般会在 AOFRW 开始执行时被创建，该文件可能存在多个。 HISTORY：表示历史 AOF 文件，它由 BASE 和 INCR AOF 变化而来，每次 AOFRW 成功完成时，本次 AOFRW 之前对应的 BASE 和 INCR AOF 都将变为 HISTORY，HISTORY 类型的 AOF 会被 Redis 自动删除。 2.4为什么AOF是执行完命令才记录日志 关系型数据库（如 MySQL）通常都是执行命令之前记录日志（方便故障恢复），而 Redis AOF 持久化机制是在执行完命令之后再记录日志。\n避免额外的检查开销：AOF 记录日志不会对命令进行语法检查，如果先写入日志结果命令出错，则还得修改日志； **不会阻塞当前写操作命令的执行：**先写日志然后执行命令，结果命令出错，还得回去改日志，就阻塞了当前命令，甚至影响下一个命令。 2.5 AOF重写 什么是重写？\n随着执行的写命令越来越多，AOF文件也越来越大，为解决这一问题，要对AOF压缩，即重写。假如先后执行了set num:1和set:num:2，实际结果是2，那么重写后就不需要set num:1这个记录了。\n重写过程中会把新数据记录到新的aof文件，防止对原先的aof文件造成污染。\nredis 的重写 AOF 过程是通过fork系统调用生成后台子进程 bgrewriteaof 来完成的**，** 如果在 rewrite 过程中又有写操作命令追加，那么这些数据会暂时写入 aof_rewrite_buf 缓冲区。等将全部 rewrite 计算结果写入临时文件后，会先将AOF重写缓冲区 中 的数据追加到临时文件，然后再 rename 为磁盘文件的原名称，覆盖原文件。\n子进程带有主进程的数据副本，这里使用子进程而不是线程，因为如果是使用线程，多线程共享内存 ，那么在修改共享内存数据的时候，需要通过加锁 来保证数据的安全，而这样就会降低性能 。而使用子进程，创建子进程时，父子进程是共享内存数据的，不过这个共享的内存只能以只读 的方式，而当父子进程任意一方修改了该共享内存，就会发生「写时复制」（这里的写时复制和RDB的写时复制是同一个），于是父子进程就有了独立的数据副本，就不用加锁来保证数据安全。\n主进程在通过fork系统调用生成bgrewriteaof子进程时，操作系统会把主进程的「页表」复制一份给子进程 ，这个页表记录着虚拟地址和物理地址映射关系，而不会复制物理内存，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。这样父子进程就可以共享只读数据了。\n当父进程或者子进程在向这个内存发起写操作时，由于违反权限CPU会触发写保护中断，然后操作系统会在「写保护中断处理函数」里进行物理内存的复制，并重新设置其内存映射关系 ，将父子进程的内存读写权限设置为可读写，最后才会对内存进行写操作，这个过程被称为写时复制 。\n3.混合持久化 Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 aof-use-rdb-preamble 开启）。 ","date":"2024-07-28T00:12:57Z","permalink":"/zh-cn/post/2024/07/redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6--rdb%E5%92%8Caof/","title":"Redis持久化机制--RDB和AOF"},{"content":"JavaWeb中，客户端通常是浏览器，通过浏览器向服务器发送请求，所以有时候称客户端为浏览器。\nCookie Cookie是服务器生成，存储在浏览器的一段字符串，可以记录用户的身份信息等数据，但是这些信息是明文存储的，很不安全。\n浏览器把cookie以k-v形式保存到某个目录下的文本文件内，下一次请求同一网站时会把该cookie发送给服务器。由于cookie是存在于浏览器上的，所以浏览器加入了一些限制来确保cookie不会被恶意使用，同时不会占据太多磁盘空间，单个 cookie 保存的数据不能超过4KB，而且每个域的cookie数量是有限的。\nCookie缺陷：\ncookie存在本地浏览器，浏览器之间的cookie不共享，所以用户换了浏览器就要重新登录\nSession Session 是基于Cookie实现的，是一种HTTP存储机制，目的是为无状态的HTTP协议提供持久机制 ，服务器会为每个用户创建的一个临时会话对象，存储在服务器，它保存了每个用户的会话信息。相较于Cookie，session容量更大，可以保存Object。\n一次session会话可以有多个请求也就有多个cookie的交互，服务器为了区分当前是谁发送的请求，给每个浏览器分配了不同的\u0026quot;身份标识\u0026quot;JSESSIONID，JSESSIONID放在cookie中，然后浏览器每次向服务器发请求的时候，都带上JSESSIONID，服务器就可以根据JSESSIONID查找用户对应的session会话，所以session是有状态的（因为服务器要保存session）。\n服务器使用session把用户的信息临时保存在了服务器上，这种用户信息存储方式相对cookie来说更安全。\nSession 在两种情况下会自动销毁：\n客户端关闭浏览器程序\nSession 超时（会话超时）：客户端一段时间内没有访问过该Session内存，服务器会清理。回话超时的时间，默认是30分钟，只要发起请求，会话时间从0重新计算。 Session缺陷：\n如果web服务器做了负载均衡，那么下一个操作请求到了另一台服务器的时候session就会丢失，也就是每个服务器的session不共享。\n服务器要保存所有人的session，如果服务器访问量大，那么对服务器来说有很大的内存开销，限制了服务器的扩展能力，是空间换时间 误解：\n关闭浏览器 ，服务器的session不会立刻消失！\n对session来说，除非浏览器通知服务器删除session，否则服务器会一直保留。\n然而浏览器从来不会在关闭之前主动通知服务器它将要关闭，大部分session机制都使用会话cookie来保存JSESSIONID，而关闭浏览器后这个JSESSIONID就消失了，再次连接服务器时也就无法找到原来的session。如果服务器设置的cookie被保存在硬盘上，或者使用某种手段改写浏览器发出的HTTP请求头，把原来的JSESSIONID发送给服务器，则再次打开浏览器仍然能够打开原来的session。\n恰恰是由于关闭浏览器不会导致session被删除，迫使服务器需要为session设置了一个失效时间，当距离客户端上一次使用session的时间超过这个失效时间时，服务器就可以以为客户端已经停止了活动，才会把session删除以节省存储空间。\nCSRF攻击 跨站请求攻击，攻击者冒充用户的浏览器去访问一个用户曾经认证过的网站并运行一些操作，如发邮件、甚至财产操作。这利用了web中用户身份验证的一个漏洞：简单的身份验证只能保证请求发自某个用户的浏览器，却不能保证请求本身是用户自愿发出的。csrf并不能够拿到用户的任何信息，只是以用户浏览器身份进行操作。\n​\nToken 基于session的缺陷，我们的解决方案是怎么让服务器不保存session，而让客户端去保存，可是如果不保存JSESSIONID, 怎么验证客户端发给服务器JSESSIONID的确是服务器生成的呢？\n关键点就在于验证，比如说， A已经登录了系统， 服务器给A发一个令牌(token)， 里边包含了A的 user id等信息， 下一次A再次通过Http 请求访问服务器的时候， 把这个token 通过Http header 带过来就可以了。\n不 ","date":"2024-07-24T11:19:04Z","permalink":"/zh-cn/post/2024/07/cookiesessionjwttoken/","title":"Cookie、Session、JWT、Token"},{"content":"目录{#main-toc}\n提示{#%E6%8F%90%E7%A4%BA-toc}\nApache Shiro和Spring Security{#Apache%20Shiro%E5%92%8CSpring%20Security-toc}\n认证和授权{#%E8%AE%A4%E8%AF%81%E5%92%8C%E6%8E%88%E6%9D%83-toc}\nRBAC{#RBAC-toc}\nDemo{#Demo-toc}\n环境{#%E7%8E%AF%E5%A2%83-toc}\nController{#Controller-toc}\n引入Spring Security{#%E5%BC%95%E5%85%A5Spring%20Security-toc}\n初探Security原理{#%E5%88%9D%E6%8E%A2Security%E5%8E%9F%E7%90%86-toc}\n认证授权图示​编辑{#%E8%AE%A4%E8%AF%81%E6%8E%88%E6%9D%83%E5%9B%BE%E7%A4%BA%E2%80%8B%E7%BC%96%E8%BE%91-toc}\n图中涉及的类和接口{#%E5%9B%BE%E4%B8%AD%E6%B6%89%E5%8F%8A%E7%9A%84%E7%B1%BB%E5%92%8C%E6%8E%A5%E5%8F%A3-toc}\n流程总结{#%E6%B5%81%E7%A8%8B%E6%80%BB%E7%BB%93-toc}\n提示 {#%E6%8F%90%E7%A4%BA} Spring Security源码的接口名和方法名都很长，看源码的时候要见名知意，有必要细看接口名和方法名，另外可以借助流程图，调试追踪代码，有助于理解学习！\nApache Shiro和Spring Security {#Apache%20Shiro%E5%92%8CSpring%20Security} ​Spring Security是一个**可高度可定制的身份验证（认证）和访问控制（授权）框架，**它是用于保护基于Spring的应用程序的实际标准，相比与另外一个安全框架Shiro，它提供了更丰富的功能，社区资源也比Shiro丰富。\nShiro轻量级，不依赖Spring，是第三方框架，简单而灵活，可以用于非Web环境！ Security重量级，依赖Spring，控制粒度更细，老版本不能脱离Web，新版本可以 Spring Boot 2默认使用Security 5，要求JDK至少是8 Spring Boot 3默认使用Security 6，要求JDK至少是17 Security 5和Security 6的区别之一就是5到6废弃了WebSecurityConfigurerAdapter类，在Security 5编写配置类需要继承WebSecurityConfigurerAdapter并重写某些方法，但是在Security 6已经不需要了 Spring Security：升级已弃用的 WebSecurityConfigurerAdapter - spring 中文网\n从 Spring Security 5 迁移到 Spring Security 6/Spring Boot 3 - spring 中文网\n认证和授权 {#%E8%AE%A4%E8%AF%81%E5%92%8C%E6%8E%88%E6%9D%83} 认证（Authentication）：验证当前访问系统的是不是本系统的用户，并且要确认具体是哪个用户\n​授权（Authorization）：经过认证后判断当前用户是否有权限进行某个操作\n注：Authentication和Authorization拼写很像，有必要分清，后面看源代码方便！\nRBAC Role-Based Access Control 基于角色的访问控制\n把权限打包给角色（角色拥有一组权限），给用户分配角色（用户拥有多个角色）\n最少包括五张表 （用户表、角色表、用户角色表、权限表、角色权限表）\nDemo 环境 {#%E7%8E%AF%E5%A2%83} Spring Boot：2.7.2\nSpringSecurity：5+\nJDK：1.8\nController ","date":"2024-07-23T17:48:45Z","permalink":"/zh-cn/post/2024/07/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8springsecurity-5/","title":"一文入门SpringSecurity 5"},{"content":"共同关注功能 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Override public Result common(Long id) { Long userId = UserHolder.getUser().getId(); String key1=\u0026#34;follow:\u0026#34;+id; String key2=\u0026#34;follow:\u0026#34;+userId; //求两个用户关注的交集就是共同关注 Set\u0026lt;String\u0026gt; intersect = stringRedisTemplate.opsForSet().intersect(key2, key1); if (intersect.isEmpty()||intersect==null){ return Result.ok(Collections.emptyList()); } List\u0026lt;Long\u0026gt; list = intersect.stream().map(Long::valueOf).collect(Collectors.toList()); List\u0026lt;UserDTO\u0026gt; userdtos = userService.listByIds(list) .stream() .map(user -\u0026gt; BeanUtil.copyProperties(user, UserDTO.class)) .collect(Collectors.toList()); return Result.ok(userdtos); } Feed流推送 关注推送又叫Feed流，直译为投喂，为用户持续的提供沉浸式体验，如抖音、快手这类短视频APP，通过无限下滑获取最新信息。\n传统的推送模式是用户寻找内容，而Feed模式是内容匹配用户\n拉模式又叫读扩散\n粉丝从博主那里拉取：博主把自己的推文放到自己的发件箱，用户从多个博主那里拉取，但是每个博主发的推文时间是乱序的，那么 ","date":"2024-07-16T17:43:11Z","permalink":"/zh-cn/post/2024/07/redis%E7%9A%84zset%E5%AE%9E%E7%8E%B0%E5%85%B1%E5%90%8C%E5%85%B3%E6%B3%A8%E6%87%92%E6%B1%89%E5%BC%8F%E5%85%B3%E6%B3%A8%E6%8E%A8%E9%80%81/","title":"Redis的zset实现共同关注、懒汉式关注推送"},{"content":"案例需求 方案分析 一个用户对于一个blog只能点赞一次，如果只使用数据库完成该功能，那么用户每点赞一次都要查询、修改数据库，这样无疑增加了数据库的压力，那么引入redis，就可以使用redis的Sorted_Set集合解决该问题（中间件的引入当然是越少越好的，这样有利于系统的稳定性，那此处为了场景演示就引入redis了，毕竟现在有点规模的项目基本都离不开redis） redis的 Sorted_Set集合 集合中的元素具有唯一性、有序性，利用唯一性完成一个用户对于一个blog只能点赞一次，利用有序性完成点赞top5的用户排序，key是blog的id，value是用户id和用于排序的时间戳，如果该key的value中有当前登录用户的userId，那么说明该用户对该blog已点赞，那么可以利用该\n","date":"2024-07-14T18:14:45Z","permalink":"/zh-cn/post/2024/07/redis%E5%AE%9E%E7%8E%B0%E7%94%A8%E6%88%B7%E7%82%B9%E8%B5%9E%E7%82%B9%E8%B5%9Etop5%E7%94%A8%E6%88%B7%E6%8E%92%E5%BA%8F/","title":"Redis实现用户点赞、点赞top5用户排序"},{"content":"消息队列介绍 List实现消息队列 Redis的list数据结构是一个双向链表，先进先出，可以利用LPUSH、LPOP、RPUSH、RPOP命令来实现元素的左右进出，但是list并不是阻塞队列，当list中无元素时，线程并不会阻塞，而是从list中取出一个null，这并不符合我们的业务需要！因此这里要用BRPOP或BLPOP命令实现阻塞效果！\n阻塞队列\n当线程尝试从队列中获取元素时，若阻塞队列中无元素，则线程会阻塞，直到队列中有元素线程才会被唤醒并从阻塞队列中取出元素。\nPubSub实现消息队列 Stream实现消息队列 Stream的消费者组 Redis消息队列总结 基于Stream的异步秒杀 Redis创建消费者、消费者组、消息队列 1 2 3 4 5 xadd s1 * k1 v1 xgroup create s1 g1 0 xgroup create stream.orders g1 0 mkstream XREADGROUP GROUP g1 c1 count 1 Block 2000 streams s1 \u0026gt; 修改seckill.lua脚本 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 -- 1.参数列表 -- 1.1优惠券id local voucherId=ARGV[1] --1.2 用户id local userId=ARGV[2] --1.3 订单id local orderId=ARGV[3] --2.数据key ..是拼接符号 --2.1 库存key local stockKey=\u0026#39;seckill:stock:\u0026#39;..voucherId --2.2 订单key local orderKey=\u0026#39;seckill:order:\u0026#39;..voucherId --3.脚本业务 --3.1 判断库存是否充足 if (tonumber(redis.call(\u0026#39;get\u0026#39;,stockKey))\u0026lt;=0) then return 1 end --3.2判断用户是否下单 若set集合中存在该用户id，则说明已下过单，返回1 if (tonumber(redis.call(\u0026#39;sismember\u0026#39;,orderKey,userId))==1) then return 2 end --3.4扣库存 redis.call(\u0026#39;incrby\u0026#39;,stockKey,-1) --3.5保存用户到set redis.call(\u0026#39;sadd\u0026#39;,orderKey,userId) --3.6发送消息到消息队列 redis.call(\u0026#39;xadd\u0026#39;,\u0026#39;stream.orders\u0026#39;,\u0026#39;*\u0026#39;,\u0026#39;userId\u0026#39;,userId,\u0026#39;voucherId\u0026#39;,voucherId,\u0026#39;id\u0026#39;,orderId) return 0 添加新的秒杀券 数据库和redis同时存入id为19的秒杀券\nApifox模拟用户抢购秒杀券 查看Redis中数据变化 1、Redis中id=19的秒杀券的数量都-1\n2、Redis中成功存入用户id\n3、 Redis中成功存入订单信息\n4、数据库中成功存入订单信息\n总结 VoucherOrderServiceImpl.java完整代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 @Slf4j @Service public class VoucherOrderServiceImpl extends ServiceImpl\u0026lt;VoucherOrderMapper, VoucherOrder\u0026gt; implements IVoucherOrderService { @Resource private StringRedisTemplate stringRedisTemplate; @Resource private ISeckillVoucherService SeckillVoucherService; @Autowired private RedissonClient redissonClient; @Resource private RedisIdWorker redisIdWorker; //阻塞队列 当线程尝试从队列中获取元素时，若队列无元素，则线程会阻塞，直到队列中有元素才会被唤醒 // private BlockingQueue\u0026lt;VoucherOrder\u0026gt; orderTasks=new ArrayBlockingQueue\u0026lt;\u0026gt;(1024*1024); //线程池，负责从阻塞队列中获取订单然后异步下单 private static final ExecutorService SECKILL_ORDER_EXECUTOR= Executors.newSingleThreadExecutor(); //spring提供的注解 作用：类初始化后就执行VoucherOrderHandler方法 //向线程池提交一个线程 @PostConstruct private void init(){ SECKILL_ORDER_EXECUTOR.submit(new VoucherOrderHandler()); } //线程 内部类 private class VoucherOrderHandler implements Runnable{ String queueName =\u0026#34;stream.orders\u0026#34;; @Override public void run() { while (true){ try { //获取队列中的订单信息 // VoucherOrder order = orderTasks.take(); //获取消息队列的订单信息 List\u0026lt;MapRecord\u0026lt;String, Object, Object\u0026gt;\u0026gt; list = stringRedisTemplate.opsForStream().read(Consumer.from(\u0026#34;g1\u0026#34;, \u0026#34;c1\u0026#34;) , StreamReadOptions.empty().count(1).block(Duration.ofSeconds(2)) , StreamOffset.create(queueName, ReadOffset.lastConsumed()) ); //判断消息是否获取成功 if (list==null||list.isEmpty()){ //获取失败说明没有消息，继续循环 continue; } //获取成功则创建订单 MapRecord\u0026lt;String, Object, Object\u0026gt; record = list.get(0); Map\u0026lt;Object, Object\u0026gt; value = record.getValue(); VoucherOrder order = BeanUtil.fillBeanWithMap(value, new VoucherOrder(), true); createVoucherOrder(order); //ACK确认信息 stringRedisTemplate.opsForStream().acknowledge(\u0026#34;s1\u0026#34;,\u0026#34;g1\u0026#34;,record.getId()); } catch (Exception e) { log.error(\u0026#34;订单处理异常\u0026#34;,e); handlePendingList(); } } } private void handlePendingList() { while (true){ try { //获取pendingList队列的订单信息 List\u0026lt;MapRecord\u0026lt;String, Object, Object\u0026gt;\u0026gt; list = stringRedisTemplate.opsForStream().read( Consumer.from(\u0026#34;g1\u0026#34;, \u0026#34;c1\u0026#34;) , StreamReadOptions.empty().count(1) , StreamOffset.create(queueName, ReadOffset.from(\u0026#34;0\u0026#34;)) ); //判断消息是否获取成功 if (list==null||list.isEmpty()){ //获取失败说明没有消息，结束循环 break; } //获取成功则下单 MapRecord\u0026lt;String, Object, Object\u0026gt; record = list.get(0); Map\u0026lt;Object, Object\u0026gt; value = record.getValue(); VoucherOrder order = BeanUtil.fillBeanWithMap(value, new VoucherOrder(), true); createVoucherOrder(order); //ACK确认信息 stringRedisTemplate.opsForStream().acknowledge(\u0026#34;s1\u0026#34;,\u0026#34;g1\u0026#34;,record.getId()); } catch (Exception e) { log.error(\u0026#34;pendingList处理异常\u0026#34;,e); } } } } //代理对象 IVoucherOrderService proxy; private void handleVoucherOrder(VoucherOrder order) { Long userId = order.getUserId(); RLock redisLock = redissonClient.getLock(\u0026#34;lock:order:\u0026#34; + userId); boolean tryLock = redisLock.tryLock(); //判断锁是否获取成功 if (!tryLock){ log.error(\u0026#34;不允许重复下单\u0026#34;); return ; } try { //锁加到这里，事务提交后才释放锁 // proxy.createVoucherOrder(order); //使用动态代理类的对象，事务可以生效 } finally { redisLock.unlock(); } } private static final DefaultRedisScript\u0026lt;Long\u0026gt; SECKILL_SCRIPT; static { SECKILL_SCRIPT=new DefaultRedisScript\u0026lt;\u0026gt;(); SECKILL_SCRIPT.setLocation(new ClassPathResource(\u0026#34;seckill.lua\u0026#34;)); SECKILL_SCRIPT.setResultType(Long.class); } @Override public Result seckillVoucher(Long voucherId) { Long userId = UserHolder.getUser().getId(); //TODO 生成了orderId，把订单信息保存到阻塞队列，由另一个线程专门根据订单信息去数据库做增删改查，这就实现了异步 long orderId = redisIdWorker.nextId(\u0026#34;order\u0026#34;); //执行lua脚本判断有无购买资格 Long result = stringRedisTemplate.execute( SECKILL_SCRIPT, Collections.emptyList(), voucherId.toString(), userId.toString(),String.valueOf(orderId) ); int i = result.intValue(); if (i!=0){ return Result.fail(i==1?\u0026#34;优惠券库存不足\u0026#34;:\u0026#34;不能重复下单\u0026#34;); } //获取事务的动态代理对象，需要在启动类加注解暴漏出对象 proxy = (IVoucherOrderService)AopContext.currentProxy();//拿到动态代理对象 //添加到阻塞队列 //orderTasks.add(order); return Result.ok(orderId); } //TODO spring对该类做了动态代理，用动态代理的对象提交的事务 @Transactional public void createVoucherOrder(VoucherOrder order) { //一人一单，根据优惠卷id和用户id去数据库查询是否已经存在该优惠卷 Long id = order.getUserId(); Long userId = order.getUserId(); RLock redisLock = redissonClient.getLock(\u0026#34;lock:order:\u0026#34; + userId); boolean isLock = redisLock.tryLock(); if (!isLock){ log.error(\u0026#34;不允许重复下单\u0026#34;); return; } //为用户id加锁而不是对整个createVoucherOrder方法加锁，减小锁范围，提升性能，这样每个用户就有不同的锁 //锁加在函数内部，锁内的代码执行完后就会释放锁，而事务的提交是在整个方法执行后提交的，也就是事务的提交在锁释放之后。 //但是锁释放后其他线程就可以进来，此时事务可能还没有提交，可能出现并发问题，重复购买 //所以要扩大锁的范围，把锁加到seckillVoucher方法后面，在事务提交后才能释放锁！ try { int count = query().eq(\u0026#34;user_id\u0026#34;, id).eq(\u0026#34;voucher_id\u0026#34;, order.getVoucherId()).count(); if (count \u0026gt;=1) { //count==1说明用户拥有了一个优惠券 log.error(\u0026#34;不能重复下单\u0026#34;); return; // return Result.fail(\u0026#34;不能重复购买优惠卷\u0026#34;); } //4.扣减库存 防止超卖，加乐观锁，扣减库存前再查询一次库存判断 // boolean b = SeckillVoucherService.update() // .setSql(\u0026#34;stock=stock-1\u0026#34;). // eq(\u0026#34;voucher_id\u0026#34;, voucherId).eq(\u0026#34;stock\u0026#34;,voucher.getStock()).update(); //使用setSql方法设置了更新语句\u0026#34;stock=stock-1\u0026#34;，接着使用eq方法添加了两个条件：\u0026#34;voucher_id\u0026#34;等于voucherId和\u0026#34;stock\u0026#34;等于voucher.getStock() //条件1：voucher_id=voucherId指当前操作的优惠卷的id=数据库中的优惠卷id，即通过优惠卷id指明了要修改哪个优惠卷的库存 //条件2：stock=voucher.getStock,说明该线程修改库存期间没有其他线程来插队修改库存，那么数据是安全的 //TODO ！！！注意！这种操作在并发情况下可能导致用户在优惠卷库存充足的情况下抢购优惠卷失败，也就是即使有库存也会抢购失败，此时可以判断库存是否充足，重新抢购 //修改如下：最后库存判断，只要\u0026gt;0就可以修改 boolean b = SeckillVoucherService.update() .setSql(\u0026#34;stock=stock-1\u0026#34;). eq(\u0026#34;voucher_id\u0026#34;, order.getVoucherId()).gt(\u0026#34;stock\u0026#34;, 0) .update(); if (!b) { // return Result.fail(\u0026#34;库存不足\u0026#34;); log.error(\u0026#34;库存不足\u0026#34;); return; } //创建订单 save(order); } finally { //释放锁 redisLock.unlock(); } } } --- ","date":"2024-07-11T23:06:25Z","permalink":"/zh-cn/post/2024/07/redis%E5%AE%9E%E7%8E%B0%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97listpubsubstream%E5%9F%BA%E4%BA%8Estream%E7%9A%84%E5%BC%82%E6%AD%A5%E7%A7%92%E6%9D%80/","title":"Redis实现消息队列：list、PubSub、Stream，基于Stream的异步秒杀"},{"content":"异步前 之前的秒杀业务的查询优惠券、查询订单、减库存、创建订单都要查询数据库 ，而且有分布式锁 ，使得整个业务耗时长 ，对此采用异步操作处理，异步操作类似于餐厅点餐，服务员负责点菜产生订单、厨师负责根据订单后厨做饭，整个流程由服务员和厨师两个线程完成，此为异步。\n可以看到异步优化前 ，1000个请求的耗时均值497ms\n异步优化方案 将判断秒杀库存和校验一人一单的操作放在redis进行，优惠券库存信息也放入redis以减少读取数据库的压力，采用set集合存储购买过优惠券的用户的id，set集合有元素不重复的特性，可以自动实现一人一单\n整体业务逻辑如下：\nRedis实现库存和秒杀资格判断（需求1和2） 优惠券信息保存到redis 修改添加秒杀券的代码，在添加秒杀券的同时把信息也保存到redis中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Override @Transactional public void addSeckillVoucher(Voucher voucher) { // 保存优惠券 save(voucher); // 保存秒杀信息 SeckillVoucher seckillVoucher = new SeckillVoucher(); seckillVoucher.setVoucherId(voucher.getId()); seckillVoucher.setStock(voucher.getStock()); seckillVoucher.setBeginTime(voucher.getBeginTime()); seckillVoucher.setEndTime(voucher.getEndTime()); seckillVoucherService.save(seckillVoucher); //保存秒杀券信息到redis stringRedisTemplate.opsForValue().set(\u0026#34;seckill:stock:\u0026#34;+voucher.getId(),voucher.getStock().toString()); } 添加秒杀券，信息成功添加到redis中，秒杀券id是13，库存是100，如下图所示：\nlua脚本查询redis中库存和一人一单购买资格 seckill.lua\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 --- --- Created by 懒大王Smile. --- DateTime: 2024/7/6 10:47 --- -- 1.参数列表 -- 1.1优惠券id local voucherId=ARGV[1] --1.2 用户id local userId=ARGV[2] --2.数据key ..是拼接符号 --2.1 库存key local stockKey=\u0026#39;seckill:stock:\u0026#39;..voucherId --2.2 订单key local orderKey=\u0026#39;seckill:order:\u0026#39;..voucherId -- ","date":"2024-07-06T19:11:07Z","permalink":"/zh-cn/post/2024/07/%E5%9F%BA%E4%BA%8Eredis%E5%92%8C%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97%E7%9A%84-%E5%BC%82%E6%AD%A5%E7%A7%92%E6%9D%80%E4%B8%9A%E5%8A%A1/","title":"基于Redis和阻塞队列的 异步秒杀业务"},{"content":"介绍Redisson 什么是 Redisson？来自于官网上的描述内容如下！\nRedisson 是一个在 Redis 的基础上实现的 Java 驻内存数据网格客户端（In-Memory Data Grid）。它不仅提供了一系列的 redis 常用数据结构命令服务，还提供了许多分布式服务，例如分布式锁、分布式对象、分布式集合、分布式远程服务、分布式调度任务服务等等。\n相比于 Jedis、Lettuce 等基于 redis 命令封装的客户端，Redisson 提供的功能更加高端和抽象\n配置Redisson 引入依赖 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.redisson\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;redisson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.13.6\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 配置客户端类 1 2 3 4 5 6 7 8 9 10 11 @Configuration public class RedisConfig { @Bean public RedissonClient redissonClient(){ Config config = new Config(); //添加了单机redis地址，也可以使用useClusterServers()添加集群地址 config.useSingleServer().setAddress(\u0026#34;redis://192.168.2.129:6379\u0026#34;).setPassword(\u0026#34;linux02\u0026#34;); return Redisson.create(config); } } 使用Redisson分布式锁 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 Long id = UserHolder.getUser().getId(); RLock redisLock = redissonClient.getLock(\u0026#34;lock:order:\u0026#34; + id); //尝试获取锁 boolean tryLock = redisLock.tryLock(); //判断锁是否获取成功 if (!tryLock){ return Result.fail(\u0026#34;不允许重复下单\u0026#34;); } try { //锁加到这里，事务提交后才释放锁 //获取事务的动态代理对象，需要在启动类加注解暴漏出对象 IVoucherOrderService proxy = (IVoucherOrderService)AopContext.currentProxy();//拿到动态代理对象 return proxy.createVoucherOrder(voucherId, voucher); //使用动态代理类的对象，事务可以生效 } finally { redisLock.unlock(); } 不可重入锁 在同一个线程中，method1获取锁后，调用method2，method2中尝试获取锁，此时锁已经被method1获取，则method2获取锁失败，这就是不可重入锁，前面实现的锁就是不可重入锁！\nRedisson可重入锁 可重入锁，从字面来理解，就是可以重复进入的锁，也叫做递归锁，指的是同一线程外层函数获得锁之后，内层递归函数仍然有获取该锁的代码，但不受影响。\nReentrantLock 和synchronized都是可重入锁。\n在一个类中，如果synchronized方法1调用了synchronized方法2，方法2是可以正常执行的，这说明synchronized是可重入锁。否则，在执行方法2想获取锁的时候，该锁已经在执行方法1时获取了，那么方法2将永远得不到执行。\n为了实现可重入锁，**redis中使用hash类型不再使用string类型，****为什么要使用hash类型，**就不得不说到Redisson可重入锁在redis中的实现原理：\n实现原理 ：\n在同一线程中，method1成功获取锁后调用method2，method2也尝试获取锁，此时要先判断method2所在线程和method1所在线程是否是同一线程，若是，则method2也获取锁成功，它和method1显然获取了同一个锁****，那么该锁被获取次数+1，而这个锁被获取的次数我们需要记录，也就是说value不仅要记录 线程名 还要记录 锁被获取的次数，那么我们就由此采用hash类型更合理！\n为什么记录锁被获取的次数？\n一个业务的完成可能要多次获取锁，如一个业务中执行了method1，method1调用了method2，method2调用了method3，这三个方法都加同一个锁（可重入锁），当method3执行完后，并不能立刻释放method3的锁，而是锁被获取的次数-1 ，因为锁是共享的，此时method1和method2还没执行完不能释放锁，那么什么时候释放锁？当然是锁被获取的次数减为0了，说明此时已经没有方法获取锁，那么可以安全的释放可重入锁了。\nSo 锁被获取的次数就是我们判断是否要释放锁的依据！\n--- ","date":"2024-07-05T20:04:44Z","permalink":"/zh-cn/post/2024/07/redisson%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%8F%AF%E9%87%8D%E5%85%A5%E9%94%81/","title":"Redisson分布式锁、可重入锁"},{"content":"分布式场景下并发安全问题的引发 前面通过加锁解决了单机状态下一人一单的问题，但是当出现了分布式，前面的加锁形式不再适用 ，每个jvm有一个自己的锁监视器，只能被内部线程获取，其他jvm无法使用，那么多台jvm的锁监视器不共用一个锁监视器，就容易出现分布式场景下并发安全问题。\n问题分析 所以我们要使用可以解决分布式场景下的位于jvm外的锁，多个jvm共同使用该锁，而不是使用每个jvm的内部锁。\n分布式锁有如下特点：\n这里我们就选用redis来实现我们的分布式锁！\nRedis锁的demo redis锁要实现如上两个基本操作：获取锁和删除锁，在获取锁的同时为了防止宕机出现死锁，要手动添加过期时间，那么为了防止只加锁没有加过期时间的情况出现，我们要保证加锁和加过期时间的原子性，也就是他俩必须同时进行！\n那么上述加锁的命令可以换成如下：\n分布式锁初步实现 实现锁接口 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 public class SimpleRedisLock implements ILock { //用户的userid private String name; private StringRedisTemplate stringRedisTemplate; public SimpleRedisLock(String name, StringRedisTemplate stringRedisTemplate) { this.name = name; this.stringRedisTemplate = stringRedisTemplate; } //锁的key值 private static final String KEY_PREFIX = \u0026#34;lock:\u0026#34;; //生成锁的value值 private static final String ID_PREFIX = UUID.randomUUID().toString(true) + \u0026#34;-\u0026#34;; @Override public boolean tryLock(long timeoutSec) { // 获取线程标示 String threadId = ID_PREFIX + Thread.currentThread().getId(); // 获取锁 Boolean success = stringRedisTemplate.opsForValue() .setIfAbsent(KEY_PREFIX + name, threadId, timeoutSec, TimeUnit.SECONDS); //防止Boolean和boolean拆箱出问题，如果success为null，则返回false return Boolean.TRUE.equals(success); } @Override public void unlock() { //释放锁 stringRedisTemplate.delete(KEY_PREFIX + name); } } 使用锁 在VoucherOrderServiceImpl.java 中的seckillVoucher方法中编写如下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 //获取用户userid Long id = UserHolder.getUser().getId(); SimpleRedisLock redisLock = new SimpleRedisLock(\u0026#34;order:\u0026#34; + id, stringRedisTemplate); //加锁，1200s是锁的过期时间 boolean tryLock = redisLock.tryLock(1200); //判断锁是否获取成功 if (!tryLock){ return Result.fail(\u0026#34;不允许重复下单\u0026#34;); } try { //锁加到这里，事务提交后才释放锁 //获取事务的动态代理对象，需要在启动类加注解暴漏出对象 IVoucherOrderService proxy = (IVoucherOrderService)AopContext.currentProxy();//拿到动态代理对象 // return createVoucherOrder(voucherId, voucher); return proxy.createVoucherOrder(voucherId, voucher); //使用动态代理类的对象，事务可以生效 } finally { //无论如何都要释放锁，防止死锁 redisLock.unlock(); } 分布式场景下调试看效果 两个application，一个是8081端口，一个是8082端口。\napifox模拟同一个用户发送请求，authorization的参数值是同一个用户的，存储在redis中。\n如下：在8082的断点处获取锁失败，在8081的断点处获取锁成功，即只有一次成功获取锁。\n数据库中优惠券库存stock-1而不是-2，优惠券订单产生1个，数据库没问题！\nredis中查看锁的key值，1010正是userid，问题解决，达到我们想要的效果！\nredis分布式锁误删问题 问题分析 当线程1获取锁成功时，如果该业务执行时间长以至于超过了设置的锁过期时间，那么在业务还未完成时，锁便自动释放，此时线程1无锁，线程2获取到了锁执行业务，当线程1业务执行完后，按照业务逻辑仍会释放锁，但此时释放的是线程2的锁，这就出现了锁误删的问题。\n解决锁误删 对于每个线程，我们获取其线程标识（每个JVM内部都维护了线程的id，这个id是自增的，那么多个jvm可能出现线程id一致的情况，为了避免该情况出现我们用UUID生成一个随机字符串作为前缀，以降低线程id重复的概率）作为锁的value\n在释放锁时，我们先从redis获取对应的value值，跟当前线程的value做对比，一致则可以删除，否则就不能删除。\n修改trylock和unlock方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 public class SimpleRedisLock implements ILock { //用户的userid private String name; private StringRedisTemplate stringRedisTemplate; public SimpleRedisLock(String name, StringRedisTemplate stringRedisTemplate) { this.name = name; this.stringRedisTemplate = stringRedisTemplate; } //锁的key值 private static final String KEY_PREFIX = \u0026#34;lock:\u0026#34;; //线程的前缀，因为分布式下，多个jvm，每个jvm中维护的线程的id都是递增的，那么可能出现多个jvm的线程id一致，所以这里用uuid生成字符串作为前缀 private static final String THREAD_PREFIX = UUID.randomUUID().toString(true)+\u0026#34;-\u0026#34;; @Override public boolean tryLock(long timeoutSec) { // 获取线程标示 线程前缀+线程id String threadId = THREAD_PREFIX + Thread.currentThread().getId(); // 获取锁 Boolean success = stringRedisTemplate.opsForValue() .setIfAbsent(KEY_PREFIX + name, threadId, timeoutSec, TimeUnit.SECONDS); //防止Boolean和boolean拆箱出问题，如果success为null，则返回false return Boolean.TRUE.equals(success); } @Override public void unlock() { // 获取线程标示 String threadId =THREAD_PREFIX + Thread.currentThread().getId(); // 获取锁中的标示 String id = stringRedisTemplate.opsForValue().get(KEY_PREFIX + name); // 判断锁标示是否一致，防止锁误删 if(threadId.equals(id)) { // 释放锁 stringRedisTemplate.delete(KEY_PREFIX + name); } } } 分布式锁的原子性 问题分析 JVM做Full GC时会阻塞所有代码，时间过长会出现锁超时自动释放，那么其他线程会趁虚而入获得锁。\n那么会出现如下情况：线程1获取锁执行业务逻辑后要释放锁，在判断完释放锁的条件为true后，即 threadId.equals(id)==true， 正要释放锁时出现 Full GC，所有代码被阻塞，直到锁超时自动释放 （注意此时锁不是正常释放而是锁超时释放的），就在这时GC完毕代码恢复，线程2趁虚而入获得锁，而线程1也恢复了要执行释放锁的代码，因为GC前已经判断过释放条件为ture，那么此时线程1仍然认为锁是自己的，会错误地释放线程2的锁，又出现了误删问题。这里我们就要保证****锁的原子性，即 判断锁的标识 和 释放锁 两个动作必须同时发生！\n问题解决（Lua脚本） Lua是一种编程语言，Redis提供了Lua脚本功能，即可以在一个脚本中写多条redis指令，确保了多条命令执行的原子性\n代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 public class SimpleRedisLock implements ILock { //用户的userid private String name; private StringRedisTemplate stringRedisTemplate; public SimpleRedisLock(String name, StringRedisTemplate stringRedisTemplate) { this.name = name; this.stringRedisTemplate = stringRedisTemplate; } //锁的key值 private static final String KEY_PREFIX = \u0026#34;lock:\u0026#34;; //线程的前缀，因为分布式下，多个jvm，每个jvm中维护的线程的id都是递增的，那么可能出现多个jvm的线程id一致，所以这里用uuid生成字符串作为前缀 private static final String THREAD_PREFIX = UUID.randomUUID().toString(true)+\u0026#34;-\u0026#34;; private static final DefaultRedisScript\u0026lt;Long\u0026gt; UNLOCK_SCRIPT; static { UNLOCK_SCRIPT = new DefaultRedisScript\u0026lt;\u0026gt;(); UNLOCK_SCRIPT.setLocation(new ClassPathResource(\u0026#34;unlock.lua\u0026#34;)); UNLOCK_SCRIPT.setResultType(Long.class); } @Override public boolean tryLock(long timeoutSec) { // 获取线程标示 线程前缀+线程id String threadId = THREAD_PREFIX + Thread.currentThread().getId(); // 获取锁 Boolean success = stringRedisTemplate.opsForValue() .setIfAbsent(KEY_PREFIX + name, threadId, timeoutSec, TimeUnit.SECONDS); //防止Boolean和boolean拆箱出问题，如果success为null，则返回false return Boolean.TRUE.equals(success); } @Override public void unlock() { // 调用lua脚本 stringRedisTemplate.execute( UNLOCK_SCRIPT, Collections.singletonList(KEY_PREFIX + name), THREAD_PREFIX + Thread.currentThread().getId()); } } 在resource资源文件夹下创建Lua脚本内容如下：\n1 2 3 4 if (redis.call(\u0026#39;get\u0026#39;,KEYS[1])==ARGV[1]) then return redis.call(\u0026#39;del\u0026#39;,KEYS[1]) end return 0 --- ","date":"2024-07-04T23:15:25Z","permalink":"/zh-cn/post/2024/07/%E5%9F%BA%E4%BA%8Eredis%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","title":"基于Redis的分布式锁"},{"content":" 乐观锁、悲观锁 优惠券超卖 超卖场景复现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 @Service public class VoucherOrderServiceImpl extends ServiceImpl\u0026lt;VoucherOrderMapper, VoucherOrder\u0026gt; implements IVoucherOrderService { @Resource private ISeckillVoucherService SeckillVoucherService; @Resource private RedisIdWorker redisIdWorker; @Transactional @Override public Result seckillVoucher(Long voucherId) { //1.根据id查询优惠卷 SeckillVoucher voucher = SeckillVoucherService.getById(voucherId); //2.判断是否开始或结束 if (voucher.getBeginTime().isAfter(LocalDateTime.now())){ return Result.fail(\u0026#34;秒杀尚未开始\u0026#34;); } if (voucher.getEndTime().isBefore(LocalDateTime.now())){ return Result.fail(\u0026#34;秒杀已经结束\u0026#34;); } //3.判断库存 if (voucher.getStock()\u0026lt;1){ return Result.fail(\u0026#34;库存不足\u0026#34;); } //4.扣减库存 防止超卖，加乐观锁，扣减库存前再查询一次库存判断 boolean b = SeckillVoucherService.update() .setSql(\u0026#34;stock=stock-1\u0026#34;). eq(\u0026#34;voucher_id\u0026#34;, voucherId).gt(\u0026#34;stock\u0026#34;, voucher.getStock()).update(); if (!b) { return Result.fail(\u0026#34;库存不足\u0026#34;); } //5.创建订单，并插入数据库 VoucherOrder order = new VoucherOrder(); Long id = UserHolder.getUser().getId(); order.setVoucherId(voucherId); //生成订单的全局唯一ID long orderID = redisIdWorker.nextId(\u0026#34;voucherOrder\u0026#34;); order.setId(orderID); order.setUserId(id); save(order); //7.返回订单 return Result.ok(\u0026#34;orderID\u0026#34;); } } 上述代码适用于非高并发情况下，然而真实的情况是很多用户同时下单，是并发问题，那么此时就会出现超卖问题。 可以使用apache JMeter或者ApiFox模拟多线程并发场景：\n在数据库中设置秒杀券库存为100，JMeter设置200并发线程模拟200个用户同时下单。\n由图二可以看到异常值是45.5%，但是实际应该是50%，因为只有100个库存，200个用户应该只有100个用户能抢到秒杀券 ，打开数据库发现：\n秒杀券数量由最初的100变为-9，而不是0，此时就是超卖问题！\n原因分析 超卖问题就是线程并发安全问题 ，在一个线程修改数据的同时插入其他线程并发操作，进而出现数据错误，那么解决方法就是加锁，这里加乐观锁！\n加乐观锁 乐观锁其实并不是真的加锁，而是在最后要更新数据库数据时做版本判断，若此时的数据版本和最初的数据版本不一致，则认为在该线程执行过程中有其他线程插入做了数据修改，此时就认为数据不是安全的，就要报异常或者重试！而如果版本一致，则认为数据安全，那么就会更新数据。\n乐观锁在最后执行数据更新的时候进行判断，不用加锁，因此性能比悲观锁高。\n解决方法 这里采用第二种CAS法，利用库存代替版本号。\n根据以上分析，解决方法就是在扣减库存进行数据更新时多加一步操作：判断此时更新时的库存是否和上一步判断库存是否充足时的库存是否一致，一致则认为没有线程并发\n1 2 @Service public class VoucherOrderServiceImpl extends ServiceImpl\u0026lt;VoucherOrderMappe ","date":"2024-05-18T22:56:09Z","permalink":"/zh-cn/post/2024/05/redis%E5%AE%9E%E6%88%98%E4%B9%90%E8%A7%82%E9%94%81%E6%82%B2%E8%A7%82%E9%94%81%E4%BC%98%E6%83%A0%E5%8A%B5%E8%B6%85%E5%8D%96%E4%B8%80%E4%BA%BA%E4%B8%80%E5%8D%95%E9%97%AE%E9%A2%98/","title":"Redis实战—乐观锁、悲观锁、优惠劵超卖、一人一单问题"},{"content":"目录{#main-toc}\n缓存穿透{#%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F-toc}\n解决案例\u0026mdash;缓存空对象{#%E8%A7%A3%E5%86%B3%E6%A1%88%E4%BE%8B%E2%80%94%E7%BC%93%E5%AD%98%E7%A9%BA%E5%AF%B9%E8%B1%A1-toc}\n缓存雪崩{#%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%C2%A0-toc}\n缓存击穿{#%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF-toc}\n解决方法{#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95-toc}\n解决案例{#%E8%A7%A3%E5%86%B3%E6%A1%88%E4%BE%8B-toc}\n缓存穿透\n客户端请求的数据在缓存和数据库中都不存在，这样缓存永远不会生效，那么所有请求都会直接打到数据库上，增大数据库压力 解决：\n缓存空对象、布隆过滤、增加id复杂度，避免被猜出规律、做好基础数据格式校验、加强用户权限校验、做热点参数限流 缓存击穿（热点key）\n一个被高并发访问并且缓存重建业务复杂的key突然失效，大量请求瞬间打到数据库 解决：\n互斥锁、逻辑过期 缓存雪崩\n同一时段的大量key同时失效或redis宕机，导致大量请求直接打到数据库 解决：\n给不同的key的TTL添加随机值、提高redis集群的高可用、缓存业务添加限流策略、添加多级缓存 缓存穿透 {#%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F} 解决案例\u0026mdash;缓存空对象 {#%E8%A7%A3%E5%86%B3%E6%A1%88%E4%BE%8B%E2%80%94%E7%BC%93%E5%AD%98%E7%A9%BA%E5%AF%B9%E8%B1%A1} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 //缓存穿透 public Shop queryWithPassThrough(Long id){ //1.从redis查询缓存 String shopJson = stringRedisTemplate.opsForValue().get(CACHE_SHOP_KEY+id); //2.判断shopJson是否有数据，有直接返回，没有判空 if (StrUtil.isNotBlank(shopJson)){ //判断某字符串是否不为空且长度不为0且不由空白符构成 //判断参数：是否不为空，长度是否不为0，值是否不包含空白字符 Shop shop = JSONUtil.toBean(shopJson, Shop.class); return shop; } //3.是否命中缓存的空对象 //shopJson不 ","date":"2024-05-16T18:00:00Z","permalink":"/zh-cn/post/2024/05/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E5%85%A5%E9%97%A8/","title":"缓存穿透、缓存击穿、缓存雪崩【入门】"},{"content":"目录{#main-toc}\n基于Session{#%E5%9F%BA%E4%BA%8ESession-toc}\nController层{#Controller%E5%B1%82-toc}\nService层{#Service%E5%B1%82-toc}\nServiceImpl层{#ServiceImpl%E5%B1%82-toc}\n​编辑校验登录状态{#%E2%80%8B%E7%BC%96%E8%BE%91%E6%A0%A1%E9%AA%8C%E7%99%BB%E5%BD%95%E7%8A%B6%E6%80%81-toc}\nThreadLocal{#ThreadLocal-toc}\n登录拦截器{#%E7%99%BB%E5%BD%95%E6%8B%A6%E6%88%AA%E5%99%A8-toc}\n添加拦截器到Config{#%E6%B7%BB%E5%8A%A0%E6%8B%A6%E6%88%AA%E5%99%A8%E5%88%B0Config-toc}\nController层实现{#Controller%E5%B1%82%E5%AE%9E%E7%8E%B0-toc}\n基于Redis{#%E5%9F%BA%E4%BA%8ERedis-toc}\nServiceImpl{#ServiceImpl-toc}\n新增刷新拦截器{#%E6%96%B0%E5%A2%9E%E5%88%B7%E6%96%B0%E6%8B%A6%E6%88%AA%E5%99%A8-toc}\n添加拦截器到Config{#%E6%B7%BB%E5%8A%A0%E6%8B%A6%E6%88%AA%E5%99%A8%E5%88%B0Config-toc}\n基于Session {#%E5%9F%BA%E4%BA%8ESession} Controller层 {#Controller%E5%B1%82} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 /** * 发送手机验证码 */ @PostMapping(\u0026#34;code\u0026#34;) public Result sendCode(@RequestParam(\u0026#34;phone\u0026#34;) String phone, HttpSession session) { // TODO 发送短信验证码并保存验证码 return userService.sendCode(phone,session); } /** * 登录功能,不存在用户则自动创建用户 * @param loginForm 登录参数，包含手机号、验证码；或者手机号、密码 * @RequestBody注解用于把前端的json数据转换成DTO对象 */ @PostMapping(\u0026#34;/login\u0026#34;) public Result login(@RequestBody LoginFormDTO loginForm, HttpSession session){ //将请求体中的数据转换为特定的对象或数据类型绑定到方法的参数上 // TODO 实现登录功能 return userService.login(loginForm,session); } Service层 {#Service%E5%B1%82} 1 2 3 Result sendCode(String phone, HttpSession session); Result login(LoginFormDTO loginForm, HttpSession session); ServiceImpl层 {#ServiceImpl%E5%B1%82} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 //登录 @Override public Result login(LoginFormDTO loginForm, HttpSession session) { //发送验证码和登录是两次不同的请求，要对手机号做二次校验 //1.再次获取手机号并再次校验手机号 String phone = loginForm.getPhone(); if(RegexUtils.isPhoneInvalid(phone)){ //2.不符合返回错误信息 return Result.fail(\u0026#34;手机号格式错误\u0026#34;); } //3.手机号校验成功，校验验证码，验证码从session获取 String code = session.getAttribute(\u0026#34;code\u0026#34;);//发送的验证码 String logincode = loginForm.getCode();//用户填写的验证码 if (code==null||!code.toString().equals(logincode)){ //4.验证码错误，返回信息 return Result.fail(\u0026#34;验证码错误\u0026#34;); } //5.验证码一致，查询是否存在用户 //query()是Mybatis-Plus提供的，本类继承了extends ServiceImpl\u0026lt;UserMapper, User\u0026gt; User user = query().eq(\u0026#34;phone\u0026#34;, phone).one(); if (user==null){ //6.用户不存在则创建新用户，新用户信息要保存到session，所以这里把新建的user返回 user=createUserWithPhone(phone); } // 7.保存用户信息到session //user信息过多，不易直接保存到session，会加大内存负载，此处转化成userDTO,还可以隐藏用户敏感信息 UserDTO userDTO = BeanUtil.copyProperties(user, UserDTO.class); session.setAttribute(\u0026#34;user\u0026#34;,userDTO); //访问tomcat时。sessionID自动写到了cookie中作为以后的登录凭证 return Result.ok(); } //自动注册用户 private User createUserWithPhone(String phone) { User user=new User(); user.setPhone(phone); //生成随机用户名 user.setNickName(\u0026#34;user_\u0026#34;+RandomUtil.randomString(5)); save(us ","date":"2024-05-15T20:01:48Z","permalink":"/zh-cn/post/2024/05/redis%E5%AE%9E%E6%88%98%E9%AA%8C%E8%AF%81%E7%A0%81%E7%99%BB%E5%BD%95%E6%B3%A8%E5%86%8C/","title":"Redis实战—验证码登录注册"},{"content":" VUE 参考官网：https://cli.vuejs.org/zh/guide/\n目录{#main-toc}\nNVM安装{#NVM%E5%AE%89%E8%A3%85-toc}\n1.卸载node.js{#1.%E5%8D%B8%E8%BD%BDnode.js-toc}\n2.安装nvm{#2.%E5%AE%89%E8%A3%85nvm-toc}\n​编辑​{#%E2%80%8B%E7%BC%96%E8%BE%91%E2%80%8B-toc}\n3.配置{#3.%E9%85%8D%E7%BD%AE-toc}\n4.使用nvm安装node.js{#4.%E4%BD%BF%E7%94%A8nvm%E5%AE%89%E8%A3%85node.js-toc}\n5.nvm常用命令{#5.nvm%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4-toc}\n创建VUE项目{#%E5%88%9B%E5%BB%BAVUE%E9%A1%B9%E7%9B%AE-toc}\n1.使用vue init 创建vue2（不推荐）{#1.%E4%BD%BF%E7%94%A8vue%20init%20%E5%88%9B%E5%BB%BAvue2%EF%BC%88%E4%B8%8D%E6%8E%A8%E8%8D%90%EF%BC%89-toc}\n2.使用vue create创建vue2和3（较推荐）{#2.%E4%BD%BF%E7%94%A8vue%20create%E5%88%9B%E5%BB%BAvue2%E5%92%8C3%EF%BC%88%E8%BE%83%E6%8E%A8%E8%8D%90%EF%BC%89-toc}\n3.使用npm create vue创建vue2和3{#3.%E4%BD%BF%E7%94%A8npm%20create%20vue%E5%88%9B%E5%BB%BAvue2%E5%92%8C3-toc}\n4.使用npm create vite创建（推荐）{#4.%E4%BD%BF%E7%94%A8npm%20create%20vite%E5%88%9B%E5%BB%BA%EF%BC%88%E6%8E%A8%E8%8D%90%EF%BC%89-toc}\n5.使用vue ui 创建（推荐）{#5.%E4%BD%BF%E7%94%A8vue%20ui%20%E5%88%9B%E5%BB%BA%EF%BC%88%E6%8E%A8%E8%8D%90%EF%BC%89-toc}\nNVM安装 {#NVM%E5%AE%89%E8%A3%85} 我们开发过程中常常遇到nodejs版本不适配的问题，需要切换到不同版本的nodejs，nodejs卸载安装麻烦，这就需要用到nvm了。\nnvm 全名 node.js version management\n顾名思义是一个node.js的版本管理工具。通过它可以安装和切换不同版本的nodejs。\n1.卸载node.js {#1.%E5%8D%B8%E8%BD%BDnode.js} 为了确保彻底删除node在看看你的node安装目录中还有没有node文件夹，有的话一起删除。再看看C:\\Users\\用户名 文件夹下有没有.npmrc以及.yarnrc等等统统删除。再去看看你的环境变量有没有node相关的，有的话也一起删除了。一定要卸载干净！\n2.安装nvm {#2.%E5%AE%89%E8%A3%85nvm} Releases · coreybutler​​​​​​/nvm-windows · GitHub\n分别选择nvm的安装路径和nodejs的安装路径\n​\n​ {#%E2%80%8B%E7%BC%96%E8%BE%91%E2%80%8B} 终端输入nvm -v查到版本号则安装成功！\n3.配置 {#3.%E9%85%8D%E7%BD%AE} 环境变量在安装过程中会自动配置好\n在nvm的安装目录找到settings.txt，配置下载源\nnode_mirror: https://npm.taobao.org/mirrors/node/ npm_mirror: https://npm.taobao.org/mirrors/npm/ 里面的root和path应该 ","date":"2024-05-14T17:22:29Z","permalink":"/zh-cn/post/2024/05/nvm%E5%AE%89%E8%A3%85%E5%8F%8Avue%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE%E7%9A%84n%E7%A7%8D%E6%96%B9%E5%BC%8F/","title":"NVM安装及VUE创建项目的N种方式"},{"content":"目录{#main-toc}\n集群配置{#%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE-toc}\n集群启动{#%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8-toc}\n脚本启动zk集群{#%E8%84%9A%E6%9C%AC%E5%90%AF%E5%8A%A8zk%E9%9B%86%E7%BE%A4%C2%A0-toc}\n脚本启动kafka集群{#%E8%84%9A%E6%9C%AC%E5%90%AF%E5%8A%A8kafka%E9%9B%86%E7%BE%A4%C2%A0-toc}\n启动成功{#%E5%90%AF%E5%8A%A8%E6%88%90%E5%8A%9F%C2%A0-toc}\nKafka操作{#Kafka%E6%93%8D%E4%BD%9C-toc}\n命令行创建Topic{#%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%88%9B%E5%BB%BATopic-toc}\n​编辑{#%E2%80%8B%E7%BC%96%E8%BE%91-toc}\n消费者生产者联动{#%E6%B6%88%E8%B4%B9%E8%80%85%E7%94%9F%E4%BA%A7%E8%80%85%E8%81%94%E5%8A%A8-toc}\n​编辑{#%E2%80%8B%E7%BC%96%E8%BE%91-toc}\nLinux配置EFAK3.0.1{#Linux%E9%85%8D%E7%BD%AEEFAK3.0.1-toc}\nKraft模式集群{#Kraft%E6%A8%A1%E5%BC%8F%E9%9B%86%E7%BE%A4-toc}\n配置{#%E9%85%8D%E7%BD%AE-toc}\n启动前初始化集群{#%E5%90%AF%E5%8A%A8%E5%89%8D%E5%88%9D%E5%A7%8B%E5%8C%96%E9%9B%86%E7%BE%A4-toc}\n浅浅把玩Kraft{#%E6%B5%85%E6%B5%85%E6%8A%8A%E7%8E%A9Kraft-toc}\nFlume联动kafka{#Flume%E8%81%94%E5%8A%A8kafka-toc}\nFlume作为生产者{#Flume%E4%BD%9C%E4%B8%BA%E7%94%9F%E4%BA%A7%E8%80%85-toc}\nFlume作为消费者 ​编辑{#Flume%E4%BD%9C%E4%B8%BA%E6%B6%88%E8%B4%B9%E8%80%85%C2%A0%E2%80%8B%E7%BC%96%E8%BE%91-toc}\nSpringBoot联动kakfa{#SpringBoot%E8%81%94%E5%8A%A8kakfa-toc}\nSpringBoot作为生产者{#SpringBoot%E4%BD%9C%E4%B8%BA%E7%94%9F%E4%BA%A7%E8%80%85-toc}\nSpringBoot作为消费者{#SpringBoot%E4%BD%9C%E4%B8%BA%E6%B6%88%E8%B4%B9%E8%80%85%C2%A0-toc}\n集群配置 {#%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE} 三台服务器：linux01、linux02、linux03\n每台服务器均安装了zookeeper、kafka，服务器之间做了ssh免密登录（集群启停脚本用）\nkafka虽然内置了zk，但是这里用的是自己安装的zk。\n服务器之间加了ip映射，如hosts文件所示，这样就不需要p地址，只需要服务器名字就可以了\n集群启动 {#%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8} 注意事项\n启动时先启动zk，再启动kafka 关闭时先关闭kafka，再关闭zk，因为kafka需要zk来维护数据信息，再关闭前kafka要和zk通讯。 kafka-server-start.sh -daemon config/server.properties kafka-server-stop.sh 脚本启动zk集群 {#%E8%84%9A%E6%9C%AC%E5%90%AF%E5%8A%A8zk%E9%9B%86%E7%BE%A4%C2%A0} 脚本启动kafka集群 {#%E8%84%9A%E6%9C%AC%E5%90%AF%E5%8A%A8kafka%E9%9B%86%E7%BE%A4%C2%A0} 启动成功 {#%E5%90%AF%E5%8A%A8%E6%88%90%E5%8A%9F%C2%A0} 启动成功，三台服务器均显示如下：\n查看zk客户端，根节点下已经有了kafka节点\n默认直接在根节点下生成admin、brokers、cluster等节点，但是不方便维护，因此在server.properties文件中改了配置，让所有节点统一生成在kafka节点。\nzk集群启停脚本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #!/bin/bash #zookeeper集群启停及状态查看脚本 ZOOKEEPER=\u0026#34;/export/server/zookeeper\u0026#34; case $1 in \u0026#34;start\u0026#34;) for i in linux01 linux02 linux03 do echo ---------- zookeeper $i 启动 ------------ ssh $i \u0026#34;$ZOOKEEPER/bin/zkServer.sh start\u0026#34; done ;; \u0026#34;stop\u0026#34;) for i in linux01 linux02 linux03 do echo ---------- zookeeper $i 停止 ------------ ssh $i \u0026#34;$ZOOKEEPER/bin/zkServer.sh stop\u0026#34; done ;; \u0026#34;status\u0026#34;) for i in linux01 linux02 linux03 do echo ---------- zookeeper $i 状态 ------------ ssh $i \u0026#34;$ZOOKEEPER/bin/zkServer.sh status\u0026#34; done ;; esac kafka集群启停脚本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #!/bin/bash case $1 in \u0026#34;start\u0026#34;){ for i in linux01 linux02 linux03 do echo --------$i 启动kafka--------- ssh $i \u0026#34;source /etc/profile;/export/server/kafka/bin/kafka-server-start.sh -daemon /export/server/kafka/config/server.properties\u0026#34; done };; \u0026#34;stop\u0026#34;){ for i in linux01 linux02 linux03 do echo --------$i 停止kafka--------- ssh $i \u0026#34;source /etc/profile;/export/server/kafka/bin/kafka-server-stop.sh stop\u0026#34; done };; esac Kafka操作 {#Kafka%E6%93%8D%E4%BD%9C} \u0026ndash;bootstrap-server是连接kafka，对于集群而言，连接任何一台服务器的kafka都是一样的\n命令行创建Topic {#%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%88%9B%E5%BB%BATopic} {#%E2%80%8B%E7%BC%96%E8%BE%91} 消费者生产者联动 {#%E6%B6%88%E8%B4%B9%E8%80%85%E7%94%9F%E4%BA%A7%E8%80%85%E8%81%94%E5%8A%A8} 先启动生产者，生产hello、hahaha，再启动消费者，生产者再生产aaaaa、bbbb。此时hello、hahaha属于历史消息，不会显示，只显示aaaaa、bbbb，若想显示历史消息，需要如下，此时消息是乱序的：\nLinux配置EFAK3.0.1 {#Linux%E9%85%8D%E7%BD%AEEFAK3.0.1} 1. 配置EFAK的环境变量\nke.sh文件中引用的efak变量名是KE_HOME，所以环境变量名一定是KE_HOME，否则efak无法启动\nsource /etc/profile\n2. 修改kafka的bin/kafka-server-start.sh的内存配置，如果不修改，可能无法启动efak\n内容如下：\n1 2 3 4 5 6 if [ \u0026#34;x$KAFKA_HEAP_OPTS\u0026#34; = \u0026#34;x\u0026#34; ]; then #export KAFKA_HEAP_OPTS=\u0026#34;-Xmx1G -Xms1G\u0026#34; export KAFKA_HEAP_OPTS=\u0026#34;-server -Xms2G -Xmx2G -XX:PermSize=128m -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:ParallelGCThreads=8 -XX:ConcGCThreads=5 -XX:InitiatingHeapOccupancyPercent=70\u0026#34; #监控kafka运行的端口号9999 export JMX_PORT=\u0026#34;9999\u0026#34; fi ","date":"2024-05-05T20:57:35Z","permalink":"/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/","title":"kafka实战 集群搭建-Kraft模式"},{"content":"目录{#main-toc}\n消息队列（MQ）{#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%EF%BC%88MQ%EF%BC%89-toc}\n消息队列一般应用场景{#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%80%E8%88%AC%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF-toc}\nJMS{#JMS-toc}\nJMS模型{#%C2%A0JMS%E6%A8%A1%E5%9E%8B-toc}\n点对点模型（peer to peer）{#%E7%82%B9%E5%AF%B9%E7%82%B9%E6%A8%A1%E5%9E%8B%EF%BC%88peer%20to%20peer%EF%BC%89-toc}\n发布订阅模型{#%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%A8%A1%E5%9E%8B-toc}\nKafka架构{#Kafka%E6%9E%B6%E6%9E%84-toc}\nBroker{#Broker-toc}\nController选举{#Controller%E9%80%89%E4%B8%BE-toc}\nBroker上下线{#Broker%E4%B8%8A%E4%B8%8B%E7%BA%BF%C2%A0-toc}\nBroker工作流程{#Broker%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B-toc}\nProducer{#Producer-toc}\nConsumer{#Consumer-toc}\nConsumer Group{#Consumer%20Group-toc}\nTopic{#Topic-toc}\nPartition分区{#Partition%E5%88%86%E5%8C%BA-toc}\n分区好处{#%E5%88%86%E5%8C%BA%E5%A5%BD%E5%A4%84%C2%A0-toc}\n生产者发送消息的分区策略{#%C2%A0%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E7%9A%84%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5-toc}\n文件存储Segment{#%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8Segment-toc}\n分区的副本{#%E5%88%86%E5%8C%BA%E7%9A%84%E5%89%AF%E6%9C%AC-toc}\nWhy分区副本{#Why%E5%88%86%E5%8C%BA%E5%89%AF%E6%9C%AC-toc}\n手动调整分区副本存储​编辑{#%E6%89%8B%E5%8A%A8%E8%B0%83%E6%95%B4%E5%88%86%E5%8C%BA%E5%89%AF%E6%9C%AC%E5%AD%98%E5%82%A8%E2%80%8B%E7%BC%96%E8%BE%91-toc}\n副本Leader分区自动平衡{#%E5%89%AF%E6%9C%ACLeader%E5%88%86%E5%8C%BA%E8%87%AA%E5%8A%A8%E5%B9%B3%E8%A1%A1-toc}\n增加副本数量{#%E5%A2%9E%E5%8A%A0%E5%89%AF%E6%9C%AC%E6%95%B0%E9%87%8F%C2%A0-toc}\n副本Leader选举{#%E5%89%AF%E6%9C%ACLeader%E9%80%89%E4%B8%BE-toc}\n副本Leader故障恢复{#%E5%89%AF%E6%9C%ACLeader%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D-toc}\n副本Follower故障恢复{#%E5%89%AF%E6%9C%ACFollower%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D%C2%A0-toc}\nISR机制{#%C2%A0ISR%E6%9C%BA%E5%88%B6-toc}\n不完全首领选举{#%E4%B8%8D%E5%AE%8C%E5%85%A8%E9%A6%96%E9%A2%86%E9%80%89%E4%B8%BE-toc}\n最少同步副本{#%E6%9C%80%E5%B0%91%E5%90%8C%E6%AD%A5%E5%89%AF%E6%9C%AC-toc}\n数据请求{#%E6%95%B0%E6%8D%AE%E8%AF%B7%E6%B1%82%C2%A0-toc}\n请求机制{#%E8%AF%B7%E6%B1%82%E6%9C%BA%E5%88%B6-toc}\n生产者详解{#%E7%94%9F%E4%BA%A7%E8%80%85%E8%AF%A6%E8%A7%A3-toc}\n生产者发送消息的过程{#%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E7%9A%84%E8%BF%87%E7%A8%8B-toc}\n消息可靠性{#%E6%B6%88%E6%81%AF%E5%8F%AF%E9%9D%A0%E6%80%A7%C2%A0-toc}\nACK应答{#ACK%E5%BA%94%E7%AD%94%C2%A0-toc}\n数据重试{#%C2%A0%E6%95%B0%E6%8D%AE%E9%87%8D%E8%AF%95-toc}\n数据乱序{#%E6%95%B0%E6%8D%AE%E4%B9%B1%E5%BA%8F%C2%A0-toc}\n同步发送{#%E5%90%8C%E6%AD%A5%E5%8F%91%E9%80%81-toc}\n异步发送{#%E5%BC%82%E6%AD%A5%E5%8F%91%E9%80%81-toc}\n生产者提高吞吐量{#%E7%94%9F%E4%BA%A7%E8%80%85%E6%8F%90%E9%AB%98%E5%90%9E%E5%90%90%E9%87%8F-toc}\n压缩算法{#%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95%C2%A0-toc}\n消费者详解{#%E6%B6%88%E8%B4%B9%E8%80%85%E8%AF%A6%E8%A7%A3-toc}\npush\u0026amp;pull{#push%26pull-toc}\n消费者组调度器{#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E8%B0%83%E5%BA%A6%E5%99%A8%C2%A0-toc}\n消费者分配分区策略{#%E6%B6%88%E8%B4%B9%E8%80%85%E5%88%86%E9%85%8D%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5%C2%A0-toc}\n消费者Leader{#%E6%B6%88%E8%B4%B9%E8%80%85Leader%C2%A0-toc}\n分区再均衡{#%E5%88%86%E5%8C%BA%E5%86%8D%E5%9D%87%E8%A1%A1-toc}\n监听分区再均衡{#%E7%9B%91%E5%90%AC%E5%88%86%E5%8C%BA%E5%86%8D%E5%9D%87%E8%A1%A1%C2%A0-toc}\n偏移量Offset{#%E5%81%8F%E7%A7%BB%E9%87%8FOffset-toc}\nLSO{#LSO-toc}\nLEO{#LEO-toc}\nHW{#HW-toc}\n手动提交偏移量{#%E6%89%8B%E5%8A%A8%E6%8F%90%E4%BA%A4%E5%81%8F%E7%A7%BB%E9%87%8F-toc}\n同步提交{#%E5%90%8C%E6%AD%A5%E6%8F%90%E4%BA%A4-toc}\n异步提交{#%E5%BC%82%E6%AD%A5%E6%8F%90%E4%BA%A4-toc}\n自动提交偏移量{#%E8%87%AA%E5%8A%A8%E6%8F%90%E4%BA%A4%E5%81%8F%E7%A7%BB%E9%87%8F-toc}\n截至 尚硅谷kafka3.x P39{#%E6%88%AA%E8%87%B3%20%E5%B0%9A%E7%A1%85%E8%B0%B7kafka3.x%20P39-toc}\nKafka是一个由Scala和Java语言开发的，经典高吞吐量的分布式消息发布和订阅系统，也是大数据技术领域中用作数据交换的核心组件之一。它具有以下特点：\n支持消息的发布和订阅，类似于 RabbtMQ、ActiveMQ 等消息队列； 支持数据实时处理； 能保证消息的可靠性投递； 支持消息的持久化存储，并通过多副本分布式的存储方案来保证消息的容错； 高吞吐率，单 Broker 可以轻松处理数千个分区以及每秒百万级的消息量； 消息队列（MQ） {#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%EF%BC%88MQ%EF%BC%89} Kafka软件最初的设计就是专门用于数据传输的消息系统，类似功能的软件有RabbitMQ、ActiveMQ、RocketMQ等，这些软件的核心功能是传输数据，而Java中如果想要实现数据传输功能，那么这个软件一般需要遵循Java消息服务技术规范JMS。前面提到的ActiveMQ软件就完全遵循了JMS技术规范，而RabbitMQ是遵循了类似JMS规范并兼容JMS规范的跨平台的AMQP规范。除了上面描述的JMS，AMQP外，还有一种用于物联网小型设备之间传输消息的MQTT通讯协议。\nKafka拥有作为一个消息系统应该具备的功能，但是却有着独特的设计。Kafka借鉴了JMS规范的思想，但是却并没有完全遵循JMS规范。这也恰恰是软件名称为Kafka，而不是KafkaMQ的原因。\n消息队列一般应用场景 {#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%80%E8%88%AC%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF} **应用耦合：**多应用间通过消息队列对同一消息进行处理，避免调用接口失败导致整个过程失败。 **异步处理：**多应用对消息队列中同一消息进行处理，应用间并发处理消息，相比串行处理，减少处理时间 限流削峰： 广泛应用于秒杀或抢购活动中，避免流量过大导致应用系统挂掉的情况。该方法有如下优点： 1.请求先入消息队列，而不是由业务处理系统直接处理，做了一次缓冲,极 大地减少了业务处理系统的压力； 2.队列长度可以做限制，事实上，秒杀时，后入队列的用户无法秒杀到商品，这些请求可以直接被抛弃，返回活动已结束或商品已售完信息； 消息驱动的系统： 系统分为消息队列、消息生产者、消息消费者，生产者 负责产生消息，消费者(可能有多个)负责对消息进行处理。具体场景：用户新上传了一批照片，人脸识别系统需要对这个用户的所有照片进行聚类，聚类完成后由对账系统重新生成用户的人脸索引(加快查询)。这三个子 系统间由消息队列连接起来，前一个阶段的处理结果放入队列中，后一个阶段从 队列中获取消息继续处理。 该方法有如下优点：1.避免了直接调用下一个系统导致当前系统失败； 2.每个子系统对于消息的处理方式可以更为灵活，可以选择收到消息时就处理，可以选择定时处理，也可以划分时间段按不同处理速度处理； JMS JMS类似于JDBC，是java平台的消息中间件通用规范，定义了系统和系统之间传输消息的接口。\n为了实现系统和系统之间的数据传输，JMS规范中定义很多用于通信的组件：\nJMS Producer **：**JMS消息生产者。所谓的生产者，就是生产数据的客户端应用程序，这些应用通过JMS接口发送JMS消息。 JMS Provider：JMS消息提供者。其实就是实现JMS接口和规范的消息中间件，也就是我们提供消息服务的软件系统，比如RabbitMQ、ActiveMQ、Kafka。 JMS Message：JMS消息。这里的消息指的就是数据。一般采用Java数据模型进行封装，其中包含消息头，消息属性和消息主体内容。 JMS Consumer：JMS消息消费者。所谓的消费者，就是从消息提供者中获取数据的客户端应用程序，这些应用通过JMS接口接收JMS消息。 JMS模型 {#%C2%A0JMS%E6%A8%A1%E5%9E%8B} 点对点模型（peer to peer） {#%E7%82%B9%E5%AF%B9%E7%82%B9%E6%A8%A1%E5%9E%8B%EF%BC%88peer%20to%20peer%EF%BC%89} 特点：\n每个消息只有一个接收者（Consumer）(即一旦被消费，就会被删除)； 发送者和接发收者间没有依赖性，发送者发送消息之后，不管有没有接收者在运行，都不会影响到发送者下次发送消息； 接收者在成功接收消息之后需向队列应答成功，以便消息队列删除当前接 收的消息 发布订阅模型 {#%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%A8%A1%E5%9E%8B} 特点：\n每个消息可以有多个订阅者，但是订阅者必须来自不同的消费者组； 针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息。 为了消费消息，订阅者需要提前订阅该角色主题，并保持在线运行； Kafka采用就是这种模型。\nKafka架构 {#Kafka%E6%9E%B6%E6%9E%84} 在 Kafka 2.8.0 版本，移除了对 Zookeeper 的依赖，通过Kraft模式 进行自己的集群管理，使用 Kafka内部的 Quorum 控制器来取代 ZooKeeper管理元数据，这样我们无需维护zk集群，只要维护Kafka集群就可以了，节省运算资源。\nkafka基本数据单元被称为 message(消息)，为减少网络开销，提高效率，多个消息会被放入同一批次(Batch) 中后再写入。\nBroker kafka 集群中包含多个服务实例（节点），这种服务实例被称为 broker（一个 broker 就是一个节点/一个服务器），每个 broker 都有一个唯一标识 broker.id，用于标识自己在集群中的身份，可以在配置文件 server.properties 中进行配置，或由程序自动生成。 Broker 接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。Broker 为消费者提供服务，对读取分区的请求做出响应，返回已经提交到磁盘的消息。 Controller选举 {#Controller%E9%80%89%E4%B8%BE} 每一个集群都会选举出一个 Broker作为集群控制器 **(Controller)，它负责分区 Leader 选举，还负责管理主题分区及其副本的状态、元数据管理。**如果在运行过程中，Controller节点出现了故障，那么Kafka会依托于ZooKeeper软件选举其他的节点作为新的Controller，让Kafka集群实现高可用。\n特殊情况\nController节点并没有宕掉，而是因为网络的抖动，不稳定，导致和ZooKeeper之间的会话超时，那么此时，整个Kafka集群就会认为之前的Controller已经下线（退出）从而选举出新的Controller，而之前的Controller的网络又恢复了，以为自己还是Controller了，继续管理整个集群，那么此时，整个Kafka集群就有两个controller进行管理，那么其他的broker就懵了，不知道听谁的了，这种情况，我们称之为脑裂现象，为了解决这个问题，Kafka通过一个任期（epoch:纪元）的概念来解决，也就是说，每一个Broker当选Controller时，会告诉当前Broker是第几任Controller，一旦重新选举时，这个任期会自动增1，那么不同任期的Controller的epoch值是不同的，那么旧的controller一旦发现集群中有新任controller的时候，那么它就会完成退出操作（清空缓存，中断和broker的连接，并重新加载最新的缓存），让自己重新变成一个普通的Broker。\nBroker上下线 {#Broker%E4%B8%8A%E4%B8%8B%E7%BA%BF%C2%A0} Controller 在初始化时，会利用 ZK 的 watch 机制注册很多不同类型的监听器，当监听的事件被触发时，Controller 就会触发相应的操作。Controller 在初始化时，会注册多种类型的监听器，主要有以下几种：\n/kafka/admin/reassign_partitions 节点，用于分区副本迁移的监听 /kafka/isr_change_notification 节点，用于 Partition ISR 变动的监听 /kafka/admin/preferred_replica_election 节点，用于需要进行 Partition 最优 leader 选举的监听 /kafka/brokers/topics 节点，用于 Topic 新建的监听 /kafka/brokers/topics/TOPIC_NAME 节点，用于 Topic Partition 扩容的监听 /kafka/admin/delete_topics 节点，用于 Topic 删除的监听 /kafka/brokers/ids 节点，用于 Broker 上下线的监听，记录有哪些kafka服务器在线。 /kafka/controller节点，辅助选举leader 每台 Broker 在上线时，都会与ZK建立一个建立一个session，并在 /brokers/ids下注册一个节点，节点名字就是broker id，这个节点是临时节点，该节点内部会有这个 Broker 的详细节点信息。Controller会监听/brokers/ids这个路径下的所有子节点，如果有新的节点出现，那么就代表有新的Broker上线，如果有节点消失，就代表有broker下线，Controller会进行相应的处理，Kafka就是利用ZK的这种watch机制及临时节点的特性来完成集群 Broker的上下线。无论Controller监听到的哪一种节点的变化，都会进行相应的处理，同步整个集群元数据。\nBroker工作流程 {#Broker%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B} Producer 一般情况下，生产者在把消息均衡地分布到在主题的所有分区上，而并不关心消息会被写到哪个分区。如果我们想要把消息写到指定的分区，可以通过自定义分区器来实现。\nConsumer 消费者一定是归属于某个消费组中的，消费者可以订阅一或多个主题，并按照分区中消息的顺序来读取。消费者通过检查消息的偏移量 (offset) 来区分读取过的消息。偏移量是一个不 断递增的数值，在创建消息时，Kafka 会把它添加到其中，在给定的分区里，每个消息的偏移量都是唯一的。消费者把每个分区最后读取的偏移量保存在 Zookeeper 或 Kafka 上，如果消费者关闭或者重启，它还可以重新获取该偏移量，以保证读取状态不会丢失。\nConsumer Group {#Consumer%20Group} 消费者组由一个或者多个消费者组成，同一个组中的消费者对于同一条消息只消费一次。\n每个消费者组都有一个 ID，即 group ID。组内的所有消费者协调在一起来消费 一个订阅主题的所有分区。当然，每个分区只能由同一个消费组内的一个消费者来消费，但可以由不同的消费组来消费。partition 数量决定了每个 consumer group 中并发消费者的最大数。\n因此要合理设置消费者组中的消费者数量，避免出现消费者闲置。\nTopic Kafka 的消息通过 Topics(主题) 进行分类，Kafka中有两个固定的，用于记录消费者偏移量和事务处理的主题，一个主题可以被分为若干个 Partitions(分区)，一个分区就是 一个提交日志 (commit log)。消息以追加的方式写入分区，然后以先入先出的顺序读取。Kafka 通过分区来实现数据的冗余和伸缩性，分区可以分布在不同的服务器上，这意味着一个 Topic 可以横跨多个服务器，以提供比单个服务器更强大的性能。\n由于一个 Topic 包含多个分区，因此无法在整个 Topic 范围内保证消息的顺序性，但可以保证消息在单个分区内的顺序性。\n","date":"2024-05-05T17:42:50Z","permalink":"/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/","title":"Kafka入门到入土——万字详解，图文并茂"},{"content":"目录{#main-toc}\n事务（Put、Take）{#%E4%BA%8B%E5%8A%A1%EF%BC%88Put%E3%80%81Take%EF%BC%89-toc}\n架构原理{#%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86-toc}\nChannel选择器{#Channel%E9%80%89%E6%8B%A9%E5%99%A8-toc}\nSinkProcessor{#SinkProcessor-toc}\n拓扑结构{#%E6%8B%93%E6%89%91%E7%BB%93%E6%9E%84-toc}\n单源多出口案例{#%E5%8D%95%E6%BA%90%E5%A4%9A%E5%87%BA%E5%8F%A3%E6%A1%88%E4%BE%8B-toc}\n故障转移案例{#%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB%E6%A1%88%E4%BE%8B-toc}\n负载均衡案例{#%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E6%A1%88%E4%BE%8B-toc}\nFlume聚合案例{#Flume%E8%81%9A%E5%90%88%E6%A1%88%E4%BE%8B-toc}\n自定义拦截器{#%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8B%A6%E6%88%AA%E5%99%A8-toc}\n自定义拦截器打成jar包{#%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8B%A6%E6%88%AA%E5%99%A8%E6%89%93%E6%88%90jar%E5%8C%85-toc}\n任务配置文件{#%E4%BB%BB%E5%8A%A1%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-toc}\n自定义Source{#%E8%87%AA%E5%AE%9A%E4%B9%89Source-toc}\n自定义Sink{#%E8%87%AA%E5%AE%9A%E4%B9%89Sink-toc}\n事务源码{#%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81-toc}\n事务（Put、Take） {#%E4%BA%8B%E5%8A%A1%EF%BC%88Put%E3%80%81Take%EF%BC%89} put事务把数据批处理写入临时缓冲区putList，，然后doCommit去检查Channel内存队列是否足够合并，如果不够，就回滚数据，如果够，就把putList的数据写入到Channel，然后由take事务从channel中拉取，写入到临时缓冲区takeList，然后把数据从takeList发送到HDFS，发送完毕后清空缓冲区，如果某个数据发送失败，就回滚到channel。\n架构原理 {#%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86} 在拦截阶段可以进行数据过滤清洗，洗掉脏数据。\nChannel选择器 {#Channel%E9%80%89%E6%8B%A9%E5%99%A8} 1）ChannelSelector\n因为一个source可以对应对各channel ，ChannelSelector 的作用就是选出 Event 将要被发往哪个 Channel。其共有两种类型， 分别是 Replicating（复制）和 Multiplexing（多路复用）。 ReplicatingSelector 会将同一个 Event 发往所有的 Channel，Multiplexing 会根据自定义的配置，将不同的Event发往不同的Channel，Multiplexing要结合拦截器使用，Multiplexing会根据数据的头信息来决定发送到哪个channel。\nSinkProcessor 2）SinkProcessor\n一个sink只能绑定一个channel，一个channel能绑定多个sink。SinkProcessor 共 有 三 种 类 型 ， 分 别 是 DefaultSinkProcessor 、LoadBalancingSinkProcessor 和 FailoverSinkProcessor。DefaultSinkProcessor 对 应 的 是 单个的 Sink ， LoadBalancingSinkProcessor 和 FailoverSinkProcessor 对应的是 Sink Group，LoadBalancingSinkProcessor 可以实现负载均衡的功能，FailoverSinkProcessor 可以错误恢复的功能。\nLoadBalancingSinkProcessor负载均衡：\n一个channel会发给多个sink\nFailoverSinkProcessor故障转移：\n当一个sink故障，任务会转移到其他sink\n拓扑结构 {#%E6%8B%93%E6%89%91%E7%BB%93%E6%9E%84} 单源多出口案例 {#%E5%8D%95%E6%BA%90%E5%A4%9A%E5%87%BA%E5%8F%A3%E6%A1%88%E4%BE%8B} 前置条件：\nlinux01上启动hive，hdfs，在linux03上部署3个flume任务，启动hdfs。linux01和linux03配置ssh免密登录。 要求：\nflume1在linux03监听linux01的hive日志，把hive日志的新内容发送给linux03上的flume2和flume3，flume2把内容写到hdfs，flume3把内容写到linux03的本地文件/export/server/flume/job/group1/datas文件夹中。 剧透：\nflume3成功把hive日志的新内容写到datas文件夹，说明linux03确实监听到了linux01 的hive日志并且成功把日志从linux01弄到了linux03，但是flume2却没有把新内容写到hdfs，猜想的可能是因为在linux03上写flume2的配置文件**sinks.k1.hdfs.path = hdfs://linux01:9820/flume/group1/%Y%m%d/%H，**linux01和linux03是不同的服务器，跨服务器没写进去，所以建议在同一台服务器搞。\n在flume/job目录中新建文件夹group1来存放本次案例的任务配置文件\nmkdir group1\ncd group1\nvim flume-file-flume.conf\nvim flume-flume-hdfs.conf\nvim flume-flume-dir.conf\n三个conf配置如下：\nflume-file-flume.conf\n# Name the components on this agent a1.sources = r1 a1.sinks = k1 k2 a1.channels = c1 c2 # 将数据流复制给所有 channel a1.sources.r1.selector.type = replicating # Describe/configure the source a1.sources.r1.type = exec a1.sources.r1.command = ssh root@linux01 'tail -F /export/server/hive/logs/hive.log' #因为hive在linux01，flume在linux03，为了跨服务器监听，这里用了ssh免密登录 a1.sources.r1.shell = /bin/bash -c # Describe the sink # sink 端的 avro 是一个数据发送者 a1.sinks.k1.type = avro a1.sinks.k1.hostname = linux03 a1.sinks.k1.port = 4141 a1.sinks.k2.type = avro a1.sinks.k2.hostname = linux03 a1.sinks.k2.port = 4142 # Describe the channel a1.channels.c1.type = memory a1.channels.c1.capacity = 1000 a1.channels.c1.transactionCapacity = 100 a1.channels.c2.type = memory a1.channels.c2.capacity = 1000 a1.channels.c2.transactionCapacity = 100 # Bind the source and si ","date":"2024-04-28T21:47:38Z","permalink":"/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/","title":"Flume进阶--万字详解【老大爷也能学会】"},{"content":"目录{#main-toc}\n概述{#%E6%A6%82%E8%BF%B0-toc}\n基础架构{#%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84-toc}\nAgent{#Agent-toc}\nSource{#Source-toc}\nSink{#Sink-toc}\nChannel{#Channel-toc}\nselector{#selector%C2%A0-toc}\ninterceptor{#interceptor-toc}\nEvent{#Event-toc}\n安装部署{#%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2-toc}\nNetcat{#Netcat-toc}\nFlume入门案例{#Flume%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B-toc}\n1)netcat本机端口监控{#1)netcat%E6%9C%AC%E6%9C%BA%E7%AB%AF%E5%8F%A3%E7%9B%91%E6%8E%A7-toc}\n2)监控hive日志上传hdfs{#2)%E7%9B%91%E6%8E%A7hive%E6%97%A5%E5%BF%97%E4%B8%8A%E4%BC%A0hdfs-toc}\n3)实时读取目录文件到hdfs{#3)%E5%AE%9E%E6%97%B6%E8%AF%BB%E5%8F%96%E7%9B%AE%E5%BD%95%E6%96%87%E4%BB%B6%E5%88%B0hdfs-toc}\n4)实时监控目录下的多个追加文件{#4)%E5%AE%9E%E6%97%B6%E7%9B%91%E6%8E%A7%E7%9B%AE%E5%BD%95%E4%B8%8B%E7%9A%84%E5%A4%9A%E4%B8%AA%E8%BF%BD%E5%8A%A0%E6%96%87%E4%BB%B6-toc}\n概述 {#%E6%A6%82%E8%BF%B0} Flume 是 Cloudera 提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传 输的系统。Flume 基于流式架构，灵活简单。\n基础架构 {#%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84} Flume运行的核心是 Agent。Flume是以agent为最小的独立运行单位。一个agent就是一个JVM。它是 一个完整的数据收集工具，含有三个核心组件，分别是source、 channel、 sink。通过这些组件， Event 可以从一个地方流向另一个地方。如下图所示：\nAgent Agent 是一个 JVM 进程，它以事件的形式将数据从源头送至目的。 Agent 主要有 3 个部分组成，Source、Channel、Sink。同一台服务器可以运行多个Agent，每个Agent可以有多个source、sink、channel。Agent的名字可以相同但是不能同时启动任务，否则会出现冲突。 Source Source 是负责接收数据到 Flume Agent 并传给Channel的组件。 Source 组件可以处理各种类型、各种格式的日志数据，包括 avro、thrift、exec、jms、spooling directory、netcat、taildir、 sequence generator、syslog、http、legacy这些不同的数据源。 Sink Sink 不断地轮询 Channel 中的事件且批量地移除它们，并将这些事件批量写入到存储系统或索引系统、或者被发送到另一个 Flume Agent。 Sink 组件目的地包括 hdfs、logger、avro、thrift、ipc、file、HBase、solr、自定义。 Channel Channel 是位于 Source 和 Sink 之间的缓冲区。因此，Channel 允许 Source 和 Sink 运作在不同的速率上。 Channel 是线程安全的，可以同时处理几个 Source 的写入操作和几个 Sink 的读取操作。 Flume 自带两种 Channel：Memory Channel 和 File Channel。 Memory Channel 是内存中的队列。Memory Channel 在不需要关心数据丢失的情景下适 用。如果需要关心数据丢失，那么 Memory Channel 就不应该使用，因为程序死亡、机器宕 机或者重启都会导致数据丢失。 File Channel 将所有事件写到磁盘。因此在程序关闭或机器宕机的情况下不会丢失数 据。 selector {#selector%C2%A0} 选择器，作用于source端，然后决定数据发往哪个目标。\ninterceptor 拦截器，flume允许使用拦截器拦截数据。允许使用拦截器链，作用于source和sink阶段。\nEvent 传输单元，Flume 数据传输的基本单元，以 Event 的形式将数据从源头送至目的地。 Event 由 Header 和 Body 两部分组成，Header 用来存放该 event 的一些属性，为 K-V 结构， Body 用来存放该条数据，形式为字节数组。 安装部署 {#%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2} 解压\ntar -zxvf /export/server/apache-flume-1.9.0-bin.tar.gz /export/server/\n为了让flume1.9兼容hadoop3.x，要删除flume lib包下的guava-11.0.2.jar\nrm guava-11.0.2.jar\nNetcat 安装\nsudo yum install -y nc\n简单案例\nFlume入门案例 {#Flume%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B} 1)netcat本机端口监控 {#1)netcat%E6%9C%AC%E6%9C%BA%E7%AB%AF%E5%8F%A3%E7%9B%91%E6%8E%A7} 在flume文件夹下创建工作目录job\nmkdir job\n在job目录下建立任务配置文件，文件名任取，建议见名知意，net表示数据源是端口，logger表示数据是日志文件\nvim net-flume-logger.conf\n配置文件内容如下：\n# Name the components on this agent a1.sources = r1 #a1是该agent名，不可重复 a1.sinks = k1 a1.channels = c1 # Describe/configure the source a1.sources.r1.type = netcat a1.sources.r1.bind = localhost a1.sources.r1.port = 4444 # Describe the sink a1.sinks.k1.type = logger # Use a channel which buffers events in memory a1.channels.c1.type = memory a1.channels.c1.capacity = 1000 #最多接收1000个event a1.channels.c1.transactionCapacity = 100 #100个事务，一次最多发送100个event，事务失败会回滚。capacity应该＜transactionCapacity # Bind the source and sink to ","date":"2024-04-22T15:22:55Z","permalink":"/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/","title":"Flume入门--万字详解"},{"content":"目录{#main-toc}\n概述{#%E6%A6%82%E8%BF%B0-toc}\n特点{#%E7%89%B9%E7%82%B9-toc}\n集群配置{#%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE%C2%A0-toc}\n以下是集群环境搭建！！不是单机环境{#%E4%BB%A5%E4%B8%8B%E6%98%AF%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%EF%BC%81%EF%BC%81%E4%B8%8D%E6%98%AF%E5%8D%95%E6%9C%BA%E7%8E%AF%E5%A2%83-toc}\n集群角色{#%E9%9B%86%E7%BE%A4%E8%A7%92%E8%89%B2-toc}\nLeader{#Leader-toc}\nFollower{#Follower-toc}\nObserver{#Observer-toc}\n会话{#%E4%BC%9A%E8%AF%9D-toc}\nWatcher{#Watcher-toc}\n节点的值变化监听{#%E8%8A%82%E7%82%B9%E7%9A%84%E5%80%BC%E5%8F%98%E5%8C%96%E7%9B%91%E5%90%AC%C2%A0-toc}\n节点的子节点变化监听（路径变化）{#%E8%8A%82%E7%82%B9%E7%9A%84%E5%AD%90%E8%8A%82%E7%82%B9%E5%8F%98%E5%8C%96%E7%9B%91%E5%90%AC%EF%BC%88%E8%B7%AF%E5%BE%84%E5%8F%98%E5%8C%96%EF%BC%89-toc}\n工作机制{#%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6-toc}\n客户端向服务端写数据流程{#%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%90%91%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B-toc}\n写请求发给leader{#%E5%86%99%E8%AF%B7%E6%B1%82%E5%8F%91%E7%BB%99leader-toc}\n写请求发给follower{#%E5%86%99%E8%AF%B7%E6%B1%82%E5%8F%91%E7%BB%99follower-toc}\n客户端向服务端读数据流程{#%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%90%91%E6%9C%8D%E5%8A%A1%E7%AB%AF%E8%AF%BB%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B-toc}\n选举机制{#%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6-toc}\n初次启动{#%E5%88%9D%E6%AC%A1%E5%90%AF%E5%8A%A8-toc}\n非处次启动{#%E9%9D%9E%E5%A4%84%E6%AC%A1%E5%90%AF%E5%8A%A8-toc}\n集群脑裂{#%E9%9B%86%E7%BE%A4%E8%84%91%E8%A3%82-toc}\n数据模型{#%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B-toc}\n节点类型{#%E8%8A%82%E7%82%B9%E7%B1%BB%E5%9E%8B-toc}\n节点信息{#%E8%8A%82%E7%82%B9%E4%BF%A1%E6%81%AF-toc}\n集群操作{#%E9%9B%86%E7%BE%A4%E6%93%8D%E4%BD%9C-toc}\n创建节点{#%E5%88%9B%E5%BB%BA%E8%8A%82%E7%82%B9-toc}\n查看节点{#%E6%9F%A5%E7%9C%8B%E8%8A%82%E7%82%B9%C2%A0-toc}\n查看节点状态{#%E6%9F%A5%E7%9C%8B%E8%8A%82%E7%82%B9%E7%8A%B6%E6%80%81%C2%A0-toc}\n更新节点{#%E6%9B%B4%E6%96%B0%E8%8A%82%E7%82%B9%C2%A0-toc}\n删除节点{#%E5%88%A0%E9%99%A4%E8%8A%82%E7%82%B9-toc}\n退出ZK{#%E9%80%80%E5%87%BAZK%C2%A0-toc}\n应用场景{#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF-toc}\n统一命名服务{#%E7%BB%9F%E4%B8%80%E5%91%BD%E5%90%8D%E6%9C%8D%E5%8A%A1-toc}\n统一配置管理{#%E7%BB%9F%E4%B8%80%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86-toc}\n统一集群管理{#%E7%BB%9F%E4%B8%80%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86-toc}\n服务器动态上下线{#%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%8A%A8%E6%80%81%E4%B8%8A%E4%B8%8B%E7%BA%BF-toc}\n软负载均衡{#%E8%BD%AF%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1-toc}\n分布式锁{#%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81-toc}\n拜占庭将军问题（Paxos算法）{#%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%B0%86%E5%86%9B%E9%97%AE%E9%A2%98%EF%BC%88Paxos%E7%AE%97%E6%B3%95%EF%BC%89-toc}\n算法描述{#%E7%AE%97%E6%B3%95%E6%8F%8F%E8%BF%B0-toc}\n算法流程{#%C2%A0%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B-toc}\nZAB协议{#ZAB%E5%8D%8F%E8%AE%AE-toc}\n崩溃恢复{#%E5%B4%A9%E6%BA%83%E6%81%A2%E5%A4%8D-toc}\n消息广播{#%E6%B6%88%E6%81%AF%E5%B9%BF%E6%92%AD-toc}\n​编辑 CAP理论{#%E2%80%8B%E7%BC%96%E8%BE%91%C2%A0CAP%E7%90%86%E8%AE%BA-toc}\nZK源码图示{#ZK%E6%BA%90%E7%A0%81%E5%9B%BE%E7%A4%BA%C2%A0-toc}\n小小面试题{#%E5%B0%8F%E5%B0%8F%E9%9D%A2%E8%AF%95%E9%A2%98-toc}\n选举机制{#%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6-toc}\n生产集群安装多少 zk 合适？{#%C2%A0%E7%94%9F%E4%BA%A7%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E5%A4%9A%E5%B0%91%20zk%20%E5%90%88%E9%80%82%EF%BC%9F-toc}\n概述 {#%E6%A6%82%E8%BF%B0} ZooKeeper 是一个开源的分布式协调服务 ，它的设计目标是为那些高吞吐的大型分布式系统提供一个高性能、高可用、且具有严格顺序访问控制 能力的分布式协调服务，并以一系列简单易用的接口提供给用户使用。\nZooKeeper 将数据存全量储在内存中以保持高性能 ，并通过服务集群来实现高可用，由于 Zookeeper 的所有更新和删除都是基于事务 的，所以其在读多写少的应用场景中有着很高的性能表现。\n简单来说zookeeper就是动物园管理者，管理协调大数据里面的一堆组件，比如hadoop、hive、habse等等。Zookeeper 可以用于实现分布 式系统中常见的发布/订阅、负载均衡、命令服务、分布式协调/通知、集群管理、Master 选举、分布式 锁和分布式队列等功能。\n特点 {#%E7%89%B9%E7%82%B9} **顺序一致性：**从一个客户端发起的事务请求，最终都会严格按照其发起顺序被应用到 Zookeeper 中； **原子性：**所有事务请求的处理结果在整个集群中所有机器上都是一致的；不存在部分机器应用了该事务，而另一部分没有应用的情况，一次数据更新要么成功要么失败。 **单一视图（全局数据一致）：**每个server保存相同的数据副本，无论client连接哪个server，看到的数据一致； **可靠性：**一旦服务端成功应用了一个事务，则其引起的改变会一直保留，直到被另外一个事务所更改； **实时性：**一旦一个事务被成功应用后，在一定时间范围内，Zookeeper 可以保证客户端立即可以读取到这个事务变更后的最新状态的数据。 集群中只要有半数以上节点存活，zk集群就可以正常服务，所以zk适合安装奇数台。 一个leader，多个follower，leader挂掉之后会从follower中重新选举。 集群配置 {#%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE%C2%A0} 可以由一组 Zookeeper服务构成 Zookeeper 集群，集群中每台机器都会单独在内存中维护自身的状 态，并且每台机器之间都保持着通讯，只要集群中有半数机器能够正常工作，那么整个集群就可以正常提供服务。对于来自客户端的每个更新请求，Zookeeper都会分配一个全局唯一的递增 ID，这个 ID 反映了所有事 务请求的先后顺序。\n以下是集群环境搭建！！不是单机环境 {#%E4%BB%A5%E4%B8%8B%E6%98%AF%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%EF%BC%81%EF%BC%81%E4%B8%8D%E6%98%AF%E5%8D%95%E6%9C%BA%E7%8E%AF%E5%A2%83} 解压、安装、配置环境变量并生效这三步省略，直接修改配置：\n进入conf/目录下，拷贝配置样本并进行修改：\ncp zoo_sample.cfg zoo.cfg\n指定数据存储目录和日志文件目录（此时还没有目录，稍后手动创建），修改后完整配置如下：\ntickTime=2000 #用于计算的基础时间单元。比如 session 超时：N*tickTime； initLimit=10 #用于集群，允许从节点连接并同步到 master 节点的初始化连接时间，以 tickTime 的倍数来表示； syncLimit=5 #用于集群， master 主节点与从节点之间发送消息，请求和应答时间长度（心 跳机制）； dataDir=/export/server/zookeeper/data #数据存储位置；稍后手动创建 dataLogDir=/export/server/zookeeper/logs #日志目录；稍后手动创建 clientPort=2181 #用于客户端连接的端口，默认 2181 # server.1 这个1是服务器的标识，可以是任意有效数字，标识这是第几个服务器节点，这个标识要写到 dataDir目录下面myid文件里，如果没有myid文件要自己创建 # 指名集群间通讯端口和选举端口 server.1=linux01:2888:3888 server.2=linux02:2888:3888 server.3=linux03:2888:3888 标识节点序号\n分别在三台主机的 dataDir 目录下新建 myid 文件,并写入对应的节点标识。Zookeeper 集群通过 myid 文件识别集群节点，并通过上文配置的节点通信端口和选举端口来进行节点通信，选举出 Leader 节点。\n在每个服务器上的/export/server/zookeeper/下创建data目录，在里面创建myid文件并写入各自序号，这个序号必须和zoo.cfg文件的序号相同。 分别在三台主机上启动ZK集群\nzkServer.sh start\n集群验证\nzkServer.sh status\n可以看到一个leader，两个follower，那么zk集群配置成功\n启动客户端\nzkCli.sh\n集群角色 {#%E9%9B%86%E7%BE%A4%E8%A7%92%E8%89%B2} ZK集群有一个leader和多个follower。\nLeader 为客户端提供读写服务，并维护集群状态，它是由集群选举所产生的；\nFollower 为客户端提供读写服务，并定期向 Leader 汇报自己的节点状态。同时也参与写操作 \u0026ldquo;过半写成功\u0026quot;的策略和 Leader 的选举；\nObserver 为客户端提供读写服务，并定期向 Leader 汇报自己的节点状态，但不参与写操作\u0026quot;过 半写成功\u0026quot;的策略和 Leader 的选举，因此 Observer 可以在不影响写性能的情况下提升集群的读性 能。\n会话 {#%E4%BC%9A%E8%AF%9D} Zookeeper 客户端通过 TCP 长连接连接到服务集群，会话 (Session) 从第一次连接开始就已经建立，之 后通过心跳检测机制来保持有效的会话状态。通过这个连接，客户端可以发送请求并接收响应，同时也 可以接收到 Watch 事件的通知。 关于会话中另外一个核心的概念是 sessionTimeOut(会话超时时间)，当由于网络故障或者客户端主动 断开等原因，导致连接断开，此时只要在会话超时时间之内重新建立连接，则之前创建的会话依然有效。 Watcher Zookeeper 中一个常用的功能是 Watcher(事件监听器)，它允许用户在指定节点上针对感兴趣的事件注 册监听，当事件发生时，监听器会被触发，并将事件信息推送到客户端。该机制是Zookeeper 实现分布式协调服务的重要特性。\n节点的值变化监听 {#%E8%8A%82%E7%82%B9%E7%9A%84%E5%80%BC%E5%8F%98%E5%8C%96%E7%9B%91%E5%90%AC%C2%A0} 1）在linux01主机上注册监听/sanguo 节点数据变化\n\\[zk: localhost:2181(CONNECTED) 26\\] get -w /sanguo\n2）在linux02主机上修改/sanguo 节点的数据\n\\[zk: localhost:2181(CONNECTED) 1\\] set /sanguo \u0026ldquo;xisi\u0026rdquo;\n3）观察linux01主机收到数据变化的监听\nWATCHER::\nWatchedEvent state:SyncConnected ype:NodeDataChanged\npath:/sanguo\n注意：在linux02再多次修改/sanguo的值，linux01上不会再收到监听。\u0026lt;\n","date":"2024-04-19T16:43:51Z","permalink":"/zh-cn/post/2024/04/%E5%A4%A7%E6%95%B0%E6%8D%AEzookeeper%E9%9B%86%E7%BE%A4%E5%85%A5%E9%97%A8%E5%8F%8A%E4%BD%BF%E7%94%A8/","title":"大数据—Zookeeper集群入门及使用"},{"content":"目录{#main-toc}\nHA 概述{#HA%20%E6%A6%82%E8%BF%B0-toc}\nHDFS高可用{#HDFS%E9%AB%98%E5%8F%AF%E7%94%A8-toc}\n保证所有NN的数据一致性{#%E4%BF%9D%E8%AF%81%E6%89%80%E6%9C%89NN%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%C2%A0-toc}\n手动模式{#%E6%89%8B%E5%8A%A8%E6%A8%A1%E5%BC%8F-toc}\n自动模式{#%E8%87%AA%E5%8A%A8%E6%A8%A1%E5%BC%8F-toc}\n解决NN连接不上JN的问题{#%E8%A7%A3%E5%86%B3NN%E8%BF%9E%E6%8E%A5%E4%B8%8D%E4%B8%8AJN%E7%9A%84%E9%97%AE%E9%A2%98-toc}\nYarn高可用{#%C2%A0Yarn%E9%AB%98%E5%8F%AF%E7%94%A8-toc}\n核心问题{#%E6%A0%B8%E5%BF%83%E9%97%AE%E9%A2%98-toc}\nHA 概述 {#HA%20%E6%A6%82%E8%BF%B0} 1）所谓 HA（High Availablity），即高可用（7*24 小时不中断服务）。\n2）实现高可用最关键的策略是消除单点故障（传统的主从模式集群单个节点发生故障会影响整个集群）。HA 严格来说应该分成各个组件的 HA 机制：HDFS 的 HA 和 YARN 的 HA。\n3）NameNode 主要在以下两个方面影响 HDFS 集群\nNameNode 机器发生意外，如宕机，集群将无法使用，直到管理员重启 NameNode 机器需要升级，包括软件、硬件升级，此时集群也将无法使用 HDFS HA 功能通过配置多个 NameNode(Active/Standby)实现在集群中对 NameNode 的热备来解决上述问题。如果出现故障，如机器崩溃或机器需要升级维护，这时可以启动另一台机器上的NameNode继续维护整个集群的运行（集群中同时只能有一台active的NN，其他NN处于standby（备用） ）。而这种启动方式分为手动和自动（推荐），但是在这之前，我们必须通过某种方式保证所有NN的元数据一致，这样才能保证active状态的NN故障后，另一个处于standby状态的NN激活为active能够正常维持集群运行，类似于公司员工的任务的交接。 HDFS高可用 {#HDFS%E9%AB%98%E5%8F%AF%E7%94%A8} 保证所有NN的数据一致性 {#%E4%BF%9D%E8%AF%81%E6%89%80%E6%9C%89NN%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%C2%A0} 在处于active的NN正常运行时，他会生成Fsimage文件，让其他处于standby的NN同步，同时引入JournalNode节点来保证edits文件数据的一致性，JournalNode作为active的NN和standby的NN的中间节点，activeNN会把edits发送给JournalNode，然后standbyNN从JournalNode获取edits。同时为了保证JournalNode的可靠性，JournalNode本身也是一个多节点的集群。\nJournalNode 节点会在集群自动的选择一个\u0026quot;主\u0026quot;节点出来，Active 节点会和 JournalNode 的主节点通信，然后 JournalNode 集群的主节点会将数据发送给其他的节点，只要有过半的节点完成了数据的存储（过半写成功），JournalNode 集群的主节点，就会将成功信息返回给 Active 节点。当 JournalNode 集群的主节点挂掉，其他的 JournalNode 节点会快速选举出新的\u0026quot;主\u0026quot;节点来。\n同时在HA架构中，并没有SecondaryNameNode，那么定期合并fsimage的eedits的任务是由standby的NN来完成的。\n手动模式 {#%E6%89%8B%E5%8A%A8%E6%A8%A1%E5%BC%8F} 配置core-site.xml\n\u0026lt;configuration\u0026gt; \u0026lt;!-- 指定hdfs的nameservice为ns1 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;fs.defaultFS\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdfs://mycluster/\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- 指定hadoop临时目录 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hadoop.tmp.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt; 配置hdfs-site.xml\n\u0026lt;configuration\u0026gt; \u0026lt;!--指定hdfs的nameservice为mycluster，需要和core-site.xml中的保持一致 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.nameservices\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;mycluster\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- hadoop-ha下面有两个NameNode，分别是nn1，nn2 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.ha.namenodes.mycluster\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;nn1,nn2,nn3\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- nn1的RPC通信地址 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.rpc-address.mycluster.nn1\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;linux01:8020\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- nn1的http通信地址 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.http-address.mycluster.nn1\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;linux01:9870\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- nn2的RPC通信地址 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.rpc-address.mycluster.nn2\u0026amp; ","date":"2024-04-15T19:23:57Z","permalink":"/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/","title":"HA—Hadoop高可用"},{"content":"目录{#main-toc}\nHadoop简介{#Hadoop%E7%AE%80%E4%BB%8B-toc}\nHadoop 三大发行版本{#Hadoop%20%E4%B8%89%E5%A4%A7%E5%8F%91%E8%A1%8C%E7%89%88%E6%9C%AC-toc}\nHadoop优势{#Hadoop%E4%BC%98%E5%8A%BF-toc}\nHadoop基本组成{#Hadoop%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90-toc}\n常用Shell命令{#%E5%B8%B8%E7%94%A8Shell%E5%91%BD%E4%BB%A4-toc}\nHDFS分布存储{#HDFS%E5%88%86%E5%B8%83%E5%AD%98%E5%82%A8-toc}\nHDFS启停{#HDFS%E5%90%AF%E5%81%9C-toc}\nNameNode（NN）{#NameNode%EF%BC%88NN%EF%BC%89-toc}\nDataNode（DN）{#DataNode%EF%BC%88DN%EF%BC%89-toc}\nSecondaryNameNode（SNN）{#SecondaryNameNode%EF%BC%88SNN%EF%BC%89-toc}\n文件写入流程{#%E6%96%87%E4%BB%B6%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B-toc}\nHDFS架构的稳定性{#HDFS%E6%9E%B6%E6%9E%84%E7%9A%84%E7%A8%B3%E5%AE%9A%E6%80%A7-toc}\n文件读取流程{#%C2%A0%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%B5%81%E7%A8%8B-toc}\n存储方式{#%E5%AD%98%E5%82%A8%E6%96%B9%E5%BC%8F-toc}\nBlock块和多副本{#Block%E5%9D%97%E5%92%8C%E5%A4%9A%E5%89%AF%E6%9C%AC-toc}\nedits和fsimage文件{#edits%E5%92%8Cfsimage%E6%96%87%E4%BB%B6-toc}\n元数据合并及控制参数{#%C2%A0%E5%85%83%E6%95%B0%E6%8D%AE%E5%90%88%E5%B9%B6%E5%8F%8A%E6%8E%A7%E5%88%B6%E5%8F%82%E6%95%B0-toc}\nHDFS漫画{#HDFS%E6%BC%AB%E7%94%BB-toc}\nMapreduce分布式并行计算框架{#Mapreduce%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6-toc}\n计算模式{#%E8%AE%A1%E7%AE%97%E6%A8%A1%E5%BC%8F-toc}\nMap和Reduce{#Map%E5%92%8CReduce-toc}\nMR执行原理{#MR%E6%89%A7%E8%A1%8C%E5%8E%9F%E7%90%86-toc}\nYarn作业调度、资源管理{#Yarn%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6%E3%80%81%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86-toc}\nYarn启停{#Yarn%E5%90%AF%E5%81%9C%C2%A0-toc}\nResourceManager{#ResourceManager-toc}\nNodeManager{#NodeManager%C2%A0-toc}\nApplicationMaster{#ApplicationMaster-toc}\nJobHistoryServer{#JobHistoryServer-toc}\nContainer{#Container-toc}\nHadoop一键启停{#Hadoop%E4%B8%80%E9%94%AE%E5%90%AF%E5%81%9C%C2%A0-toc}\nHadoop简介 {#Hadoop%E7%AE%80%E4%BB%8B} 狭义来说，hadoop是Apache基金会开发的分布式系统基础架构，用来解决海量数据的存储和海量数据的分析计算问题。广义上来说，Hadoop 通常是指一个更广泛的概念 \u0026mdash;\u0026mdash; Hadoop 生态圈。\nHadoop 三大发行版本 {#Hadoop%20%E4%B8%89%E5%A4%A7%E5%8F%91%E8%A1%8C%E7%89%88%E6%9C%AC} Apache、Cloudera、Hortonworks\nApache 版本最原始（最基础）的版本，对于入门学习最好。\nCloudera在大型互联网企业中用的较多。其主要产品有CDH、Cloudera Manager，Cloudera Support\nHadoop优势 {#Hadoop%E4%BC%98%E5%8A%BF} 高可靠性： Hadoop 底层维护多个数据副本，所以即使 Hadoop 某个计算元素或存储出现故障，也不会导致数据的丢失。\n高扩展性： 在集群间分配任务数据，可方便的扩展数以千计的节点。\n高效性： 在 MapReduce 的思想下，Hadoop 是并行工作的，以加快任务处理速度。\n高容错性： 能够自动将失败的任务重新分配。\n**低成本：**Hadoop不要求机器的配置达到极高的标准，大部分普通商用服务器即可满足要求，通过提供多个副本和容错机制提高集群的可靠性\nHadoop基本组成 {#Hadoop%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90} 常用Shell命令 {#%E5%B8%B8%E7%94%A8Shell%E5%91%BD%E4%BB%A4} hdfs dfs -ls \u0026lt;path\u0026gt;：列出指定 HDFS 路径下的文件和目录 hdfs dfs -mkdir \u0026lt;path\u0026gt;：在 HDFS 中创建新目录 hdfs dfs -put \u0026lt;localsrc\u0026gt; \u0026lt;dst\u0026gt;：将本地文件（或目录）复制到 HDFS hdfs dfs -get \u0026lt;src\u0026gt; \u0026lt;localdst\u0026gt;：将 HDFS 上的文件（或目录）复制到本地 hdfs dfs -mv \u0026lt;src\u0026gt; \u0026lt;dst\u0026gt;：移动 HDFS 中的文件目录或重命名文件目录 hdfs dfs -cp \u0026lt;src\u0026gt; \u0026lt;dst\u0026gt;：复制 HDFS 中的文件或目录 hdfs dfs -rm \u0026lt;path\u0026gt;：删除 HDFS 中的文件 hdfs dfs -cat \u0026lt;path\u0026gt;：在控制台显示 HDFS 文件的内容 hdfs dfs -du \u0026lt;path\u0026gt;：显示 HDFS 文件或目录的大小 hdfs dfs -df \u0026lt;path\u0026gt;：显示 HDFS 的可用空间 hdfs fsck path [-files [-blocks [-location]]] -files列出路径内的文件状态 -files -blocks输出文件块报告（几个块，几个副本） -files -blocks -locations 输出每个block的详情 HDFS分布存储 {#HDFS%E5%88%86%E5%B8%83%E5%AD%98%E5%82%A8} HDFS是一个分布式文件系统，具有高容错、高吞吐 量等特性，分布在多个集群节点上的文件系统。有NN、DN、SNN三种角色。\nHDFS启停 {#HDFS%E5%90%AF%E5%81%9C} NameNode（NN） {#NameNode%EF%BC%88NN%EF%BC%89} HDFS的主角色，负责管理每个文件的块所在的 DataNode、整个HDFS文件系统、存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限）等。\nDataNode（DN） {#DataNode%EF%BC%88DN%EF%BC%89} HDFS从角色，负责处理客户端的读写请求，存储删除文件块，以及块数据校验和。\nSecondaryNameNode（SNN） {#SecondaryNameNode%EF%BC%88SNN%EF%BC%89} NN的辅助角色，帮NN打杂，监控 HDFS 状态的辅助后台程序，每隔一段时间获取 HDFS 元数据的快照。\n可通过9870端口（默认9870）访问web界面，查看集群各节点状态及信息\n文件写入流程 {#%E6%96%87%E4%BB%B6%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B} 发送的写入请求通过后，客户端会根据NN返回的信息自动把数据分块，向网络距离最近的DN写入数据。同时，DN会完成备份操作，把备份传到其他的DN，然后由其他的DN再次做备份传播，直到满足设置的备份数量\u0026amp;nb ","date":"2024-04-15T14:38:50Z","permalink":"/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/","title":"Hadoop入门—HDFS、MR、Yarn"},{"content":"目录{#main-toc}\n数据类型{#%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B-toc}\n库操作{#%E5%BA%93%E6%93%8D%E4%BD%9C-toc}\n表操作{#%E8%A1%A8%E6%93%8D%E4%BD%9C-toc}\n数据导入导出{#%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA%C2%A0%C2%A0-toc}\n创建表{#%E5%88%9B%E5%BB%BA%E8%A1%A8-toc}\n临时表{#%E4%B8%B4%E6%97%B6%E8%A1%A8-toc}\n内部表{#%E5%86%85%E9%83%A8%E8%A1%A8-toc}\n外部表{#%E5%A4%96%E9%83%A8%E8%A1%A8-toc}\n内外部表转换{#%E5%86%85%E5%A4%96%E9%83%A8%E8%A1%A8%E8%BD%AC%E6%8D%A2-toc}\n分区表{#%E5%88%86%E5%8C%BA%E8%A1%A8-toc}\n分桶表{#%E5%88%86%E6%A1%B6%E8%A1%A8-toc}\n查询表{#%E6%9F%A5%E8%AF%A2%E8%A1%A8-toc}\nJOIN{#JOIN-toc}\n修改表{#%E4%BF%AE%E6%94%B9%E8%A1%A8-toc}\n删除表{#%E5%88%A0%E9%99%A4%E8%A1%A8-toc}\n清空表{#%E6%B8%85%E7%A9%BA%E8%A1%A8-toc}\n特例-update和delete{#%E7%89%B9%E4%BE%8B-update%E5%92%8Cdelete%C2%A0-toc}\n视图{#%E8%A7%86%E5%9B%BE-toc}\n视图增删改{#%E8%A7%86%E5%9B%BE%E5%A2%9E%E5%88%A0%E6%94%B9%C2%A0-toc}\n索引{#%E7%B4%A2%E5%BC%95-toc}\n索引原理{#%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86-toc}\n索引增删改{#%E7%B4%A2%E5%BC%95%E5%A2%9E%E5%88%A0%E6%94%B9%C2%A0-toc}\n设置自动使用索引{#%E8%AE%BE%E7%BD%AE%E8%87%AA%E5%8A%A8%E4%BD%BF%E7%94%A8%E7%B4%A2%E5%BC%95-toc}\n索引缺陷{#%C2%A0%E7%B4%A2%E5%BC%95%E7%BC%BA%E9%99%B7-toc}\n数据类型 {#%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B} decimal 类型：\ndecimal(11,2) 代表最多有 11 位数字，其中后 2 位是小数，整数部分是 9位；如果整数部分超过 9 位，则这个字段就会变成 null；如果小数部分不足 2 位， 则后面用 0 补齐两位，如果小数部分超过两位，则超出部分四舍五入。也可直接写 decimal，后面不指定位数，默认是 decimal(10,0) 整数 10 位，没有小数 map类型：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 zhangsan chinese:90,math:87,english:63,nature:76 lisi chinese:60,math:30,english:78,nature:0 wangwu chinese:89,math:25 create table if not exists map1( name string, score map\u0026lt;string,int\u0026gt;) row format delimited fields terminated by \u0026#39;\\t\u0026#39; collection items terminated by \u0026#39;,\u0026#39; map keys terminated by \u0026#39;:\u0026#39;; load data local inpath \u0026#39;./data/map1.txt\u0026#39; into table map1; #查询数学⼤于35分的学⽣的英语和⾃然成绩： select m.name,m.score[\u0026#39;english\u0026#39;] ,m.score[\u0026#39;nature\u0026#39;] from map1 m where m.score[\u0026#39;math\u0026#39;] \u0026gt; 35; #查看每个⼈的前两科的成绩总和 select m.name,m.score[\u0026#39;chinese\u0026#39;]+m.score[\u0026#39;math\u0026#39;] from map1 m; struct类型：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 zhangsan 90,87,63,76 lisi 60,30,78,0 wangwu 89,25,81,9 create table if not exists struct1( name string, score struct\u0026lt;chinese:int,math:int,english:int,natrue:int\u0026gt; ) row format delimited fields terminated by \u0026#39;\\t\u0026#39; collection items terminated by \u0026#39;,\u0026#39;; 导⼊数据： load data local inpath \u0026#39;./data/arr1.txt\u0026#39; into table struct1; select name,score.english,score.chinese from str2 where score.math \u0026gt; 35; array类型：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 zhangsan 78,89,92,96 lisi 67,75,83,94 王五 23,12 create table if not exists arr1( name string, scores array\u0026lt;string\u0026gt; ) row format delimited fields terminated by \u0026#39;\\t\u0026#39; collection items terminated by \u0026#39;,\u0026#39;; load data local inpath \u0026#39;/data/arr1.txt\u0026#39; into table arr1; select * from arr1; #结果 +--------+---------------+ |name |scores | +--------+---------------+ |zhangsan|[\u0026#34;78,89,92,96\u0026#34;]| |lisi |[\u0026#34;67,75,83,94\u0026#34;]| |王五 |[\u0026#34;23,12\u0026#34;] | +--------+---------------+ 库操作 {#%E5%BA%93%E6%93%8D%E4%BD%9C} 创建库\n1 2 3 4 CREATE DATABASE [IF NOT EXISTS] database_name [COMMENT database_comment] [LOCATION hdfs_path] [WITH DBPROPERTIES (property_name=property_value, ...)]; 查询库\n1 2 3 SHOW DATABASES [LIKE \u0026#39;identifier_with_wildcards\u0026#39;]; #注：like通配表达式说明：*表示任意个任意字符，|表示或的关系。 查看数据库信息\n1 DESCRIBE DATABASE [EXTENDED] db_name; 修改数据库\n1 2 3 4 5 6 7 8 9 10 11 12 13 用户可以使用alter database命令修改数据库某些信息，其中能够修改的信息包括dbproperties、location、owner user。需要注意的是：修改数据库location，不会改变当前已有表的路径信息，而只是改变后续创建的新表的默认的父目录。 --修改dbproperties ALTER DATABASE database_name SET DBPROPERTIES (property_name=property_value, ...); --修改location ALTER DATABASE database_name SET LOCATION hdfs_path; --修改owner user ALTER DATABASE database_name SET OWNER USER user_name; 删除数据库\n1 2 3 4 5 DROP DATABASE [IF EXISTS] database_name [RESTRICT|CASCADE]; RESTRICT：严格模式，若数据库不为空，则会删除失败，默认为该模式。 CASCADE：级联模式，若数据库不为空，则会将库中的表一并删除。 切换当前数据库\n1 USE database_name; 表操作 {#%E8%A1%A8%E6%93%8D%E4%BD%9C} 表有临时表、外部表、内部表（管理表）、分区表，分桶表\nLinux上传文件到hdfs上\nhdfs dfs -put student.txt 基于其他表的结构建表\ncreate table teacher2 like teacher; ","date":"2024-04-14T21:41:05Z","permalink":"/zh-cn/post/2024/04/hive%E5%85%A5%E9%97%A8-hql%E8%A1%A8%E6%93%8D%E4%BD%9C%E5%BA%93%E6%93%8D%E4%BD%9C%E8%A7%86%E5%9B%BE%E7%B4%A2%E5%BC%95%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","title":"Hive入门-HQL、表操作、库操作、视图、索引、数据类型"},{"content":"目录{#main-toc}\nHive本质{#Hive%E6%9C%AC%E8%B4%A8-toc}\nHive主要有以下3个模块{#Hive%E4%B8%BB%E8%A6%81%E6%9C%89%E4%BB%A5%E4%B8%8B3%E4%B8%AA%E6%A8%A1%E5%9D%97-toc}\nMetastore{#Metastore-toc}\n架构{#%E6%9E%B6%E6%9E%84%C2%A0-toc}\nHive日志配置{#Hive%E6%97%A5%E5%BF%97%E9%85%8D%E7%BD%AE-toc}\nHQL执行过程{#HQL%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B-toc}\nHive四种玩法：{#Hive%E5%9B%9B%E7%A7%8D%E7%8E%A9%E6%B3%95%EF%BC%9A-toc}\n1）CLI{#1%EF%BC%89CLI-toc}\n2）HiveServer2{#2%EF%BC%89HiveServer2-toc}\n3）Beeline{#3%EF%BC%89Beeline-toc}\n4）Web UI{#4%EF%BC%89Web%20UI-toc}\nHive 本质 {#Hive%E6%9C%AC%E8%B4%A8} Hive是构建在hadoop上的数据仓库，也可以说是一个操作hdfs文件 的客户端，它可以将结构化的数据文件映射成表，并提供类 SQL查询功能，用于查询的 SQL 语句会被转化为 MapReduce 作业，然后提交到 Hadoop 上运行。Hive执行引擎可以是MapReduce、Spark、Tez，如果是MR，Hive就会把HQL翻译成MR进行数据计算。\n由于Hive是针对数据仓库应⽤设计的，⽽数据仓库的内容是读多写少的。因此，Hive中不⽀持 对数据的改写和添加，所有的数据都是在加载的时候中确定好的。\nHive不适合⽤于联机事务处理(OLTP)，也不提供实时查询功能。它最适合应⽤在基于⼤量不可变数据的批处理 作业。Hive 的特点是可伸缩（在Hadoop 的集群上动态的添加设备），可扩展、容错、输⼊格式的松散耦合。 Hive 的⼊⼝是DRIVER ，执⾏的SQL语句⾸先提交到DRIVER驱动，然后调COMPILER解释驱动，最终解释成 MapReduce 任务执⾏，最后将结果返回。\n优点：\n简单、容易上手 (提供了类似 sql 的查询语言 hql)，使得精通 sql 但是不了解 Java 编程的人也能很 好地进行大数据分析；\n灵活性高，可以自定义用户函数 (UDF) 和存储格式；\n为超大的数据集设计的计算和存储能力，集群扩展容易;\n4.统一的元数据管理，可与 presto／impala／sparksql 等共享数据；\n执行延迟高，不适合做数据的实时处理，但适合做海量数据的离线处理。 Hive主要有以下3个模块 {#Hive%E4%B8%BB%E8%A6%81%E6%9C%89%E4%BB%A5%E4%B8%8B3%E4%B8%AA%E6%A8%A1%E5%9D%97} **⽤户接⼝模块：**含CLI、HWI、JDBC、Thrift Server等，⽤来实现对Hive的访问。CLI是Hive⾃带 的命令⾏界⾯；HWI是Hive的⼀个简单⽹⻚界⾯；JDBC、ODBC以及Thrift Server可向⽤户提供进 ⾏编程的接⼝，其中Thrift Server是基于Thrift软件框架开发的，提供Hi ","date":"2024-04-14T12:23:06Z","permalink":"/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/","title":"Hive本质、架构、玩法"},{"content":"目录{#main-toc}\nYarn和MR资源配置{#Yarn%E5%92%8CMR%E8%B5%84%E6%BA%90%E9%85%8D%E7%BD%AE-toc}\nYarn资源配置{#Yarn%E8%B5%84%E6%BA%90%E9%85%8D%E7%BD%AE-toc}\nMR资源配置{#MR%E8%B5%84%E6%BA%90%E9%85%8D%E7%BD%AE-toc}\nExplain查看执行计划{#Explain%E6%9F%A5%E7%9C%8B%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92-toc}\n分组聚合优化{#%E5%88%86%E7%BB%84%E8%81%9A%E5%90%88%E4%BC%98%E5%8C%96-toc}\n优化前VS优化后{#%E4%BC%98%E5%8C%96%E5%89%8DVS%E4%BC%98%E5%8C%96%E5%90%8E-toc}\nJoin优化{#Join%E4%BC%98%E5%8C%96-toc}\nCommon Join（普通join）{#Common%20Join%EF%BC%88%E6%99%AE%E9%80%9Ajoin%EF%BC%89-toc}\n原理{#%E5%8E%9F%E7%90%86-toc}\nMap Join{#Map%20Join-toc}\n原理{#%E5%8E%9F%E7%90%86-toc}\n优化{#%E4%BC%98%E5%8C%96%C2%A0-toc}\n法一：hint提示{#%E6%B3%95%E4%B8%80%EF%BC%9Ahint%E6%8F%90%E7%A4%BA-toc}\n法二：自动触发{#%E6%B3%95%E4%BA%8C%EF%BC%9A%E8%87%AA%E5%8A%A8%E8%A7%A6%E5%8F%91-toc}\n优化案例{#%C2%A0%E4%BC%98%E5%8C%96%E6%A1%88%E4%BE%8B-toc}\nBucket Map Join{#Bucket%20Map%20Join-toc}\n原理{#%E5%8E%9F%E7%90%86-toc}\n优化{#%E4%BC%98%E5%8C%96-toc}\nhint提示{#hint%E6%8F%90%E7%A4%BA%C2%A0-toc}\n优化案例{#%C2%A0%E4%BC%98%E5%8C%96%E6%A1%88%E4%BE%8B-toc}\nSort Merge Bucket Map Join(SMB map join){#Sort%20Merge%20Bucket%20Map%20Join(SMB%20map%20join)-toc}\n原理{#%E5%8E%9F%E7%90%86-toc}\n优化{#%E4%BC%98%E5%8C%96-toc}\n数据倾斜优化{#%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E4%BC%98%E5%8C%96-toc}\n分组聚合导致的数据倾斜{#%E5%88%86%E7%BB%84%E8%81%9A%E5%90%88%E5%AF%BC%E8%87%B4%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C-toc}\nMap-Side聚合{#Map-Side%E8%81%9A%E5%90%88-toc}\nSkew-GroupBy优化{#Skew-GroupBy%E4%BC%98%E5%8C%96-toc}\n优化前{#%E4%BC%98%E5%8C%96%E5%89%8D-toc}\n优化后{#%E4%BC%98%E5%8C%96%E5%90%8E%C2%A0-toc}\nJoin导致的数据倾斜{#Join%E5%AF%BC%E8%87%B4%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C-toc}\nmap join{#map%20join-toc}\nskew join{#skew%20join-toc}\n任务并行度优化{#%E4%BB%BB%E5%8A%A1%E5%B9%B6%E8%A1%8C%E5%BA%A6%E4%BC%98%E5%8C%96-toc}\nMap端并行度{#Map%E7%AB%AF%E5%B9%B6%E8%A1%8C%E5%BA%A6-toc}\nReduce端并行度{#Reduce%E7%AB%AF%E5%B9%B6%E8%A1%8C%E5%BA%A6-toc}\n小文件合并优化{#%E5%B0%8F%E6%96%87%E4%BB%B6%E5%90%88%E5%B9%B6%E4%BC%98%E5%8C%96-toc}\n合并Map端输入的小文件{#%E5%90%88%E5%B9%B6Map%E7%AB%AF%E8%BE%93%E5%85%A5%E7%9A%84%E5%B0%8F%E6%96%87%E4%BB%B6-toc}\n合并Reduce端输出的小文件{#%E5%90%88%E5%B9%B6Reduce%E7%AB%AF%E8%BE%93%E5%87%BA%E7%9A%84%E5%B0%8F%E6%96%87%E4%BB%B6-toc}\n其他优化{#%E5%85%B6%E4%BB%96%E4%BC%98%E5%8C%96-toc}\nCBO优化{#CBO%E4%BC%98%E5%8C%96-toc}\n谓词下推{#%E8%B0%93%E8%AF%8D%E4%B8%8B%E6%8E%A8-toc}\n矢量化查询{#%E7%9F%A2%E9%87%8F%E5%8C%96%E6%9F%A5%E8%AF%A2-toc}\nFetch抓取{#Fetch%E6%8A%93%E5%8F%96-toc}\n本地模式{#%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%BC%8F-toc}\n并行执行{#%E5%B9%B6%E8%A1%8C%E6%89%A7%E8%A1%8C-toc}\n严格模式{#%E4%B8%A5%E6%A0%BC%E6%A8%A1%E5%BC%8F-toc}\nYarn和MR资源配置 {#Yarn%E5%92%8CMR%E8%B5%84%E6%BA%90%E9%85%8D%E7%BD%AE} 配置项参考官网：https://apache.github.io/hadoop/\nYarn资源配置 {#Yarn%E8%B5%84%E6%BA%90%E9%85%8D%E7%BD%AE} 修改yarn-site.xml,调整的Yarn参数均与CPU、内存等资源有关，配置如下：\n\u0026lt;property\u0026gt;\n\u0026lt;name\u0026gt;yarn.nodemanager.resource.memory-mb\u0026lt;/name\u0026gt;\n\u0026lt;value\u0026gt;65536\u0026lt;/value\u0026gt;\n\u0026lt;description\u0026gt;一个NodeManager节点分配给Container使用的内存。该参数的配置，取决于NodeManager所在节点的总内存容量和该节点运行的其他服务的数量\u0026lt;/description\u0026gt;\n\u0026lt;/property\u0026gt;\n\u0026lt;property\u0026gt;\n\u0026lt;name\u0026gt;yarn.nodemanager.resource.cpu-vcores\u0026lt;/name\u0026gt;\n\u0026lt;value\u0026gt;16\u0026lt;/value\u0026gt;\n\u0026lt;description\u0026gt;一个NodeManager节点分配给Container使用的CPU核数。该参数的配置，同样取决于NodeManager所在节点的总CPU核数和该节点运行的其他服务。\u0026lt;/description\u0026gt;\n\u0026lt;/property\u0026gt;\n\u0026lt;property\u0026gt;\n\u0026lt;name\u0026gt;yarn.scheduler.maximum-allocation-mb\u0026lt;/name\u0026gt;\n\u0026lt;value\u0026gt;16384\u0026lt;/value\u0026gt;\n\u0026lt;description\u0026gt;单个Container能够使用的最大内存。\u0026lt;/description\u0026gt;\n\u0026lt;/property\u0026gt;\n\u0026lt;property\u0026gt;\n\u0026lt;name\u0026gt;yarn.scheduler.minimum-allocation-mb\u0026lt;/name\u0026gt;\n\u0026lt;value\u0026gt;512\u0026lt;/value\u0026gt;\n\u0026lt;description\u0026gt;单个Container能够使用的最小内存。\u0026lt;/description\u0026gt;\n\u0026lt;/property\u0026gt;\n修改后重新分发该配置文件并重启Yarn\nMR资源配置 {#MR%E8%B5%84%E6%BA%90%E9%85%8D%E7%BD%AE} MapReduce资源配置主要包括Map Task的内存和CPU核数，以及Reduce Task的内存和CPU核数。核心配置参数如下：\n1{#_Hlk110418691}） mapreduce.map.memory.mb\n该参数的含义是，单个Map Task申请的container容器内存大小，其默认值为1024。该值不能超出yarn.scheduler.maximum-allocation-mb和yarn.scheduler.minimum-allocation-mb规定的范围。\n该参数需要根据不同的计算任务单独进行配置，在hive中，可直接使用如下方式为每个SQL语句单独进行配置：set mapreduce.map.memory.mb=2048;\n2 ） mapreduce.map.cpu.vcores\n该参数的含义是，单个Map Task申请的container容器cpu核数，其默认值为1。该值一般无需调整。如需调整要修改mapred-site.xml文件（mapred-default.xml）\n3） mapreduce.reduce.cpu.vcores\n该参数的含义是，单个Reduce Task申请的container容器cpu核数，其默认值为1。该值一般无需调整。如需调整要修改mapred-site.xml文件（mapred-default.xml）\n4）mapreduce.reduce.memory.mb\n该参数的含义是，单个Reduce Task申请的container容器内存大小，其默认值为1024。该值同样不能超出yarn.scheduler.maximum-allocation-mb和yarn.scheduler.minimum-allocation-mb规定的范围。\n该参数需要根据不同的计算任务单独进行配置，在hive中，可直接使用如下方式为每个SQL语句单独进行配置：set mapreduce.reduce.memory.mb=2048;\nExplain查看执行计划 {#Explain%E6%9F%A5%E7%9C%8B%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92} Explain用于呈现HQL语句的详细执行步骤，由一系列Stage组成，简单的理解为HQL查询语句的不同执行阶段，这一系列Stage具有依赖关系，每个Stage对应一个MapReduce Job或一个文件系统操作等。\n若某个Stage对应的一个MapReduce Job，则其Map端和Reduce端的计算逻辑分别由Map Operator Tree和Reduce Operator Tree进行描述，Operator Tree由一系列的Operator组成，一个Operator代表在Map或Reduce阶段的一个单一的逻辑操作，例如TableScan Operator，Select Operator，Join Operator等。具体如下图：\n常见的Operator及其作用如下\nTableScan：表扫描操作，通常map端第一个操作肯定是表扫描操作\nSelect Operator：选取操作\nGroup By Operator：map端的分组聚合操作，在后面的分组聚合中会讲到\nReduce Output Operator：输出到 reduce 操作\nFilter Operator：过滤操作\nJoin Operator：join 操作\nFile Output Operator：文件输出操作\nFetch Operator 客户端获取数据操作 Explain语法\nEXPLAIN \\[FORMATTED \\| EXTENDED \\| DEPENDENCY\\] query-sql\nFORMATTED：将执行计划以JSON字符串的形式输出 EXTENDED：输出执行计划中的额外信息，通常是读写的文件名等信息 DEPENDENCY：输出执行计划读取的表及分区 例：\nhive (default)\u0026gt;\nexplain formatted\nselect user_id,count(*) from order_detail group by user_id;\n分组聚合优化 {#%E5%88%86%E7%BB%84%E8%81%9A%E5%90%88%E4%BC%98%E5%8C%96} 分组聚合是通过MR Job实现的，map端读取数据，并按照分组字段分区，通过shuffle，把数据发到reduce，各组数据在reduce端完成最终的聚合运算。\n分组聚合的优化主要围绕减少shuffle数据量进行，具体做法是map-side聚合。map-side聚合是在map端维护一个hash table，先利用其完成数据的部分聚合，再把聚合的结果按照分组字段分区，发到reduce端完成最终聚合，以此提高分组聚合运算效率。简而言之就是增加了一个map端的部分聚合过程，以减少shuffle的工作量，进而减少reduce端的聚合工作量。\nmap-side聚合相关参数如下\n\u0026ndash;启用map-side聚合，默认是true\nset hive.map.aggr=true;\n\u0026ndash;用于检测源表数据是否适合进行map-side聚合。检测的方法是：系统自动先对若干条数据进行map-side聚合，若聚合后的条数和聚合前的条数比值小于该值，则认为该表适合进行map-side聚合；否则，认为该表数据不适合进行map-side聚合，后续数据便不再进行map-side聚合。0.5意味着平均有2条数据可以聚合成1条，1意味着没有出现任何的聚合\nset hive.map.aggr.hash.min.reduction=0.5;\n\u0026ndash;用于hive.map.aggr.hash.min.reduction=0.5 检测源表是否适合map-side聚合的条数。\nset hive.groupby.mapaggr.checkinterval=100000;\n\u0026ndash;map-side聚合所用的hash table占用map task堆内存的最大比例，若超出该值，则会对hash table进行一次flush。\nset hive.map.aggr.hash.force.flush.memory.threshold=0.7;\n优化前VS优化后 {#%E4%BC%98%E5%8C%96%E5%89%8DVS%E4%BC%98%E5%8C%96%E5%90%8E} set hive.map.aggr=false关闭分组聚合优化，查看执行效果，在Map端没有了Group By Operator\nset hive.map.aggr=true开启分组聚合优化，查看执行效果，在Map端有了Group By Operator，\n若发生map-side优化，优化后比优化前的HQL执行耗时应该有所减少，且map的output数量明显小于input数量。\n若没有触发map-side，则map的output数量虽然比input数量有所减少但可以忽略不计。具体有没有触发map-side可以去web UI界面查看map日志。\n注意！！map-side聚合不够智能，即map端的分组聚合是否执行一定程度上会受到分组字段在表中存储的位置和分布的影响，这是底层存储问题，未必是因为数据真的不适合分组聚合。要解决此问题可以提前对数据分区分桶，使用分区分桶表，使得同一区域存储的数据分布具有一定的相似性，这样聚合结果会有所提升。\n例：\n1）select province_id,count(*) from order_detail group by province_id;\n该语句查询所有订单，根据省份id分组聚合，省份只有34个，这样map后的数据应该只有34条，所以聚合结果是应该是比较可观的。所以group by 的基数越小，一般越适合聚合。\n2）select product_id,count(*) from order_detail group by product_id;\n若product_id这一分组字段在order_detail表中分布比较散，那么可能会导致hive在表中切片抽样进行map-side检测的时候测试聚合结果\u0026gt;0.5，那么最终就没有使用map-side聚合。所以说如果能保证抽样数据的测试结果\u0026lt;=0.5，就会实现分组聚合，当然也可以调整hive.map.aggr.hash.min.reduction 的值以提高map-side的命中率。\n若100w 的数据集分组聚合之后的输出 \u0026gt;100w, 可能的原因是多次触发了 hash table 的 flush\nJoin优化 {#Join%E4%BC%98%E5%8C%96} Join优化就是控制HQL语句走哪种join算法，这些join算法有的快，有的慢，有的激进，有的保守。我们要做的就是让HQL走最适合自己的join算法。\nCommon Join（普通join） {#Common%20Join%EF%BC%88%E6%99%AE%E9%80%9Ajoin%EF%BC%89} 原理 {#%E5%8E%9F%E7%90%86} hive中最稳定的join算法，其通过一个MapReduce Job完成一个join操作。Map端负责读取join操作所需表的数据，并按照关联字段进行分区，通过Shuffle，将其发送到Reduce端，相同key的数据在Reduce端完成最终的Join操作。\n需要注意 的是，HQL语句中的join操作和执行计划中的Common Join任务并非一对一的关系，即HQL中的A表 ","date":"2024-04-13T20:49:38Z","permalink":"/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/","title":"Hive调优"},{"content":"1.修饰变量 1.1.const int* p int n=10; int m=20; const int* p=\u0026amp;m; //此时const修饰 *p，也就是p保存的地址里面的值不能改变，若*p=60，则会报错 但是可以改变p存放的地址： p=\u0026amp;n; printf(\u0026quot;%d\u0026quot;,*p);//打印结果是10 1.2. int* const p int n=10; int m=20; int* const p=\u0026amp;n; //此时const只修饰p，也就是p的值只能为\u0026amp;n，无法修改，若p=\u0026amp;m 会报错 但是可以改变*p的值： *p=60; //虽然p存放的\u0026amp;n无法修改，但是*p得到的n的值可以修改为60 printf(\u0026quot;*p=%d,n=\u0026quot;,*p,n);//打印结果为60，60 2.修饰函数 2.1.修饰函数的形参 void StringCopy(char* dest, const char* src); 这个字符串copy函数中，把src指向的字符串复制到dest中，也就是src的值是不需要改变的，而dest指针指向的值改变。对*src加上const后就可以防止其中的值被修改，起到保护作用。\n而起到保护作呕也能够的原因是：\n在实参中，指针会指向一段内存地址，调用函数之后，函数会产生一个临时指针变量，这个临时指针变量的地址与实参的地址不同，但却指向同一块空间地址。那么**形参加上const 修饰之后，保护了这一块内存地址不被修改，如果刻意修改这一块内存，编译器会报错。当然，如果使用c++中的引用，效率会比指针更高，因为引用本身是一个变量，而这个变量仅仅是另外一个变量的别名，它不是指针，不占用内存空间，不会产生临时指针变量，并且不存在NULL空引用，无需assert，比指针更安全。**同时，理论上指针的级数没有限制;但引用只有一级。\n即不存在引用的引用，但可以有指针的指针。\n2.2.修饰函数的返回值 如果用const修饰返回值类型为指针，那么函数返回值（即指针）的内容不能被修改，该返回值只能被赋给加const 修饰的同类型指针。\nconst char * GetString(void); //const修饰的函数返回值类型是char* 那么：\nchar *str = GetString();//报错，没有const修饰 const char *str = GetString();//正确 --- ","date":"2023-08-04T22:32:09Z","permalink":"/zh-cn/post/2023/08/const%E4%BD%BF%E7%94%A8%E5%8F%8A%E6%84%8F%E4%B9%89-----const-int-p%E5%92%8Cint-const-p/","title":"const使用及意义-----const int* p和int* const p"},{"content":"引导图 正文 1.数组指针 先不讨论什么是数组指针，举个例子\n1 2 3 4 5 int* p1; //p1是整型指针，它指向的是整型，指针类型是int* char* p2; //p2是字符指针，它指向的是字符，指针类型是char* 注意！！！为什么我写成了int* p1而不是int *p1，其实两种写法都可以，只不过为了方便理解，把int*看成一种类似于int，char，float的变量类型，同理char*也是如此，后文不再阐述。\nSo数组指针就是指向数组的指针！\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 int arr[5]={1,2,3,4,5}; //数组名arr相当于数组首元素arr[0]的地址,+1跨越了一个数组元素 //但是有一个例外，sizeof(数组名)计算的是整个数组的大小，而非一个数组元素的大小 //\u0026amp;arr才是数组真正的地址，+1跨越了一个数组 int (*parr)[5];//取数组地址\u0026amp;arr赋给数组指针parr //因为*parr是带括号的！！所以*parr一体，所以把*parr拿掉，剩下int [5]，左边表示元素类型int，右边表示元素个数[5]，这就是数组指针的本质。 //具体如何理解呢？ //因为原数组arr有5个元素，所以数组指针parr指向的数组元素个数也得为5，写作[5], 就好比5个人乘车，车上必须有5个座位，如果有4个，总不能一个人坐车顶吧。 //而且，原数组arr元素皆为int，所以数组指针为int型， 那么在上句的基础上写作int [5]，最后再加上(*parr),就有了int (*parr)[5]。 当然，若原数组arr元素为int*,那么数组指针写成int* (*parr)[5]; 记住，它只是一个数组指针，只负责指向一个数组，至于数组的元素类型是int还是int*，元素个数是\n\\[5\\]还是\n\\[6\\],都是它所指向的数组决定的，而非指针决定，以下所有内容均可这样理解。至于为何写成（*parr）而不是*parr，这和符号优先级有关，看完下文的\u0026quot;指针数组\u0026quot;就明白了~\n1.1.数组指针作为形参接收二维数组 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 void test1(int arr[][3]) {函数体} void test2(int (*parr)[3]) { for(int i=0;i\u0026lt;2;i++) {\tfor(int j=0;j\u0026lt;3;j++) { printf(\u0026#34;%d \u0026#34;,*(*(parr+i)+j)); } printf(\u0026#34;\\n\u0026#34;); } void test3(int* arr) {函数体} void test4(int* arr[3]) {函数体} void test5(int** arr) {函数体} int main() { int arr[2][3]={{9，8，7},{6，5，4}}; test1(arr); //√ test2(arr); //√ test3(arr); //× test4(arr); //× test5(arr); //× } test1中，二维数组作形参接收二维数组参数，没毛病；在test2中，首先要说明的是，二维数组作为参数传参，传过去的是二维数组的第一行的地址（看个人理解），也就是parr里面放的是{9，8，7}这个一维数组的地址。我们让其+i就是第i行的地址，然后*（parr+i），把第i行的地址取出来，再+j，此时得到第i行的第j个元素的地址(*(parr+i)+j)，再对其解引用*(*(parr+i)+j)得到第i行第j个元素的值。至于test3，形参是整型指针，而实参是一个一维数组的地址，要用数组指针接收才行，错。test4，形参是整型指针数组，用来接收整型指针，而我们的实参是一维数组地址，驴唇不对马嘴，pass。test5，形参是二级指针，用来接收一级指针变量的地址或者二级指针，同样驴唇不对马嘴，pass。\n2.指针数组 同上，先不讨论什么是指针数组，举个例子\n1 2 3 4 5 int arr1[5]={1,2,3,4,5}; //这是 整型 数组，存放整型元素 char arr2[5]={\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;,\u0026#39;d\u0026#39;,\u0026#39;e\u0026#39;}; //这是 字符 数组，存放字符型元素 So指针数组就是存放指针的数组！\n1 2 3 4 5 6 7 8 9 10 11 12 13 int arr[5]={1,2,3,4,5}; int* p; int m; char* k; int* parr[3]={arr,p,\u0026amp;m}; //* parr没有带括号！！那么只把parr拿掉，只剩int* [3],和数组指针一样，左边表示元素类型int*，右边表示元素个数[3],这是指针数组的本质。 //当然还可以写成int* [4],只要≥3就行，因为parr至少要存放3个元素 //注意！！！ k是字符型指针，无法存放到整型指针数组中 //如何理解？ //首先，arr和\u0026amp;m是地址，p是指针，一共3个元素全放到指针数组parr里，就有了元素个数[3] //其次，arr和\u0026amp;m以及p都是int*(注意，m是int，\u0026amp;m取了地址就是int*，而arr本身就是地址)，所以指针数组元素类型为int*，于是有了int* [3],数组取名为parr 没错，只要是int*类型的都可以放到数组parr里，因为parr就是存放整型指针的数组。\n不用管数组arr里面几个元素，我们已经在parr里面放了数组arr的首元素地址，那么就可以借此访问数组arr的所有元素。\n3.指向指针数组的数组指针 顾名思义，这是一个数组指针，只不过它指向的是指针数组，而这个数组里面存放的是指针。\n它长个什么样呢？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 //6个指针数组的元素 int *p0,*p1,*p2; int p3，p4; int p5[]={7,8,9，10}; //2个指针数组 int *pa[3]={p0,\u0026amp;p3,p5}; int *pb[3]={p1,p2 ,\u0026amp;p4}; //OK,接下来我要用 数组指针 指着这俩 指针数组 ~ int* (pc[2])[3]={pa,pb};//pc就是指向指针数组的数组指针 //如何理解呢？ //首先pc[2]带了括号，那就把pc[2]拿掉，剩下int* [3],这不就是个指针数组吗？左边元素类型int*，右边数组元素个数[3]. //当然可以写成int* [4],总之\u0026gt;=3就行，因为数组pa和pb元素个数都为3，至少得放得下3个 //如果再加上pc[2]，那就是说明我有俩指针pc[0]和pc[1],分别指向两个数组pa和pb，pa和pb各有3个元素 //当然pc[2]可以写成pc[3],只要\u0026gt;=2就行，因为数组指针pc至少要指向2个指针数组pa和pb 4.存放数组指针的指针数组 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 //2个数组 int p1[3]={4,5,6}; int p5[3]={7,8,9}; //2个数组指针 int (*pa)[3]=p1; int (*pb)[3]=p5; //1个指针数组存放2个数组指针 int* (pc[2])[3]={pa,pb};//pc就是存放数组指针的指针数组 //如何理解？ //老规矩，pc[2]带了括号，是一体的，把pc[2]拿掉，剩下int* [3], //左边就是元素类型int*，右边是数组指针指向的数组的元素个数[3]， //当然还可以写成int* [4],总之\u0026gt;=3就行，因为数组p1和p5最多3个元素，至少得放得下3个； //同理pc[2]可以写成pc[3]，\u0026gt;=2就行，因为至少要存放2个数组指针pa和pb。 5.函数指针 5.1.函数指针作形参接收参数 先看看这个qsort函数，是C语言库函数之一，用于对任何元素类型的数组排序。它有4个形参，第一个是要排序数组的地址，第二个是数组元素个数，第三个是数组元素的字节大小，也就是跨越一个元素的步长，第四个就是本节重点，一个函数指针，用来接收数组排序所需的排序函数，比如冒泡，选择排序\u0026hellip;\nOK，请看下面的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #include\u0026lt;stdio.h\u0026gt; int add(int x,int y) { return x+y;} int sub(int x,int y) { return x-y;} int Calc(int (*p)(int,int))//函数指针作为形参接收函数地址 { int x=0,y=0; printf(\u0026#34;请输入两个操作数:\u0026gt;\u0026#34;); scanf(\u0026#34;%d %d\u0026#34;,\u0026amp;x,\u0026amp;y); return (*p)(x,y);//p(x,y)也可以 } int main() { int ret=Calc(add);//把add函数地址传过去，用函数指针接收 printf(\u0026#34;加法运算 %d\\n\u0026#34;,ret);//结果是8 ret=Calc(sub); printf(\u0026#34;减法运算 %d\\n\u0026#34;,ret);//结果是-2 return 0; } 运算结果如下：\n这就是函数指针。。。\n5.2.函数指针接收函数地址 如图：函数名本身就是函数的地址，和\u0026amp;函数名效果相同，*ptr说明其是指针，int （*ptr）说明函数的返回值是int，而(int , int)则是函数add的形参。当然，函数指针也可以和数组指针一样放在指针数组中，比如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 int add(int x,int y) { return x+y;} int sub(int x,int y) { return x-y;} int main() { int (*p1)(int,int)=add; int (*p2)(int,int)=sub; int (*p[2])(int ,int)={p1,p2};//两个函数指针放到函数指数组里 (*p1)(3,5);//结果是8 (*p2)(3,5);//结果是-2 } 当然我还可以再找一个指针指向这个函数指针数组，然后把这个指针再放到指针数组里，这样无限套娃\u0026hellip;..\n玩点好玩的 1 (* (void(*)()) 0)() 这个出自《C语言陷阱与缺陷》这本书，作用是调用首地址为0地址的子例程。首先0，用(void(*)())\n把它转化成函数指针，也就是(void(*)()) 0，然后对这个函数指针调用（* (void(*)()) 0) ( ),显然形参为空。看解释：\n1 2 3 4 5 6 //调用0地址处的函数 //该函数无参，返回类型是void //1.void(*) () ---函数指针类型 //2.(void(*) ()) 0 ---对0强制类型转化，成为一个函数地址 //3.*(void(*) ()) 0 ---我TM直接对地址解引用 //4.(*(void(*) ()) 0) () ---调用0地址处的函数 OK，本文到此为止，NND写了我四五个小时\u0026hellip;. ","date":"2023-08-04T16:08:31Z","permalink":"/zh-cn/post/2023/08/c-%E6%8C%87%E9%92%88%E8%BF%9B%E9%98%B6--%E6%95%B0%E7%BB%84%E6%8C%87%E9%92%88-%E6%8C%87%E9%92%88%E6%95%B0%E7%BB%84-%E5%87%BD%E6%95%B0%E6%8C%87%E9%92%88%E5%8F%8A%E4%BC%A0%E5%8F%82/","title":"C 指针进阶--数组指针 指针数组 函数指针及传参"}]