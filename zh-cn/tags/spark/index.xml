<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Spark on 青秋博客</title>
        <link>/zh-cn/tags/spark/</link>
        <description>Recent content in Spark on 青秋博客</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>青秋博客</copyright>
        <lastBuildDate>Wed, 04 Sep 2024 00:12:24 +0000</lastBuildDate><atom:link href="/zh-cn/tags/spark/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>一文入门大数据准流式计算引擎Spark【万字详解，全网最新】</title>
        <link>/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8Espark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/</link>
        <pubDate>Wed, 04 Sep 2024 00:12:24 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8Espark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/</guid>
        <description>&lt;blockquote&gt;
&lt;h2 id=&#34;往期推荐-e5be80e69c9fe68ea8e88d90&#34;&gt;&lt;a href=&#34;#%e5%be%80%e6%9c%9f%e6%8e%a8%e8%8d%90-e5be80e69c9fe68ea8e88d90&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;往期推荐 {#%E5%BE%80%E6%9C%9F%E6%8E%A8%E8%8D%90}
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/140787541&#34;  title=&#34;浅谈维度建模、数据分析模型，何为数据仓库，与数据库的区别-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;浅谈维度建模、数据分析模型，何为数据仓库，与数据库的区别-CSDN博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/141761563&#34;  title=&#34;数仓架构：离线数仓、实时数仓Lambda和Kappa、湖仓一体数据湖-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;数仓架构：离线数仓、实时数仓Lambda和Kappa、湖仓一体数据湖-CSDN博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/140783320&#34;  title=&#34;DW层的数仓建模：范式建模、维度建模及数据分析模型、实体建模-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DW层的数仓建模：范式建模、维度建模及数据分析模型、实体建模-CSDN博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/140786773&#34;  title=&#34;数仓分层ODS、DWD、DWM、DWS、DIM、DM、ADS_dm ads-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;数仓分层ODS、DWD、DWM、DWS、DIM、DM、ADS_dm ads-CSDN博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;后续考虑，会出Spark调优、shuffle、数据倾斜优化等&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;目录&lt;/strong&gt;{#main-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%BE%80%E6%9C%9F%E6%8E%A8%E8%8D%90&#34; &gt;往期推荐&lt;/a&gt;{#%E5%BE%80%E6%9C%9F%E6%8E%A8%E8%8D%90-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#1.%20Spark%E7%AE%80%E4%BB%8B&#34; &gt;1. Spark简介&lt;/a&gt;{#1.%20Spark%E7%AE%80%E4%BB%8B-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#1.1%20Spark%E7%89%B9%E7%82%B9&#34; &gt;1.1 Spark特点&lt;/a&gt;{#1.1%20Spark%E7%89%B9%E7%82%B9-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#1.2%20Spark%E5%92%8CMR%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E5%AF%B9%E6%AF%94&#34; &gt;1.2 Spark和MR处理任务对比&lt;/a&gt;{#1.2%20Spark%E5%92%8CMR%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E5%AF%B9%E6%AF%94-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.%20Spark%E7%BB%84%E4%BB%B6&#34; &gt;2. Spark组件&lt;/a&gt;{#2.%20Spark%E7%BB%84%E4%BB%B6-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1%20Spark%20Core&#34; &gt;2.1 Spark Core&lt;/a&gt;{#2.1%20Spark%20Core-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.1%20RDD%E7%AE%97%E5%AD%90&#34; &gt;2.1.1 RDD算子&lt;/a&gt;{#2.1.1%20RDD%E7%AE%97%E5%AD%90-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.1.1%20%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89RDD%EF%BC%9F&#34; &gt;2.1.1.1 为什么有RDD？&lt;/a&gt;{#2.1.1.1%20%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89RDD%EF%BC%9F-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.1.2%20RDD%E4%BB%8B%E7%BB%8D&#34; &gt;2.1.1.2 RDD介绍&lt;/a&gt;{#2.1.1.2%20RDD%E4%BB%8B%E7%BB%8D-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.2%20RDD%20%E7%89%B9%E7%82%B9&#34; &gt;2.1.2 RDD 特点&lt;/a&gt;{#2.1.2%20RDD%20%E7%89%B9%E7%82%B9-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.3%20RDD%E5%81%9A%E4%BA%86%E4%BB%80%E4%B9%88&#34; &gt;2.1.3 RDD做了什么&lt;/a&gt;{#2.1.3%20RDD%E5%81%9A%E4%BA%86%E4%BB%80%E4%B9%88-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.4%20RDD%E7%9A%84%E8%BD%AC%E6%8D%A2%E5%92%8C%E8%A1%8C%E5%8A%A8%E6%93%8D%E4%BD%9C&#34; &gt;2.1.4 RDD的转换和行动操作&lt;/a&gt;{#2.1.4%20RDD%E7%9A%84%E8%BD%AC%E6%8D%A2%E5%92%8C%E8%A1%8C%E5%8A%A8%E6%93%8D%E4%BD%9C-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.4.1%C2%A0%20Transformation%EF%BC%88%E8%BD%AC%E6%8D%A2%EF%BC%89%E7%AE%97%E5%AD%90%E6%A6%82%E8%BF%B0&#34; &gt;2.1.4.1 Transformation（转换）算子概述&lt;/a&gt;{#2.1.4.1%C2%A0%20Transformation%EF%BC%88%E8%BD%AC%E6%8D%A2%EF%BC%89%E7%AE%97%E5%AD%90%E6%A6%82%E8%BF%B0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.4.2%C2%A0%20Action%EF%BC%88%E8%A1%8C%E5%8A%A8%EF%BC%89%E7%AE%97%E5%AD%90%E6%A6%82%E8%BF%B0%C2%A0&#34; &gt;2.1.4.2 Action（行动）算子概述&lt;/a&gt;{#2.1.4.2%C2%A0%20Action%EF%BC%88%E8%A1%8C%E5%8A%A8%EF%BC%89%E7%AE%97%E5%AD%90%E6%A6%82%E8%BF%B0%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.5%20RDD%E6%8C%81%E4%B9%85%E5%8C%96%E5%92%8C%E7%BC%93%E5%AD%98&#34; &gt;2.1.5 RDD持久化和缓存&lt;/a&gt;{#2.1.5%20RDD%E6%8C%81%E4%B9%85%E5%8C%96%E5%92%8C%E7%BC%93%E5%AD%98-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.6%20%E5%AD%98%E5%82%A8%E7%BA%A7%E5%88%AB&#34; &gt;2.1.6 存储级别&lt;/a&gt;{#2.1.6%20%E5%AD%98%E5%82%A8%E7%BA%A7%E5%88%AB-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.7%20Checkpoint%E6%A3%80%E6%9F%A5%E7%82%B9%E6%9C%BA%E5%88%B6%C2%A0&#34; &gt;2.1.7 Checkpoint检查点机制&lt;/a&gt;{#2.1.7%20Checkpoint%E6%A3%80%E6%9F%A5%E7%82%B9%E6%9C%BA%E5%88%B6%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.8%20RDD%E5%AE%BD%E7%AA%84%E4%BE%9D%E8%B5%96&#34; &gt;2.1.8 RDD宽窄依赖&lt;/a&gt;{#2.1.8%20RDD%E5%AE%BD%E7%AA%84%E4%BE%9D%E8%B5%96-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.8.1%20%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%AE%BE%E8%AE%A1%E5%AE%BD%E7%AA%84%E4%BE%9D%E8%B5%96&#34; &gt;2.1.8.1 为什么要设计宽窄依赖&lt;/a&gt;{#2.1.8.1%20%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%AE%BE%E8%AE%A1%E5%AE%BD%E7%AA%84%E4%BE%9D%E8%B5%96-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.8.2%20DAG%E7%94%9F%E6%88%90%E5%92%8C%E5%88%92%E5%88%86Stage&#34; &gt;2.1.8.2 DAG生成和划分Stage&lt;/a&gt;{#2.1.8.2%20DAG%E7%94%9F%E6%88%90%E5%92%8C%E5%88%92%E5%88%86Stage-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.2%20Spark%20SQL&#34; &gt;2.2 Spark SQL&lt;/a&gt;{#2.2%20Spark%20SQL-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.2.1%20Spark%20SQL%E5%8F%91%E5%B1%95%EF%BC%88%E7%B2%BE%E5%BD%A9%EF%BC%89&#34; &gt;2.2.1 Spark SQL发展（精彩）&lt;/a&gt;{#2.2.1%20Spark%20SQL%E5%8F%91%E5%B1%95%EF%BC%88%E7%B2%BE%E5%BD%A9%EF%BC%89-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.2.2%20Spark%20SQL%E6%A6%82%E8%BF%B0&#34; &gt;2.2.2 Spark SQL概述&lt;/a&gt;{#2.2.2%20Spark%20SQL%E6%A6%82%E8%BF%B0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.2.3%20Spark%20SQL%E7%89%B9%E7%82%B9&#34; &gt;2.2.3 Spark SQL特点&lt;/a&gt;{#2.2.3%20Spark%20SQL%E7%89%B9%E7%82%B9-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.2.4%20Spark%20SQL%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%20DataFrame%E5%92%8CDataset&#34; &gt;2.2.4 Spark SQL数据模型 DataFrame和Dataset&lt;/a&gt;{#2.2.4%20Spark%20SQL%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%20DataFrame%E5%92%8CDataset-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.2.5%20%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8CSparkSQL%E7%BC%96%E7%A8%8B&#34; &gt;2.2.5 如何进行SparkSQL编程&lt;/a&gt;{#2.2.5%20%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8CSparkSQL%E7%BC%96%E7%A8%8B-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.3%20Spark%20Streaming&#34; &gt;2.3 Spark Streaming&lt;/a&gt;{#2.3%20Spark%20Streaming-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.3.1%20%E7%AE%80%E4%BB%8B&#34; &gt;2.3.1 简介&lt;/a&gt;{#2.3.1%20%E7%AE%80%E4%BB%8B-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.3.2%20%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E7%89%B9%E7%82%B9&#34; &gt;2.3.2 流式计算特点&lt;/a&gt;{#2.3.2%20%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E7%89%B9%E7%82%B9-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.3.3%20%E5%B8%B8%E8%A7%81%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%92%8C%E7%A6%BB%E7%BA%BF%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6&#34; &gt;2.3.3 常见流式计算和离线计算框架&lt;/a&gt;{#2.3.3%20%E5%B8%B8%E8%A7%81%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%92%8C%E7%A6%BB%E7%BA%BF%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.3.4%20SparkStreaming%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86&#34; &gt;2.3.4 SparkStreaming的基本工作原理&lt;/a&gt;{#2.3.4%20SparkStreaming%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.3.5%20SparkStreaming%E7%9A%84%E7%BC%93%E5%AD%98&#34; &gt;2.3.5 SparkStreaming的缓存&lt;/a&gt;{#2.3.5%20SparkStreaming%E7%9A%84%E7%BC%93%E5%AD%98-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.3.6%20SparkStreaming%E7%9A%84%E5%AE%B9%E9%94%99&#34; &gt;2.3.6 SparkStreaming的容错&lt;/a&gt;{#2.3.6%20SparkStreaming%E7%9A%84%E5%AE%B9%E9%94%99-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.3.7%20DStream%E6%93%8D%E4%BD%9C&#34; &gt;2.3.7 DStream操作&lt;/a&gt;{#2.3.7%20DStream%E6%93%8D%E4%BD%9C-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.4%20MLlib&#34; &gt;2.4 MLlib&lt;/a&gt;{#2.4%20MLlib-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.5%20Graphx&#34; &gt;2.5 Graphx&lt;/a&gt;{#2.5%20Graphx-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Spark%E5%A4%9A%E7%A7%8D%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F&#34; &gt;Spark多种部署模式&lt;/a&gt;{#Spark%E5%A4%9A%E7%A7%8D%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F-toc}&lt;/p&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li&gt;Spark简介 {#1.%20Spark%E7%AE%80%E4%BB%8B}&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;Spark 于 2009 年诞生于加州大学伯克利分校 AMPLab，2013 年被捐赠给 Apache 软件基金会，2014 年 2 月成为 Apache 的顶级项目。&lt;/p&gt;
&lt;p&gt;相对于 MapReduce 的批处理计算，&lt;strong&gt;Spark基于内存计算&lt;/strong&gt;，可以带来上百倍的性能提升，因此它成为继 MapReduce 之后，最为广泛使用的&lt;strong&gt;分布式计算框架、大数据分析引擎&lt;/strong&gt;。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;11-spark特点-1120sparke789b9e782b9&#34;&gt;&lt;a href=&#34;#11-spark%e7%89%b9%e7%82%b9-1120sparke789b9e782b9&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;1.1 Spark特点 {#1.1%20Spark%E7%89%B9%E7%82%B9}
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;快&lt;/strong&gt;：采用&lt;strong&gt;DAG执行引擎，支持循环数据流和内存计算&lt;/strong&gt;，使得 Spark 速度更快，在内存中的速度 是Hadoop MR的百倍，在磁盘上的速度是Hadoop MR的十倍(官网数据)。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;通用&lt;/strong&gt;：Spark提供了统一的解决方案。Spark可以⽤于批处理、交互式查询（Spark SQL）、实时流处理（Spark Streaming）、机器学习（Spark MLlib）和图计算（GraphX）。这些不同类型的处理都可以在同⼀个应用中无缝使用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;易用&lt;/strong&gt;：Spark支持Java、Python、Scala的API和超过80种⾼级算法，⽽且⽀持交互式的Python和Scala的shell。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;兼容&lt;/strong&gt;：Spark可以使⽤Hadoop的YARN和Apache Mesos作为它的资源管理和调度器，器，并且不需要任何数据迁移就可以处理所有Hadoop支持的数据，包括HDFS、HBase和Cassandra等。Spark也可以不依赖于第三⽅的资源管理和调度器，它实现了Standalone作为其内置的资源管理和调度框架。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;12-spark和mr处理任务对比-1220sparke5928cmre5a484e79086e4bbbbe58aa1e5afb9e6af94&#34;&gt;&lt;a href=&#34;#12-spark%e5%92%8cmr%e5%a4%84%e7%90%86%e4%bb%bb%e5%8a%a1%e5%af%b9%e6%af%94-1220sparke5928cmre5a484e79086e4bbbbe58aa1e5afb9e6af94&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;1.2 Spark和MR处理任务对比 {#1.2%20Spark%E5%92%8CMR%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E5%AF%B9%E6%AF%94}
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/direct/598e70154d4147deb1269a7566774e6c.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/direct/404b28dcc6494c1fad6636a3e2c2450b.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Spark组件 {#2.%20Spark%E7%BB%84%E4%BB%B6}&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id=&#34;21-spark-core-2120spark20core&#34;&gt;&lt;a href=&#34;#21-spark-core-2120spark20core&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;2.1 Spark Core {#2.1%20Spark%20Core}
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;Spark Core实现了 Spark 的基本功能，包含任务调度、内存管理、错误恢复、与存储系统 交互等模块。Spark Core 中还包含 了对弹性分布式数据集(resilient distributed dataset，简称RDD)的 API 定义。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;211-rdd算子-21120rdde7ae97e5ad90&#34;&gt;&lt;a href=&#34;#211-rdd%e7%ae%97%e5%ad%90-21120rdde7ae97e5ad90&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;2.1.1 RDD算子 {#2.1.1%20RDD%E7%AE%97%E5%AD%90}
&lt;/h4&gt;&lt;h5 id=&#34;2111-为什么有rdd-211120e4b8bae4bb80e4b988e69c89rddefbc9f&#34;&gt;&lt;a href=&#34;#2111-%e4%b8%ba%e4%bb%80%e4%b9%88%e6%9c%89rdd-211120e4b8bae4bb80e4b988e69c89rddefbc9f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;2.1.1.1 为什么有RDD？ {#2.1.1.1%20%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89RDD%EF%BC%9F}
&lt;/h5&gt;&lt;blockquote&gt;
&lt;p&gt;在许多迭代式算法(比如机器学习、图算法等)和交互式数据挖掘中，不同计算阶段之间会重用中间结果，即&lt;strong&gt;一个阶段的输出结果会作为下一个阶段的输入&lt;/strong&gt;。但是， 之前的 &lt;strong&gt;MapReduce 框架采用非循环式的数据流模型&lt;/strong&gt;，把中间结果写入到 HDFS 中，带来了大量的数据复制、磁盘 IO 和序列化开销，且这些框架只能支持一些 特定的计算模式(map/reduce)，并没有提供一种&lt;strong&gt;通用的数据抽象&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;RDD 提供了一个抽象的数据模型，让我们不必担心底层数据的分布式特性，只需&lt;strong&gt;将具体的应用逻辑表达为一系列转换操作(函数)&lt;/strong&gt; ，不同 RDD 之间的转换操作之间还可以形成依赖关系，进而实现&lt;strong&gt;管道化&lt;/strong&gt;，从而&lt;strong&gt;避免了中间结果的存储&lt;/strong&gt;，大大降低数据复制、磁盘 IO 和序列化开销，并且还提供了更多的 API操作！&lt;/p&gt;&lt;/blockquote&gt;
&lt;h5 id=&#34;2112-rdd介绍-211220rdde4bb8be7bb8d&#34;&gt;&lt;a href=&#34;#2112-rdd%e4%bb%8b%e7%bb%8d-211220rdde4bb8be7bb8d&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;2.1.1.2 RDD介绍 {#2.1.1.2%20RDD%E4%BB%8B%E7%BB%8D}
&lt;/h5&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;RDD（Resilient Distributed Dataset）叫做&lt;strong&gt;弹性分布式数据集&lt;/strong&gt;，是Spark中&lt;strong&gt;最基本的数据抽象&lt;/strong&gt;，是Spark计算的基石，它代表⼀个不可变、可分区、里面的元素可并行计算的集合。&lt;/li&gt;
&lt;li&gt;RDD具有数据流模型的特点：自动容错、位置感知性调度和可伸缩性。RDD允许用户在执⾏多个查询时显式地将⼯作集缓存在内存中，后续的查询能够&lt;strong&gt;重⽤⼯作集&lt;/strong&gt;，这极⼤地提升了查询速度。&lt;/li&gt;
&lt;li&gt;MR中对数据是没有进行抽象的，而在Spark中对数据进行了抽象，提供⼀些列处理⽅法也就是 RDD，为用户屏蔽了底层对数据的复杂抽象和处理，为⽤户提供了⼀组⽅便 的数据转换与求值方法，好比Java中类的封装。&lt;/li&gt;
&lt;/ul&gt;
&lt;br /&gt;
&lt;p&gt;&lt;strong&gt;注意 : RDD本身是不存储数据，而是记录了数据的位置，数据的转换关系(调用什么方法、传入什么函数)！！！&lt;/strong&gt;&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;&lt;strong&gt;以下是RDD源码翻译解读：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/direct/8b0a801743be4b50a960e23592f8e3b2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;212-rdd-特点-21220rdd20e789b9e782b9&#34;&gt;&lt;a href=&#34;#212-rdd-%e7%89%b9%e7%82%b9-21220rdd20e789b9e782b9&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;2.1.2 RDD 特点 {#2.1.2%20RDD%20%E7%89%B9%E7%82%B9}
&lt;/h4&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;弹性体现：
&lt;ol&gt;
&lt;li&gt;存储的弹性：内存与磁盘的自动切换；&lt;/li&gt;
&lt;li&gt;容错的弹性：RDD的血统（Lineag）会&lt;strong&gt;记录RDD的元数据信息和转换行为&lt;/strong&gt; ，当RDD的部分分区数据丢失时，它可以根据这些信息来重新运算并恢复丢失的数据分区。&lt;/li&gt;
&lt;li&gt;计算的弹性：计算出错重试机制；&lt;/li&gt;
&lt;li&gt;分片的弹性：可根据需要重新分片；&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;分布式：数据存储在大数据集群不同节点上&lt;/li&gt;
&lt;li&gt;数据集：RDD&lt;strong&gt;封装了计算逻辑&lt;/strong&gt;，并不保存数据&lt;/li&gt;
&lt;li&gt;数据抽象：RDD是⼀个抽象，需要具体实现&lt;/li&gt;
&lt;li&gt;不可变：RDD封装的&lt;strong&gt;计算逻辑不可改变&lt;/strong&gt;，想要改变只能产⽣新的RDD&lt;/li&gt;
&lt;li&gt;可分区、并行计算&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;213-rdd做了什么-21320rdde5819ae4ba86e4bb80e4b988&#34;&gt;&lt;a href=&#34;#213-rdd%e5%81%9a%e4%ba%86%e4%bb%80%e4%b9%88-21320rdde5819ae4ba86e4bb80e4b988&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;2.1.3 RDD做了什么 {#2.1.3%20RDD%E5%81%9A%E4%BA%86%E4%BB%80%E4%B9%88}
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;从计算的角度来讲，数据处理过程中需要计算资源（内存 &amp;amp; CPU）和计算模型（逻辑）。执⾏时，需要&lt;strong&gt;将计算资源&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;hr&gt;
</description>
        </item>
        
    </channel>
</rss>
