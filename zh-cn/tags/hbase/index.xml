<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>HBase on 青秋博客</title>
        <link>/zh-cn/tags/hbase/</link>
        <description>Recent content in HBase on 青秋博客</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>青秋博客</copyright>
        <lastBuildDate>Mon, 29 Jul 2024 11:30:00 +0000</lastBuildDate><atom:link href="/zh-cn/tags/hbase/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>大数据HBase图文简介及Phoenix</title>
        <link>/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/</link>
        <pubDate>Mon, 29 Jul 2024 11:30:00 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/</guid>
        <description>&lt;h2 id=&#34;引言&#34;&gt;&lt;a href=&#34;#%e5%bc%95%e8%a8%80&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;引言
&lt;/h2&gt;&lt;p&gt;要想明白为什么 HBase 的产生，就需要先了解一下 Hadoop。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Hadoop 可以通过 HDFS 来存 储结构化、半结构甚至非结构化的数据，是传统数据库的补充，是海量数据存储的最佳方法，它针对大文件的存储、批量访问和流式访问都做了优化，同时也通过多副本解决了容灾问题。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;但是 Hadoop 的缺陷在于它&lt;strong&gt;只能执行批处理&lt;/strong&gt;，并且只能以&lt;strong&gt;顺序方式访问数据&lt;/strong&gt;，这意味着即使是最简单的工作也必须搜索整个数据集，&lt;strong&gt;无法实现对数据的随机访问&lt;/strong&gt;。实现数据的&lt;strong&gt;随机访问是传统的关系型数据库所擅长的&lt;/strong&gt;，但它们却不能用于海量数据的存储。在这种情况下，必须有一种新的方案来&lt;strong&gt;同时解决海量数据存储和随机访问的问题&lt;/strong&gt;，HBase 就是其中之一 (HBase，Cassandra，couchDB，Dynamo 和 MongoDB 都能存储海量数据并支持随机访问)。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;数据结构分类：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;结构化数据：即以关系型数据库表形式管理的数据；&lt;/li&gt;
&lt;li&gt;半结构化数据：非关系模型的，有基本固定结构模式的数据，例如日志文件、XML 文档、 JSON 文档、Email 等；&lt;/li&gt;
&lt;li&gt;非结构化数据：没有固定模式的数据，如 WORD、PDF、PPT、EXL，各种格式的图片、视 频等。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;hbase-简介&#34;&gt;&lt;a href=&#34;#hbase-%e7%ae%80%e4%bb%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HBase 简介
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;HBase 全称 Hadoop Database ，是一个基于 HDFS 的分布式的、面向列的开源数据库，但是这个数据库没有 SQL，只提供了 API，需要 API 编程来使用 HBase，而后面提到的 Phoenix 才使得可以用 SQL 操作 HBase！&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;HBase 有如下特点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;容量大：一个表可以有数十亿行，上百万列，这也和它的扩展性息息相关；&lt;/li&gt;
&lt;li&gt;面向列：数据是按照列存储，每一列都单独存放，数据即索引，在查询时可以只访问指定列的数据，有效地降低了系统的 I/O 负担；&lt;/li&gt;
&lt;li&gt;稀疏性：空 (null) 列并不占用存储空间，表可以设计的非常稀疏 ；&lt;/li&gt;
&lt;li&gt;易扩展：的扩展性主要体现在两个方面，一个是基于上层处理能力（RegionServer） 的扩展，一个是基于存储的扩展（HDFS）。通过横向添加 RegionSever 的机器， 进行水平扩展，提升 Hbase 上层的处理能力，提升 Hbsae 服务更多 Region 的 能力。&lt;/li&gt;
&lt;li&gt;数据多版本：每个单元中的数据可以有多个版本，按照时间戳排序，新的数据在最上面；&lt;/li&gt;
&lt;li&gt;采用 HDFS 作为底层存储，支持结构化、半结构化和非结构化的存储；&lt;/li&gt;
&lt;li&gt;支持数据分片；&lt;/li&gt;
&lt;li&gt;易于使用的 Java 客户端 API，客户端可以通过 HBase 实现对 HDFS 上数据的随机访问；&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image.png&#34;
	width=&#34;1135&#34;
	height=&#34;612&#34;
	srcset=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image_hu_1c021cc8169d6b19.png 480w, /zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image_hu_ba0871a8f16ba121.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;185&#34;
		data-flex-basis=&#34;445px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;hbase-的表&#34;&gt;&lt;a href=&#34;#hbase-%e7%9a%84%e8%a1%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HBase 的表
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;表 schema 仅定义列族，表具有多个列族，每个列族可以包含任意数量的列，列由多个单元格 （cell ）组成，单元格可以存储多个版本的数据，多个版本数据以时间戳进行区分。&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;所有数据的底层存储格式都是字节数组；&lt;/li&gt;
&lt;li&gt;不持复杂的事务，只支持行级事务，即单行数据的读写都是原子性的；&lt;/li&gt;
&lt;li&gt;查询功能简单，不支持 join 等复杂操作；&lt;/li&gt;
&lt;li&gt;仅支持通过主键(row key)和主键的 range 来检索数据；&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-1.png&#34;
	width=&#34;1101&#34;
	height=&#34;797&#34;
	srcset=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-1_hu_5bc7b7725805adfb.png 480w, /zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-1_hu_eb82ecc2a0e98dbf.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;138&#34;
		data-flex-basis=&#34;331px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;row-key-行键&#34;&gt;&lt;a href=&#34;#row-key-%e8%a1%8c%e9%94%ae&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Row Key 行键
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;Row Key 是用来检索记录的主键。想要访问 HBase Table 中的数据，只有以下三种方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过指定的 Row Key 进行访问；&lt;/li&gt;
&lt;li&gt;通过 Row Key 的 range 进行访问，即访问指定范围内的行；&lt;/li&gt;
&lt;li&gt;进行全表扫描；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Row Key 可以是任意字符串，存储时数据按照 Row Key 的&lt;strong&gt;字典序进行排序&lt;/strong&gt;，这里需要注意以下两点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;因为字典序对 int 排序的结果是 1,10,100,11,12,13,14,15,16,17,18,19,2,20,21,…,9,91,92,93,94,95,96,97,98,99。如果你使用整型的字符串作为行键，那么为了保持整型的自然序，&lt;strong&gt;行键必须用 0 作左填充&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;行的一次读写操作时原子性的 (不论一次读写多少列)。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;column-family-列族&#34;&gt;&lt;a href=&#34;#column-family-%e5%88%97%e6%97%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Column Family 列族
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;HBase 表中的每个列，都归属于某个列族。列族是表的 Schema 的一部分，所以列族需要在创建表时定义。&lt;/li&gt;
&lt;li&gt;列族的所有列都以列族名作为前缀，例如 courses:history ， courses:math 都属于 courses 这个列族。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;column-qualifier-列限定符&#34;&gt;&lt;a href=&#34;#column-qualifier-%e5%88%97%e9%99%90%e5%ae%9a%e7%ac%a6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Column Qualifier 列限定符
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;列限定符，可以理解为是具体的列名，例如 courses:history ， courses:math 都属于 courses 这个列族，它们的列限定符分别是 history 和 math 。需要注意的是列限定符不是表 Schema 的一部分，可以在插入数据的过程中动态创建列。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;cell-单元格&#34;&gt;&lt;a href=&#34;#cell-%e5%8d%95%e5%85%83%e6%a0%bc&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Cell 单元格
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;Cell 是行，列族和列限定符的组合，并包含值和时间戳。可以等价理解为关系型数据库中由指定行和指定列确定的一个单元格，而不同的是 HBase 中的一个单元格是由多个版本的数据组成的，每个版本的数据用时间戳进行区分。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;timestamp-时间戳&#34;&gt;&lt;a href=&#34;#timestamp-%e6%97%b6%e9%97%b4%e6%88%b3&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Timestamp 时间戳
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;HBase 中通过 row key 和 column 确定的为一个存储单元称为 Cell 。每个 Cell 都保存着同一份数 据的多个版本。版本通过时间戳来索引，时间戳的类型是 64 位整型，时间戳可以由 HBase 在数据写入 时自动赋值，也可以由客户显式指定。每个 Cell 中，不同版本的数据按照时间戳倒序排列，即最新的数据排在最前面。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;hbase-的存储结构&#34;&gt;&lt;a href=&#34;#hbase-%e7%9a%84%e5%ad%98%e5%82%a8%e7%bb%93%e6%9e%84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HBase 的存储结构
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-2.png&#34;
	width=&#34;1518&#34;
	height=&#34;785&#34;
	srcset=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-2_hu_4d44bb99c9d0bcbd.png 480w, /zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-2_hu_930d5ac1c3f1ab27.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;193&#34;
		data-flex-basis=&#34;464px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;regions&#34;&gt;&lt;a href=&#34;#regions&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Regions
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;HBase Table 中的所有行按照 Row Key 的字典序排列。HBase Tables 通过行键的范围 (row key range) 被&lt;strong&gt;水平切分&lt;/strong&gt;成多个 Region , &lt;strong&gt;一个 Region 包含了在 start key 和 end key 之间的所有行。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;每个表一开始只有一个 Region ，随着数据不断增加， Region 会不断增大，当增大到一个阀值的时 候， Region 就会&lt;strong&gt;等分&lt;/strong&gt;为两个新的 Region 。当 Table 中的行不断增多，就会有越来越多的 Region 。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-3.png&#34;
	width=&#34;1006&#34;
	height=&#34;649&#34;
	srcset=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-3_hu_f98bb24009154550.png 480w, /zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-3_hu_885c1a6987552d12.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;155&#34;
		data-flex-basis=&#34;372px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Region 是 HBase 中&lt;strong&gt;分布式存储和负载均衡的最小单元&lt;/strong&gt;。这意味着不同的 Region 可以分布在不同的 Region Server 上。但&lt;strong&gt;一个 Region 是不会拆分到多个 Server&lt;/strong&gt; 上的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-4.png&#34;
	width=&#34;1042&#34;
	height=&#34;576&#34;
	srcset=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-4_hu_a686118d976c0b46.png 480w, /zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-4_hu_83ca7e87c140d2f4.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;180&#34;
		data-flex-basis=&#34;434px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;region-server&#34;&gt;&lt;a href=&#34;#region-server&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Region Server
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;Region Server &lt;strong&gt;运行在 HDFS 的 DataNode&lt;/strong&gt; 上。它具有以下组件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;WAL(Write Ahead Log，预写日志)：对 HBase 读写数据的时候，数据&lt;strong&gt;不是直接写进磁盘&lt;/strong&gt;，它会&lt;strong&gt;在内存中保留&lt;/strong&gt;一段时间，但把数据保存在内存中可能有更高的概率引起数据丢失，为了解决这个问题，数据会先写在一个叫 做 Write-Ahead logfile 的文件中&lt;strong&gt;存储尚未进持久化存储的数据记录&lt;/strong&gt;，以便在发生故障时进行恢复。&lt;/li&gt;
&lt;li&gt;BlockCache：读缓存。它&lt;strong&gt;将频繁读取的数据存储在内存中，如果存储不足，它将按照 最近最少使 用原则 清除多余的数据。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;MemStore：写缓存。它&lt;strong&gt;存储尚未写入磁盘的新数据，&lt;strong&gt;并会在数据写入磁盘之前对其进行排序。 每个 Region 上的&lt;/strong&gt;每个列族都有一个 MemStore&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;HFile ：将行数据按照 Key\Values 的形式存储在文件系统上，是实际的存储文件。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Region Server 存取一个子表时，会创建一个 Region 对象，然后对表的每个列族创建一个 Store 实例，每个 Store 会有 0 个或多个 StoreFile 与之对应，每个 StoreFile 则对应一个 HFile ，HFile 就是实际存储在 HDFS 上的文件。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;hbase-的系统架构&#34;&gt;&lt;a href=&#34;#hbase-%e7%9a%84%e7%b3%bb%e7%bb%9f%e6%9e%b6%e6%9e%84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HBase 的系统架构
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-5.png&#34;
	width=&#34;1478&#34;
	height=&#34;774&#34;
	srcset=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-5_hu_a073c34b524d71e3.png 480w, /zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-5_hu_e37f046de00bb9d0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;190&#34;
		data-flex-basis=&#34;458px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;HBase 系统遵循 Master/Salve 架构，由三种不同类型的组件组成：&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;zookeeper&#34;&gt;&lt;a href=&#34;#zookeeper&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Zookeeper
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;保证任何时候，集群中只有一个 Master；&lt;/li&gt;
&lt;li&gt;存贮所有 Region 的寻址入口；&lt;/li&gt;
&lt;li&gt;实时监控 Region Server 的状态，将 Region Server 的上线和下线信息实时通知给 Master；&lt;/li&gt;
&lt;li&gt;存储 HBase 的 Schema，包括有哪些 Table，每个 Table 有哪些 Column Family 等信息；&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;master&#34;&gt;&lt;a href=&#34;#master&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Master
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;为 Region Server 分配或移除 Region ；&lt;/li&gt;
&lt;li&gt;负责 Region Server 的负载均衡 ；&lt;/li&gt;
&lt;li&gt;处理 Region Server 的故障转移；&lt;/li&gt;
&lt;li&gt;处理 GFS 上的垃圾文件回收；&lt;/li&gt;
&lt;li&gt;处理 Schema 的更新请求；&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-6.png&#34;
	width=&#34;1449&#34;
	height=&#34;723&#34;
	srcset=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-6_hu_602aff3094b4ca1c.png 480w, /zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-6_hu_fa0a120d709e3199.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;200&#34;
		data-flex-basis=&#34;480px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;region-server-1&#34;&gt;&lt;a href=&#34;#region-server-1&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Region Server
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;负责维护 Master 分配给它的 Region ，并处理发送到 Region 上的 IO 请求；&lt;/li&gt;
&lt;li&gt;负责切分在运行过程中变得过大的 Region；&lt;/li&gt;
&lt;li&gt;维护 HLog&lt;/li&gt;
&lt;li&gt;刷新缓存到 HDFS&lt;/li&gt;
&lt;li&gt;存储 HBase 的实际数据&lt;/li&gt;
&lt;li&gt;压缩数据&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-7.png&#34;
	width=&#34;1412&#34;
	height=&#34;690&#34;
	srcset=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-7_hu_3b7183c5185c40e2.png 480w, /zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-7_hu_a32f5a80efac50a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;204&#34;
		data-flex-basis=&#34;491px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;三个组件间的协作&#34;&gt;&lt;a href=&#34;#%e4%b8%89%e4%b8%aa%e7%bb%84%e4%bb%b6%e9%97%b4%e7%9a%84%e5%8d%8f%e4%bd%9c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;三个组件间的协作
&lt;/h3&gt;&lt;p&gt;HBase 使用 ZooKeeper 作为分布式协调服务来维护集群中的服务器状态。 Zookeeper 负责维护可用 服务列表，并提供服务故障通知等服务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个 Region Server 都会在 ZooKeeper 上创建一个临时节点，Master 通过 Zookeeper 的 Watcher 机制对节点进行监控，从而发现新加入的 Region Server 或故障退出的 Region Server；&lt;/li&gt;
&lt;li&gt;所有 Masters 会&lt;strong&gt;竞争&lt;/strong&gt;性地在 Zookeeper 上创建同一个临时节点，由于 Zookeeper 只能有一个同名节点，所以必然只有一个 Master 能够创建成功，此时该 Master 就是主 Master，主 Master 会 定期向 Zookeeper &lt;strong&gt;发送心跳&lt;/strong&gt;。备用 Masters 则通过 Watcher 机制对主 HMaster 所在节点&lt;strong&gt;进行监听&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;如果主 Master 未能定时发送心跳，则其持有的 Zookeeper 会话会过期，相应的临时节点也会被 删除，这会触发定义在该节点上的 Watcher 事件，使得备用的 Master Servers 得到通知。所有备 用的 Master Servers 在接到通知后，会再次去竞争性地创建临时节点，完成主 Master 的选举。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;写数据流程&#34;&gt;&lt;a href=&#34;#%e5%86%99%e6%95%b0%e6%8d%ae%e6%b5%81%e7%a8%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;写数据流程
&lt;/h2&gt;&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;Client 向 Region Server 提交写请求；&lt;/li&gt;
&lt;li&gt;Region Server 找到目标 Region；&lt;/li&gt;
&lt;li&gt;Region 检查数据是否与 Schema 一致；&lt;/li&gt;
&lt;li&gt;如果客户端没有指定版本，则获取当前系统时间作为数据版本；&lt;/li&gt;
&lt;li&gt;将更新写入 WAL Log；&lt;/li&gt;
&lt;li&gt;将更新写入 Memstore；&lt;/li&gt;
&lt;li&gt;判断 Memstore 存储是否已满，如果存储已满则需要 flush 为 Store Hfile 文件。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-8.png&#34;
	width=&#34;1395&#34;
	height=&#34;681&#34;
	srcset=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-8_hu_d2c3f98f2cc52422.png 480w, /zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-8_hu_bd2f42fcfdcea680.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;204&#34;
		data-flex-basis=&#34;491px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;读数据流程&#34;&gt;&lt;a href=&#34;#%e8%af%bb%e6%95%b0%e6%8d%ae%e6%b5%81%e7%a8%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;读数据流程
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;以下是客户端首次读写 HBase 上数据的流程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;客户端从 Zookeeper 获取 META 表所在的 Region Server；&lt;/li&gt;
&lt;li&gt;客户端访问 META 表所在的 Region Server，从 META 表中查询到访问行键所在的 Region Server，之后客户端将&lt;strong&gt;缓存&lt;/strong&gt;这些信息以及 META 表的位置；&lt;/li&gt;
&lt;li&gt;客户端从行键所在的 Region Server 上获取数据。&lt;/li&gt;
&lt;li&gt;如果再次读取，客户端将&lt;strong&gt;从缓存中获取&lt;/strong&gt;行键所在的 Region Server。这样客户端就不需要再次查询 META 表，除非 Region 移动导致缓存失效，这样的话，则将会重新查询并更新缓存。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注： META 表是 HBase 中一张特殊的表，它保存了所有 Region 的位置信息，META 表自己的位置信息 则存储在 ZooKeeper 上。
&lt;img src=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-9.png&#34;
	width=&#34;1404&#34;
	height=&#34;707&#34;
	srcset=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-9_hu_9ee2c9e6c3a06dd9.png 480w, /zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-9_hu_bd7abe86cb55993a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;198&#34;
		data-flex-basis=&#34;476px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;phoenix-简介&#34;&gt;&lt;a href=&#34;#phoenix-%e7%ae%80%e4%bb%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Phoenix 简介
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Phoenix 是 HBase 的开源 SQL 中间层，在 Phoenix 之前，如果要使用  HBase，只能调用它的 Java API，但是 Phoenix 允许使用标准 JDBC 的方式来操作 HBase ！&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Phoenix 的理念是 we put sql SQL back in NOSQL&lt;/strong&gt; ，即可以使用标准的 SQL 就能完成对 HBase 上数据的操作，这也意味着可以&lt;strong&gt;通过集成 Spring Data JPA 或 Mybatis 等常用的持久层框架来操作 HBase&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;其次 Phoenix 的性能表现也非常优异， Phoenix 查询引擎会将 SQL 查询转换为一个或多个 HBase Scan，通过并行执行来生成标准的 JDBC 结果集。它通过直接使用 HBase API 以及协处理器和自定义过 滤器，可以为小型数据查询提供毫秒级的性能，为千万行数据的查询提供秒级的性能。&lt;/li&gt;
&lt;li&gt;同时 Phoenix 还 拥有二级索引等 HBase 不具备的特性，不仅如此 Phoenix 对于用户输入的 SQL 同样会有大量的优化手段（就像 hive 自带 sql 优化器一样）&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
</description>
        </item>
        
    </channel>
</rss>
