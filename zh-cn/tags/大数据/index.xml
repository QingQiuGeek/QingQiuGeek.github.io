<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>大数据 on 青秋博客</title>
        <link>/zh-cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/</link>
        <description>Recent content in 大数据 on 青秋博客</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>青秋博客</copyright>
        <lastBuildDate>Thu, 05 Sep 2024 23:07:21 +0000</lastBuildDate><atom:link href="/zh-cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>一文搞懂大数据流式计算引擎 Flink【万字详解，史上最全】</title>
        <link>/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/</link>
        <pubDate>Thu, 05 Sep 2024 23:07:21 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/</guid>
        <description>&lt;h2 id=&#34;flink-知识图谱&#34;&gt;&lt;a href=&#34;#flink-%e7%9f%a5%e8%af%86%e5%9b%be%e8%b0%b1&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Flink 知识图谱
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image.png&#34;
	width=&#34;1151&#34;
	height=&#34;769&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image_hu_525e59219e7dae9d.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image_hu_d12f9b84c09fa02f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;149&#34;
		data-flex-basis=&#34;359px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;flink-发展&#34;&gt;&lt;a href=&#34;#flink-%e5%8f%91%e5%b1%95&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Flink 发展
&lt;/h2&gt;&lt;p&gt;Apache Flink 诞生于柏林工业大学的一个研究性项目，&lt;strong&gt;原名 StratoSphere&lt;/strong&gt; 。2014 年，由 StratoSphere 项目孵化出 Flink，并于同年捐赠 Apache，之后成为 Apache 的顶级项目。2019 年 1 年，&lt;strong&gt;阿里巴巴收购了 Flink 的母公司 Data Artisans，并宣布开源内部的 Blink&lt;/strong&gt;，Blink 是阿里巴巴基于 Flink 优化后的版本，增加了大量的新功能，并在性能和稳定性上进行了各种优化，经历过阿里内部多种复杂业务的挑战和检验。同时阿里巴巴也表示会逐步将这些新功能和特性 Merge 回社区版本的 Flink 中，因此 Flink 成为目前最为火热的大数据处理框架。&lt;/p&gt;
&lt;h3 id=&#34;四代计算引擎&#34;&gt;&lt;a href=&#34;#%e5%9b%9b%e4%bb%a3%e8%ae%a1%e7%ae%97%e5%bc%95%e6%93%8e&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;四代计算引擎
&lt;/h3&gt;&lt;p&gt;在国外一些社区，有很多人&lt;strong&gt;将大数据的计算引擎分成了 4 代&lt;/strong&gt;，当然，也有很多人不会认同。我们先姑且这么认为和讨论。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先&lt;strong&gt;第一代的计算引擎，无疑就是 Hadoop 承载的 MapReduce&lt;/strong&gt;。这里大家应该都 不会对 MapReduce 陌生，它将计算分为两个阶段，分别为 Map 和 Reduce。对于上层应用来说，就不得不想方设法去拆分算法，甚至于不得不在上层应用实现 多个 Job 的&lt;strong&gt;串联&lt;/strong&gt;，以完成一个完整的算法，例如&lt;strong&gt;迭代计算&lt;/strong&gt; 。 由于这样的弊端，&lt;strong&gt;催生了支持 DAG 框架的产生&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;因此，&lt;strong&gt;支持 DAG 的框架被划分为第二代计算引擎&lt;/strong&gt;。如 Tez 以及更上层的 Oozie。这里我们不去细究各种 DAG 实现之间的区别，不过对于当时的 Tez 和 Oozie 来说，&lt;strong&gt;大多还是批处理的任务&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;接下来就是&lt;strong&gt;以 Spark 为代表的第三代的计算引擎&lt;/strong&gt;。第三代计算引擎的特点主要 是 Job 内部的 DAG 支持（不跨越 Job），以及强调的&lt;strong&gt;准实时计算&lt;/strong&gt;。在这里，很多人也会认为第三代计算引擎也能够很好的运行批处理的 Job。 随着第三代计算引擎的出现，促进了上层应用快速发展，例如各种迭代计算的性能以及对流计算和 SQL 等的支持。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Flink 的诞生就被归在了第四代&lt;/strong&gt;。这应该主 要表现在 Flink 对流计算的支持，以及更一步的实时性上面。当然 Flink 也可 以支持 Batch 的任务，以及 DAG 的运算。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;flink-简介&#34;&gt;&lt;a href=&#34;#flink-%e7%ae%80%e4%bb%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Flink 简介
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Flink 是一个分布式、高性能、**&lt;strong&gt;有状态*&lt;/strong&gt;*的流处理框架&lt;/strong&gt;，它能够对&lt;strong&gt;有界和无界&lt;/strong&gt;的数据流进行高效的处理。Flink 的 **核心是流处理（DataStream），当然也支持批处理（DataSet），Flink 将批处理看成是流处理的一种特殊情况，即数据流是有 明确界限的。**这和 Spark Streaming 的思想是完全相反的，Spark Streaming 的核心是批处理，它将流处理看成是批处理的一种特殊情况， 即把数据流进行极小粒度的拆分，拆分为多个微批处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;flink-特点&#34;&gt;&lt;a href=&#34;#flink-%e7%89%b9%e7%82%b9&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Flink 特点
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;支持高吞吐、低延迟、高性能的流处理&lt;/li&gt;
&lt;li&gt;结果准确，Flink 提供了事件时间和处理时间，对乱序数据仍能提供一直准确的结果&lt;/li&gt;
&lt;li&gt;支持高度灵活的窗口（Window）操作，支持基于 time、count、session， 以及 data-driven 的窗口操作&lt;/li&gt;
&lt;li&gt;支持基于轻量级分布式快照（Snapshot）实现的容错&lt;/li&gt;
&lt;li&gt;一个运行时&lt;strong&gt;同时支持&lt;/strong&gt; Batch on Streaming 处理和 Streaming 处理&lt;/li&gt;
&lt;li&gt;Flink 在 JVM 内部实现了自己的内存管理&lt;/li&gt;
&lt;li&gt;支持迭代计算，Spark 也支持&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;支持程序自动优化&lt;/strong&gt;：避免特定情况下 Shuffle、排序等昂贵操作，中间结果有必要进行缓存&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;批处理和流处理&#34;&gt;&lt;a href=&#34;#%e6%89%b9%e5%a4%84%e7%90%86%e5%92%8c%e6%b5%81%e5%a4%84%e7%90%86&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;批处理和流处理
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;批处理&lt;br&gt;
有界、持久、大量，一般用于离线计算&lt;/li&gt;
&lt;li&gt;流处理&lt;br&gt;
无界、实时，流处理方式无需对整个数据集执行操作，而是&lt;strong&gt;对通过系统传输的每个数据项执行操作&lt;/strong&gt;，一般用于实时统计&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在 Spark 生态体系中，对于批处理和流处理采用了不同的技术框架，&lt;strong&gt;批处理由 SparkSQL 实现，流处理由 Spark Streaming 实现&lt;/strong&gt;，这也是大部分框架采用的策略，使用独立的处理器实现批处理和流处理，而 Flink 可以同时实现批处理和流处理，Flink 将批处理（即处理 有限的静态数据）视作一种特殊的流处理，即&lt;strong&gt;把数据看作是有界的 ！&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;有界流和无界流&#34;&gt;&lt;a href=&#34;#%e6%9c%89%e7%95%8c%e6%b5%81%e5%92%8c%e6%97%a0%e7%95%8c%e6%b5%81&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;有界流和无界流
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;无界数据流：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;有定义流的开始，但没有定义流的结束&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;它们会无休止的产生数据&lt;/li&gt;
&lt;li&gt;无界流的数据必须&lt;strong&gt;持续处理&lt;/strong&gt;，即数据被摄取后需要立刻处理&lt;/li&gt;
&lt;li&gt;我们不能等到所有数据都到达再处理，因为输入是无限的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;有界数据流：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;有定义流的开始，也有定义流的结束&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;有界流可以在摄取所有数据后再进行计算&lt;/li&gt;
&lt;li&gt;有界流所有数据可以被排序，所以并不需要有序摄取&lt;/li&gt;
&lt;li&gt;有界流处理通常被称为批处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;flink-和-spark-streaming&#34;&gt;&lt;a href=&#34;#flink-%e5%92%8c-spark-streaming&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Flink 和 Spark Streaming
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Spark 本质是批处理&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spark 数据模型：Spak 采用 RDD 模型，Spark Streaming 的&lt;strong&gt;DStream 实际上也就是一组组小批据 RDD 的集合&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Spark 运行时架构：Spark 是批计算，将 DAG 划分为不同的 stage,一个完成后才可以计算下一个&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Flink 以流处理为根本&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Flink 数据模型：Flink 基本据模型是数据流，以及事件(Event)序列&lt;/li&gt;
&lt;li&gt;Flink 运行时架构：Flink 是标准的流执行模式，一个事件在一个节点处理完后可以直接发往下一个节点进行处理
&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-1.png&#34;
	width=&#34;1095&#34;
	height=&#34;433&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-1_hu_9ca1dd98d5e3fb30.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-1_hu_fa45f08d20e349ff.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;252&#34;
		data-flex-basis=&#34;606px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;flink-三层核心架构&#34;&gt;&lt;a href=&#34;#flink-%e4%b8%89%e5%b1%82%e6%a0%b8%e5%bf%83%e6%9e%b6%e6%9e%84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Flink 三层核心架构
&lt;/h2&gt;&lt;p&gt;下图为 Flink 技术栈的核心组成部分，由上而下分别是 &lt;strong&gt;API &amp;amp; Libraries 层、Runtime 核心层以及物理部署层。&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;*&lt;strong&gt;*A&lt;/strong&gt;PI &amp;amp; Libraries 层，&lt;strong&gt;提供了面向流式处理的接口（&lt;strong&gt;DataStream API&lt;/strong&gt;）、面向批处理的接口（&lt;strong&gt;DataSet API&lt;/strong&gt;）、用于复杂&lt;/strong&gt;事件处理的 CEP 库**、用于&lt;strong&gt;结构化数据查询的 SQL &amp;amp; Table 库&lt;/strong&gt;、基于**批处理的机器学习库 FlinkML 和 图形处理库 Gelly**。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Runtime 核心层，&lt;strong&gt;这一层是 Flink 分布式计算框架的&lt;/strong&gt;核心实现层&lt;/strong&gt;，包括作业转换，任务调度，资源分配，任务执行等功能，基于这一层的实现，可以在流式引擎下&lt;strong&gt;同时进行&lt;/strong&gt;流处理和批处理。&lt;/li&gt;
&lt;li&gt;**物理部署层，**用于支持在不同平台上部署运行 Flink 应用。
&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-2.png&#34;
	width=&#34;1141&#34;
	height=&#34;710&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-2_hu_62a954499df047d2.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-2_hu_bea4f2ef6babbcf.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;160&#34;
		data-flex-basis=&#34;385px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;api--libraries-层详解&#34;&gt;&lt;a href=&#34;#api--libraries-%e5%b1%82%e8%af%a6%e8%a7%a3&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;API &amp;amp; Libraries 层详解
&lt;/h3&gt;&lt;p&gt;在 API &amp;amp; Libraries 层，有如下更细致的划分，API 的&lt;strong&gt;一致性由下至上依次递增，接口的表现能力由下至上依次递减。&lt;/strong&gt;
&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-3.png&#34;
	width=&#34;1134&#34;
	height=&#34;461&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-3_hu_88170cbc0aee8778.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-3_hu_6e052cc6b154f1b2.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;245&#34;
		data-flex-basis=&#34;590px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;sqltable-api-层&#34;&gt;&lt;a href=&#34;#sqltable-api-%e5%b1%82&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;SQL&amp;amp;Table API 层
&lt;/h4&gt;&lt;p&gt;SQL &amp;amp; Table API &lt;strong&gt;同时适用于批处理和流处理&lt;/strong&gt;，这意味着可以对有界数据流和无界数据流以相同的语义进行查询，并产生相同的结果。除了基本查询外， 它还支持自定义的标量函数，聚合函数以及表值函数，可以满足多样化的查询需求。&lt;/p&gt;
&lt;h4 id=&#34;datastream--dataset-api-层&#34;&gt;&lt;a href=&#34;#datastream--dataset-api-%e5%b1%82&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt; DataStream &amp;amp; DataSet API 层
&lt;/h4&gt;&lt;p&gt;DataStream &amp;amp; DataSet API 是 Flink 数据处理的&lt;strong&gt;核心 API&lt;/strong&gt;，支持使用 Java 语言或 Scala 语言进行调用，提供了数据读取，数据转换和数据输出等一系列常用操作的封装。&lt;/p&gt;
&lt;h4 id=&#34;stateful-stream-processing-层&#34;&gt;&lt;a href=&#34;#stateful-stream-processing-%e5%b1%82&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Stateful Stream Processing 层
&lt;/h4&gt;&lt;p&gt;Stateful Stream Processing 是&lt;strong&gt;最低级别的抽象&lt;/strong&gt;，它通过 Process Function 函数内嵌到 DataStream API 中。 Process Function 是 Flink 提供的最底层 API，具有最大的灵活性，允许开发者&lt;strong&gt;对时间和状态进行细粒度的控制&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;三种-time-概念&#34;&gt;&lt;a href=&#34;#%e4%b8%89%e7%a7%8d-time-%e6%a6%82%e5%bf%b5&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;三种 Time 概念
&lt;/h2&gt;&lt;p&gt;在 Flink 中，如果以时间段划分边界的话，那么时间就是一个极其重要的字段。 Flink 中的时间有三种类型，如下图所示：
&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-4.png&#34;
	width=&#34;1155&#34;
	height=&#34;573&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-4_hu_d5f257a2deabc01d.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-4_hu_6ba617f9c2e1caa1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;201&#34;
		data-flex-basis=&#34;483px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Event Time：是事件创建的时间。它通常由事件中的时间戳描述，即事件本身就要携带时间信息，例如采集的日志数据中，每一条日志都会记录自己的生成时间，Flink 通过时间戳分配器访问事件时间戳。&lt;/li&gt;
&lt;li&gt;Ingestion Time：是数据进入 Flink 的时间。&lt;/li&gt;
&lt;li&gt;Processing Time：是每一个执行基于时间操作的算子的本地系统时间，与机器相关，默认的时间属性就是 Processing Time&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在 Flink 的流式处理中，绝大部分的业务都会使用 eventTime，一般只在 eventTime 无法使用时，才会被迫使用 ProcessingTime&lt;/p&gt;
&lt;h3 id=&#34;watermark-水印&#34;&gt;&lt;a href=&#34;#watermark-%e6%b0%b4%e5%8d%b0&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt; WaterMark 水印
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;流处理从事件产生，到流经 source，再到 operator，中间有一个过程和时间，虽然大部分情况下，流到 operator 的数据都是&lt;strong&gt;按照事件产生的 时间顺序&lt;/strong&gt;来的，但是也不排除&lt;strong&gt;由于网络、背压等原因，导致乱序的产生&lt;/strong&gt;，所谓乱序，就是指 Flink 接收到的事件的先后顺序不是严格按照事件的 Event Time 顺序排列的，所以 Flink 最初设计的时候，就考虑到了网络延迟，网络乱序等问题，所以提出了一个抽象概念：水印（WaterMark）&lt;/li&gt;
&lt;li&gt;当出现乱序，如果只根据 EventTime 决定 Window 的运行，我们不能明确数据是否全部到位，但又不能无限期的等下去， 此时必须要有个机制来保证一个特定的时间后，必须触发 Window 去进行计算了， 这个特别的机制，就是 Watermark。&lt;/li&gt;
&lt;li&gt;Watermark 是用于处理乱序事件的，通常用 Watermark 机制结合 Window 来实现。 数据流中的 Watermark 用于表示 timestamp 小于 Watermark 的数据，都已经到达了，因此，Window 的执行也是由 Watermark 触发的。 Watermark 可以理解成一个延迟触发机制，我们可以设置 Watermark 的延时时长 t ，每次系统会校验已经到达的数据中最大的 maxEventTime，然后认定 EventTime 小于 maxEventTime - t 的所有数据都已经到达，如果有窗口的停止时间等于 maxEventTime - t，那么这个窗口被触发执行。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;对延迟数据的理解&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;延迟数据是指： 在当前窗口【假设窗口范围为 10-15】已经计算之后，又来了一个属于该窗口的 数据【假设事件时间为 13】，这时候仍会触发 Window 操作，这种数据就称为 延迟数据。&lt;/li&gt;
&lt;li&gt;那么问题来了，延迟时间怎么计算呢？&lt;br&gt;
假设窗口范围为 10-15，延迟时间为 2s，则只要 WaterMark=15+2， 10-15 这个窗口就不能再触发 Window 操作，即使新来的数据的 Event Time 属 于这个窗口时间内 。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;windows-窗口类型&#34;&gt;&lt;a href=&#34;#windows-%e7%aa%97%e5%8f%a3%e7%b1%bb%e5%9e%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Windows 窗口类型
&lt;/h2&gt;&lt;p&gt;在大多数场景下，我们需要统计的数据流都是无界的，因此我们无法等待整个数据流终止后才进行统 计。通常情况下，我们只需要&lt;strong&gt;对某个时间范围或者数量范围内的数据&lt;/strong&gt;进行统计分析（&lt;strong&gt;把无限数据分割成块进行计算分析&lt;/strong&gt;）：如每隔五分钟统计一次过去一小时内所有商品的点击量；或者每发生 1000 次点击后，都去统计一下每个商品点击率的占比。在 Flink 中，可以使用窗口 (Window) 来实现这类功能。按照统计维度的不同，Flink 中的窗口可以分为&lt;strong&gt;时间窗口 (Time Windows) 和计数窗口 (Count Windows) 。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;时间窗口&#34;&gt;&lt;a href=&#34;#%e6%97%b6%e9%97%b4%e7%aa%97%e5%8f%a3&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;时间窗口
&lt;/h3&gt;&lt;p&gt;时间窗口以时间点来定义窗口的开始（start）和结束（end），所以截取出的就是某一时间段的数据。到达结束时间时，窗口不再收集数据，触发计算输出结果，并将窗口关闭销毁。所以可以说基本思路就是“定点发车”。&lt;/p&gt;
&lt;h4 id=&#34;滚动窗口-tumbling-windows&#34;&gt;&lt;a href=&#34;#%e6%bb%9a%e5%8a%a8%e7%aa%97%e5%8f%a3-tumbling-windows&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;滚动窗口 Tumbling Windows
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;滚动窗口指彼此之间没有重叠的窗口&lt;/strong&gt;。例如：每隔 1 小时统计过去 1 小时内的商品点击量，那么 1 天就只能分为 24 个窗口，每个窗口之间是&lt;strong&gt;不存在重叠&lt;/strong&gt;的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特点：时间对齐，长度固定，窗口不重叠&lt;/strong&gt;
&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-5.png&#34;
	width=&#34;1025&#34;
	height=&#34;627&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-5_hu_48597f479e73129c.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-5_hu_e6c741da5984e184.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;163&#34;
		data-flex-basis=&#34;392px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;滑动窗口-sliding-windows&#34;&gt;&lt;a href=&#34;#%e6%bb%91%e5%8a%a8%e7%aa%97%e5%8f%a3-sliding-windows&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;滑动窗口 Sliding Windows
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;滑动窗口用于滚动进行聚合分析&lt;/strong&gt;，例如：每隔 6 分钟统计一次过去一小时内所有商品的点击量，那么 1 天可以分为 240 个窗口，统计窗口之间存在重叠。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特点：时间对齐，长度固定，窗口重叠&lt;/strong&gt;
&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-6.png&#34;
	width=&#34;1039&#34;
	height=&#34;663&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-6_hu_6fc72321f98f70e9.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-6_hu_d026d5c08cd8c04.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;156&#34;
		data-flex-basis=&#34;376px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;会话窗口-session-windows&#34;&gt;&lt;a href=&#34;#%e4%bc%9a%e8%af%9d%e7%aa%97%e5%8f%a3-session-windows&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;会话窗口 Session Windows
&lt;/h4&gt;&lt;p&gt;当用户在进行持续浏览时，可能每时每刻都会有点击数据，例如在活动区间内，用户可能频繁的将某类 商品加入和移除购物车，而你只想知道用户本次浏览&lt;strong&gt;最终&lt;/strong&gt;的购物车情况，此时就&lt;strong&gt;等用户持有的会话结束后再进行统计&lt;/strong&gt;。想要实现这类统计，可以通过 Session Windows 来进行实现。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特点：时间不对齐，长度不固定，窗口不重叠&lt;/strong&gt;
&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-7.png&#34;
	width=&#34;1081&#34;
	height=&#34;626&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-7_hu_662b7d65ae53d43a.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-7_hu_fae8d4f126e02735.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;172&#34;
		data-flex-basis=&#34;414px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;全局窗口-global-windows&#34;&gt;&lt;a href=&#34;#%e5%85%a8%e5%b1%80%e7%aa%97%e5%8f%a3-global-windows&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;全局窗口 Global Windows
&lt;/h4&gt;&lt;p&gt;全局窗口会将所有 &lt;strong&gt;key 相同的元素分配到同一个窗口&lt;/strong&gt;中，其通常配合触发器 (trigger) 进行使用。如果没有相应触发器，则计算将不会被执行。
&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-8.png&#34;
	width=&#34;1042&#34;
	height=&#34;587&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-8_hu_15ffce3c19ad12b5.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-8_hu_7ebd2ababe86490e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;计数窗口&#34;&gt;&lt;a href=&#34;#%e8%ae%a1%e6%95%b0%e7%aa%97%e5%8f%a3&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;计数窗口
&lt;/h3&gt;&lt;p&gt;计数窗口基于元素的个数来截取数据，到达固定的个数时就触发计算并关闭窗口。每个窗口截取数据的个数， 就是窗口的大小。基本思路是“人齐发车”。&lt;/p&gt;
&lt;p&gt;Count Windows 用于以数量为维度来进行数据聚合，同样也分为&lt;strong&gt;滚动窗口和滑动窗口&lt;/strong&gt;，实现方式也和 时间窗口基本一致。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：CountWindow 的 window_size 指的是相同 Key 的元素的个数，不是输入的所有元素的总数&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tumbling-count-window (无重叠数据)&lt;/li&gt;
&lt;li&gt;sliding-count-window (有重叠数据)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;状态管理&#34;&gt;&lt;a href=&#34;#%e7%8a%b6%e6%80%81%e7%ae%a1%e7%90%86&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;状态管理
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;参考博客：&lt;/strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/ytp552200ytp/article/details/124793108#:~:text=Flink%20%E6%8F%90%E4%BE%9B%23:~:text=Flink%20%E6%8F%90%E4%BE%9B&#34;  title=&#34;Flink 状态管理详解（超全收藏）_flink状态后端的应用场景-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Flink 状态管理详解（超全收藏）_flink 状态后端的应用场景-CSDN 博客&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;状态的-flink-官方定义&#34;&gt;&lt;a href=&#34;#%e7%8a%b6%e6%80%81%e7%9a%84-flink-%e5%ae%98%e6%96%b9%e5%ae%9a%e4%b9%89&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;  状态的 Flink 官方定义
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;当前计算流程需要依赖到之前计算的结果，那么之前计算的结果就是状态。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;状态分类及状态存储类型&#34;&gt;&lt;a href=&#34;#%e7%8a%b6%e6%80%81%e5%88%86%e7%b1%bb%e5%8f%8a%e7%8a%b6%e6%80%81%e5%ad%98%e5%82%a8%e7%b1%bb%e5%9e%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;  状态分类及状态存储类型
&lt;/h3&gt;&lt;p&gt;相对于其他流计算框架，Flink 一个比较重要的特性就是其**支持有状态计算，即你可以将中间的计算结果进行保存，并提供给后续的计算使用（Spark 的 RDD 也可以保存计算结果供下个 RDD 使用，DAG）&lt;br&gt;
具体而言，Flink 有两种基本类型的状态 (State) ：  键控状态（Keyed State） 与算子状态（Operator State）。**这两种状态可以以两种形式存在：原始状态(raw state) 、托管状态(managed state），托管状态是由 Flink 框架管理的状态，原始状态由用户自行管理状态。&lt;/p&gt;
&lt;h4 id=&#34;算子状态&#34;&gt;&lt;a href=&#34;#%e7%ae%97%e5%ad%90%e7%8a%b6%e6%80%81&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;算子状态
&lt;/h4&gt;&lt;p&gt;算子状态是和算子进行绑定的，与 Key 无关，一个算子的状态不能被其他算子所访问到。官方文档上对 Operator State 的解释是：each operator state is bound to one parallel operator instance，所以更为确切的说一个算子状态是与一个并发的算子实例所绑定的，即假设算子的并行度是 2，那么其应有两个对应的算子状态：
&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-9.png&#34;
	width=&#34;1031&#34;
	height=&#34;697&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-9_hu_845c1b444311144b.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-9_hu_740e14d8da63aae9.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;147&#34;
		data-flex-basis=&#34;355px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;算子状态存储类型&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ListState：存储列表类型的状态。&lt;/li&gt;
&lt;li&gt;UnionListState：存储列表类型的状态，与 ListState 的区别在于：如果并行度发生变化， ListState 会将该算子的所有并发的状态实例进行汇总，然后均分给新的 Task；而 UnionListState 只是将所有并发的状态实例汇总起来，具体的划分行为则由用户进行定义。&lt;/li&gt;
&lt;li&gt;BroadcastState：用于广播的算子状态。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;键控状态&#34;&gt;&lt;a href=&#34;#%e9%94%ae%e6%8e%a7%e7%8a%b6%e6%80%81&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;键控状态
&lt;/h4&gt;&lt;p&gt;键控状态是一种特殊的算子状态，即&lt;strong&gt;状态是根据 key 值进行区分&lt;/strong&gt;的，Flink 会&lt;strong&gt;为每类键值维护一个状态实例&lt;/strong&gt;。如下图所示，每个颜色代表不同 key 值，对应四个不同的状态实例。需要注意的 是键控状态只能在 KeyedStream 上进行使用，我们可以通过 stream.keyBy(&amp;hellip;) 来得到 KeyedStream 。
&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-10.png&#34;
	width=&#34;1058&#34;
	height=&#34;781&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-10_hu_ccfc34a839158b78.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-10_hu_93d51cafda194689.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;135&#34;
		data-flex-basis=&#34;325px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;键控状态存储类型&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ValueState：存储单值类型的状态。可以使用 update(T) 进行更新，并通过 T value() 进行 检索。&lt;/li&gt;
&lt;li&gt;ListState：存储列表类型的状态。可以使用 add(T) 或 addAll(List) 添加元素；并通过 get() 获得整个列表。&lt;/li&gt;
&lt;li&gt;ReducingState：用于存储经过 ReduceFunction 计算后的结果，使用 add(T) 增加元素。 AggregatingState：用于存储经过 AggregatingState 计算后的结果，使用 add(IN) 添加元素。&lt;/li&gt;
&lt;li&gt;FoldingState：已被标识为废弃，会在未来版本中移除，官方推荐使用 AggregatingState 代 替。&lt;/li&gt;
&lt;li&gt;MapState：维护 Map 类型的状态。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;broadcast-state&#34;&gt;&lt;a href=&#34;#broadcast-state&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt; Broadcast State
&lt;/h4&gt;&lt;p&gt;Broadcast State 是 Flink 1.5 引入的新特性。在开发过程中，如果遇到需要 下发/广播配置、规则等低吞吐事件流到下游所有 task 时，就可以使用 Broadcast State 特性。下游的 task 接收这些配置、规则并保存为 BroadcastState, 将这些配置应用到另一个数据流的计算中 。&lt;/p&gt;
&lt;h3 id=&#34;状态后端持久化存储&#34;&gt;&lt;a href=&#34;#%e7%8a%b6%e6%80%81%e5%90%8e%e7%ab%af%e6%8c%81%e4%b9%85%e5%8c%96%e5%ad%98%e5%82%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;状态后端(持久化存储)
&lt;/h3&gt;&lt;p&gt;默认情况下，&lt;strong&gt;所有的状态都存储在 JVM 的堆内存中，在状态数据过多的情况下，这种方式很有可能导致内存溢出&lt;/strong&gt;，因此 Flink 该提供了其它方式来&lt;strong&gt;存储状态数据&lt;/strong&gt;，这些存储方式统一称为状态后端 (或状态管理器)，主要有以下三种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;MemoryStateBackend&lt;/strong&gt;&lt;br&gt;
默认的方式，即基于 &lt;strong&gt;JVM 的堆内存&lt;/strong&gt;进行存储，主要适用于本地开发和调试。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FsStateBackend&lt;/strong&gt;&lt;br&gt;
&lt;strong&gt;基于文件系统进行存储，可以是本地文件系统，也可以是 HDFS 等分布式文件系统&lt;/strong&gt;。 需要注意而是虽然选择使用了 FsStateBackend ，但正在进行的数据仍然是存储在 TaskManager 的内存中的，只有在 checkpoint 时，才会将状态快照写入到指定文件系统上。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RocksDBStateBackend&lt;/strong&gt;&lt;br&gt;
RocksDBStateBackend 是 Flink 内置的&lt;strong&gt;第三方状态管理器&lt;/strong&gt;，采用&lt;strong&gt;嵌入式的 key-value 型数据库 RocksDB&lt;/strong&gt; 来存储正在进行的数据。等到 checkpoint 时，再将其中的数据持久化到指定的文件系统中， 所以采用 RocksDBStateBackend 时也&lt;strong&gt;需要配置持久化存储的文件系统&lt;/strong&gt;。之所以这样做是因为 RocksDB 作为嵌入式数据库安全性比较低，但比起全文件系统的方式，其读取速率更快；比起全内存的方式，其 存储空间更大，因此它是一种比较均衡的方案。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;flink-算子&#34;&gt;&lt;a href=&#34;#flink-%e7%ae%97%e5%ad%90&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Flink 算子
&lt;/h2&gt;&lt;h3 id=&#34;dataset-批处理算子&#34;&gt;&lt;a href=&#34;#dataset-%e6%89%b9%e5%a4%84%e7%90%86%e7%ae%97%e5%ad%90&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;DataSet 批处理算子
&lt;/h3&gt;&lt;h4 id=&#34;source-算子&#34;&gt;&lt;a href=&#34;#source-%e7%ae%97%e5%ad%90&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Source 算子
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;fromCollection：从本地集合读取数据&lt;/li&gt;
&lt;li&gt;readTextFile：从文件中读取&lt;/li&gt;
&lt;li&gt;readTextFile：遍历目录&lt;/li&gt;
&lt;li&gt;readTextFile：读取压缩文件&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;transform-转换算子&#34;&gt;&lt;a href=&#34;#transform-%e8%bd%ac%e6%8d%a2%e7%ae%97%e5%ad%90&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt; Transform 转换算子
&lt;/h4&gt;&lt;p&gt;Transform 算子基于 Source 算子操作，所以要首先构建 Flink 执行环境及 Source 算子。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数据源读入数据之后，就可以使用各种转换算子，将一个或多个 DataStream 转换为新的 DataStream。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;基本转换算子（&lt;strong&gt;map/ filter/ flatMap&lt;/strong&gt;）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;map：将 DataSet 中的每一个元素转换为另外一个元素&lt;/li&gt;
&lt;li&gt;flatMap：将 DataSet 中的每一个元素转换为 0&amp;hellip;n 个元素&lt;/li&gt;
&lt;li&gt;filter：过滤出来一些符合条件的元素，返回 boolean 值为 true 的元素&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;聚合算子（&lt;strong&gt;Aggregation&lt;/strong&gt;）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;reduce：可以对一个 dataset 或者一个 group 来进行聚合计算，最终聚合成一个元素 reduceGroup：将一个 dataset 或者一个 group 聚合成一个或多个元素。reduceGroup 是 reduce 的一种优化方案； 它会先分组 reduce，然后在做整体的 reduce；这样做的好处就是可以减少网络 IO&lt;/li&gt;
&lt;li&gt;minBy 和 maxBy：选择具有最小值或最大值的元素&lt;/li&gt;
&lt;li&gt;Aggregate：在数据集上进行聚合求最值（最大值、最小值），注意： 使用 aggregate，只能使用字段索引名或索引名称来进行分组 groupBy(0) ，否则会报一下错误: Exception in thread &amp;ldquo;main&amp;rdquo; java.lang.UnsupportedOperationException: Aggregate does not support grouping with KeySelector functions, yet.&lt;/li&gt;
&lt;li&gt;&amp;hellip;&amp;hellip;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;sink-输出算子&#34;&gt;&lt;a href=&#34;#sink-%e8%be%93%e5%87%ba%e7%ae%97%e5%ad%90&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt; Sink 输出算子
&lt;/h4&gt;&lt;p&gt;Flink 作为数据处理框架，最终还是要把计算处理的结果写入外部存储，为外部应用提供 支持。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;collect 将数据输出到本地集合&lt;/li&gt;
&lt;li&gt;writeAsText 将数据输出到文件&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;datastream-流处理算子&#34;&gt;&lt;a href=&#34;#datastream-%e6%b5%81%e5%a4%84%e7%90%86%e7%ae%97%e5%ad%90&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;DataStream 流处理算子
&lt;/h3&gt;&lt;p&gt;流处理算子和批处理算子差不多，就不详细解释了。&lt;/p&gt;
&lt;p&gt;参考博客：&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/shudaqi2010/article/details/119115127&#34;  title=&#34;一文学完Flink流计算常用算子（Flink算子大全）_flink算子scala-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;一文学完 Flink 流计算常用算子（Flink 算子大全）_flink 算子 scala-CSDN 博客&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;flink-容错&#34;&gt;&lt;a href=&#34;#flink-%e5%ae%b9%e9%94%99&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Flink 容错
&lt;/h2&gt;&lt;h3 id=&#34;checkpoint-机制&#34;&gt;&lt;a href=&#34;#checkpoint-%e6%9c%ba%e5%88%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt; Checkpoint 机制
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Flink 的 checkpoint 机制原理来自“Chandy-Lamport algorithm”算法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;为了&lt;strong&gt;使状态具有良好的容错性&lt;/strong&gt;，Flink 提供了检查点机制 (CheckPoints) 。通过检查点机制， Flink 定期在数据流上生成 checkpoint barrier ，当某个算子收到 barrier 时，即会基于当前状态生成一份&lt;strong&gt;快照&lt;/strong&gt;，然后再将该 barrier 传递到下游算子，下游算子接收到该 barrier 后，也基于当前状态生成一份快照，&lt;strong&gt;依次传递直至到最后的 Sink 算子上&lt;/strong&gt;。当出现异常后，Flink 就可以根据最近的一次的快照数据将所有算子恢复到先前的状态。（Spark 也有 Checkpoint 机制）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;简单理解为 checkpoint 是把 state 数据定时持久化存储了&lt;/strong&gt;
&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-11.png&#34;
	width=&#34;1194&#34;
	height=&#34;493&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-11_hu_4adf5fa87f2aec5f.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-11_hu_724f20ef0a7405f1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;242&#34;
		data-flex-basis=&#34;581px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;flink-cep&#34;&gt;&lt;a href=&#34;#flink-cep&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Flink CEP
&lt;/h2&gt;&lt;p&gt;Complex Event Processing，复杂事件处理，Flink CEP 是一个基于 Flink 的复杂事件处理库，可以从多个数据流中&lt;strong&gt;发现复杂事件，识别有意义的事件&lt;/strong&gt;（例如机会或者威胁），并尽快的做出响应，而不是需要等待几天或则几个月相当长的时间，才发现问题。&lt;/p&gt;
&lt;h3 id=&#34;使用场景&#34;&gt;&lt;a href=&#34;#%e4%bd%bf%e7%94%a8%e5%9c%ba%e6%99%af&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;使用场景  
&lt;/h3&gt;&lt;p&gt;检测恶意用户和刷屏用户&lt;/p&gt;
&lt;p&gt;实时反作弊和风控&lt;/p&gt;
&lt;p&gt;实时营销&lt;/p&gt;
&lt;p&gt;实时网络攻击检测&lt;/p&gt;
&lt;h3 id=&#34;cep-api&#34;&gt;&lt;a href=&#34;#cep-api&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;CEP API
&lt;/h3&gt;&lt;p&gt;CEP API 的核心是 &lt;strong&gt;Pattern(模式) API，它允许你快速定义复杂的事件模式&lt;/strong&gt;。每 个模式包含多个阶段（stage）或者也可称为状态（state）。从一个状态切换到另一个状态，用户可以指定条件，这些条件可以作用在邻近的事件或独立事件上。&lt;/p&gt;
&lt;h2 id=&#34;flink-cdc&#34;&gt;&lt;a href=&#34;#flink-cdc&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Flink CDC
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;CDC 是 Change Data Capture（&lt;strong&gt;变更数据获取&lt;/strong&gt;）的简称。核心思想是，&lt;strong&gt;监测并捕获数据库的变动&lt;/strong&gt;（包括数据或数据表的插入、更新以及删除等，和 Flume 很像，不过 Flume 是监控的系统日志），将这些变更&lt;strong&gt;按发生的顺序完整记录&lt;/strong&gt;下来，&lt;strong&gt;写入到消息中间件中以供其他服务进行订阅及消费&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;在广义的概念上，只要能捕获数据变更的技术，我们都可以称为 CDC 。通常我们说的 CDC 技术&lt;strong&gt;主要面向数据库的变更&lt;/strong&gt;，是一种用于捕获数据库中数据变更的技术。&lt;/li&gt;
&lt;li&gt;CDC 技术应用场景非常广泛：&lt;br&gt;
数据同步，用于备份，容灾；&lt;br&gt;
数据分发，一个数据源分发给多个下游；&lt;br&gt;
数据采集(E)，面向数据仓库/数据湖的 ETL 数据集成&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cdc-种类&#34;&gt;&lt;a href=&#34;#cdc-%e7%a7%8d%e7%b1%bb&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;CDC 种类
&lt;/h3&gt;&lt;p&gt;CDC 主要分为基于查询和基于 Binlog 两种方式，我们主要了解一下这两种之间的区别：
&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-12.png&#34;
	width=&#34;1006&#34;
	height=&#34;380&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-12_hu_3b9489096a84d916.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-flink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/image-12_hu_a6bd3090da142ce7.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;264&#34;
		data-flex-basis=&#34;635px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;flink-sql&#34;&gt;&lt;a href=&#34;#flink-sql&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Flink SQL
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Flink SQL 是 Flink 实时计算为简化计算模型，&lt;strong&gt;降低用户使用实时计算门槛而设计的一套符合标准 SQL 语义的开发语言（为了降低 Spark 门槛，也有 Spark SQL；为了降低 HBase 门槛，有了 Phoneix；为了方便的操作 HDFS 文件，有了 Hive SQL&amp;hellip;&amp;hellip;）&lt;/strong&gt;。 自 2015 年开始，阿里巴巴开始调 研开源流计算引擎，最终决定基于 Flink 打造新一代计算引擎，针对 Flink 存在的不足进行优化和改进，并且在 2019 年初将最终代码开源，也就是我们熟知 的 Blink。Blink 在原来的 Flink 基础上最显著的一个贡献就是 Flink SQL 的 实现。&lt;/li&gt;
&lt;li&gt;Flink SQL 是面向用户的 API 层，在我们传统的流式计算领域，比如 Storm、 Spark Streaming 都会提供一些 Function 或者 Datastream API，用户通过 Java 或 Scala 写业务逻辑，这种方式虽然灵活，但有一些不足，比如具备一定门槛且调优较难，随着版本的不断更新，API 也出现了很多不兼容的地方。在这个背景下，毫无疑问，SQL 就成了我们最佳选择！&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>一文入门大数据准流式计算引擎 Spark【万字详解，全网最新】</title>
        <link>/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/</link>
        <pubDate>Wed, 04 Sep 2024 00:12:24 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/</guid>
        <description>&lt;h2 id=&#34;spark-简介&#34;&gt;&lt;a href=&#34;#spark-%e7%ae%80%e4%bb%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Spark 简介
&lt;/h2&gt;&lt;p&gt;Spark 于 2009 年诞生于加州大学伯克利分校 AMPLab，2013 年被捐赠给 Apache 软件基金会，2014 年 2 月成为 Apache 的顶级项目。&lt;/p&gt;
&lt;p&gt;相对于 MapReduce 的批处理计算，&lt;strong&gt;Spark 基于内存计算&lt;/strong&gt;，可以带来上百倍的性能提升，因此它成为继 MapReduce 之后，最为广泛使用的&lt;strong&gt;分布式计算框架、大数据分析引擎&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;spark-特点&#34;&gt;&lt;a href=&#34;#spark-%e7%89%b9%e7%82%b9&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Spark 特点
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;快&lt;/strong&gt;：采用&lt;strong&gt;DAG 执行引擎，支持循环数据流和内存计算&lt;/strong&gt;，使得 Spark 速度更快，在内存中的速度 是 Hadoop MR 的百倍，在磁盘上的速度是 Hadoop MR 的十倍(官网数据)。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;通用&lt;/strong&gt;：Spark 提供了统一的解决方案。Spark 可以⽤于批处理、交互式查询（Spark SQL）、实时流处理（Spark Streaming）、机器学习（Spark MLlib）和图计算（GraphX）。这些不同类型的处理都可以在同⼀个应用中无缝使用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;易用&lt;/strong&gt;：Spark 支持 Java、Python、Scala 的 API 和超过 80 种⾼级算法，⽽且⽀持交互式的 Python 和 Scala 的 shell。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;兼容&lt;/strong&gt;：Spark 可以使⽤ Hadoop 的 YARN 和 Apache Mesos 作为它的资源管理和调度器，器，并且不需要任何数据迁移就可以处理所有 Hadoop 支持的数据，包括 HDFS、HBase 和 Cassandra 等。Spark 也可以不依赖于第三⽅的资源管理和调度器，它实现了 Standalone 作为其内置的资源管理和调度框架。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;spark-和-mr-处理任务对比&#34;&gt;&lt;a href=&#34;#spark-%e5%92%8c-mr-%e5%a4%84%e7%90%86%e4%bb%bb%e5%8a%a1%e5%af%b9%e6%af%94&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Spark 和 MR 处理任务对比
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image.png&#34;
	width=&#34;1035&#34;
	height=&#34;335&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image_hu_89e9ef41d7701caf.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image_hu_f7a2df21a1ec0d1c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;308&#34;
		data-flex-basis=&#34;741px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-1.png&#34;
	width=&#34;1087&#34;
	height=&#34;353&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-1_hu_970b3d5f166717f5.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-1_hu_7983b45c642d74f9.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;307&#34;
		data-flex-basis=&#34;739px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;spark-组件&#34;&gt;&lt;a href=&#34;#spark-%e7%bb%84%e4%bb%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Spark 组件
&lt;/h2&gt;&lt;h3 id=&#34;spark-core&#34;&gt;&lt;a href=&#34;#spark-core&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Spark Core
&lt;/h3&gt;&lt;p&gt;Spark Core 实现了 Spark 的基本功能，包含任务调度、内存管理、错误恢复、与存储系统 交互等模块。Spark Core 中还包含 了对弹性分布式数据集(resilient distributed dataset，简称 RDD)的 API 定义。&lt;/p&gt;
&lt;h4 id=&#34;rdd-算子&#34;&gt;&lt;a href=&#34;#rdd-%e7%ae%97%e5%ad%90&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;RDD 算子
&lt;/h4&gt;&lt;h5 id=&#34;为什么有-rdd&#34;&gt;&lt;a href=&#34;#%e4%b8%ba%e4%bb%80%e4%b9%88%e6%9c%89-rdd&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;为什么有 RDD？
&lt;/h5&gt;&lt;p&gt;在许多迭代式算法(比如机器学习、图算法等)和交互式数据挖掘中，不同计算阶段之间会重用中间结果，即&lt;strong&gt;一个阶段的输出结果会作为下一个阶段的输入&lt;/strong&gt;。但是， 之前的 &lt;strong&gt;MapReduce 框架采用非循环式的数据流模型&lt;/strong&gt;，把中间结果写入到 HDFS 中，带来了大量的数据复制、磁盘 IO 和序列化开销，且这些框架只能支持一些 特定的计算模式(map/reduce)，并没有提供一种&lt;strong&gt;通用的数据抽象&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;RDD 提供了一个抽象的数据模型，让我们不必担心底层数据的分布式特性，只需&lt;strong&gt;将具体的应用逻辑表达为一系列转换操作(函数)&lt;/strong&gt; ，不同 RDD 之间的转换操作之间还可以形成依赖关系，进而实现&lt;strong&gt;管道化&lt;/strong&gt;，从而&lt;strong&gt;避免了中间结果的存储&lt;/strong&gt;，大大降低数据复制、磁盘 IO 和序列化开销，并且还提供了更多的 API 操作！&lt;/p&gt;
&lt;h5 id=&#34;rdd-介绍&#34;&gt;&lt;a href=&#34;#rdd-%e4%bb%8b%e7%bb%8d&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;RDD 介绍
&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;RDD（Resilient Distributed Dataset）叫做&lt;strong&gt;弹性分布式数据集&lt;/strong&gt;，是 Spark 中&lt;strong&gt;最基本的数据抽象&lt;/strong&gt;，是 Spark 计算的基石，它代表⼀个不可变、可分区、里面的元素可并行计算的集合。&lt;/li&gt;
&lt;li&gt;RDD 具有数据流模型的特点：自动容错、位置感知性调度和可伸缩性。RDD 允许用户在执⾏多个查询时显式地将⼯作集缓存在内存中，后续的查询能够&lt;strong&gt;重⽤⼯作集&lt;/strong&gt;，这极⼤地提升了查询速度。&lt;/li&gt;
&lt;li&gt;MR 中对数据是没有进行抽象的，而在 Spark 中对数据进行了抽象，提供⼀些列处理⽅法也就是 RDD，为用户屏蔽了底层对数据的复杂抽象和处理，为⽤户提供了⼀组⽅便 的数据转换与求值方法，好比 Java 中类的封装。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;注意 : RDD 本身是不存储数据，而是记录了数据的位置，数据的转换关系(调用什么方法、传入什么函数)！！！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;以下是 RDD 源码翻译解读：&lt;/strong&gt; &lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-2.png&#34;
	width=&#34;1083&#34;
	height=&#34;1150&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-2_hu_1a232703d894b756.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-2_hu_b23baff52680b4e9.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;94&#34;
		data-flex-basis=&#34;226px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;rdd-特点&#34;&gt;&lt;a href=&#34;#rdd-%e7%89%b9%e7%82%b9&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;RDD 特点
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;弹性体现：
&lt;ol&gt;
&lt;li&gt;存储的弹性：内存与磁盘的自动切换；&lt;/li&gt;
&lt;li&gt;容错的弹性：RDD 的血统（Lineag）会&lt;strong&gt;记录 RDD 的元数据信息和转换行为&lt;/strong&gt; ，当 RDD 的部分分区数据丢失时，它可以根据这些信息来重新运算并恢复丢失的数据分区。&lt;/li&gt;
&lt;li&gt;计算的弹性：计算出错重试机制；&lt;/li&gt;
&lt;li&gt;分片的弹性：可根据需要重新分片；&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;分布式：数据存储在大数据集群不同节点上&lt;/li&gt;
&lt;li&gt;数据集：RDD&lt;strong&gt;封装了计算逻辑&lt;/strong&gt;，并不保存数据&lt;/li&gt;
&lt;li&gt;数据抽象：RDD 是⼀个抽象，需要具体实现&lt;/li&gt;
&lt;li&gt;不可变：RDD 封装的&lt;strong&gt;计算逻辑不可改变&lt;/strong&gt;，想要改变只能产⽣新的 RDD&lt;/li&gt;
&lt;li&gt;可分区、并行计算&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;rdd-做了什么&#34;&gt;&lt;a href=&#34;#rdd-%e5%81%9a%e4%ba%86%e4%bb%80%e4%b9%88&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;RDD 做了什么
&lt;/h4&gt;&lt;p&gt;从计算的角度来讲，数据处理过程中需要计算资源（内存 &amp;amp; CPU）和计算模型（逻辑）。执⾏时，需要&lt;strong&gt;将计算资源 和计算模型进行协调和整合&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;Spark 框架在执行时，先申请资源，然后将应⽤程序的数据处理逻辑&lt;strong&gt;分解成⼀个⼀个的计算任务&lt;/strong&gt;。然后将&lt;strong&gt;任务分发到已经分配资源的计算节点&lt;/strong&gt;上, &lt;strong&gt;按照指定的计算模型进行数据计算&lt;/strong&gt;。最后得到计算结果。&lt;/p&gt;
&lt;h4 id=&#34;rdd-的转换和行动操作&#34;&gt;&lt;a href=&#34;#rdd-%e7%9a%84%e8%bd%ac%e6%8d%a2%e5%92%8c%e8%a1%8c%e5%8a%a8%e6%93%8d%e4%bd%9c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;RDD 的转换和行动操作
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;RDD 算子分为两种类型的操作：&lt;strong&gt;转换操作和行动操作&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;转换操作是返回⼀个新的 RDD 的操作&lt;/strong&gt;，比如 map 和 flatMap&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;行动操作则是向 Driver 返回结果或将结果写出到外部存在设备&lt;/strong&gt;，比如 collect 和 saveAsTextFile&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;transformation转换算子概述&#34;&gt;&lt;a href=&#34;#transformation%e8%bd%ac%e6%8d%a2%e7%ae%97%e5%ad%90%e6%a6%82%e8%bf%b0&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;  Transformation(转换)算子概述
&lt;/h5&gt;&lt;p&gt;RDD 中的所有转换都是&lt;strong&gt;延迟加载&lt;/strong&gt;的，它们只是记住这些应⽤到基础数据集上的转换动作，并&lt;strong&gt;不会直接计算结果&lt;/strong&gt;。只有当发生⼀个要求返回结果给 Driver 的动作时，这些转换才会真正运 行。&lt;strong&gt;这样可以在 Action 时对 RDD 操作形成 DAG 有向无环图进行 Stage 的划分和并行优化，这这种设计让 Spark 更加有效率地运行！&lt;/strong&gt; 列举部分算子：
&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-3.png&#34;
	width=&#34;1023&#34;
	height=&#34;1298&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-3_hu_c5d2997a79139ab.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-3_hu_cb7a2e436729642b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;78&#34;
		data-flex-basis=&#34;189px&#34;
	
&gt;&lt;/p&gt;
&lt;h5 id=&#34;action行动算子概述&#34;&gt;&lt;a href=&#34;#action%e8%a1%8c%e5%8a%a8%e7%ae%97%e5%ad%90%e6%a6%82%e8%bf%b0&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Action(行动)算子概述  
&lt;/h5&gt;&lt;p&gt;&lt;strong&gt;在 RDD 上运⾏计算,并返回结果给 Driver 或写入文件系统&lt;/strong&gt;， 列举部分算子：
&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-4.png&#34;
	width=&#34;1251&#34;
	height=&#34;1100&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-4_hu_9d60be3e9c41d5f1.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-4_hu_778af530c8906f5b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;113&#34;
		data-flex-basis=&#34;272px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;rdd-持久化和缓存&#34;&gt;&lt;a href=&#34;#rdd-%e6%8c%81%e4%b9%85%e5%8c%96%e5%92%8c%e7%bc%93%e5%ad%98&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;RDD 持久化和缓存
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Spark 速度非常快的原因之⼀，就是在不同操作中可以&lt;strong&gt;在内存中持久化或缓存多个数据集&lt;/strong&gt;。当持久化某个 RDD 后， 每⼀个节点都将把计算的分片结果保存在内存中，并在对此 RDD 或衍⽣出的 RDD 进行的其他动作中&lt;strong&gt;重⽤&lt;/strong&gt;，这使得后续的动作变得更加迅速！&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;缓存是 Spark 构建迭代式算法和快速交互式查询的关键&lt;/strong&gt;。如果⼀个有持久化数据的节点发⽣故障，&lt;strong&gt;Spark 会在需要⽤到缓存的数据时重算丢失的数据分区&lt;/strong&gt;。如果希望节点故障的情况不会拖累我们的执⾏速度，也可以把数据备份到多个节点上。&lt;/li&gt;
&lt;li&gt;RDD 通过 &lt;strong&gt;persist 或 cache 方法&lt;/strong&gt;可以将前面的计算结果缓存，但是&lt;strong&gt;并不是这两个方法被调用时立即缓存&lt;/strong&gt;，而是触发后面的 action 时，该 RDD 将会被缓存在 计算节点的内存中，并供后面重用。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;存储级别&#34;&gt;&lt;a href=&#34;#%e5%ad%98%e5%82%a8%e7%ba%a7%e5%88%ab&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;存储级别
&lt;/h4&gt;&lt;p&gt;默认的存储级别都是&lt;strong&gt;仅在内存存储一份&lt;/strong&gt;，Spark 的存储级别还有好多种，存储级别在 object StorageLevel 中定义的。
&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-5.png&#34;
	width=&#34;1080&#34;
	height=&#34;332&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-5_hu_c4d5bafc32f65d98.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-5_hu_5824fac9db300d96.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;325&#34;
		data-flex-basis=&#34;780px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-6.png&#34;
	width=&#34;1097&#34;
	height=&#34;562&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-6_hu_dce8c9f1f7f4dbd6.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-6_hu_c6cb38245d53f62f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;195&#34;
		data-flex-basis=&#34;468px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;checkpoint-检查点机制&#34;&gt;&lt;a href=&#34;#checkpoint-%e6%a3%80%e6%9f%a5%e7%82%b9%e6%9c%ba%e5%88%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Checkpoint 检查点机制  
&lt;/h4&gt;&lt;p&gt;Spark 中对于数据的保存除了持久化操作之外，还提供了⼀种&lt;strong&gt;检查点的机制&lt;/strong&gt;，检查点（本质是通过将 RDD 写入 Disk 做检查点）是为了&lt;strong&gt;通过血统（lineage）做持久化容错的辅助&lt;/strong&gt;，lineage 过长会造成容错成本过高，这样就不如在中间阶段做检查点容错，如果之后有节点出现问题⽽丢失分区，&lt;strong&gt;从做检查点的 RDD 开始重做 Lineage&lt;/strong&gt;，就会减少资源开销。检查点通过将数据写⼊到 HDFS 文件系统实现了 RDD 的检查点功能。&lt;/p&gt;
&lt;h4 id=&#34;rdd-宽窄依赖&#34;&gt;&lt;a href=&#34;#rdd-%e5%ae%bd%e7%aa%84%e4%be%9d%e8%b5%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;RDD 宽窄依赖
&lt;/h4&gt;&lt;p&gt;RDD 和 它依赖的父 RDD 的关系有两种不同的类型，&lt;/p&gt;
&lt;p&gt;宽依赖(wide dependency/shuffle dependency) ：父 RDD 的一个分区被子 RDD 的多个分区依赖(涉及到 shuffle)&lt;/p&gt;
&lt;p&gt;窄依赖(narrow dependency）：父 RDD 的一个分区只会被子 RDD 的一个分区依赖；
&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-7.png&#34;
	width=&#34;1065&#34;
	height=&#34;289&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-7_hu_51d87d4518550f98.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-7_hu_a820f9abd888888e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;368&#34;
		data-flex-basis=&#34;884px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-8.png&#34;
	width=&#34;1033&#34;
	height=&#34;754&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-8_hu_95162decf3b9916a.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-8_hu_a724399596932073.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;137&#34;
		data-flex-basis=&#34;328px&#34;
	
&gt;&lt;/p&gt;
&lt;h5 id=&#34;为什么要设计宽窄依赖&#34;&gt;&lt;a href=&#34;#%e4%b8%ba%e4%bb%80%e4%b9%88%e8%a6%81%e8%ae%be%e8%ae%a1%e5%ae%bd%e7%aa%84%e4%be%9d%e8%b5%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;为什么要设计宽窄依赖
&lt;/h5&gt;&lt;p&gt;对于窄依赖： 窄依赖的多个分区可以并行计算；窄依赖的一个分区的数据如果丢失只需要重新计算对应的分区的数据就可以了。&lt;/p&gt;
&lt;p&gt;对于宽依赖： 划分 Stage(阶段)的依据，对于宽依赖，必须等到上一阶段计算完成才能计算下 一阶段。&lt;/p&gt;
&lt;h5 id=&#34;dag-生成和划分-stage&#34;&gt;&lt;a href=&#34;#dag-%e7%94%9f%e6%88%90%e5%92%8c%e5%88%92%e5%88%86-stage&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;DAG 生成和划分 Stage
&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;DAG 是什么？&lt;/strong&gt;&lt;br&gt;
DAG(有向无环图)指的是&lt;strong&gt;数据转换执行的过程&lt;/strong&gt;，有方向，无闭环(其实就是 RDD 执行的流程)；&lt;strong&gt;原始的 RDD 通过一系列的转换操作就形成了 DAG 有向无环图&lt;/strong&gt;，任务执行时，可以按照 DAG 的描述，执行真正的计算(数据被操作的一个过程)。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DAG 的边界&lt;/strong&gt;&lt;br&gt;
开始：通过 SparkContext 创建的 RDD&lt;br&gt;
结束：触发 Action，一旦触发 Action 就会形成一个完整的 DAG&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;DAG 划分 Stage&lt;/strong&gt; &lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-9.png&#34;
	width=&#34;1004&#34;
	height=&#34;334&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-9_hu_a38ceff118ea72f0.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-9_hu_244cfc01d9359b3c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;300&#34;
		data-flex-basis=&#34;721px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;一个 Spark 程序可以有多个 DAG&lt;/strong&gt;(有几个 Action，就有几个 DAG)。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;一个 DAG 可以有多个 Stage&lt;/strong&gt;(根据宽依赖/shuffle 进行划分)。&lt;/li&gt;
&lt;li&gt;同一个 Stage 可以有多个 Task 并行执行(task 数=分区数，如上图，Stage1 中 有三个分区 P1、P2、P3，对应的也有三个 Task)。&lt;/li&gt;
&lt;li&gt;可以看到这个 DAG 中 &lt;strong&gt;reduceByKey 操作是一个宽依赖，Spark 内核会以此为边界将其前后划分成不同的 Stage。&lt;/strong&gt; 同时在图 Stage1 中，从 textFile 到 flatMap 到 map 都是窄依赖，这几步操作可以形成一个流水线操作，通过 flatMap 操作生成 partition 不用等待整个 RDD 计算结束，可以直接进行 map 操作，这样大大 提高了计算的效率。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;spark-sql&#34;&gt;&lt;a href=&#34;#spark-sql&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Spark SQL
&lt;/h3&gt;&lt;h4 id=&#34;spark-sql-发展精彩&#34;&gt;&lt;a href=&#34;#spark-sql-%e5%8f%91%e5%b1%95%e7%b2%be%e5%bd%a9&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Spark SQL 发展（精彩）
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Spark SQL 是构建在 SparkCore 基础之上的⼀个基于 SQL 的计算模块&lt;/strong&gt;。 SparkSQL 的前身叫【Shark】，最开始 Shark 的底层代码优化、sql 的解析、执行引擎等完全基于 Hive（Shark On Hive），Hive 实现了 SQL on Hadoop，使用 MapReduce 执行任务，但是使用 MapReduce 做计算（Hive On MR），使得 Hive 的查询延迟比较高，而 Shark 改写 Hive 的物理执行计划，使用 Shark 代替 MapReduce 物理引擎（Hive On Shark），使用列式内存存储，使得 Shark 执行速度比 Hive 快，然而 Shark 执行计划的生成严重依赖 Hive（Shark On Hive On Shark），想要增加新的优化非常困难； &lt;strong&gt;并且 Hive 是进程级别的并行，Spark 是线程级别的并行&lt;/strong&gt;，所以 Hive 中很多线程不安全的代码不适用于 Shark，所以在 15 年中旬的时候，Shark 负责⼈，将 Shark 项⽬结束掉，重新独⽴出来的⼀个项⽬，就是 SparkSQL，不再依赖 Hive，此后逐渐的形成两条互相独立的业务：SparkSQL 和 Hive-On-Spark。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如果说 Hive 是将 SQL 转化为 MR，那么 SparkSQL 是将 SQL 转换成 RDD+优化执行，因为我们直接操作 RDD 需要编程实现（学习成本），有了 SQL 我们即使不懂编程也可以实现 RDD 计算！&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;spark-sql-概述&#34;&gt;&lt;a href=&#34;#spark-sql-%e6%a6%82%e8%bf%b0&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Spark SQL 概述
&lt;/h4&gt;&lt;p&gt;Spark SQL&lt;strong&gt;主要用于结构化数据（数据分为结构化数据、半结构化数据、非结构化数据）RDD 主要用于处理非结构化、半结构化、结构化数据。与 RDD API 编程式操作不同，Spark SQL 可以使用 SQL 完成数据分析计算&lt;/strong&gt;，Spark SQL 提供的接口为 Spark&lt;strong&gt;提供了有关数据结构和正在执⾏的计算的更多信息&lt;/strong&gt;。在内部，Spark SQL 使⽤这些额外的信息来执⾏&lt;strong&gt;额外的优化&lt;/strong&gt;。有几种与 Spark SQL 交互的⽅法，包括 SQL 和 Dataset API。计算结果时，将使⽤相同的执⾏引擎，这与⽤于表示计算的 API/语⾔⽆关。这种统⼀意味着开发⼈员可以轻松地在不同的 API 之间来回切换，基于 API 的切换提供了表示给定转换的最⾃然的⽅式。&lt;/p&gt;
&lt;h4 id=&#34;spark-sql-特点&#34;&gt;&lt;a href=&#34;#spark-sql-%e7%89%b9%e7%82%b9&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Spark SQL 特点
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;集成性&lt;/li&gt;
&lt;li&gt;统一性&lt;/li&gt;
&lt;li&gt;集成 Hive&lt;/li&gt;
&lt;li&gt;支持多种数据源&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;spark-sql-数据模型-dataframe-和-dataset&#34;&gt;&lt;a href=&#34;#spark-sql-%e6%95%b0%e6%8d%ae%e6%a8%a1%e5%9e%8b-dataframe-%e5%92%8c-dataset&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Spark SQL 数据模型 DataFrame 和 Dataset
&lt;/h4&gt;&lt;p&gt;我们可以通过两种方式使用 Spark，一种是命令式，使用 Spark shell 编程操作 RDD，另一种是通过 SparkSQL 的数据模型 DataFrame 和 Dataset&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DataFrame 和 Dataset 可以理解为是⼀张 mysql 中的⼆维表，表有什么？表头，表名，字段，字段类型。&lt;strong&gt;RDD 其实说白了也是⼀张二维表，但是这张二维表相比较于 DataFrame 和 Dataset 却少了很多东西，比如表头，表名，字段，字段类型，只有数据和操作数据的方法&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;DataFrame 是 1.3 的时候出现的，Dataset 是在 spark 1.6.2 出现的，**早期的时候 DataFrame 叫 SchemaRDD，SchemaRDD 和 RDD 相比，就多了 Schema，所谓元数据信息。**相比 DataFrame，&lt;strong&gt;Dataset 提供了编译时类型检查&lt;/strong&gt;，对于分布式程序来讲，提交⼀次作业要编译、打包、上传、运行，到提交到集群运行时才发现错误，很麻烦，这也是引⼊ Dataset 的⼀个重要原因！&lt;/li&gt;
&lt;li&gt;⼀般的，将 RDD 称之为 Spark 体系中的第一代编程模型；&lt;strong&gt;DataFrame 比 RDD 多了⼀个 Schema 元数据信息&lt;/strong&gt;，被称之为 Spark 体系中的第⼆代编程模型；Dataset 吸收了 RDD 的优点(强类型推断、函数式编程)和 DataFrame 中的优化(SQL 优化引擎、内存列存储)，成为 Spark 的最新⼀代的编程模型。
&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-10.png&#34;
	width=&#34;1205&#34;
	height=&#34;705&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-10_hu_e1c418e12b863467.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-10_hu_f17bda282b48d1ff.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;170&#34;
		data-flex-basis=&#34;410px&#34;
	
&gt; &lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-11.png&#34;
	width=&#34;1214&#34;
	height=&#34;290&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-11_hu_dc655840c25e6a22.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-11_hu_3aebb3b080d30b91.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;418&#34;
		data-flex-basis=&#34;1004px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;如何进行-sparksql-编&#34;&gt;&lt;a href=&#34;#%e5%a6%82%e4%bd%95%e8%bf%9b%e8%a1%8c-sparksql-%e7%bc%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;如何进行 SparkSQL 编
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Spark Core 中，如果想要执行应用程序，需要首先&lt;strong&gt;构建上下文环境对象 SparkContext&lt;/strong&gt;，&lt;strong&gt;Spark SQL 其实可以理解为对 Spark Core 的⼀种封装，不仅仅在模型上进行了封装，上下文环境对象也进行了封装。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;在老的版本中，SparkSQL 提供两种 SQL 查询起始点：⼀个叫&lt;strong&gt;SQLContext&lt;/strong&gt;，⽤于 Spark 自己提供的 SQL 查询； ⼀个叫&lt;strong&gt;HiveContext&lt;/strong&gt;，⽤于连接 Hive 的查询。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SparkSession 是 Spark 最新的 SQL 查询起始点，实质上是 SQLContext 和 HiveContext 的组合&lt;/strong&gt;，所以在 SQLContex 和 HiveContext 上可⽤的 API 在 Spark Session 上同样是可以使⽤的。&lt;/li&gt;
&lt;li&gt;SparkSession 内部封装了 SparkContext，所以计算实际上是由 sparkContext 完成的。 &lt;strong&gt;构建 SparkSession 需要依赖 SparkConf 或者 SparkContext&lt;/strong&gt;，可以使⽤⼯⼚构建器(Builder ⽅式)模式创建 SparkSession。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;spark-streaming&#34;&gt;&lt;a href=&#34;#spark-streaming&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Spark Streaming
&lt;/h3&gt;&lt;h4 id=&#34;简介&#34;&gt;&lt;a href=&#34;#%e7%ae%80%e4%bb%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;简介
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Spark Streaming 是 Spark 提供的对&lt;strong&gt;实时数据&lt;/strong&gt;进行**流式计算（实时计算）**的组件。提供了用来操作数据流的 API，并且与 Spark Core 中的 RDD API 高度对应。&lt;/li&gt;
&lt;li&gt;从计算的延迟上⾯，又可以分为&lt;strong&gt;纯实时流式计算和准实时流式计算，SparkStreaming 属于准实时计算框架&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;所谓纯实时的计算，指的是&lt;strong&gt;来⼀条记录(event 事件)，启动⼀次计算的作业&lt;/strong&gt;；离线计算指的是每次计算非常大的⼀批(比如几百 G，好几个 T)数据；准实时则是介于纯实时和离线计算之间的⼀种计算方式，那就是微批处理，即&lt;strong&gt;把大量数据微分成多小批进行计算&lt;/strong&gt;，近似看成流计算。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;流式计算特点&#34;&gt;&lt;a href=&#34;#%e6%b5%81%e5%bc%8f%e8%ae%a1%e7%ae%97%e7%89%b9%e7%82%b9&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;流式计算特点
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;数据是无界的(unbounded)&lt;/li&gt;
&lt;li&gt;数据是动态的&lt;/li&gt;
&lt;li&gt;计算速度快&lt;/li&gt;
&lt;li&gt;计算不止一次&lt;/li&gt;
&lt;li&gt;计算不能终止&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;离线计算特点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据是有界的(Bounded)&lt;/li&gt;
&lt;li&gt;数据静态的&lt;/li&gt;
&lt;li&gt;计算速度通常较慢&lt;/li&gt;
&lt;li&gt;计算只执⾏⼀次&lt;/li&gt;
&lt;li&gt;计算终会终⽌&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;常见流式计算和离线计算框架&#34;&gt;&lt;a href=&#34;#%e5%b8%b8%e8%a7%81%e6%b5%81%e5%bc%8f%e8%ae%a1%e7%ae%97%e5%92%8c%e7%a6%bb%e7%ba%bf%e8%ae%a1%e7%ae%97%e6%a1%86%e6%9e%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;常见流式计算和离线计算框架
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;离线&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;mapreduce&lt;/li&gt;
&lt;li&gt;spark-core&lt;/li&gt;
&lt;li&gt;flink 的 dataset&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;流式&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;storm  第⼀代的流式处理框架&lt;/li&gt;
&lt;li&gt;sparkStreaming（其实是为微批处理）第二代的流式处理框架&lt;/li&gt;
&lt;li&gt;flink 的 datastream  第三代的流式处理框架
&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-12.png&#34;
	width=&#34;1094&#34;
	height=&#34;642&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-12_hu_e0935637f0e3394d.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-12_hu_42c4bb90cd92c470.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;170&#34;
		data-flex-basis=&#34;408px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;sparkstreaming-的基本工作原理&#34;&gt;&lt;a href=&#34;#sparkstreaming-%e7%9a%84%e5%9f%ba%e6%9c%ac%e5%b7%a5%e4%bd%9c%e5%8e%9f%e7%90%86&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;SparkStreaming 的基本工作原理
&lt;/h4&gt;&lt;p&gt;SparkCore 的数据模型是 RDD，SparkSQL 数据模型是 DataFrame 和 DataSet，&lt;strong&gt;SparkStreaming 的数据模型是 DStream，DStream 和 RDD 一样，是一种高级抽象，它基于内存处理连续的数据流，本质上还是 RDD 的基于内存的计算。&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;接收实时输入数据流，然后将数据拆分成多个 batch，比如每收集 1 秒的数据封装为⼀个 batch，然后将每个 batch 交给 Spark 的计算引擎进行处理，最后会⽣产出⼀个结果数据流，其中的数据，也是由一个一个的 batch 所组成的。&lt;/li&gt;
&lt;li&gt;DStream，英⽂全称为 Discretized Stream，中文翻译为“离散流”，它代表了⼀个持续不断的数据流。DStream 可以通过输入数据源来创建，比如 Kafka、Flume、ZMQ 和 Kinesis；也可以通过对其他 DStream 应用高阶函数来创建，比如 map、reduce、join、window。&lt;/li&gt;
&lt;li&gt;**DStream 的内部，其实是一系列时间上连续的 RDD。DStream 中的每个 RDD 都包含了⼀个时间段内的数据。
&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-13.png&#34;
	width=&#34;1087&#34;
	height=&#34;221&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-13_hu_c85dd40cb892b784.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-13_hu_5a46580c8c95213a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;491&#34;
		data-flex-basis=&#34;1180px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;对 DStream 应⽤的算子，比如 map，其实在底层会被翻译为对 DStream 中每个 RDD 的操作。比如&lt;strong&gt;对⼀个 DStream 执行⼀个 map 操作，会产生⼀个新的 DStream&lt;/strong&gt;。但是，在底层，其实是对输入 DStream 中&lt;strong&gt;每个时间段的 RDD&lt;/strong&gt;，都来⼀遍 map 操作，然后**⽣成的新的 RDD**，即作为新的 DStream 中的那个时间段的⼀个 RDD。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;sparkstreaming-的缓存&#34;&gt;&lt;a href=&#34;#sparkstreaming-%e7%9a%84%e7%bc%93%e5%ad%98&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;SparkStreaming 的缓存
&lt;/h4&gt;&lt;p&gt;SparkStreaming 的缓存，说白了就是 DStream 的缓存，DStream 的缓存就只有⼀个⽅⾯，那就是 DStream 对应的 RDD 缓存，RDD 如何缓存？&lt;strong&gt;rdd.persist()&lt;/strong&gt;，所以 DStream 的缓存说⽩了就是 RDD 的缓存，使⽤ persist()指定，并指定持久化策略，⼤多算⼦默认情况下，持久化策略为 MEMORY_AND_DISK_SER_2&lt;/p&gt;
&lt;h4 id=&#34;sparkstreaming-的容错&#34;&gt;&lt;a href=&#34;#sparkstreaming-%e7%9a%84%e5%ae%b9%e9%94%99&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;SparkStreaming 的容错
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;每⼀个 Spark Streaming 应⽤，正常来说都是要 7*24 ⼩时运转的，这也是实时计算程序的特点。因为要持续不断的对数据进⾏计算，因此对实时计算应⽤的要求必须进行&lt;strong&gt;容错保底&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;Spark Streaming 程序就必须将足够的信息 checkpoint 到容错的存储系统上，从⽽让它能够从失败中进行恢复。有两种数据需要被 checkpoint：&lt;/li&gt;
&lt;li&gt;元数据 checkpoint：将定义了流式计算逻辑的信息，保存到容错的存储系统上，⽐如 HDFS。当运行 Spark Streaming 应⽤程序的 Driver 进程所在节点失败时，该信息可以⽤于进⾏恢复。元数据信息包括了： 创建 Spark Streaming 应⽤程序的&lt;strong&gt;配置信息&lt;/strong&gt;，比如 SparkConf 中的信息。 定义了 Spark Stream 应⽤程序的计算逻辑的&lt;strong&gt;DStream 操作信息&lt;/strong&gt;。 定义了那些 job 正在排队，还&lt;strong&gt;未处理的 batch 信息&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;数据 checkpoint：&lt;strong&gt;将实时计算过程中产生的 RDD 的数据保存到可靠的存储系统中&lt;/strong&gt;。 对于一些将多个 batch 的数据进⾏聚合的，有状态的 transformation 操作，这是⾮常有⽤的。在这种 &lt;strong&gt;transformation 操作中，生成的 RDD 是依赖于之前的 batch 的 RDD，这会导致随着时间的推移，RDD 的依赖链条变得越来越长。 要避免由于依赖链条越来越长，导致的⼀起变得越来越长的失败恢复时间，有状态的 transformation 操作执⾏过程中间产⽣的 RDD，会定期地被 checkpoint 到可靠的存储系统上&lt;/strong&gt;，比如 HDFS。从而削减 RDD 的依赖链条，进而缩短失败恢复时，RDD 的恢复时间。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;dstream-操作&#34;&gt;&lt;a href=&#34;#dstream-%e6%93%8d%e4%bd%9c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;DStream 操作
&lt;/h4&gt;&lt;p&gt;DStream 上的操作与 RDD 的类似，分为以下两种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Transformations(转换)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;**无状态转换：**每批次处理不依赖于之前批次的数据
&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-14.png&#34;
	width=&#34;965&#34;
	height=&#34;701&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-14_hu_89af84bc9099ba16.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-14_hu_e344be5ff2174862.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;137&#34;
		data-flex-basis=&#34;330px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;**有状态转换：**当前批次的处理需要使用之前批次的数据或者中间结果，有状态转换包括基于追踪状态变化的转换(updateStateByKey)和滑动窗口的转换：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Output Operations(输出)/Action&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Output Operations 可以将 DStream 的数据输出到外部的数据库或文件系统。 当某个 Output Operations 被调用时，spark streaming 程序才会开始真正的 计算过程(与 RDD 的 Action 类似)。
&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-16.png&#34;
	width=&#34;947&#34;
	height=&#34;274&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-16_hu_da10acb9d2b6b537.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-16_hu_781bc4d2e6d69df3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;345&#34;
		data-flex-basis=&#34;829px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-15.png&#34;
	width=&#34;940&#34;
	height=&#34;211&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-15_hu_701c0ed1923876b2.png 480w, /zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-spark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/image-15_hu_1494eb3aed1eab78.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;445&#34;
		data-flex-basis=&#34;1069px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;mllib&#34;&gt;&lt;a href=&#34;#mllib&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;MLlib
&lt;/h3&gt;&lt;p&gt;提供常见的机器学习(ML)功能的程序库。包括分类、回归、聚类、协同过滤等，还提供了模型评估、数据导入等额 外的⽀持功能&lt;/p&gt;
&lt;h3 id=&#34;graphx&#34;&gt;&lt;a href=&#34;#graphx&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Graphx
&lt;/h3&gt;&lt;p&gt;GraphX 在 Spark 基础上提供了一站式的数据解决⽅案，可以⾼效地完成图计算的完整流⽔作业。GraphX 是⽤于图 计算和并⾏图计算的新的（alpha）Spark API。通过引⼊弹性分布式属性图（Resilient Distributed Property Graph），⼀种顶点和边都带有属性的有向多重图，扩展了 Spark RDD&lt;/p&gt;
&lt;h2 id=&#34;spark-多种部署模式&#34;&gt;&lt;a href=&#34;#spark-%e5%a4%9a%e7%a7%8d%e9%83%a8%e7%bd%b2%e6%a8%a1%e5%bc%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Spark 多种部署模式
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Local 多⽤于本地测试，如在 eclipse，idea 中写程序测试等。&lt;/li&gt;
&lt;li&gt;Standalone 是 Spark ⾃带的⼀个资源调度框架，它⽀持完全分布式。&lt;/li&gt;
&lt;li&gt;Yarn ⽣态圈⾥⾯的⼀个资源调度框架，Spark 也是可以基于 Yarn 来计算的。&lt;/li&gt;
&lt;li&gt;Mesos 资源调度框架，与 Yarn 类似。&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>浅谈维度建模、数据分析模型，何为数据仓库，与数据库的区别</title>
        <link>/zh-cn/post/2024/09/%E6%B5%85%E8%B0%88%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E4%BD%95%E4%B8%BA%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%8C%BA%E5%88%AB/</link>
        <pubDate>Sun, 01 Sep 2024 21:34:40 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/09/%E6%B5%85%E8%B0%88%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E4%BD%95%E4%B8%BA%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%8C%BA%E5%88%AB/</guid>
        <description>&lt;h2 id=&#34;前言&#34;&gt;&lt;a href=&#34;#%e5%89%8d%e8%a8%80&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;前言
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;1991 年，数据仓库之父 比尔·恩门 著书《Building the DataWarehouse》，要求&lt;strong&gt;构建数据仓库&lt;/strong&gt; 时，遵循&lt;strong&gt;范式建模&lt;/strong&gt;，即从关系型数据库中提取的范式数据，仍按范式存储到数据仓库中，这样就导致&lt;strong&gt;数仓中有很多小表，查询的时候必然会有很多表的关联&lt;/strong&gt;，极大地影响查询效率和性能。&lt;/li&gt;
&lt;li&gt;1994 年，拉尔夫·金博尔 著书《The DataWarehouse Toolkit》，提出&lt;strong&gt;维度建模和数据集市的概念&lt;/strong&gt;，&lt;strong&gt;维度建模是反范式建模，自下而上&lt;/strong&gt; ，然而这种方式仍有缺点：那就是每个业务平台的数据有各自的数据集市，集市之间&lt;strong&gt;数据隔离，存在数据不一致、重复&lt;/strong&gt;的情况。&lt;/li&gt;
&lt;li&gt;1998-2001 年，比尔·恩门派和金博尔派合并，比尔·恩门提出&lt;strong&gt;CIF 架构：数仓分层&lt;/strong&gt;，不同层采用不同的建模方式，同时解决了数据不一致和查询效率低的问题。
&lt;strong&gt;基于以上，有了范式建模、维度建模、实体建模三种主要建模方式&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;浅谈维度建模&#34;&gt;&lt;a href=&#34;#%e6%b5%85%e8%b0%88%e7%bb%b4%e5%ba%a6%e5%bb%ba%e6%a8%a1&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;浅谈维度建模
&lt;/h3&gt;&lt;p&gt;维度建模主要&lt;strong&gt;面向分析场景，分为维度表和事实表，&lt;strong&gt;是数据仓库中最常用的数据建模技术之一，建模过程和关系型数据库的建表很像，下图中，商家 ID、产品 ID、时间 ID 就是不同的&lt;/strong&gt;维度列&lt;/strong&gt;，而订单额就是&lt;strong&gt;度量值&lt;/strong&gt;，&lt;strong&gt;维度+度量值=事实表&lt;/strong&gt;。&lt;strong&gt;每个维度列同时也有自己的维度表&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/09/%E6%B5%85%E8%B0%88%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E4%BD%95%E4%B8%BA%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%8C%BA%E5%88%AB/image.png&#34;
	width=&#34;1390&#34;
	height=&#34;917&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E6%B5%85%E8%B0%88%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E4%BD%95%E4%B8%BA%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%8C%BA%E5%88%AB/image_hu_c2320fa1ccc21e73.png 480w, /zh-cn/post/2024/09/%E6%B5%85%E8%B0%88%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E4%BD%95%E4%B8%BA%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%8C%BA%E5%88%AB/image_hu_ed9a7f1cbc578571.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;151&#34;
		data-flex-basis=&#34;363px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;那么基于以上，有如下两种数据分析模型。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;数据分析模型&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e6%8d%ae%e5%88%86%e6%9e%90%e6%a8%a1%e5%9e%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;数据分析模型
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/09/%E6%B5%85%E8%B0%88%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E4%BD%95%E4%B8%BA%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%8C%BA%E5%88%AB/image-1.png&#34;
	width=&#34;1621&#34;
	height=&#34;871&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E6%B5%85%E8%B0%88%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E4%BD%95%E4%B8%BA%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%8C%BA%E5%88%AB/image-1_hu_cc7f0e35bbf830cf.png 480w, /zh-cn/post/2024/09/%E6%B5%85%E8%B0%88%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E4%BD%95%E4%B8%BA%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%8C%BA%E5%88%AB/image-1_hu_ab69c5f079837f4c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;186&#34;
		data-flex-basis=&#34;446px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/09/%E6%B5%85%E8%B0%88%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E4%BD%95%E4%B8%BA%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%8C%BA%E5%88%AB/image-2.png&#34;
	width=&#34;1659&#34;
	height=&#34;958&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E6%B5%85%E8%B0%88%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E4%BD%95%E4%B8%BA%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%8C%BA%E5%88%AB/image-2_hu_171ecbdb507d0e7d.png 480w, /zh-cn/post/2024/09/%E6%B5%85%E8%B0%88%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E4%BD%95%E4%B8%BA%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%8C%BA%E5%88%AB/image-2_hu_1e74558ec6b336be.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;173&#34;
		data-flex-basis=&#34;415px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;对比&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;查询效率：雪花模型有很多小表，看起来更为&lt;strong&gt;范式化&lt;/strong&gt;，但这导致查询时需要关联很多表，&lt;strong&gt;查询效率比星型模型低&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;数据冗余：星型模型的表通常是&lt;strong&gt;宽表，伪范式&lt;/strong&gt;，即表有很多字段，这导致星型模型存在较多的&lt;strong&gt;数据冗余&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;数据仓库&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e6%8d%ae%e4%bb%93%e5%ba%93&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;数据仓库
&lt;/h2&gt;&lt;h3 id=&#34;何为数据仓库&#34;&gt;&lt;a href=&#34;#%e4%bd%95%e4%b8%ba%e6%95%b0%e6%8d%ae%e4%bb%93%e5%ba%93&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;何为数据仓库
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;数据仓库（Data Warehouse）即是存储&lt;strong&gt;历史&lt;/strong&gt;数据的仓库，简写为&lt;strong&gt;DW 或 DWH&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;数据仓库的&lt;strong&gt;目的是构建面向分析的集成化数据环境（OLAP），为企业提供决策支持&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;仓库的数据来自各个业务平台，业务平台中的数据形式多种多样，可能是 MySQL 等关系数据库里的结构化数据，可能是 Word、Excel 文档中的非结构化数据，还可能是 HTML、XML 等自描述的半结构化数据。这些业务数据经过一系列的 ETL（抽取、转换、加载），最终以一种&lt;strong&gt;统一的格式&lt;/strong&gt;装载进数据仓库。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据仓库本身并不“生产”任何数据，也不需要“消费”任何的数据，只是在内部对数据做了一些数据清洗转移操作，好比流水线&lt;/strong&gt;，数据来源于外部，最终开放给外部应用。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;数据仓库特征&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e6%8d%ae%e4%bb%93%e5%ba%93%e7%89%b9%e5%be%81&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;数据仓库特征
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;面向主题&lt;/strong&gt;：&lt;br&gt;
传统数据库中，最大的特点是面向应用进行数据的组织，各个业务系统可能是相互分离的。而&lt;strong&gt;数据仓库则是面向主题的&lt;/strong&gt;。主题是一个抽象的概念，是较高层次上企业信息系统中的&lt;strong&gt;数据综合、归类并进行分析利用的抽象&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;集成性&lt;/strong&gt;：&lt;br&gt;
通过&lt;strong&gt;对分散、独立、异构的数据库数据进行 ETL 并汇总&lt;/strong&gt;得到了数据仓库的数据，这样保证了数据仓库内的&lt;strong&gt;数据的一致性&lt;/strong&gt;。 数据仓库中的综合数据不能从原有的数据库系统直接得到。因此在数据进入数据仓库之前，必然要经过清洗、一致性等操作，这一步是数据仓库建设中最关键、最复杂的一步。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;反应历史变化&lt;/strong&gt;：&lt;strong&gt;数仓反应的是某段时间内的历史数据&lt;/strong&gt;，这也是数仓和数据库的区别之一。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;不可修改&lt;/strong&gt;：数据进入数据仓库以后，一般情况下被较长时间保留。数据仓库中一般有大量的查询操作，但修改删除操作很少，只需定时加载更新即可。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;时效性&lt;/strong&gt;：数仓存储的是历史数据，按照时间顺序追加，有时间属性。数仓用户通过分析企业过去一段时间业务的经营状况，挖掘潜在价值。但是分析的结果只能反映过去某段时间的情况，随着业务变化时间改变，数仓中的数据就会失去价值，需要载入新数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;数据仓库和数据库的区别&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e6%8d%ae%e4%bb%93%e5%ba%93%e5%92%8c%e6%95%b0%e6%8d%ae%e5%ba%93%e7%9a%84%e5%8c%ba%e5%88%ab&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;  数据仓库和数据库的区别
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;数据库与数据仓库的区别实际讲的是 OLTP 与 OLAP 的区别：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;操作型处理，叫联机事务处理 OLTP，也可以称面向交易的处理系统，&lt;strong&gt;针对日常事务处理。用户较为关心操作的响应时间、数据的安全性、完整性和并发支持的用户数等问题&lt;/strong&gt;。传统的数据库系统作为数据管理的主要手段，主要用于操作型处理，像 MYSQL，Oracle 等关系型数据库一般属于 OLTP。&lt;/li&gt;
&lt;li&gt;分析型处理，叫联机分析处理 OLAP，一般针对&lt;strong&gt;某些主题的历史数据&lt;/strong&gt;进行分析，&lt;strong&gt;支持管理决策。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;首先要明白，数据仓库的出现，并不是要取代数据库。&lt;strong&gt;数据库是面向事务的设计，数据仓库是面向主题设计的。数据库一般存储业务数据，数据仓库存储的一般是历史数据&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数据库设计是尽量避免冗余&lt;/strong&gt;，一般针对某一业务应用进行设计，比如一张简单的 User 表，记录用户名、 密码等简单数据即可，符合业务应用，但是不符合分析。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据仓库在设计是有意引入冗余&lt;/strong&gt;，依照分析需求，分析维度、分析指标进行设计。 数据库是为&lt;strong&gt;捕获数据&lt;/strong&gt;而设计，数据仓库是为&lt;strong&gt;分析数据&lt;/strong&gt;而设计。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;为什么不直接用业务平台的数据而要建设数仓&#34;&gt;&lt;a href=&#34;#%e4%b8%ba%e4%bb%80%e4%b9%88%e4%b8%8d%e7%9b%b4%e6%8e%a5%e7%94%a8%e4%b8%9a%e5%8a%a1%e5%b9%b3%e5%8f%b0%e7%9a%84%e6%95%b0%e6%8d%ae%e8%80%8c%e8%a6%81%e5%bb%ba%e8%ae%be%e6%95%b0%e4%bb%93&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;  为什么不直接用业务平台的数据而要建设数仓？ 
&lt;/h3&gt;&lt;p&gt;实际在数仓出现之前，确实是这么做的，但是有很多数据分析的先驱者当时已经发现，简单的直接访问方式很难良好工作，原因如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;由于&lt;strong&gt;安全&lt;/strong&gt;或其他因素不能直接访问某些业务数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;业务平台存储的是当前数据，存在于 RDBMS，并且数据版本变更很频繁，而大数据需要的是历史数据，读多改少。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;各个平台&lt;strong&gt;数据存储是隔离的&lt;/strong&gt;，且**数据格式不统一，**难以建立、维护、汇总数据。&lt;/li&gt;
&lt;li&gt;业务系统的表结构（OLTP）为事务处理性能而优化，有时并&lt;strong&gt;不适合查询与分析（OLAP）&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;有时用户要看到的某些数据字段在数据库中并不存在，是后期聚合处理生成的。&lt;/li&gt;
&lt;li&gt;业务平台是跑业务的，本身就占用了一定数据库读写资源，大数据分析再从每个表中频繁读取数据，影响业务平台的性能，不够专业。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;以银行业务为例&#34;&gt;&lt;a href=&#34;#%e4%bb%a5%e9%93%b6%e8%a1%8c%e4%b8%9a%e5%8a%a1%e4%b8%ba%e4%be%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;以银行业务为例  
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;数据库是事务系统的数据平台，客户在银行做的每笔交易都会写入数据库，被记录下来，可以简单地理解为用数据库记账。&lt;/li&gt;
&lt;li&gt;数据仓库是分析系统的数据平台，它从事务系统获取数据，并做汇总、加工，为决策者提供决策的依据。比如，某银行某分行一个月发生多少交易，该分行当前存款余额是多少。如果存款又多，消费交易又多，那么该地区就有必要设立 ATM 了。 显然，银行的交易量是巨大的，通常以百万甚至千万次来计算。&lt;/li&gt;
&lt;li&gt;事务系统是实时的，这就要求&lt;strong&gt;时效性&lt;/strong&gt;，客户存一笔钱需要几十秒是无法忍受的，这就要求数据库只能存储很短一段时间的数据。 而&lt;strong&gt;分析系统是事后&lt;/strong&gt;的，它要提供关注时间段内所有的有效数据。这些数据是海量的，汇总计算起来也要慢一些，但是，只要能够提供有效的分析数据就达到目的了。&lt;/li&gt;
&lt;li&gt;数据仓库，是在数据库已经大量存在的情况下，为了进一步挖掘数据资源、为了决策需要而产生的，&lt;strong&gt;它决不是所谓的“大型数据库”&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;参考博客：&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/u012955829/article/details/141496865&#34;  title=&#34;数据仓库系列 1：什么是数据仓库,它与传统数据库有什么不同?-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;数据仓库系列 1：什么是数据仓库,它与传统数据库有什么不同?-CSDN 博客&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>数仓架构：离线数仓、实时数仓Lambda和Kappa、湖仓一体数据湖</title>
        <link>/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/</link>
        <pubDate>Sun, 01 Sep 2024 00:53:40 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/</guid>
        <description>&lt;h2 id=&#34;数仓架构&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e4%bb%93%e6%9e%b6%e6%9e%84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;数仓架构
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image.png&#34;
	width=&#34;1696&#34;
	height=&#34;572&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image_hu_7e6a0ff07c243f2a.png 480w, /zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image_hu_cc71e5828ebe9dfe.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;296&#34;
		data-flex-basis=&#34;711px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数仓架构大致分为离线数仓架构和实时数仓架构&lt;/strong&gt;，数仓架构可以简单理解为构成数仓的各层关系，如 ODS、DWM、DWD、DWS，具体分层这里不赘述。&lt;/p&gt;
&lt;h3 id=&#34;离线数仓架构&#34;&gt;&lt;a href=&#34;#%e7%a6%bb%e7%ba%bf%e6%95%b0%e4%bb%93%e6%9e%b6%e6%9e%84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;离线数仓架构
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-1.png&#34;
	width=&#34;2001&#34;
	height=&#34;787&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-1_hu_c31f25fb758a335.png 480w, /zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-1_hu_1b395ee76f362f9c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;254&#34;
		data-flex-basis=&#34;610px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;显而易见，这种架构不能处理实时数据，那么必然会有数据的流失。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;任何事物都是随着时间的演进变得越来越完善，当然也是越来越复杂，数仓也不例外。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;离线数仓架构&lt;/strong&gt; 包括&lt;strong&gt;数据集市架构、Inmon 企业信息工厂架构、Kimball 数据仓库架构、混合型数据仓库架构&lt;/strong&gt;，接下来就详细说说这几种架构。&lt;/p&gt;
&lt;h4 id=&#34;数据集市架构&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e6%8d%ae%e9%9b%86%e5%b8%82%e6%9e%b6%e6%9e%84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;数据集市架构
&lt;/h4&gt;&lt;p&gt;数据集市架构重点在于&lt;strong&gt;集市&lt;/strong&gt; 二字，数据集市是按&lt;strong&gt;主题域&lt;/strong&gt; 组织的数据集合，用于支持&lt;strong&gt;部门级的决策&lt;/strong&gt;。有两种类型的数据集市：独立数据集市 和 从属数据集市。&lt;/p&gt;
&lt;h5 id=&#34;独立数据集市&#34;&gt;&lt;a href=&#34;#%e7%8b%ac%e7%ab%8b%e6%95%b0%e6%8d%ae%e9%9b%86%e5%b8%82&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;独立数据集市
&lt;/h5&gt;&lt;p&gt;独立数据集市集中于部门所关心的&lt;strong&gt;单一主题域&lt;/strong&gt; ，&lt;strong&gt;数据以部门为基础&lt;/strong&gt;，例如制造部门、人力资源部门和其他部门都各自有他们自己的数据集市。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-2.png&#34;
	width=&#34;1200&#34;
	height=&#34;715&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-2_hu_c77e04856e7b7f9a.png 480w, /zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-2_hu_ad2a24a99787845d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;167&#34;
		data-flex-basis=&#34;402px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;优点：因为一个部门的业务相对于整个企业要简单，数据量也小得多，所以部门的独立数据集市&lt;strong&gt;周期短、见效快&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;缺点：独立数据集市各自为政。从业务角度看，当部门的分析&lt;strong&gt;需求扩展&lt;/strong&gt; 或者&lt;strong&gt;跨部门跨主题域分析&lt;/strong&gt; 时，独立数据市场会力不从心。 当&lt;strong&gt;数据存在歧义&lt;/strong&gt; ，比如同一个产品在 A 部门和 B 部门的定义不同，将无法在部门间进行信息比较。 每个部门使用不同的技术，建立不同的 ETL 的过程，处理不同的事务系统，而在多个独立的数据集市之间还会存在数据的交叉与重叠，甚至会有&lt;strong&gt;数据不一致&lt;/strong&gt;的情况！&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;从属数据集市&#34;&gt;&lt;a href=&#34;#%e4%bb%8e%e5%b1%9e%e6%95%b0%e6%8d%ae%e9%9b%86%e5%b8%82&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;从属数据集市
&lt;/h5&gt;&lt;p&gt;从属数据集市的数据&lt;strong&gt;来源于数据仓库&lt;/strong&gt;
从属数据集市的数据&lt;strong&gt;来源于数据仓库&lt;/strong&gt;，即从属于数据仓库。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-3.png&#34;
	width=&#34;1227&#34;
	height=&#34;711&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-3_hu_540ae30a441fa4bd.png 480w, /zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-3_hu_3ac590a49fe7b0b0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;172&#34;
		data-flex-basis=&#34;414px&#34;
	
&gt; &lt;strong&gt;优点：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;性能：当数据仓库的查询性能出现问题，可以考虑建立几个从属数据集市，将查询从数据仓库移出到数据集市。&lt;/li&gt;
&lt;li&gt;安全：每个部门可以完全控制他们自己的数据。&lt;/li&gt;
&lt;li&gt;数据一致：因为每个数据集市的数据来源都是同一个数据仓库，&lt;strong&gt;有效消除了数据不一致&lt;/strong&gt;的情况。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;inmon-企业信息工厂架构&#34;&gt;&lt;a href=&#34;#inmon-%e4%bc%81%e4%b8%9a%e4%bf%a1%e6%81%af%e5%b7%a5%e5%8e%82%e6%9e%b6%e6%9e%84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt; Inmon 企业信息工厂架构
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-4.png&#34;
	width=&#34;1038&#34;
	height=&#34;523&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-4_hu_1c14e7bed420b672.png 480w, /zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-4_hu_3633c1a2b51e5fb1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;198&#34;
		data-flex-basis=&#34;476px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Inmon 架构是范式建模&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;企业级&lt;/strong&gt;数据仓库是企业级别的，正如 Inmon 数据仓库所定义的，企业级数据仓库是一个细节数据的集成资源库。其中的数据以最低粒度级别被捕获，存储在满足三范式设计的关系数据库中。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;部门级&lt;/strong&gt;数据集市是企业中部门级别的，是面向主题数据的部门级视图，数据从企业级数据仓库获取。数据在进入部门数据集市时可能进行聚合。数据集市使用多维模型设计，用于数据分析。重要的一点是，&lt;strong&gt;所有的报表工具、BI 工具或其他数据分析应用都应该从数据集市查询数据，而不是直接查询企业级数据仓库&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;kimball-数据仓库架构&#34;&gt;&lt;a href=&#34;#kimball-%e6%95%b0%e6%8d%ae%e4%bb%93%e5%ba%93%e6%9e%b6%e6%9e%84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Kimball 数据仓库架构
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-5.png&#34;
	width=&#34;1055&#34;
	height=&#34;652&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-5_hu_1097b5e275684fc7.png 480w, /zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-5_hu_a9c4447d45e6edce.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;161&#34;
		data-flex-basis=&#34;388px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对比上一张图可以看到，Kimball 与 Inmon 两种架构的&lt;strong&gt;主要区别在于数据仓库的设计和建立。&lt;/strong&gt; Kimball 的数据仓库包含&lt;strong&gt;高粒度&lt;/strong&gt;的企业数据，使用&lt;strong&gt;多维&lt;/strong&gt;模型设计，是&lt;strong&gt;维度建模&lt;/strong&gt;，这也意味着数据仓库由&lt;strong&gt;星型模式&lt;/strong&gt;的维度表和事实表构成。分析系统或报表工具可以&lt;strong&gt;直接访问多维数据仓库&lt;/strong&gt;里的数据。&lt;/li&gt;
&lt;li&gt;在此架构中的数据集市也与 Inmon 中的不同。&lt;strong&gt;这里的数据集市是一个逻辑概念，只是多维数据仓库中的主题域划分，并没有自己的物理存储，也可以说是虚拟的数据集市&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;混合型数据仓库架构&#34;&gt;&lt;a href=&#34;#%e6%b7%b7%e5%90%88%e5%9e%8b%e6%95%b0%e6%8d%ae%e4%bb%93%e5%ba%93%e6%9e%b6%e6%9e%84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;混合型数据仓库架构
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-6.png&#34;
	width=&#34;1065&#34;
	height=&#34;532&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-6_hu_99daeed36bdc4ad6.png 480w, /zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-6_hu_b248f92a52a25278.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;200&#34;
		data-flex-basis=&#34;480px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;所谓的混合型结构，指的是在一个数据仓库环境中，&lt;strong&gt;联合使用 Inmon 和 Kimball 两种架构。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;从架构图可以看到，这种架构将 Inmon 方法中的&lt;strong&gt;数据集市替换成了一个多维数据仓库&lt;/strong&gt;，而数据集市则是多维数据仓库上的&lt;strong&gt;逻辑视图&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;使用这种架构的&lt;strong&gt;好处&lt;/strong&gt;是：既可以利用规范化设计消除数据冗余，保证数据的粒度足够细；又可以利用多维结构更灵活地在企业级实现报表和分析。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;实时数仓架构&#34;&gt;&lt;a href=&#34;#%e5%ae%9e%e6%97%b6%e6%95%b0%e4%bb%93%e6%9e%b6%e6%9e%84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;实时数仓架构
&lt;/h3&gt;&lt;p&gt;在某些场景中，数据的价值随着时间的推移而逐渐减少。所以在传统大数据离线数仓的基础上，逐渐对 数据的实时性提出了更高的要求。&lt;/p&gt;
&lt;h4 id=&#34;lambda-架构&#34;&gt;&lt;a href=&#34;#lambda-%e6%9e%b6%e6%9e%84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Lambda 架构
&lt;/h4&gt;&lt;h5 id=&#34;传统的-lambda-实时开发&#34;&gt;&lt;a href=&#34;#%e4%bc%a0%e7%bb%9f%e7%9a%84-lambda-%e5%ae%9e%e6%97%b6%e5%bc%80%e5%8f%91&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;传统的 Lambda 实时开发
&lt;/h5&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-7.png&#34;
	width=&#34;2007&#34;
	height=&#34;967&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-7_hu_1e434f2dd077419.png 480w, /zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-7_hu_b9d0b59f91422561.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;207&#34;
		data-flex-basis=&#34;498px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;上述架构，在实时计算链路中，如果存在多个实时业务，每个业务都要对自己的数据进行数据清洗等操作，而数据清洗这操作是重复的。所以对其进行了如下优化，提高数据复用&lt;/strong&gt;&lt;/p&gt;
&lt;h5 id=&#34;升级的-lambda-实时开发&#34;&gt;&lt;a href=&#34;#%e5%8d%87%e7%ba%a7%e7%9a%84-lambda-%e5%ae%9e%e6%97%b6%e5%bc%80%e5%8f%91&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;  升级的 Lambda 实时开发
&lt;/h5&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-8.png&#34;
	width=&#34;1989&#34;
	height=&#34;910&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-8_hu_c61cdecacdba28.png 480w, /zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-8_hu_e8621ed39dc0f557.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;218&#34;
		data-flex-basis=&#34;524px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;对实时链路进行数据分层，改成实时数仓，解决了数据复用的问题，可以对数据进行统一清洗等操作。&lt;/strong&gt;&lt;/p&gt;
&lt;h5 id=&#34;为什么-lambda-架构同时存在流处理和批处理&#34;&gt;&lt;a href=&#34;#%e4%b8%ba%e4%bb%80%e4%b9%88-lambda-%e6%9e%b6%e6%9e%84%e5%90%8c%e6%97%b6%e5%ad%98%e5%9c%a8%e6%b5%81%e5%a4%84%e7%90%86%e5%92%8c%e6%89%b9%e5%a4%84%e7%90%86&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;为什么 Lambda 架构同时存在流处理和批处理？
&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;假如整个系统只有一个批处理层，会导致用户必须等待很久才能获取计算结果，一般有&lt;strong&gt;时间延迟&lt;/strong&gt;。电商数据分析部门只能查看前一天的统计分析结果，无法获取当前的结果，这对于实时决策来说有 一个巨大的&lt;strong&gt;时间鸿沟&lt;/strong&gt;，很可能导致管理者错过最佳决策时机。&lt;/li&gt;
&lt;li&gt;Lambda 架构属于较早的一种架构方式，早期的流处理不如现在这样成熟，在准确性、扩展性和容错性 上，流处理层无法直接取代批处理层，只能给用户提供一个近似结果，还不能为用户提供一个一致准确的结果。因此 Lambda 架构中，出现了批处理和流处理并存的现象。&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;lambda-架构缺点&#34;&gt;&lt;a href=&#34;#lambda-%e6%9e%b6%e6%9e%84%e7%bc%ba%e7%82%b9&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Lambda 架构缺点
&lt;/h5&gt;&lt;p&gt;不管是传统的还是升级后的 Lambda 架构，严格来说并**不是纯正的实时数仓，而是离线+实时！**这就导致 Lambda 有如下缺点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;同样的需求要开发两套一样的代码，比如批处理要统计昨天一天的人数，流处理要统计实时在线人数，都是统计人数，却要开发两套代码。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;跑两套相同的代码，集群资源使用增多&lt;/li&gt;
&lt;li&gt;离线结果和实时结果可能不一致，当然以离线为主&lt;/li&gt;
&lt;li&gt;离线批量计算 T+1 可能算不完，数据量大&lt;/li&gt;
&lt;li&gt;服务器存储压力大&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;既然离线数仓占用计算压力大，存储压力大，那就不使用离线，使用纯实时的 kappa 架构&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;kappa-架构&#34;&gt;&lt;a href=&#34;#kappa-%e6%9e%b6%e6%9e%84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Kappa 架构
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-9.png&#34;
	width=&#34;1927&#34;
	height=&#34;766&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-9_hu_3c1b3e3ffeba5553.png 480w, /zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-9_hu_820ab240f24a9894.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;251&#34;
		data-flex-basis=&#34;603px&#34;
	
&gt;&lt;/p&gt;
&lt;h5 id=&#34;kappa-架构缺点&#34;&gt;&lt;a href=&#34;#kappa-%e6%9e%b6%e6%9e%84%e7%bc%ba%e7%82%b9&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Kappa 架构缺点  
&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;只支持流处理，没有批处理&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;使用 kafka 进行消息缓存&lt;/strong&gt;，kafka 不支撑海量数据存储，数据存储也有时间限制&lt;/li&gt;
&lt;li&gt;kafka 不支持 OLAP，即&lt;strong&gt;无法用 SQL 语句进行简单的数据校验&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;无法复用数据血缘管理体系（数据治理），因为 kafka 没有 schema 那种字段&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;kafka 中的数据是 append 追加，不支持数据的更新、插入&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;kappa-和-lambda-对比&#34;&gt;&lt;a href=&#34;#kappa-%e5%92%8c-lambda-%e5%af%b9%e6%af%94&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Kappa 和 Lambda 对比
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-10.png&#34;
	width=&#34;1466&#34;
	height=&#34;898&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-10_hu_c7f2c7bd8d8ffe05.png 480w, /zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-10_hu_89cc1a119ce724de.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;163&#34;
		data-flex-basis=&#34;391px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;湖仓一体数据湖&#34;&gt;&lt;a href=&#34;#%e6%b9%96%e4%bb%93%e4%b8%80%e4%bd%93%e6%95%b0%e6%8d%ae%e6%b9%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;  湖仓一体—数据湖  
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;基于 Lambda 和 Kappa 架构的缺点，出现了批流一体&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;从架构角度来看类似 Lambda 架构，批流一体既可以处理批数据，又可以处理流数据；&lt;/li&gt;
&lt;li&gt;从计算框架角度来看，就是 flink、spark 框架，既支持批处理，又支持流处理；&lt;/li&gt;
&lt;li&gt;从 SQL 角度来看，就是数仓各层统一支持 SQL，这就弥补了 kappa 中 kafka 不支持 SQL 的缺点；&lt;/li&gt;
&lt;li&gt;从存储层面来看，能做到海量数据的存储，而不是像 kappa 一样存储在 kafka 缓存中；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-11.png&#34;
	width=&#34;1943&#34;
	height=&#34;889&#34;
	srcset=&#34;/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-11_hu_8a8c122827cf955b.png 480w, /zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/image-11_hu_1fe41bb1e4b89f7a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;218&#34;
		data-flex-basis=&#34;524px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Kafka 换成了 Iceberg&lt;/strong&gt;，IceBerg 就是数据湖技术的一种，介于上层计算引擎和底层存储格式之间的一个中间层，我们可以把它定义成一种“数据组织格式”，底层存储还是 HDFS。除此之外数据湖还有 Hudi（发展最完善）这里不具体阐述。&lt;/p&gt;
&lt;p&gt;数据湖支持 SQL 查询，解决了如下问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;存储统一&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;底层存储是 HDFS，解决了 kafka 存储量小，数据有时间限制的问题&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;任意分层都可以 OLAP（支持 SQL 查询）&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Iceberg 有 Schema 概念，可以追踪数据的血缘关系（数据治理）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;支持数据实时更新，数据可以 update/insert&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>DW层的数仓建模：范式建模、维度建模及数据分析模型、实体建模</title>
        <link>/zh-cn/post/2024/08/dw%E5%B1%82%E7%9A%84%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/</link>
        <pubDate>Fri, 02 Aug 2024 11:00:00 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/08/dw%E5%B1%82%E7%9A%84%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/</guid>
        <description>&lt;p&gt;&lt;strong&gt;数仓建模即数据仓库建模，对数据仓库中的数据进行适当的联合，类似数据库分库建表，明晰数据关系，以便进行数据处理操作。（可以适当冗余，不遵循范式）&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;数仓建模在哪层建&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e4%bb%93%e5%bb%ba%e6%a8%a1%e5%9c%a8%e5%93%aa%e5%b1%82%e5%bb%ba&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;数仓建模在哪层建
&lt;/h2&gt;&lt;p&gt;以维度建模为例，建模是在数据源层的下一层进行建设，在上节的分层架构中，就是在&lt;strong&gt;DW 层进行数仓建模&lt;/strong&gt;，所以 DW 层是数仓建设的核心层！&lt;/p&gt;
&lt;h2 id=&#34;数仓建模要怎么建三种建模法&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e4%bb%93%e5%bb%ba%e6%a8%a1%e8%a6%81%e6%80%8e%e4%b9%88%e5%bb%ba%e4%b8%89%e7%a7%8d%e5%bb%ba%e6%a8%a1%e6%b3%95&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;数仓建模要怎么建(三种建模法)
&lt;/h2&gt;&lt;p&gt;常见的有&lt;strong&gt;范式建模法、维度建模法、实体建模法&lt;/strong&gt;等，每种方法从本质上将是从不同的角度看待业务中的问题。&lt;/p&gt;
&lt;h3 id=&#34;范式建模法third-normal-form3nf&#34;&gt;&lt;a href=&#34;#%e8%8c%83%e5%bc%8f%e5%bb%ba%e6%a8%a1%e6%b3%95third-normal-form3nf&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;范式建模法(Third Normal Form，3NF)
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;范式建模法其实是我们在构建数据模型常用的一个方法，该方法主要由 &lt;strong&gt;Inmon&lt;/strong&gt; 所提倡，主要解决关系型数据库的数据存储，利用的一种技术层面上的方法。目前，我们在关系型数据库中的建模 方法，大部分采用的是三范式建模法。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;范式&lt;/strong&gt;是符合某一种级别的关系模式的集合。构造数据库必须遵循一定的规则，而在关系型数据库 中这种规则就是范式，这一过程也被称为规范化。目前关系数据库有六种范式：第一范式 （1NF）、第二范式（2NF）、第三范式（3NF）、Boyce-Codd 范式（BCNF）、第四范式 （4NF）和第五范式（5NF）&lt;/li&gt;
&lt;li&gt;在数据仓库的模型设计中，&lt;strong&gt;一般采用第三范式&lt;/strong&gt; 。一个符合第三范式的关系必须具有以下三个条件 :
&lt;ul&gt;
&lt;li&gt;每个属性值唯一，不具有多义性 ;&lt;/li&gt;
&lt;li&gt;每个非主属性必须完全依赖于整个主键，而非主键的一部分 ;&lt;/li&gt;
&lt;li&gt;每个非主属性不能依赖于其他关系中的属性，因为这样的话，这种属性应该归到其他关系中去；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/08/dw%E5%B1%82%E7%9A%84%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/image.png&#34;
	width=&#34;1113&#34;
	height=&#34;475&#34;
	srcset=&#34;/zh-cn/post/2024/08/dw%E5%B1%82%E7%9A%84%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/image_hu_f3cc772c33a9dc46.png 480w, /zh-cn/post/2024/08/dw%E5%B1%82%E7%9A%84%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/image_hu_f62a8676ffd3bf01.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;234&#34;
		data-flex-basis=&#34;562px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;据 Inmon 的观点，&lt;strong&gt;数据仓库模型的建设方法和业务系统的企业数据模型类似&lt;/strong&gt;。在业务系统中，企业数据模型决定了数据的来源，而企业数据模型也分为两个层次，即&lt;strong&gt;主题域模型和逻辑模型&lt;/strong&gt;。同样，主题域模型可以看成是业务模型的概念模型，而逻辑模型则是域模型在关系型数据库上的实例化。&lt;/p&gt;
&lt;h3 id=&#34;维度建模法dimensional-modeling&#34;&gt;&lt;a href=&#34;#%e7%bb%b4%e5%ba%a6%e5%bb%ba%e6%a8%a1%e6%b3%95dimensional-modeling&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;维度建模法(Dimensional Modeling)
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;维度模型是数据仓库领域另一位大师&lt;strong&gt;Ralph Kimall&lt;/strong&gt;所倡导，他的《数据仓库工具箱》是数据仓库工程领域最流行的数仓建模经典。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;维度建模专门应用于分析型数据库、数据仓库、数据集市建模&lt;/strong&gt;，以分析决策的需求出发构建模型，构建的数据模型为分析需求服务，因此它&lt;strong&gt;重点解决用户如何更快速完成分析需求，同时还有较好的大规模复杂查询的响应性能&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;典型的代表是我们比较熟知的星形模型（Star-schema），以及在一些特殊场景下适用的雪花模型（Snow-schema）。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;维度建模中比较重要的概念就是 &lt;strong&gt;事实表（Fact table）和维度表（Dimension table）&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;事实表：&lt;br&gt;
发生在现实世界中的&lt;strong&gt;操作型事件，其所产生的可度量数值，存储在事实表中&lt;/strong&gt;。从最低的粒度级别来看， 事实表行对应一个度量事件，反之亦然。&lt;br&gt;
事实表特征：&lt;strong&gt;事实表=维度+度量&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;维度表：维度就是所分析的数据的一个量，维度表就是以合适的角度来创建的表，&lt;strong&gt;维度表的主键可以作为与之关联的任何事实表的外键&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/08/dw%E5%B1%82%E7%9A%84%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/image-1.png&#34;
	width=&#34;1152&#34;
	height=&#34;811&#34;
	srcset=&#34;/zh-cn/post/2024/08/dw%E5%B1%82%E7%9A%84%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/image-1_hu_e94965b353ae4f05.png 480w, /zh-cn/post/2024/08/dw%E5%B1%82%E7%9A%84%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/image-1_hu_bbe59f101819271d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;142&#34;
		data-flex-basis=&#34;340px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;总的说来，在数据仓库中不需要严格遵守规范化设计原则，有时还会故意设计数据冗余。因为数据仓库的主导功能就是面向分析，以查询为主，不涉及数据更新操作。事实表的设计是以能够正确记录历史信息为准则，维度表的设计是以能够以合适的角度来聚合主题内容为准则。&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;维度建模模式数据分析模型&#34;&gt;&lt;a href=&#34;#%e7%bb%b4%e5%ba%a6%e5%bb%ba%e6%a8%a1%e6%a8%a1%e5%bc%8f%e6%95%b0%e6%8d%ae%e5%88%86%e6%9e%90%e6%a8%a1%e5%9e%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;维度建模模式(数据分析模型)
&lt;/h4&gt;&lt;h5 id=&#34;星型模式&#34;&gt;&lt;a href=&#34;#%e6%98%9f%e5%9e%8b%e6%a8%a1%e5%bc%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;星型模式
&lt;/h5&gt;&lt;p&gt;&lt;strong&gt;星型模式&lt;/strong&gt;(Star Schema)是最常用的维度建模方式。星型模式是以事实表为中心，所有的维度表直接连接在事实表上，像星星一样。&lt;strong&gt;星形模式的维度建模由一个事实表和一组维表组成&lt;/strong&gt;，且具有以下特点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维表只和事实表关联，&lt;strong&gt;维表之间没有关联&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;每个维表&lt;strong&gt;主键为单列，且该主键放置在事实表中，作为两边连接的外键&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;以事实表为核心，维表围绕核心呈星形分布；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/08/dw%E5%B1%82%E7%9A%84%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/image-2.png&#34;
	width=&#34;1134&#34;
	height=&#34;847&#34;
	srcset=&#34;/zh-cn/post/2024/08/dw%E5%B1%82%E7%9A%84%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/image-2_hu_3c27d263079837cb.png 480w, /zh-cn/post/2024/08/dw%E5%B1%82%E7%9A%84%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/image-2_hu_bcc07608778e77ea.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;321px&#34;
	
&gt;&lt;/p&gt;
&lt;h5 id=&#34;星座模式&#34;&gt;&lt;a href=&#34;#%e6%98%9f%e5%ba%a7%e6%a8%a1%e5%bc%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;星座模式
&lt;/h5&gt;&lt;p&gt;星座模式是星型模式延伸而来，星型模式是基于一张事实表的，而&lt;strong&gt;星座模式是基于多张事实表的，而且共享维表&lt;/strong&gt;。很多时候维度空间内的事实表不止一个，而一个维表也可能被多个事实表用到。&lt;strong&gt;在业务发展后期，绝大部分维度建模都采用的是星座模式&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/08/dw%E5%B1%82%E7%9A%84%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/image-3.png&#34;
	width=&#34;1152&#34;
	height=&#34;683&#34;
	srcset=&#34;/zh-cn/post/2024/08/dw%E5%B1%82%E7%9A%84%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/image-3_hu_6898b953bc91e811.png 480w, /zh-cn/post/2024/08/dw%E5%B1%82%E7%9A%84%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/image-3_hu_66b06e6c68d4ef40.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;168&#34;
		data-flex-basis=&#34;404px&#34;
	
&gt;&lt;/p&gt;
&lt;h5 id=&#34;雪花模式&#34;&gt;&lt;a href=&#34;#%e9%9b%aa%e8%8a%b1%e6%a8%a1%e5%bc%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;  雪花模式
&lt;/h5&gt;&lt;p&gt;雪花模式(Snowflake Schema)是对星型模式的扩展。雪花模式的维度表可以拥有其他维度表的，虽然这种模型相比星型更规范一些，但是由于这种模型不太容易理解，&lt;strong&gt;维护成本比较高&lt;/strong&gt;，而且性能方面需要关联多层维表，&lt;strong&gt;性能也比星型模型要低&lt;/strong&gt;。所以一般不是很常用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/08/dw%E5%B1%82%E7%9A%84%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/image-4.png&#34;
	width=&#34;1148&#34;
	height=&#34;771&#34;
	srcset=&#34;/zh-cn/post/2024/08/dw%E5%B1%82%E7%9A%84%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/image-4_hu_86b8aaf35b9a482a.png 480w, /zh-cn/post/2024/08/dw%E5%B1%82%E7%9A%84%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/image-4_hu_da7c54673d240641.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;148&#34;
		data-flex-basis=&#34;357px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;维度建模过程&#34;&gt;&lt;a href=&#34;#%e7%bb%b4%e5%ba%a6%e5%bb%ba%e6%a8%a1%e8%bf%87%e7%a8%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;维度建模过程
&lt;/h3&gt;&lt;p&gt;数仓工具箱中的维度建模四步走：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/08/dw%E5%B1%82%E7%9A%84%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/image-5.png&#34;
	width=&#34;1107&#34;
	height=&#34;668&#34;
	srcset=&#34;/zh-cn/post/2024/08/dw%E5%B1%82%E7%9A%84%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/image-5_hu_d98f97b6f1f3545a.png 480w, /zh-cn/post/2024/08/dw%E5%B1%82%E7%9A%84%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/image-5_hu_cec3fb77290704.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;165&#34;
		data-flex-basis=&#34;397px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;选择业务过程&#34;&gt;&lt;a href=&#34;#%e9%80%89%e6%8b%a9%e4%b8%9a%e5%8a%a1%e8%bf%87%e7%a8%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;选择业务过程
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;维度建模是紧贴业务的，所以必须&lt;strong&gt;以业务为根基&lt;/strong&gt;进行建模，那么选择业务过程，顾名思义就是在整个业务流程中&lt;strong&gt;选取需要建模的业务&lt;/strong&gt;，根据运营提供的需求及日后的易扩展性等进行选择业务。&lt;/li&gt;
&lt;li&gt;比如商城，整个商城流程分为商家端，用户端，平台端，运营需求是总订单量，订单人数，及&lt;strong&gt;用户购买情况&lt;/strong&gt;等，我们选择业务过程就选择用户端的数据，商家及平台端暂不考虑。业务选择非常重要，因为后面所有的步骤都是基于此业务数据展开的。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;声明粒度&#34;&gt;&lt;a href=&#34;#%e5%a3%b0%e6%98%8e%e7%b2%92%e5%ba%a6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;  声明粒度
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;相关名词不清楚的可以查看该博客&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/140798330&#34;  title=&#34;​​​​​​数仓常见名词解析和名词之间的关系-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;​​​​​​ 数仓常见名词解析和名词之间的关系-CSDN 博客&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;先举个例子：对于用户来说，一个用户有一个身份证号，一个户籍地址，多个手机号，多张银行卡，那么&lt;strong&gt;与用户粒度相同的粒度&lt;/strong&gt;属性有身份证粒度，户籍地址粒度，比用户粒度&lt;strong&gt;更细的粒度&lt;/strong&gt;有手机号粒度，银行卡粒度，&lt;strong&gt;存在一对一的关系就是相同粒度&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;为什么要提相同粒度呢？在同一事实表中，必须具有相同的粒度，&lt;strong&gt;同一事实表中不要混用多种不同的粒度&lt;/strong&gt;，不同的粒度数据建立不同的事实表。并且从给定的业务过程获取数据时，建议从关注&lt;strong&gt;原子粒度&lt;/strong&gt;开始设计，&lt;strong&gt;也就是从最细粒度开始&lt;/strong&gt;，因为原子粒度能够承受无法预期的用户查询。但是上卷汇总粒度对查询性能的提升很重要的，所以对于有明确需求的数据，我们建立针对需求的上卷汇总粒度，对需求不明朗的数据我们建立原子粒度。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;确认维度&#34;&gt;&lt;a href=&#34;#%e7%a1%ae%e8%ae%a4%e7%bb%b4%e5%ba%a6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;确认维度
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;维度表是作为业务分析的入口和描述性标识，所以也被称为数据仓库的“灵魂”&lt;/strong&gt;。在一堆的数据中怎么确认哪些是维度属性呢，如果该列是对具体值的描述，是一个文本或常量，某一约束和行标识的参与者， 此时该属性往往是维度属性，数仓工具箱中告诉我们牢牢掌握事实表的粒度，就能将所有可能存在的维度区分开，并且要确保维度表中不能出现重复数据，应使维度主键唯一。&lt;/p&gt;
&lt;h4 id=&#34;确认事实&#34;&gt;&lt;a href=&#34;#%e7%a1%ae%e8%ae%a4%e4%ba%8b%e5%ae%9e&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;确认事实
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;事实表是用来度量的，基本上都以数量值表示，事实表中的每行对应一个度量，每行中的数据是一个特定级别的细节数据，称为粒度&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;维度建模的核心原则之一是&lt;strong&gt;同一事实表中的所有度量必须具有相同的粒度&lt;/strong&gt;。这样能确保不会出现重复计算度量的问题。&lt;strong&gt;有时候往往不能确定该列数据是事实属性还是维度属 性&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;记住最实用的事实就是数值类型和可加类型事实。所以可以通过分析该列是否是一种包含多个值并作为计算的参与者的度量，这种情况下该列往往是事实。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;实体建模法entity-modeling&#34;&gt;&lt;a href=&#34;#%e5%ae%9e%e4%bd%93%e5%bb%ba%e6%a8%a1%e6%b3%95entity-modeling&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;  实体建模法(Entity Modeling)
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;实体建模法并不是数据仓库建模中常见的一个方法，它来源于哲学的一个流派。从哲学的意义上说，客观世界应该是可以细分的，客观世界应该可以分成由一个个实体，以及实体与实体之间的关系组成。&lt;/li&gt;
&lt;li&gt;那么我们在数据仓库的建模过程中完全可以引入这个抽象的方法，将整个业务也可以划分成一个个的实体，而&lt;strong&gt;每个实体之间的关系，以及针对这些关系的说明就是我们数据建模需要做的工作。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;将任何一个业务过程划分成 3 个部分，实体，事件，说明，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/08/dw%E5%B1%82%E7%9A%84%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/image-6.png&#34;
	width=&#34;1033&#34;
	height=&#34;470&#34;
	srcset=&#34;/zh-cn/post/2024/08/dw%E5%B1%82%E7%9A%84%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/image-6_hu_1fe55141184f1474.png 480w, /zh-cn/post/2024/08/dw%E5%B1%82%E7%9A%84%E6%95%B0%E4%BB%93%E5%BB%BA%E6%A8%A1%E8%8C%83%E5%BC%8F%E5%BB%BA%E6%A8%A1%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BD%93%E5%BB%BA%E6%A8%A1/image-6_hu_6716408583d6f38d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;219&#34;
		data-flex-basis=&#34;527px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;上图表述的是一个抽象的含义，如果我们描述一个简单的事实：“小明开车去学校上学”。以这个业务事 实为例，我们可以把“小明”，“学校”看成是一个实体，“上学”描述的是一个业务过程，我们在这里可以抽象为一个具体“事件”，而“开车去”则可以看成是事件“上学”的一个说明。&lt;/strong&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>数仓分层ODS、DWD、DWM、DWS、DIM、DM、ADS</title>
        <link>/zh-cn/post/2024/08/%E6%95%B0%E4%BB%93%E5%88%86%E5%B1%82odsdwddwmdwsdimdmads/</link>
        <pubDate>Thu, 01 Aug 2024 11:00:00 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/08/%E6%95%B0%E4%BB%93%E5%88%86%E5%B1%82odsdwddwmdwsdimdmads/</guid>
        <description>&lt;h2 id=&#34;数仓分层&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e4%bb%93%e5%88%86%e5%b1%82&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;数仓分层
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;那么为什么要数据仓库进行分层呢？&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;用空间换时间&lt;/strong&gt;，通过大量的预处理来提升应用系统的用户体验（效率），因此数据仓库会存在&lt;strong&gt;大量冗余的数据&lt;/strong&gt;；&lt;strong&gt;不分层的话，如果源业务系统的业务规则发生变化将会影响整个数据清洗过程，工作量巨大&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;通过&lt;strong&gt;数据分层管理可以简化数据清洗&lt;/strong&gt;的过程，把一个复杂的工作拆成了多个简单的工作，把一个大的黑盒变成了一个白盒，每一层的处理逻辑都相对简单和容易理解，这样比较容易保证每一个步骤的正确性，当数据发生错误的时候，往往我们只需要&lt;strong&gt;溯源&lt;/strong&gt;并局部调整某个步骤即可。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分层是以解决当前业务快速的数据支撑为目的&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;抽象出共性的框架并能够赋能给其他业务线，同时为业务发展提供稳定、准确的数据支撑&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;并能够按照已有的模型为新业务发展提供方向，也就是数据驱动和赋能&lt;/strong&gt; &amp;gt; &lt;strong&gt;一个好的分层架构，要有以下好处：&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;1. 清晰数据结构&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. 数据血缘追踪：数据 ETL 转化过程中的流动变化&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. 减少重复开发，提高数据复用性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4. 数据关系条理化&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5. 屏蔽原始数据的影响&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;数仓分层要结合公司业务进行，并且需要清晰明确各层职责，&lt;strong&gt;一般&lt;/strong&gt;采用如下分层结构：
&lt;img src=&#34;/zh-cn/post/2024/08/%E6%95%B0%E4%BB%93%E5%88%86%E5%B1%82odsdwddwmdwsdimdmads/image.png&#34;
	width=&#34;1080&#34;
	height=&#34;1031&#34;
	srcset=&#34;/zh-cn/post/2024/08/%E6%95%B0%E4%BB%93%E5%88%86%E5%B1%82odsdwddwmdwsdimdmads/image_hu_49c0e3a6ac4a06ad.png 480w, /zh-cn/post/2024/08/%E6%95%B0%E4%BB%93%E5%88%86%E5%B1%82odsdwddwmdwsdimdmads/image_hu_8e8bf53f13e4d0d8.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;104&#34;
		data-flex-basis=&#34;251px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;数仓建模在哪层建设呢？我们以&lt;strong&gt;维度建模&lt;/strong&gt; 为例，建模是在数据源层的下一层进行建设，在上图中，就是在 &lt;strong&gt;DW 层进行数仓建模&lt;/strong&gt;，所以 DW 层是数仓建设的核心层。 下面详细阐述下每层建设规范！&lt;/p&gt;
&lt;h3 id=&#34;数据源层odsoperational-data-store&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e6%8d%ae%e6%ba%90%e5%b1%82odsoperational-data-store&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;数据源层：ODS(Operational Data Store)
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;ODS 层是最接近数据源的一层，又叫&lt;strong&gt;贴源层&lt;/strong&gt; ，考虑后续可能需要&lt;strong&gt;追溯数据&lt;/strong&gt; 问题， 因此对于这一层就&lt;strong&gt;不建议做过多的数据清洗工作&lt;/strong&gt;，原封不动地接入原始数据即可， 至于&lt;strong&gt;数据去噪、去重、异常值处理等过程可以放在后面的 DWD 层&lt;/strong&gt;来做！&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;数据仓库层dwdata-warehouse&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e6%8d%ae%e4%bb%93%e5%ba%93%e5%b1%82dwdata-warehouse&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;数据仓库层：DW(Data Warehouse)
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;数据仓库层是数据仓库核心层，在这里把从 ODS 层中获得的数据按照主题建立各种数据模型。该层又依次&lt;strong&gt;细分为 DWD、DWM、DWS&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;数据明细层dwddata-warehouse-detail&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e6%8d%ae%e6%98%8e%e7%bb%86%e5%b1%82dwddata-warehouse-detail&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;数据明细层：DWD(Data Warehouse Detail)
&lt;/h4&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;该层一般&lt;strong&gt;保持和 ODS 层一样的数据粒度&lt;/strong&gt;，并且提供&lt;strong&gt;一定的数据质量保证&lt;/strong&gt; 。&lt;strong&gt;DWD 层要做的就是将数据清理、整合、规范化，把脏数据、垃圾数据、规范不一致的、状态定义不一致的、命名不规范的数据处理掉。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;同时，为了提高数据明细层的易用性，该层会采用一些&lt;strong&gt;维度退化&lt;/strong&gt;手法，将维度退化至事实表中，减少事实表和维表的关联。&lt;/li&gt;
&lt;li&gt;另外，在该层也会做&lt;strong&gt;一部分的数据聚合&lt;/strong&gt;，将相同主题的数据汇集到一张表中，提高数据的可用性 。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;数据中间层dwmdata-warehouse-middle&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e6%8d%ae%e4%b8%ad%e9%97%b4%e5%b1%82dwmdata-warehouse-middle&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;数据中间层：DWM(Data WareHouse Middle)
&lt;/h4&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;该层会在 DWD 层的数据基础上，数据做&lt;strong&gt;轻度聚合&lt;/strong&gt; ，生成一系列的&lt;strong&gt;中间表&lt;/strong&gt; ， &lt;strong&gt;提升公共指标的复用性&lt;/strong&gt;，减少重复加工。&lt;/li&gt;
&lt;li&gt;直观来讲，就是对通用的核心维度进行聚合操作，算出相应的统计指标。&lt;/li&gt;
&lt;li&gt;在实际计算中，如果直接从 DWD 或者 ODS 计算出宽表的统计指标，会存在计算量太大并且维度太少的问题，因此一般的做法是，&lt;strong&gt;在 DWM 层先计算出多个小的中间表，然后再拼接成一张 DWS 的宽表&lt;/strong&gt;。由于宽和窄的界限不易界定，&lt;strong&gt;也可以去掉 DWM&lt;/strong&gt; 这一层，只留 DWS 层，将所有的数据再放在 DWS 也可。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;数据服务层dwsdata-warehouse-service&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e6%8d%ae%e6%9c%8d%e5%8a%a1%e5%b1%82dwsdata-warehouse-service&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;数据服务层：DWS(Data WareHouse Service)
&lt;/h4&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;DWS 层为公共汇总层，会进行&lt;strong&gt;轻度汇总&lt;/strong&gt; ，&lt;strong&gt;粒度比明细数据稍粗&lt;/strong&gt;，基于 DWD 层上的基础数据，整合汇总成分析某一个主题域的服务数据。&lt;/li&gt;
&lt;li&gt;DWS 层应覆 盖 80% 的应用场景。又&lt;strong&gt;称数据集市或宽表&lt;/strong&gt;。 按照业务划分，如主题域流量、订单、用户等，生成字段比较多的宽表，用于提供后续的业务查询，OLAP 分析，数据分发等。&lt;/li&gt;
&lt;li&gt;一般来讲，该层的数据表会相对比较少，一张表会涵盖比较多的业务内容，由于其&lt;strong&gt;字段较多&lt;/strong&gt;，因此一般也会称该层的表为&lt;strong&gt;宽表&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;数据集市层dmdata-mart&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e6%8d%ae%e9%9b%86%e5%b8%82%e5%b1%82dmdata-mart&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;数据集市层：DM(Data Mart)
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;基于 DW 的基础数据，整合汇总成一个个数据集市，数据集市通常是面向部门的某个主题域的报表数据。比如用户留存表、用户活跃表、商品销量表、商品营收表等等。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;维表层dimdimension&#34;&gt;&lt;a href=&#34;#%e7%bb%b4%e8%a1%a8%e5%b1%82dimdimension&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;维表层：DIM(Dimension)
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;如果维表过多，也可针对维表设计单独一层，维表层主要包含两部分数据：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;高基数维度数据：一般是用户资料表、商品资料表类似的资料表。数据量可能是千万级或者上亿级别。&lt;/li&gt;
&lt;li&gt;低基数维度数据：一般是配置表，比如枚举值对应的中文含义，或者日期维表。 数据量可能是个位数或者几千几万&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;数据应用层adsapplication-data-service&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e6%8d%ae%e5%ba%94%e7%94%a8%e5%b1%82adsapplication-data-service&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;数据应用层：ADS(Application Data Service)
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;在这里，主要是&lt;strong&gt;提供给数据产品和数据分析使用的数据&lt;/strong&gt; ，一般会存放在 ES、 PostgreSql、Redis 等系统中供线上系统使用，也可能会存在 Hive 或者 Druid 中供数据分析和数据挖掘使用。比如我们经常说的&lt;strong&gt;报表数据&lt;/strong&gt;，一般就放在这里。&lt;/p&gt;&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>大数据HBase图文简介及Phoenix</title>
        <link>/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/</link>
        <pubDate>Mon, 29 Jul 2024 11:30:00 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/</guid>
        <description>&lt;h2 id=&#34;引言&#34;&gt;&lt;a href=&#34;#%e5%bc%95%e8%a8%80&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;引言
&lt;/h2&gt;&lt;p&gt;要想明白为什么 HBase 的产生，就需要先了解一下 Hadoop。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Hadoop 可以通过 HDFS 来存 储结构化、半结构甚至非结构化的数据，是传统数据库的补充，是海量数据存储的最佳方法，它针对大文件的存储、批量访问和流式访问都做了优化，同时也通过多副本解决了容灾问题。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;但是 Hadoop 的缺陷在于它&lt;strong&gt;只能执行批处理&lt;/strong&gt;，并且只能以&lt;strong&gt;顺序方式访问数据&lt;/strong&gt;，这意味着即使是最简单的工作也必须搜索整个数据集，&lt;strong&gt;无法实现对数据的随机访问&lt;/strong&gt;。实现数据的&lt;strong&gt;随机访问是传统的关系型数据库所擅长的&lt;/strong&gt;，但它们却不能用于海量数据的存储。在这种情况下，必须有一种新的方案来&lt;strong&gt;同时解决海量数据存储和随机访问的问题&lt;/strong&gt;，HBase 就是其中之一 (HBase，Cassandra，couchDB，Dynamo 和 MongoDB 都能存储海量数据并支持随机访问)。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;数据结构分类：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;结构化数据：即以关系型数据库表形式管理的数据；&lt;/li&gt;
&lt;li&gt;半结构化数据：非关系模型的，有基本固定结构模式的数据，例如日志文件、XML 文档、 JSON 文档、Email 等；&lt;/li&gt;
&lt;li&gt;非结构化数据：没有固定模式的数据，如 WORD、PDF、PPT、EXL，各种格式的图片、视 频等。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;hbase-简介&#34;&gt;&lt;a href=&#34;#hbase-%e7%ae%80%e4%bb%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HBase 简介
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;HBase 全称 Hadoop Database ，是一个基于 HDFS 的分布式的、面向列的开源数据库，但是这个数据库没有 SQL，只提供了 API，需要 API 编程来使用 HBase，而后面提到的 Phoenix 才使得可以用 SQL 操作 HBase！&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;HBase 有如下特点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;容量大：一个表可以有数十亿行，上百万列，这也和它的扩展性息息相关；&lt;/li&gt;
&lt;li&gt;面向列：数据是按照列存储，每一列都单独存放，数据即索引，在查询时可以只访问指定列的数据，有效地降低了系统的 I/O 负担；&lt;/li&gt;
&lt;li&gt;稀疏性：空 (null) 列并不占用存储空间，表可以设计的非常稀疏 ；&lt;/li&gt;
&lt;li&gt;易扩展：的扩展性主要体现在两个方面，一个是基于上层处理能力（RegionServer） 的扩展，一个是基于存储的扩展（HDFS）。通过横向添加 RegionSever 的机器， 进行水平扩展，提升 Hbase 上层的处理能力，提升 Hbsae 服务更多 Region 的 能力。&lt;/li&gt;
&lt;li&gt;数据多版本：每个单元中的数据可以有多个版本，按照时间戳排序，新的数据在最上面；&lt;/li&gt;
&lt;li&gt;采用 HDFS 作为底层存储，支持结构化、半结构化和非结构化的存储；&lt;/li&gt;
&lt;li&gt;支持数据分片；&lt;/li&gt;
&lt;li&gt;易于使用的 Java 客户端 API，客户端可以通过 HBase 实现对 HDFS 上数据的随机访问；&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image.png&#34;
	width=&#34;1135&#34;
	height=&#34;612&#34;
	srcset=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image_hu_1c021cc8169d6b19.png 480w, /zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image_hu_ba0871a8f16ba121.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;185&#34;
		data-flex-basis=&#34;445px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;hbase-的表&#34;&gt;&lt;a href=&#34;#hbase-%e7%9a%84%e8%a1%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HBase 的表
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;表 schema 仅定义列族，表具有多个列族，每个列族可以包含任意数量的列，列由多个单元格 （cell ）组成，单元格可以存储多个版本的数据，多个版本数据以时间戳进行区分。&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;所有数据的底层存储格式都是字节数组；&lt;/li&gt;
&lt;li&gt;不持复杂的事务，只支持行级事务，即单行数据的读写都是原子性的；&lt;/li&gt;
&lt;li&gt;查询功能简单，不支持 join 等复杂操作；&lt;/li&gt;
&lt;li&gt;仅支持通过主键(row key)和主键的 range 来检索数据；&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-1.png&#34;
	width=&#34;1101&#34;
	height=&#34;797&#34;
	srcset=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-1_hu_5bc7b7725805adfb.png 480w, /zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-1_hu_eb82ecc2a0e98dbf.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;138&#34;
		data-flex-basis=&#34;331px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;row-key-行键&#34;&gt;&lt;a href=&#34;#row-key-%e8%a1%8c%e9%94%ae&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Row Key 行键
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;Row Key 是用来检索记录的主键。想要访问 HBase Table 中的数据，只有以下三种方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过指定的 Row Key 进行访问；&lt;/li&gt;
&lt;li&gt;通过 Row Key 的 range 进行访问，即访问指定范围内的行；&lt;/li&gt;
&lt;li&gt;进行全表扫描；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Row Key 可以是任意字符串，存储时数据按照 Row Key 的&lt;strong&gt;字典序进行排序&lt;/strong&gt;，这里需要注意以下两点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;因为字典序对 int 排序的结果是 1,10,100,11,12,13,14,15,16,17,18,19,2,20,21,…,9,91,92,93,94,95,96,97,98,99。如果你使用整型的字符串作为行键，那么为了保持整型的自然序，&lt;strong&gt;行键必须用 0 作左填充&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;行的一次读写操作时原子性的 (不论一次读写多少列)。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;column-family-列族&#34;&gt;&lt;a href=&#34;#column-family-%e5%88%97%e6%97%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Column Family 列族
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;HBase 表中的每个列，都归属于某个列族。列族是表的 Schema 的一部分，所以列族需要在创建表时定义。&lt;/li&gt;
&lt;li&gt;列族的所有列都以列族名作为前缀，例如 courses:history ， courses:math 都属于 courses 这个列族。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;column-qualifier-列限定符&#34;&gt;&lt;a href=&#34;#column-qualifier-%e5%88%97%e9%99%90%e5%ae%9a%e7%ac%a6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Column Qualifier 列限定符
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;列限定符，可以理解为是具体的列名，例如 courses:history ， courses:math 都属于 courses 这个列族，它们的列限定符分别是 history 和 math 。需要注意的是列限定符不是表 Schema 的一部分，可以在插入数据的过程中动态创建列。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;cell-单元格&#34;&gt;&lt;a href=&#34;#cell-%e5%8d%95%e5%85%83%e6%a0%bc&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Cell 单元格
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;Cell 是行，列族和列限定符的组合，并包含值和时间戳。可以等价理解为关系型数据库中由指定行和指定列确定的一个单元格，而不同的是 HBase 中的一个单元格是由多个版本的数据组成的，每个版本的数据用时间戳进行区分。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;timestamp-时间戳&#34;&gt;&lt;a href=&#34;#timestamp-%e6%97%b6%e9%97%b4%e6%88%b3&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Timestamp 时间戳
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;HBase 中通过 row key 和 column 确定的为一个存储单元称为 Cell 。每个 Cell 都保存着同一份数 据的多个版本。版本通过时间戳来索引，时间戳的类型是 64 位整型，时间戳可以由 HBase 在数据写入 时自动赋值，也可以由客户显式指定。每个 Cell 中，不同版本的数据按照时间戳倒序排列，即最新的数据排在最前面。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;hbase-的存储结构&#34;&gt;&lt;a href=&#34;#hbase-%e7%9a%84%e5%ad%98%e5%82%a8%e7%bb%93%e6%9e%84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HBase 的存储结构
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-2.png&#34;
	width=&#34;1518&#34;
	height=&#34;785&#34;
	srcset=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-2_hu_4d44bb99c9d0bcbd.png 480w, /zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-2_hu_930d5ac1c3f1ab27.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;193&#34;
		data-flex-basis=&#34;464px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;regions&#34;&gt;&lt;a href=&#34;#regions&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Regions
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;HBase Table 中的所有行按照 Row Key 的字典序排列。HBase Tables 通过行键的范围 (row key range) 被&lt;strong&gt;水平切分&lt;/strong&gt;成多个 Region , &lt;strong&gt;一个 Region 包含了在 start key 和 end key 之间的所有行。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;每个表一开始只有一个 Region ，随着数据不断增加， Region 会不断增大，当增大到一个阀值的时 候， Region 就会&lt;strong&gt;等分&lt;/strong&gt;为两个新的 Region 。当 Table 中的行不断增多，就会有越来越多的 Region 。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-3.png&#34;
	width=&#34;1006&#34;
	height=&#34;649&#34;
	srcset=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-3_hu_f98bb24009154550.png 480w, /zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-3_hu_885c1a6987552d12.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;155&#34;
		data-flex-basis=&#34;372px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Region 是 HBase 中&lt;strong&gt;分布式存储和负载均衡的最小单元&lt;/strong&gt;。这意味着不同的 Region 可以分布在不同的 Region Server 上。但&lt;strong&gt;一个 Region 是不会拆分到多个 Server&lt;/strong&gt; 上的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-4.png&#34;
	width=&#34;1042&#34;
	height=&#34;576&#34;
	srcset=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-4_hu_a686118d976c0b46.png 480w, /zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-4_hu_83ca7e87c140d2f4.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;180&#34;
		data-flex-basis=&#34;434px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;region-server&#34;&gt;&lt;a href=&#34;#region-server&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Region Server
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;Region Server &lt;strong&gt;运行在 HDFS 的 DataNode&lt;/strong&gt; 上。它具有以下组件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;WAL(Write Ahead Log，预写日志)：对 HBase 读写数据的时候，数据&lt;strong&gt;不是直接写进磁盘&lt;/strong&gt;，它会&lt;strong&gt;在内存中保留&lt;/strong&gt;一段时间，但把数据保存在内存中可能有更高的概率引起数据丢失，为了解决这个问题，数据会先写在一个叫 做 Write-Ahead logfile 的文件中&lt;strong&gt;存储尚未进持久化存储的数据记录&lt;/strong&gt;，以便在发生故障时进行恢复。&lt;/li&gt;
&lt;li&gt;BlockCache：读缓存。它&lt;strong&gt;将频繁读取的数据存储在内存中，如果存储不足，它将按照 最近最少使 用原则 清除多余的数据。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;MemStore：写缓存。它&lt;strong&gt;存储尚未写入磁盘的新数据，&lt;strong&gt;并会在数据写入磁盘之前对其进行排序。 每个 Region 上的&lt;/strong&gt;每个列族都有一个 MemStore&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;HFile ：将行数据按照 Key\Values 的形式存储在文件系统上，是实际的存储文件。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Region Server 存取一个子表时，会创建一个 Region 对象，然后对表的每个列族创建一个 Store 实例，每个 Store 会有 0 个或多个 StoreFile 与之对应，每个 StoreFile 则对应一个 HFile ，HFile 就是实际存储在 HDFS 上的文件。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;hbase-的系统架构&#34;&gt;&lt;a href=&#34;#hbase-%e7%9a%84%e7%b3%bb%e7%bb%9f%e6%9e%b6%e6%9e%84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HBase 的系统架构
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-5.png&#34;
	width=&#34;1478&#34;
	height=&#34;774&#34;
	srcset=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-5_hu_a073c34b524d71e3.png 480w, /zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-5_hu_e37f046de00bb9d0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;190&#34;
		data-flex-basis=&#34;458px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;HBase 系统遵循 Master/Salve 架构，由三种不同类型的组件组成：&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;zookeeper&#34;&gt;&lt;a href=&#34;#zookeeper&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Zookeeper
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;保证任何时候，集群中只有一个 Master；&lt;/li&gt;
&lt;li&gt;存贮所有 Region 的寻址入口；&lt;/li&gt;
&lt;li&gt;实时监控 Region Server 的状态，将 Region Server 的上线和下线信息实时通知给 Master；&lt;/li&gt;
&lt;li&gt;存储 HBase 的 Schema，包括有哪些 Table，每个 Table 有哪些 Column Family 等信息；&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;master&#34;&gt;&lt;a href=&#34;#master&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Master
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;为 Region Server 分配或移除 Region ；&lt;/li&gt;
&lt;li&gt;负责 Region Server 的负载均衡 ；&lt;/li&gt;
&lt;li&gt;处理 Region Server 的故障转移；&lt;/li&gt;
&lt;li&gt;处理 GFS 上的垃圾文件回收；&lt;/li&gt;
&lt;li&gt;处理 Schema 的更新请求；&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-6.png&#34;
	width=&#34;1449&#34;
	height=&#34;723&#34;
	srcset=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-6_hu_602aff3094b4ca1c.png 480w, /zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-6_hu_fa0a120d709e3199.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;200&#34;
		data-flex-basis=&#34;480px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;region-server-1&#34;&gt;&lt;a href=&#34;#region-server-1&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Region Server
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;负责维护 Master 分配给它的 Region ，并处理发送到 Region 上的 IO 请求；&lt;/li&gt;
&lt;li&gt;负责切分在运行过程中变得过大的 Region；&lt;/li&gt;
&lt;li&gt;维护 HLog&lt;/li&gt;
&lt;li&gt;刷新缓存到 HDFS&lt;/li&gt;
&lt;li&gt;存储 HBase 的实际数据&lt;/li&gt;
&lt;li&gt;压缩数据&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-7.png&#34;
	width=&#34;1412&#34;
	height=&#34;690&#34;
	srcset=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-7_hu_3b7183c5185c40e2.png 480w, /zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-7_hu_a32f5a80efac50a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;204&#34;
		data-flex-basis=&#34;491px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;三个组件间的协作&#34;&gt;&lt;a href=&#34;#%e4%b8%89%e4%b8%aa%e7%bb%84%e4%bb%b6%e9%97%b4%e7%9a%84%e5%8d%8f%e4%bd%9c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;三个组件间的协作
&lt;/h3&gt;&lt;p&gt;HBase 使用 ZooKeeper 作为分布式协调服务来维护集群中的服务器状态。 Zookeeper 负责维护可用 服务列表，并提供服务故障通知等服务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个 Region Server 都会在 ZooKeeper 上创建一个临时节点，Master 通过 Zookeeper 的 Watcher 机制对节点进行监控，从而发现新加入的 Region Server 或故障退出的 Region Server；&lt;/li&gt;
&lt;li&gt;所有 Masters 会&lt;strong&gt;竞争&lt;/strong&gt;性地在 Zookeeper 上创建同一个临时节点，由于 Zookeeper 只能有一个同名节点，所以必然只有一个 Master 能够创建成功，此时该 Master 就是主 Master，主 Master 会 定期向 Zookeeper &lt;strong&gt;发送心跳&lt;/strong&gt;。备用 Masters 则通过 Watcher 机制对主 HMaster 所在节点&lt;strong&gt;进行监听&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;如果主 Master 未能定时发送心跳，则其持有的 Zookeeper 会话会过期，相应的临时节点也会被 删除，这会触发定义在该节点上的 Watcher 事件，使得备用的 Master Servers 得到通知。所有备 用的 Master Servers 在接到通知后，会再次去竞争性地创建临时节点，完成主 Master 的选举。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;写数据流程&#34;&gt;&lt;a href=&#34;#%e5%86%99%e6%95%b0%e6%8d%ae%e6%b5%81%e7%a8%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;写数据流程
&lt;/h2&gt;&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;Client 向 Region Server 提交写请求；&lt;/li&gt;
&lt;li&gt;Region Server 找到目标 Region；&lt;/li&gt;
&lt;li&gt;Region 检查数据是否与 Schema 一致；&lt;/li&gt;
&lt;li&gt;如果客户端没有指定版本，则获取当前系统时间作为数据版本；&lt;/li&gt;
&lt;li&gt;将更新写入 WAL Log；&lt;/li&gt;
&lt;li&gt;将更新写入 Memstore；&lt;/li&gt;
&lt;li&gt;判断 Memstore 存储是否已满，如果存储已满则需要 flush 为 Store Hfile 文件。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-8.png&#34;
	width=&#34;1395&#34;
	height=&#34;681&#34;
	srcset=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-8_hu_d2c3f98f2cc52422.png 480w, /zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-8_hu_bd2f42fcfdcea680.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;204&#34;
		data-flex-basis=&#34;491px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;读数据流程&#34;&gt;&lt;a href=&#34;#%e8%af%bb%e6%95%b0%e6%8d%ae%e6%b5%81%e7%a8%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;读数据流程
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;以下是客户端首次读写 HBase 上数据的流程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;客户端从 Zookeeper 获取 META 表所在的 Region Server；&lt;/li&gt;
&lt;li&gt;客户端访问 META 表所在的 Region Server，从 META 表中查询到访问行键所在的 Region Server，之后客户端将&lt;strong&gt;缓存&lt;/strong&gt;这些信息以及 META 表的位置；&lt;/li&gt;
&lt;li&gt;客户端从行键所在的 Region Server 上获取数据。&lt;/li&gt;
&lt;li&gt;如果再次读取，客户端将&lt;strong&gt;从缓存中获取&lt;/strong&gt;行键所在的 Region Server。这样客户端就不需要再次查询 META 表，除非 Region 移动导致缓存失效，这样的话，则将会重新查询并更新缓存。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注： META 表是 HBase 中一张特殊的表，它保存了所有 Region 的位置信息，META 表自己的位置信息 则存储在 ZooKeeper 上。
&lt;img src=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-9.png&#34;
	width=&#34;1404&#34;
	height=&#34;707&#34;
	srcset=&#34;/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-9_hu_9ee2c9e6c3a06dd9.png 480w, /zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/image-9_hu_bd7abe86cb55993a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;198&#34;
		data-flex-basis=&#34;476px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;phoenix-简介&#34;&gt;&lt;a href=&#34;#phoenix-%e7%ae%80%e4%bb%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Phoenix 简介
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Phoenix 是 HBase 的开源 SQL 中间层，在 Phoenix 之前，如果要使用  HBase，只能调用它的 Java API，但是 Phoenix 允许使用标准 JDBC 的方式来操作 HBase ！&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Phoenix 的理念是 we put sql SQL back in NOSQL&lt;/strong&gt; ，即可以使用标准的 SQL 就能完成对 HBase 上数据的操作，这也意味着可以&lt;strong&gt;通过集成 Spring Data JPA 或 Mybatis 等常用的持久层框架来操作 HBase&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;其次 Phoenix 的性能表现也非常优异， Phoenix 查询引擎会将 SQL 查询转换为一个或多个 HBase Scan，通过并行执行来生成标准的 JDBC 结果集。它通过直接使用 HBase API 以及协处理器和自定义过 滤器，可以为小型数据查询提供毫秒级的性能，为千万行数据的查询提供秒级的性能。&lt;/li&gt;
&lt;li&gt;同时 Phoenix 还 拥有二级索引等 HBase 不具备的特性，不仅如此 Phoenix 对于用户输入的 SQL 同样会有大量的优化手段（就像 hive 自带 sql 优化器一样）&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>kafka实战 集群搭建-Kraft模式</title>
        <link>/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/</link>
        <pubDate>Sun, 05 May 2024 20:57:35 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/</guid>
        <description>&lt;h2 id=&#34;集群配置&#34;&gt;&lt;a href=&#34;#%e9%9b%86%e7%be%a4%e9%85%8d%e7%bd%ae&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;集群配置
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;三台服务器：linux01、linux02、linux03&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;每台服务器均安装了 zookeeper、kafka，服务器之间做了 ssh 免密登录（集群启停脚本用）&lt;/p&gt;
&lt;p&gt;kafka 虽然内置了 zk，但是这里用的是自己安装的 zk。&lt;/p&gt;
&lt;p&gt;服务器之间加了 ip 映射，如 hosts 文件所示，这样就不需要 p 地址，只需要服务器名字就可以了&lt;br&gt;
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image.png&#34;
	width=&#34;1605&#34;
	height=&#34;357&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image_hu_acb736d39a8f9deb.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image_hu_b05ef5f7d5920c1c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;449&#34;
		data-flex-basis=&#34;1078px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;集群启动&#34;&gt;&lt;a href=&#34;#%e9%9b%86%e7%be%a4%e5%90%af%e5%8a%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;集群启动
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;注意事项&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;启动时先启动 zk，再启动 kafka&lt;/li&gt;
&lt;li&gt;关闭时先关闭 kafka，再关闭 zk，因为 kafka 需要 zk 来维护数据信息，再关闭前 kafka 要和 zk 通讯。&lt;/li&gt;
&lt;li&gt;kafka-server-start.sh -daemon config/server.properties&lt;/li&gt;
&lt;li&gt;kafka-server-stop.sh&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;脚本启动-zk-集群&#34;&gt;&lt;a href=&#34;#%e8%84%9a%e6%9c%ac%e5%90%af%e5%8a%a8-zk-%e9%9b%86%e7%be%a4&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;脚本启动 zk 集群
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-1.png&#34;
	width=&#34;1175&#34;
	height=&#34;708&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-1_hu_54eed240e6805164.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-1_hu_f46e1c6b91b91830.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;165&#34;
		data-flex-basis=&#34;398px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;脚本启动-kafka-集群&#34;&gt;&lt;a href=&#34;#%e8%84%9a%e6%9c%ac%e5%90%af%e5%8a%a8-kafka-%e9%9b%86%e7%be%a4&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;脚本启动 kafka 集群
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-2.png&#34;
	width=&#34;810&#34;
	height=&#34;366&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-2_hu_68b8d0747e772832.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-2_hu_9ddb87b4cb9efeb3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;221&#34;
		data-flex-basis=&#34;531px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;启动成功&#34;&gt;&lt;a href=&#34;#%e5%90%af%e5%8a%a8%e6%88%90%e5%8a%9f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;启动成功
&lt;/h3&gt;&lt;p&gt;启动成功，三台服务器均显示如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-3.png&#34;
	width=&#34;1568&#34;
	height=&#34;227&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-3_hu_a45bf7f6dc5c59cd.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-3_hu_4db7bc7aef40aec5.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;690&#34;
		data-flex-basis=&#34;1657px&#34;
	
&gt;
&lt;strong&gt;查看 zk 客户端，根节点下已经有了 kafka 节点&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;默认直接在根节点下生成 admin、brokers、cluster 等节点，但是不方便维护，因此在 server.properties 文件中改了配置，让所有节点统一生成在 kafka 节点。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-4.png&#34;
	width=&#34;2843&#34;
	height=&#34;204&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-4_hu_b1676ac90e70cae.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-4_hu_f4ef2e3224540269.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;1393&#34;
		data-flex-basis=&#34;3344px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;zk 集群启停脚本&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#!/bin/bash
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;#zookeeper集群启停及状态查看脚本&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;ZOOKEEPER&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/export/server/zookeeper&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;case&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;$1&lt;/span&gt; in
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;start&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; i in linux01 linux02 linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;do&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; ---------- zookeeper &lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; 启动 ------------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		ssh &lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$ZOOKEEPER&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;/bin/zkServer.sh start&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;p&#34;&gt;;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;stop&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; i in linux01 linux02 linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;do&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; ---------- zookeeper &lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; 停止 ------------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		ssh &lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$ZOOKEEPER&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;/bin/zkServer.sh stop&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;p&#34;&gt;;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;status&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; i in linux01 linux02 linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;do&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; ---------- zookeeper &lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; 状态 ------------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		ssh &lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$ZOOKEEPER&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;/bin/zkServer.sh status&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;p&#34;&gt;;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;esac&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;kafka 集群启停脚本&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#!/bin/bash
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;case&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;$1&lt;/span&gt; in
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;start&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; i in linux01 linux02 linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;k&#34;&gt;do&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        &lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; --------&lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; 启动kafka---------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        ssh &lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;source /etc/profile;/export/server/kafka/bin/kafka-server-start.sh -daemon /export/server/kafka/config/server.properties&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;stop&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; i in linux01 linux02 linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;k&#34;&gt;do&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        &lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; --------&lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; 停止kafka---------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        ssh &lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;source /etc/profile;/export/server/kafka/bin/kafka-server-stop.sh stop&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;esac&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;kafka-操作&#34;&gt;&lt;a href=&#34;#kafka-%e6%93%8d%e4%bd%9c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Kafka 操作
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;&amp;ndash;bootstrap-server 是连接 kafka，对于集群而言，连接任何一台服务器的 kafka 都是一样的&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;命令行创建-topic&#34;&gt;&lt;a href=&#34;#%e5%91%bd%e4%bb%a4%e8%a1%8c%e5%88%9b%e5%bb%ba-topic&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;命令行创建 Topic
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-5.png&#34;
	width=&#34;2565&#34;
	height=&#34;455&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-5_hu_5d4b4363e97d6550.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-5_hu_6e494f35cdd49a1b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;563&#34;
		data-flex-basis=&#34;1352px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;消费者生产者联动&#34;&gt;&lt;a href=&#34;#%e6%b6%88%e8%b4%b9%e8%80%85%e7%94%9f%e4%ba%a7%e8%80%85%e8%81%94%e5%8a%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;消费者生产者联动
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-6.png&#34;
	width=&#34;1592&#34;
	height=&#34;235&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-6_hu_55b0b58826548509.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-6_hu_a60fdd3c815cb034.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;677&#34;
		data-flex-basis=&#34;1625px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-7.png&#34;
	width=&#34;1591&#34;
	height=&#34;165&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-7_hu_fa59b332ca3881f9.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-7_hu_fd3349103b8dd85a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;964&#34;
		data-flex-basis=&#34;2314px&#34;
	
&gt;
先启动生产者，生产 hello、hahaha，再启动消费者，生产者再生产 aaaaa、bbbb。此时 hello、hahaha 属于历史消息，不会显示，只显示 aaaaa、bbbb，若想显示历史消息，需要如下，此时消息是乱序的：
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-8.png&#34;
	width=&#34;1895&#34;
	height=&#34;257&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-8_hu_68ff474d3d8586b4.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-8_hu_1fca3fe6bfb12f82.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;737&#34;
		data-flex-basis=&#34;1769px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;linux-配置-efak301&#34;&gt;&lt;a href=&#34;#linux-%e9%85%8d%e7%bd%ae-efak301&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Linux 配置 EFAK3.0.1
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;1. 配置 EFAK 的环境变量&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ke.sh 文件中引用的 efak 变量名是 KE_HOME，所以环境变量名一定是 KE_HOME，否则 efak 无法启动&lt;br&gt;
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-9.png&#34;
	width=&#34;587&#34;
	height=&#34;93&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-9_hu_e49bfdad56deb5e8.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-9_hu_470135dd049dc851.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;631&#34;
		data-flex-basis=&#34;1514px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;source /etc/profile&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;2. 修改 kafka 的 bin/kafka-server-start.sh 的内存配置，如果不修改，可能无法启动 efak&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-10.png&#34;
	width=&#34;2840&#34;
	height=&#34;346&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-10_hu_d57b4857951ecdac.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-10_hu_d7447abbbfec669e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;820&#34;
		data-flex-basis=&#34;1969px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;内容如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;x&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$KAFKA_HEAP_OPTS&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;x&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;then&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;#export KAFKA_HEAP_OPTS=&amp;#34;-Xmx1G -Xms1G&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;KAFKA_HEAP_OPTS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;-server     -Xms2G   -Xmx2G   -XX:PermSize=128m   -XX:+UseG1GC   -XX:MaxGCPauseMillis=200  -XX:ParallelGCThreads=8   -XX:ConcGCThreads=5   -XX:InitiatingHeapOccupancyPercent=70&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;#监控kafka运行的端口号9999&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;JMX_PORT&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;9999&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;fi&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;注意！修改 kafka 配置文件后记得重新分发给集群其他的 kafka！&lt;/p&gt;
&lt;p&gt;scp kafka-server-start.sh root@linux02:/export/server/kafka/bin&lt;/p&gt;
&lt;p&gt;scp kafka-server-start.sh root@linux03:/export/server/kafka/bin&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;3. 修改 EFAK 的 conf/system-config.properties 文件，关键内容如下&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-11.png&#34;
	width=&#34;1956&#34;
	height=&#34;250&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-11_hu_be0541a5ae6984e1.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-11_hu_9ff358cfe73ac771.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;782&#34;
		data-flex-basis=&#34;1877px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;EFAK 需要配置 mysql 的&lt;strong&gt;ke 数据库&lt;/strong&gt;来存储元数据，username 是连接 mysql 的登录用户，名字随便起，和 linux03 服务器无关，需要提前在 mysql 创建好并授权访问。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;我的&lt;strong&gt;mysql5.7&lt;/strong&gt; 在 linux01 服务器，而 EFAK 在 linux03 服务器，这就需要跨服务器连接，解决方法如下。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.  在 linux01 的 mysql 创建名为 linux03 的用户，并授予对 ke 数据库的所有权，并规定只有服务器 linux03 的 ip 地址才能访问。&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;CREATE USER &amp;rsquo;linux03&amp;rsquo;@&amp;lsquo;xxx.xxx.x.xxx&amp;rsquo; IDENTIFIED BY &amp;lsquo;#252012&amp;rsquo;;&lt;br&gt;
GRANT ALL PRIVILEGES ON ke.* TO &amp;rsquo;linux03&amp;rsquo;@&amp;lsquo;xxx.xxx.x.xxx&amp;rsquo;;&lt;br&gt;
注：这里的 xxx.xxx.x.xxx 是部署了 EFAK 的服务器 ip，也就是服务器 linux03 的 ip&lt;br&gt;
如果创建用户失败，提示了创建的用户密码安全级别过低，那么可以降低密码安全级别&lt;br&gt;
SET GLOBAL validate_password.policy = LOW; &lt;br&gt;
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-12.png&#34;
	width=&#34;728&#34;
	height=&#34;508&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-12_hu_9410c962c86b8fc7.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-12_hu_e947b296b836a7ed.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;143&#34;
		data-flex-basis=&#34;343px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;flush privileges;&lt;/strong&gt;&lt;br&gt;
大概意思就是允许 ip 为 xxx.xxx.x.xxx 的 linux03 用户访问数据库&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;5. 启动并登录 EFAK&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;依次启动 zk、kafka&lt;/p&gt;
&lt;p&gt;zk 和 kafka 集群启动脚本是我自己编写的&lt;/p&gt;
&lt;p&gt;zk-All.sh start&lt;/p&gt;
&lt;p&gt;All-kafka start&lt;/p&gt;
&lt;p&gt;然后 ke.sh start&lt;br&gt;
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-13.png&#34;
	width=&#34;1796&#34;
	height=&#34;714&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-13_hu_5d710c3e464160fb.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-13_hu_b4042c0e9fdcd9b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;251&#34;
		data-flex-basis=&#34;603px&#34;
	
&gt;
启动成功！&lt;/p&gt;
&lt;p&gt;账户是 admin，密码 123456&lt;br&gt;
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-14.png&#34;
	width=&#34;2736&#34;
	height=&#34;1415&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-14_hu_f5fa80a33480e07a.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-14_hu_da8639f917e59c09.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;193&#34;
		data-flex-basis=&#34;464px&#34;
	
&gt; &amp;gt; &lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-15.png&#34;
	width=&#34;2731&#34;
	height=&#34;1405&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-15_hu_59def7060ed1aea4.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-15_hu_93d6137bc1a1bce2.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;194&#34;
		data-flex-basis=&#34;466px&#34;
	
&gt;
访问成功，可以看到 3 台 broker 成功运行&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;kraft-模式集群&#34;&gt;&lt;a href=&#34;#kraft-%e6%a8%a1%e5%bc%8f%e9%9b%86%e7%be%a4&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Kraft 模式集群
&lt;/h2&gt;&lt;p&gt;在 Kafka 2.8.0 版本，移除了对 Zookeeper 的依赖，通过 &lt;strong&gt;Kraft 模式的 controller&lt;/strong&gt;管理集群，使用 Kafka &lt;strong&gt;内部的 Quorum 控制器&lt;/strong&gt;来取代 ZooKeeper 管理元数据，&lt;strong&gt;元数据保存在 controller&lt;/strong&gt;中，这样我们无需维护 zk 集群，只要维护 Kafka 集群就可以了，节省运算资源。&lt;br&gt;
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-16.png&#34;
	width=&#34;1145&#34;
	height=&#34;379&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-16_hu_a289fc867e9ef692.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-16_hu_c0c556bb2d3ec27e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;302&#34;
		data-flex-basis=&#34;725px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;kafka 不再依赖外部框架，能独立运行&lt;/li&gt;
&lt;li&gt;controller 管理集群时不需要和 zk 通讯，集群性能提升&lt;/li&gt;
&lt;li&gt;脱离了 zk 依赖，集群扩展不受 zk 读写能力的限制&lt;/li&gt;
&lt;li&gt;controller 不再动态选举，而由配置文件决定，这样可以针对性的加强 controller 的节点配置，而不是像以前一样对随机 controller 节点的高负载束手无策。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;配置&#34;&gt;&lt;a href=&#34;#%e9%85%8d%e7%bd%ae&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;配置
&lt;/h3&gt;&lt;p&gt;不在原来的 kafka 集群操作，这里换新的 kafka 集群&lt;/p&gt;
&lt;p&gt;编辑 kafka 的 config/kraft 目录下的 server.properties 文件&lt;/p&gt;
&lt;p&gt;linux01 服务器配置如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-17.png&#34;
	width=&#34;1507&#34;
	height=&#34;473&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-17_hu_5901d6f870f24885.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-17_hu_3e387f14b5121a89.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;318&#34;
		data-flex-basis=&#34;764px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-18.png&#34;
	width=&#34;1649&#34;
	height=&#34;211&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-18_hu_e51369e0bbf16694.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-18_hu_d0dd47ad950f5bb4.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;781&#34;
		data-flex-basis=&#34;1875px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-19.png&#34;
	width=&#34;1366&#34;
	height=&#34;203&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-19_hu_412ac310855b5291.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-19_hu_387662bb469a5122.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;672&#34;
		data-flex-basis=&#34;1614px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;配好后分发该配置文件，并在各个服务器修改对应的参数，如 node.id、advertised.listeners、log.dirs&lt;/p&gt;
&lt;h3 id=&#34;启动前初始化集群&#34;&gt;&lt;a href=&#34;#%e5%90%af%e5%8a%a8%e5%89%8d%e5%88%9d%e5%a7%8b%e5%8c%96%e9%9b%86%e7%be%a4&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;启动前初始化集群
&lt;/h3&gt;&lt;p&gt;在 linux01 生成存储目录唯一 ID&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-20.png&#34;
	width=&#34;1057&#34;
	height=&#34;103&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-20_hu_3a58ad8ead6148de.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-20_hu_bed5759ad4a7cf35.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;1026&#34;
		data-flex-basis=&#34;2462px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;用该 ID 格式化&lt;strong&gt;所有服务器&lt;/strong&gt;的 kafka 存储目录&lt;br&gt;
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-21.png&#34;
	width=&#34;2585&#34;
	height=&#34;98&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-21_hu_2f8758996c2f24e1.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-21_hu_3258a79cae287df7.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;2637&#34;
		data-flex-basis=&#34;6330px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-22.png&#34;
	width=&#34;2232&#34;
	height=&#34;79&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-22_hu_90b51c7da860ca5.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-22_hu_608b5f0742ce85de.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;2825&#34;
		data-flex-basis=&#34;6780px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-23.png&#34;
	width=&#34;2161&#34;
	height=&#34;74&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-23_hu_e7c99a634226dcf2.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-23_hu_e23059bf46a8505a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;2920&#34;
		data-flex-basis=&#34;7008px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;启动 kraft 集群，这里使用自定义脚本，把脚本配置到环境变量，效果更佳&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#!/bin/bash
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;case&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;$1&lt;/span&gt; in
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;start&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; i in linux01 linux02 linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;k&#34;&gt;do&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        &lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; --------&lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; 启动kraft---------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        ssh &lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;source /etc/profile;/export/server/kraft/bin/kafka-server-start.sh -daemon /export/server/kraft/config/kraft/server.properties&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;stop&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; i in linux01 linux02 linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;k&#34;&gt;do&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        &lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; --------&lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; 停止kraft---------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        ssh &lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;source /etc/profile;/export/server/kraft/bin/kafka-server-stop.sh stop&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;status&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; i in linux01 linux02 linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;k&#34;&gt;do&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        &lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; --------&lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; 查看kraft状态---------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        ssh &lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;source /etc/profile;jps -ml&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;esac&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;查看是否启动成功，这里也使用脚本一键查看集群所有 jps，把脚本配置到环境变量，效果更佳&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#!/bin/bash
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;        &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; i in linux01 linux02 linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;k&#34;&gt;do&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        &lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; --------&lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; 查看jps---------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        ssh &lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;source /etc/profile; jps&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-25.png&#34;
	width=&#34;781&#34;
	height=&#34;450&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-25_hu_979d450b74f3b2d8.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-25_hu_1a76554a0203ec81.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;173&#34;
		data-flex-basis=&#34;416px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;无需 zk，启动成功！&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;浅浅把玩-kraft&#34;&gt;&lt;a href=&#34;#%e6%b5%85%e6%b5%85%e6%8a%8a%e7%8e%a9-kraft&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;strong&gt;浅浅把玩 Kraft&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;创建主题 first&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-26.png&#34;
	width=&#34;2492&#34;
	height=&#34;101&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-26_hu_48fff353777c1a4e.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-26_hu_78031f8a91d64a79.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;2467&#34;
		data-flex-basis=&#34;5921px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-27.png&#34;
	width=&#34;1500&#34;
	height=&#34;88&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-27_hu_779425861a1dabc3.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-27_hu_a384b69cba4c4489.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;1704&#34;
		data-flex-basis=&#34;4090px&#34;
	
&gt; 
在 linux01 创建生产者，在 linux03 创建消费者&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-28.png&#34;
	width=&#34;780&#34;
	height=&#34;540&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-28_hu_284102e529445955.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-28_hu_991248eb8b202de9.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;144&#34;
		data-flex-basis=&#34;346px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-29.png&#34;
	width=&#34;1836&#34;
	height=&#34;251&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-29_hu_b9949c828a3d2fe4.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-29_hu_d9efb6423eca895d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;731&#34;
		data-flex-basis=&#34;1755px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-30.png&#34;
	width=&#34;1600&#34;
	height=&#34;188&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-30_hu_f190973aec3218b2.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-30_hu_458387386a9c4fe0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;851&#34;
		data-flex-basis=&#34;2042px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;flume-联动-kafka&#34;&gt;&lt;a href=&#34;#flume-%e8%81%94%e5%8a%a8-kafka&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Flume 联动 kafka
&lt;/h2&gt;&lt;h3 id=&#34;flume-作为生产者&#34;&gt;&lt;a href=&#34;#flume-%e4%bd%9c%e4%b8%ba%e7%94%9f%e4%ba%a7%e8%80%85&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Flume 作为生产者
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-31.png&#34;
	width=&#34;1054&#34;
	height=&#34;382&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-31_hu_a2a0093e84abc830.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-31_hu_1d03d62c880a252a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;275&#34;
		data-flex-basis=&#34;662px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-32.png&#34;
	width=&#34;1020&#34;
	height=&#34;299&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-32_hu_138cb1786f17e834.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-32_hu_91438e14b3e72b00.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;341&#34;
		data-flex-basis=&#34;818px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;案例玩法：依次启动 zk、kafka 集群，在 linux01 编辑 flume 的 file_to_kafka.conf 任务配置，监控 app.log 文件内容，把监控的内容发送到 kafka 的 first 主题，然后启动 flume 任务作为生产者。在 linux02 启动 kafka 消费者，消费 first 主题，检查 linux01 的监控文件 app.log 变化时，消费者是否消费到了消息。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;flume 的 job/group3/file_to_kafka.conf 配置:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#定义source，sink，channel&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a3.sources &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; r3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a3.sinks &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; k3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a3.channels &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; c3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 配置source&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a3.sources.r3.type &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; TAILDIR
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a3.sources.r3.filegroups&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;f3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#监控的目录&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a3.sources.r3.filegroups.f3&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;/export/server/flume/job/group3/applog/app.*
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#断点续传的json&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a3.sources.r3.positionFile&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;/export/server/flume/job/group3/tail_dir2.json
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 配置 sink&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a3.sinks.k3.type &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; org.apache.flume.sink.kafka.KafkaSink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a3.sinks.k3.kafka.bootstrap.servers&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;linux01:9092,linux02:9092,linux03:9092
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a3.sinks.k3.kafka.topic&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;first
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a3.sinks.k3.kafka.flumeBatchSize&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;20&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a3.sinks.k3.kafka.producer.acks&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a3.sinks.k3.kafka.producer.linger.ms&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 配置channel&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a3.channels.c3.type &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a3.channels.c3.capacity &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1000&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a3.channels.c3.transactionCapacity &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Bind the source and sink to the channel&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a3.sources.r3.channels &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; c3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a3.sinks.k3.channel &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; c3
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;确保 zk，kafka 集群已启动&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;在 linux02 创建 kafka 消费者，消费 first 主题&lt;br&gt;
kafka-console-consumer.sh &amp;ndash;bootstrap-server linux02:9092 &amp;ndash;topic first&lt;/li&gt;
&lt;li&gt;在 linux01 启动 flume 任务&lt;br&gt;
bin/flume-ng agent -c conf/ -n a3 -f job/group3/file_to_kafka.conf&lt;/li&gt;
&lt;li&gt;对监控的文件 app.log 追加内容，kafka 消费者成功接收到消息&lt;br&gt;
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-33.png&#34;
	width=&#34;741&#34;
	height=&#34;320&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-33_hu_1b2c146d96ccee11.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-33_hu_e8ae0b2692f52404.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;231&#34;
		data-flex-basis=&#34;555px&#34;
	
&gt; &amp;gt; &lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-34.png&#34;
	width=&#34;1532&#34;
	height=&#34;238&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-34_hu_c06bc0c670684eb4.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-34_hu_69613da2f3bbe719.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;643&#34;
		data-flex-basis=&#34;1544px&#34;
	
&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;flume-作为消费者&#34;&gt;&lt;a href=&#34;#flume-%e4%bd%9c%e4%b8%ba%e6%b6%88%e8%b4%b9%e8%80%85&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Flume 作为消费者  
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-35.png&#34;
	width=&#34;965&#34;
	height=&#34;331&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-35_hu_e02e433e8d6c1b9c.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-35_hu_3d0362da08cfa14e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;291&#34;
		data-flex-basis=&#34;699px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;在 linux01 的 flume 的 job 目录下编辑 kafka_to_file.conf 文件，内容如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Name the components on this agent&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a2.sources &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; r2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a2.sinks &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; k2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a2.channels &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; c2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Describe/configure the source&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a2.sources.r2.type &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; org.apache.flume.source.kafka.KafkaSource
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a2.sources.r2.batchSize&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;50&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a2.sources.r2.batchDurationMillis&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a2.sources.r2.kafka.bootstrap.servers&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;linux02:9092
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a2.sources.r2.kafka.topics&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;first
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a2.sources.r2.kafka.consumer.group.id&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;custom.g.id
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Describe the sink&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a2.sinks.k2.type &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; logger
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Use a channel which buffers events in memory&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a2.channels.c2.type &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a2.channels.c2.capacity &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1000&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a2.channels.c2.transactionCapacity &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Bind the source and sink to the channel&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a2.sources.r2.channels &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; c2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;a2.sinks.k2.channel &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; c2
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;依次启动 zk、kafka 集群，然后启动 flume 任务和 kakfa 生产者&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;flume-ng agent -n a2 -c conf/ -f job/kafka_to_file.conf -Dflume.root.logger=INFO,console&lt;/li&gt;
&lt;li&gt;kafka-console-producer.sh &amp;ndash;bootstrap-server linux03:9092 &amp;ndash;topic first&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-36.png&#34;
	width=&#34;1672&#34;
	height=&#34;174&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-36_hu_4ce1ba711578983d.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-36_hu_35e72e807ffea2ab.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;960&#34;
		data-flex-basis=&#34;2306px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-37.png&#34;
	width=&#34;2873&#34;
	height=&#34;370&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-37_hu_f5b0665eff65149f.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-37_hu_392ac6891d70a210.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;776&#34;
		data-flex-basis=&#34;1863px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;案例成功！&lt;/p&gt;
&lt;h2 id=&#34;springboot-联动-kakfa&#34;&gt;&lt;a href=&#34;#springboot-%e8%81%94%e5%8a%a8-kakfa&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;SpringBoot 联动 kakfa
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-38.png&#34;
	width=&#34;1363&#34;
	height=&#34;463&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-38_hu_1810ab1a1a53a541.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-38_hu_d7e493f54e086f6b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;294&#34;
		data-flex-basis=&#34;706px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;springboot-作为生产者&#34;&gt;&lt;a href=&#34;#springboot-%e4%bd%9c%e4%b8%ba%e7%94%9f%e4%ba%a7%e8%80%85&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;SpringBoot 作为生产者
&lt;/h3&gt;&lt;p&gt;创建 springboot 工程&lt;/p&gt;
&lt;p&gt;application.properties 文件内容如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;server.port=8080
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;#连接kafka集群
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;spring.kafka.bootstrap-servers=linux01:9092,linux02:9092,linux03:9092
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;#key-value序列化
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;pom 文件内容如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;77
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;78
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;79
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;80
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;81
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;82
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;83
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;84
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;85
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;86
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;project&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;xmlns=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;http://maven.apache.org/POM/4.0.0&amp;#34;&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;xmlns:xsi=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;http://www.w3.org/2001/XMLSchema-instance&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         &lt;span class=&#34;na&#34;&gt;xsi:schemaLocation=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&amp;#34;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;modelVersion&amp;gt;&lt;/span&gt;4.0.0&lt;span class=&#34;nt&#34;&gt;&amp;lt;/modelVersion&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.mykafka&lt;span class=&#34;nt&#34;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;springboot_kafka&lt;span class=&#34;nt&#34;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;0.0.1-SNAPSHOT&lt;span class=&#34;nt&#34;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;springboot_kafka&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;springboot_kafka&lt;span class=&#34;nt&#34;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;properties&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;java.version&amp;gt;&lt;/span&gt;1.8&lt;span class=&#34;nt&#34;&gt;&amp;lt;/java.version&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;project.build.sourceEncoding&amp;gt;&lt;/span&gt;UTF-8&lt;span class=&#34;nt&#34;&gt;&amp;lt;/project.build.sourceEncoding&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;project.reporting.outputEncoding&amp;gt;&lt;/span&gt;UTF-8&lt;span class=&#34;nt&#34;&gt;&amp;lt;/project.reporting.outputEncoding&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;spring-boot.version&amp;gt;&lt;/span&gt;2.6.13&lt;span class=&#34;nt&#34;&gt;&amp;lt;/spring-boot.version&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/properties&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;dependencies&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.springframework.boot&lt;span class=&#34;nt&#34;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;spring-boot-starter-web&lt;span class=&#34;nt&#34;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.springframework.kafka&lt;span class=&#34;nt&#34;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;spring-kafka&lt;span class=&#34;nt&#34;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.projectlombok&lt;span class=&#34;nt&#34;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;lombok&lt;span class=&#34;nt&#34;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;optional&amp;gt;&lt;/span&gt;true&lt;span class=&#34;nt&#34;&gt;&amp;lt;/optional&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.springframework.boot&lt;span class=&#34;nt&#34;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;spring-boot-starter-test&lt;span class=&#34;nt&#34;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;scope&amp;gt;&lt;/span&gt;test&lt;span class=&#34;nt&#34;&gt;&amp;lt;/scope&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.springframework.kafka&lt;span class=&#34;nt&#34;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;spring-kafka-test&lt;span class=&#34;nt&#34;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;scope&amp;gt;&lt;/span&gt;test&lt;span class=&#34;nt&#34;&gt;&amp;lt;/scope&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependencies&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;dependencyManagement&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;dependencies&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.springframework.boot&lt;span class=&#34;nt&#34;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;spring-boot-dependencies&lt;span class=&#34;nt&#34;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;${spring-boot.version}&lt;span class=&#34;nt&#34;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;type&amp;gt;&lt;/span&gt;pom&lt;span class=&#34;nt&#34;&gt;&amp;lt;/type&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;scope&amp;gt;&lt;/span&gt;import&lt;span class=&#34;nt&#34;&gt;&amp;lt;/scope&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependencies&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependencyManagement&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;build&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;plugins&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;plugin&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.maven.plugins&lt;span class=&#34;nt&#34;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;maven-compiler-plugin&lt;span class=&#34;nt&#34;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;3.8.1&lt;span class=&#34;nt&#34;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                    &lt;span class=&#34;nt&#34;&gt;&amp;lt;source&amp;gt;&lt;/span&gt;1.8&lt;span class=&#34;nt&#34;&gt;&amp;lt;/source&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                    &lt;span class=&#34;nt&#34;&gt;&amp;lt;target&amp;gt;&lt;/span&gt;1.8&lt;span class=&#34;nt&#34;&gt;&amp;lt;/target&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                    &lt;span class=&#34;nt&#34;&gt;&amp;lt;encoding&amp;gt;&lt;/span&gt;UTF-8&lt;span class=&#34;nt&#34;&gt;&amp;lt;/encoding&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;/plugin&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;plugin&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.springframework.boot&lt;span class=&#34;nt&#34;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;spring-boot-maven-plugin&lt;span class=&#34;nt&#34;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;${spring-boot.version}&lt;span class=&#34;nt&#34;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                    &lt;span class=&#34;nt&#34;&gt;&amp;lt;mainClass&amp;gt;&lt;/span&gt;org.mykafka.springboot_kafka.SpringbootKafkaApplication&lt;span class=&#34;nt&#34;&gt;&amp;lt;/mainClass&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                    &lt;span class=&#34;nt&#34;&gt;&amp;lt;skip&amp;gt;&lt;/span&gt;true&lt;span class=&#34;nt&#34;&gt;&amp;lt;/skip&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;executions&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                    &lt;span class=&#34;nt&#34;&gt;&amp;lt;execution&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        &lt;span class=&#34;nt&#34;&gt;&amp;lt;id&amp;gt;&lt;/span&gt;repackage&lt;span class=&#34;nt&#34;&gt;&amp;lt;/id&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        &lt;span class=&#34;nt&#34;&gt;&amp;lt;goals&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                            &lt;span class=&#34;nt&#34;&gt;&amp;lt;goal&amp;gt;&lt;/span&gt;repackage&lt;span class=&#34;nt&#34;&gt;&amp;lt;/goal&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        &lt;span class=&#34;nt&#34;&gt;&amp;lt;/goals&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/execution&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;/executions&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;/plugin&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;/plugins&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/build&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;/project&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;ProducerController 代码&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;package&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;org.mykafka.springboot_kafka&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;org.springframework.beans.factory.annotation.Autowired&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;org.springframework.kafka.core.KafkaTemplate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;org.springframework.web.bind.annotation.RequestMapping&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;org.springframework.web.bind.annotation.RestController&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;/**
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt; * @Author:懒大王Smile
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt; * @Date: 2024/5/12
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt; * @Time: 22:42
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt; * @Description:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt; */&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@RestController&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;ProducerController&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Autowired&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;KafkaTemplate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kafka&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@RequestMapping&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;/ProducerSend&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;msg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;kafka&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;send&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;first&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;msg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;System&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;msg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;ok&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;项目展示&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-39.png&#34;
	width=&#34;697&#34;
	height=&#34;661&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-39_hu_67311199368c67e6.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-39_hu_24ef9f42320452f2.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;105&#34;
		data-flex-basis=&#34;253px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;项目启动之后在浏览器访问，kafka 消费者成功接收到数据！&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-40.png&#34;
	width=&#34;1279&#34;
	height=&#34;224&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-40_hu_42f5f285e613a5f6.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-40_hu_179c1a33079e2f0b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;570&#34;
		data-flex-basis=&#34;1370px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-41.png&#34;
	width=&#34;1606&#34;
	height=&#34;202&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-41_hu_77fe679d3bce86f5.png 480w, /zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/image-41_hu_88a089e3928b8b5d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;795&#34;
		data-flex-basis=&#34;1908px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;springboot-作为消费者&#34;&gt;&lt;a href=&#34;#springboot-%e4%bd%9c%e4%b8%ba%e6%b6%88%e8%b4%b9%e8%80%85&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;SpringBoot 作为消费者  
&lt;/h3&gt;&lt;p&gt;application.properties 文件内容如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;server.port=8080
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;#key-value反序列化
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;#消费者组id
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;spring.kafka.consumer.group-id=mykafka
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;ConsumerController 代码如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;package&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;org.mykafka.springboot_kafka&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;org.springframework.context.annotation.Configuration&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;org.springframework.kafka.annotation.KafkaListener&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;/**
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt; * @Author:懒大王Smile
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt; * @Date: 2024/5/13
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt; * @Time: 23:12
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt; * @Description:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt; */&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Configuration&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;ConsumerController&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@KafkaListener&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topics&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;first&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;consumerTopic&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;msg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;System&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;收到消息：&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;msg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Spark 联动 kafka&lt;/p&gt;
&lt;p&gt;尚硅谷 p73&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Kafka入门到入土——万字详解，图文并茂</title>
        <link>/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/</link>
        <pubDate>Sun, 05 May 2024 17:42:50 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/</guid>
        <description>&lt;p&gt;Kafka 是一个由 Scala 和 Java 语言开发的，经典高吞吐量的分布式消息发布和订阅系统，也是大数据技术领域中用作数据交换的核心组件之一。它具有以下特点：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;支持消息的发布和订阅，类似于 RabbtMQ、ActiveMQ 等消息队列；&lt;/li&gt;
&lt;li&gt;支持数据实时处理；&lt;/li&gt;
&lt;li&gt;能保证消息的可靠性投递；&lt;/li&gt;
&lt;li&gt;支持消息的持久化存储，并通过多副本分布式的存储方案来保证消息的容错；&lt;/li&gt;
&lt;li&gt;高吞吐率，单 Broker 可以轻松处理数千个分区以及每秒百万级的消息量；&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;消息队列mq&#34;&gt;&lt;a href=&#34;#%e6%b6%88%e6%81%af%e9%98%9f%e5%88%97mq&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;消息队列（MQ）
&lt;/h2&gt;&lt;p&gt;Kafka 软件最初的设计就是专门用于数据传输的消息系统，类似功能的软件有 RabbitMQ、ActiveMQ、RocketMQ 等，这些软件的核心功能是传输数据，而 Java 中如果想要实现数据传输功能，那么这个软件一般需要遵循 Java 消息服务技术规范 JMS。前面提到的 ActiveMQ 软件就完全遵循了 JMS 技术规范，而 RabbitMQ 是遵循了类似 JMS 规范并兼容 JMS 规范的跨平台的 AMQP 规范。除了上面描述的 JMS，AMQP 外，还有一种用于物联网小型设备之间传输消息的 MQTT 通讯协议。&lt;/p&gt;
&lt;p&gt;Kafka 拥有作为一个消息系统应该具备的功能，但是却有着独特的设计。&lt;strong&gt;Kafka 借鉴了 JMS 规范的思想，但是却并没有完全遵循 JMS 规范&lt;/strong&gt;。这也恰恰是软件名称为 Kafka，而不是 KafkaMQ 的原因。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image.png&#34;
	width=&#34;960&#34;
	height=&#34;684&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image_hu_1a533f54941f3407.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image_hu_3adc4e4ce7128d83.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;140&#34;
		data-flex-basis=&#34;336px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;消息队列一般应用场景&#34;&gt;&lt;a href=&#34;#%e6%b6%88%e6%81%af%e9%98%9f%e5%88%97%e4%b8%80%e8%88%ac%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;消息队列一般应用场景
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;**应用耦合：**多应用间通过消息队列对同一消息进行处理，避免调用接口失败导致整个过程失败。
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-1.png&#34;
	width=&#34;2092&#34;
	height=&#34;1166&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-1_hu_dd1d11bf4a82fc01.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-1_hu_253b311fae2dedf7.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;179&#34;
		data-flex-basis=&#34;430px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;**异步处理：**多应用对消息队列中同一消息进行处理，应用间并发处理消息，相比串行处理，减少处理时间
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-2.png&#34;
	width=&#34;2122&#34;
	height=&#34;1199&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-2_hu_b18d8e67e763dc82.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-2_hu_9543a809a7c3984e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;176&#34;
		data-flex-basis=&#34;424px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;限流削峰：&lt;/strong&gt; 广泛应用于秒杀或抢购活动中，避免流量过大导致应用系统挂掉的情况。该方法有如下优点：
&lt;ul&gt;
&lt;li&gt;1.请求先入消息队列，而不是由业务处理系统直接处理，做了一次缓冲,极 大地减少了业务处理系统的压力；&lt;/li&gt;
&lt;li&gt;2.队列长度可以做限制，事实上，秒杀时，后入队列的用户无法秒杀到商品，这些请求可以直接被抛弃，返回活动已结束或商品已售完信息；
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-3.png&#34;
	width=&#34;2048&#34;
	height=&#34;1197&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-3_hu_440a50f6832267e.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-3_hu_fd479b4cdb97012a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;171&#34;
		data-flex-basis=&#34;410px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;消息驱动的系统：&lt;/strong&gt; 系统分为消息队列、消息生产者、消息消费者，生产者 负责产生消息，消费者(可能有多个)负责对消息进行处理。&lt;strong&gt;具体场景&lt;/strong&gt;：用户新上传了一批照片，人脸识别系统需要对这个用户的所有照片进行聚类，聚类完成后由对账系统重新生成用户的人脸索引(加快查询)。这三个子 系统间由消息队列连接起来，前一个阶段的处理结果放入队列中，后一个阶段从 队列中获取消息继续处理。
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-4.png&#34;
	width=&#34;1032&#34;
	height=&#34;128&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-4_hu_fbee7cb336004b5a.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-4_hu_c702560dd6c22a4c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;806&#34;
		data-flex-basis=&#34;1935px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;该方法有如下优点：1.避免了直接调用下一个系统导致当前系统失败； 2.每个子系统对于消息的处理方式可以更为灵活，可以选择收到消息时就处理，可以选择定时处理，也可以划分时间段按不同处理速度处理；&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;jms&#34;&gt;&lt;a href=&#34;#jms&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;JMS
&lt;/h3&gt;&lt;p&gt;JMS 类似于 JDBC，是 java 平台的消息中间件通用规范，定义了系统和系统之间传输消息的接口。&lt;/p&gt;
&lt;p&gt;为了实现系统和系统之间的数据传输，JMS 规范中定义很多用于通信的组件：
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-5.png&#34;
	width=&#34;631&#34;
	height=&#34;102&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-5_hu_fb8a49d93f1948b0.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-5_hu_566712941c66bc7d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;618&#34;
		data-flex-basis=&#34;1484px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;JMS Producer&lt;/strong&gt; **：**JMS 消息生产者。所谓的生产者，就是生产数据的客户端应用程序，这些应用通过 JMS 接口发送 JMS 消息。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JMS Provider&lt;/strong&gt;：JMS 消息提供者。其实就是实现 JMS 接口和规范的消息中间件，也就是我们提供消息服务的软件系统，比如 RabbitMQ、ActiveMQ、Kafka。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JMS Message&lt;/strong&gt;：JMS 消息。这里的消息指的就是数据。一般采用 Java 数据模型进行封装，其中包含消息头，消息属性和消息主体内容。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JMS Consumer&lt;/strong&gt;：JMS 消息消费者。所谓的消费者，就是从消息提供者中获取数据的客户端应用程序，这些应用通过 JMS 接口接收 JMS 消息。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;jms-模型&#34;&gt;&lt;a href=&#34;#jms-%e6%a8%a1%e5%9e%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;JMS 模型
&lt;/h4&gt;&lt;h5 id=&#34;点对点模型peer-to-peer&#34;&gt;&lt;a href=&#34;#%e7%82%b9%e5%af%b9%e7%82%b9%e6%a8%a1%e5%9e%8bpeer-to-peer&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;点对点模型（peer to peer）
&lt;/h5&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-6.png&#34;
	width=&#34;1079&#34;
	height=&#34;520&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-6_hu_31b88d90f5084dfd.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-6_hu_d79cb9a358bee63b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;207&#34;
		data-flex-basis=&#34;498px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特点：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个消息只有一个接收者（Consumer）(即一旦被消费，就会被删除)；&lt;/li&gt;
&lt;li&gt;发送者和接发收者间没有依赖性，发送者发送消息之后，不管有没有接收者在运行，都不会影响到发送者下次发送消息；&lt;/li&gt;
&lt;li&gt;接收者在成功接收消息之后需向队列应答成功，以便消息队列删除当前接 收的消息&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h5 id=&#34;发布订阅模型&#34;&gt;&lt;a href=&#34;#%e5%8f%91%e5%b8%83%e8%ae%a2%e9%98%85%e6%a8%a1%e5%9e%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;发布订阅模型
&lt;/h5&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-7.png&#34;
	width=&#34;1116&#34;
	height=&#34;606&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-7_hu_5f8a486867bee6e9.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-7_hu_88f1c9f3b98cb8d0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;184&#34;
		data-flex-basis=&#34;441px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特点：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个消息可以有多个订阅者，但是订阅者必须来自不同的消费者组；&lt;/li&gt;
&lt;li&gt;针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息。&lt;/li&gt;
&lt;li&gt;为了消费消息，订阅者需要提前订阅该角色主题，并保持在线运行；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Kafka 采用就是这种模型。&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;kafka-架构&#34;&gt;&lt;a href=&#34;#kafka-%e6%9e%b6%e6%9e%84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Kafka 架构
&lt;/h2&gt;&lt;p&gt;在 Kafka 2.8.0 版本，移除了对 Zookeeper 的依赖，通过&lt;strong&gt;Kraft 模式&lt;/strong&gt; 进行自己的集群管理，使用 Kafka&lt;strong&gt;内部的 Quorum 控制器&lt;/strong&gt;来取代 ZooKeeper 管理元数据，这样我们无需维护 zk 集群，只要维护 Kafka 集群就可以了，节省运算资源。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;kafka 基本数据单元被称为 message(消息)&lt;/strong&gt;，为减少网络开销，提高效率，多个消息会被放入同一批次(Batch) 中后再写入。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-8.png&#34;
	width=&#34;2145&#34;
	height=&#34;1218&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-8_hu_83217a609e20f5d.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-8_hu_ceece0ec3c83ef80.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;176&#34;
		data-flex-basis=&#34;422px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;broker&#34;&gt;&lt;a href=&#34;#broker&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Broker
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;kafka 集群中包含多个服务实例（节点），这种服务实例被称为 broker（一个 broker 就是一个节点/一个服务器），每个 broker 都有一个唯一标识 broker.id，用于标识自己在集群中的身份，可以在配置文件 server.properties 中进行配置，或由程序自动生成。&lt;/li&gt;
&lt;li&gt;Broker 接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。Broker 为消费者提供服务，对读取分区的请求做出响应，返回已经提交到磁盘的消息。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;controller-选举&#34;&gt;&lt;a href=&#34;#controller-%e9%80%89%e4%b8%be&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Controller 选举
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;每一个集群都会选举出一个 Broker 作为&lt;strong&gt;集群控制器&lt;/strong&gt; **(Controller)，它负责分区 Leader 选举，还负责管理主题分区及其副本的状态、元数据管理。**如果在运行过程中，Controller 节点出现了故障，那么 Kafka 会依托于 ZooKeeper 软件选举其他的节点作为新的 Controller，让 Kafka 集群实现高可用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特殊情况&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Controller 节点并没有宕掉，而是因为网络的抖动，不稳定，导致和 ZooKeeper 之间的会话超时，那么此时，整个 Kafka 集群就会认为之前的 Controller 已经下线（退出）从而选举出新的 Controller，而之前的 Controller 的网络又恢复了，以为自己还是 Controller 了，继续管理整个集群，那么此时，整个 Kafka 集群就有两个 controller 进行管理，那么其他的 broker 就懵了，不知道听谁的了，这种情况，我们称之为脑裂现象，为了解决这个问题，Kafka 通过一个任期（epoch:纪元）的概念来解决，也就是说，每一个 Broker 当选 Controller 时，会告诉当前 Broker 是第几任 Controller，一旦重新选举时，这个任期会自动增 1，那么不同任期的 Controller 的 epoch 值是不同的，那么旧的 controller 一旦发现集群中有新任 controller 的时候，那么它就会完成退出操作（清空缓存，中断和 broker 的连接，并重新加载最新的缓存），让自己重新变成一个普通的 Broker。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;broker-上下线&#34;&gt;&lt;a href=&#34;#broker-%e4%b8%8a%e4%b8%8b%e7%ba%bf&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Broker 上下线
&lt;/h4&gt;&lt;p&gt;Controller 在初始化时，会利用 ZK 的 watch 机制注册很多不同类型的监听器，当监听的事件被触发时，Controller 就会触发相应的操作。Controller 在初始化时，会注册多种类型的监听器，主要有以下几种：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;/kafka/admin/reassign_partitions 节点，用于分区副本迁移的监听&lt;/li&gt;
&lt;li&gt;/kafka/isr_change_notification 节点，用于 Partition ISR 变动的监听&lt;/li&gt;
&lt;li&gt;/kafka/admin/preferred_replica_election 节点，用于需要进行 Partition 最优 leader 选举的监听&lt;/li&gt;
&lt;li&gt;/kafka/brokers/topics 节点，用于 Topic 新建的监听&lt;/li&gt;
&lt;li&gt;/kafka/brokers/topics/TOPIC_NAME 节点，用于 Topic Partition 扩容的监听&lt;/li&gt;
&lt;li&gt;/kafka/admin/delete_topics 节点，用于 Topic 删除的监听&lt;/li&gt;
&lt;li&gt;/kafka/brokers/ids 节点，用于 Broker 上下线的监听，记录有哪些 kafka 服务器在线。&lt;/li&gt;
&lt;li&gt;/kafka/controller 节点，辅助选举 leader
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-9.png&#34;
	width=&#34;1998&#34;
	height=&#34;1119&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-9_hu_1ef10362958a7860.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-9_hu_a7126ec11b5c21c6.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;178&#34;
		data-flex-basis=&#34;428px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;每台 Broker 在上线时，都会与 ZK 建立一个建立一个 session，并在 /brokers/ids 下注册一个节点，节点名字就是 broker id，这个节点是临时节点，该节点内部会有这个 Broker 的详细节点信息。Controller 会监听/brokers/ids 这个路径下的所有子节点，如果有新的节点出现，那么就代表有新的 Broker 上线，如果有节点消失，就代表有 broker 下线，Controller 会进行相应的处理，Kafka 就是利用 ZK 的这种 watch 机制及临时节点的特性来完成集群 Broker 的上下线。无论 Controller 监听到的哪一种节点的变化，都会进行相应的处理，同步整个集群元数据。&lt;/p&gt;
&lt;h4 id=&#34;broker-工作流程&#34;&gt;&lt;a href=&#34;#broker-%e5%b7%a5%e4%bd%9c%e6%b5%81%e7%a8%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Broker 工作流程
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-10.png&#34;
	width=&#34;1971&#34;
	height=&#34;1116&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-10_hu_ec33e031990f7d01.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-10_hu_ad8033ad93d7cfa8.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;176&#34;
		data-flex-basis=&#34;423px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;producer&#34;&gt;&lt;a href=&#34;#producer&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Producer
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;一般情况下，生产者在把消息均衡地分布到在主题的所有分区上，而并不关心消息会被写到哪个分区。如果我们想要把消息写到指定的分区，可以通过&lt;strong&gt;自定义分区器&lt;/strong&gt;来实现。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;consumer&#34;&gt;&lt;a href=&#34;#consumer&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Consumer
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;消费者一定是归属于某个消费组中的&lt;/strong&gt;，消费者可以订阅一或多个主题，并按照分区中消息的顺序来读取。消费者通过检查消息的偏移量 (offset) 来区分读取过的消息。偏移量是一个不 断递增的数值，在创建消息时，Kafka 会把它添加到其中，在给定的分区里，每个消息的偏移量都是唯一的。消费者把每个分区最后读取的偏移量保存在 Zookeeper 或 Kafka 上，如果消费者关闭或者重启，它还可以重新获取该偏移量，以保证读取状态不会丢失。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;consumer-group&#34;&gt;&lt;a href=&#34;#consumer-group&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Consumer Group
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;消费者组由一个或者多个消费者组成，&lt;strong&gt;同一个组中的消费者对于同一条消息只消费一次。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;每个消费者组都有一个 ID，即 group ID。组内的所有消费者协调在一起来消费 一个订阅主题的所有分区。当然，&lt;strong&gt;每个分区只能由同一个消费组内的一个消费者来消费，但可以由不同的消费组来消费。partition 数量决定了每个 consumer group 中并发消费者的最大数。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;因此要合理设置消费者组中的消费者数量，避免出现消费者闲置。&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;topic&#34;&gt;&lt;a href=&#34;#topic&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Topic
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;Kafka 的消息通过 Topics(主题) 进行分类，Kafka 中有两个固定的，用于记录消费者偏移量和事务处理的主题，一个主题可以被分为若干个 Partitions(分区)，一个分区就是 一个提交日志 (commit log)。消息以追加的方式写入分区，然后以先入先出的顺序读取。&lt;strong&gt;Kafka 通过分区来实现数据的冗余和伸缩性，分区可以分布在不同的服务器上，这意味着一个 Topic 可以横跨多个服务器，以提供比单个服务器更强大的性能&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;由于一个 Topic 包含多个分区，因此无法在整个 Topic 范围内保证消息的顺序性，但可以保证消息在单个分区内的顺序性。&lt;/strong&gt; &amp;gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-11.png&#34;
	width=&#34;1401&#34;
	height=&#34;547&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-11_hu_8d47895eb9670cc4.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-11_hu_98cee807c7fcf93f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;256&#34;
		data-flex-basis=&#34;614px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;partition-分区&#34;&gt;&lt;a href=&#34;#partition-%e5%88%86%e5%8c%ba&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Partition 分区
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;Kafka 消息传输采用发布、订阅模式，所以消息生产者必须将数据发送到一个主题，假如发送给这个主题的数据非常多，那么主题所在 broker 节点的负载和吞吐量就会受到极大的考验，甚至有可能因为热点问题引起 broker 节点故障，导致服务不可用解决方案就是分区。&lt;/p&gt;
&lt;p&gt;topic 是逻辑上的概念，而 partition 是物理上的概念，每个 topic 包含一个或者多个 partition，每个分区保存部分 topic 的数据，所有的 partition 当中的数据全部合并起来， 就是一个 topic 当中的所有的数据。一个 broker 服务下，有多个 Topic，每个 Topic 可以创建多个分区，broker 数与分区数没有关系； 在 kafka 中，每一个分区会有一个编号，编号从 0 开始。&lt;/p&gt;
&lt;p&gt;**单个分区的消息是有序的，而全局的 topic 的多个分区的消息****是无序的。这就是为什么一条消息只能被同一个消费者组里面的一个消费者消费，这样就某种程度上保证了消息的不重复消费和乱序消费。**&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;h4 id=&#34;分区好处&#34;&gt;&lt;a href=&#34;#%e5%88%86%e5%8c%ba%e5%a5%bd%e5%a4%84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;分区好处
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;合理使用存储资源：海量资源按照分区切割成一块块存储在多台 broker，合理控制分区任务，实现负载均衡。&lt;/li&gt;
&lt;li&gt;提高并行度：生产者以分区为单位发送数据，消费者以分区为单位消费数据。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;h4 id=&#34;生产者发送消息的分区策略&#34;&gt;&lt;a href=&#34;#%e7%94%9f%e4%ba%a7%e8%80%85%e5%8f%91%e9%80%81%e6%b6%88%e6%81%af%e7%9a%84%e5%88%86%e5%8c%ba%e7%ad%96%e7%95%a5&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;  生产者发送消息的分区策略
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;默认分区器 DefaultPartitioner&lt;br&gt;
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-12.png&#34;
	width=&#34;1715&#34;
	height=&#34;977&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-12_hu_14edfaf7848d142e.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-12_hu_a44bd717fda1e4bd.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;175&#34;
		data-flex-basis=&#34;421px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;自定义分区&lt;br&gt;
自己创建类实现 Partitioner 接口，重写 partition 方法
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;package&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;com.atguigu.test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;import org.apache.kafka.clients.producer.Partitioner;
import org.apache.kafka.common.Cluster;&lt;/p&gt;
&lt;p&gt;import java.util.Map;&lt;/p&gt;
&lt;p&gt;/**&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;TODO 自定义分区器实现步骤：&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;pre&gt;&lt;code&gt; 1. 实现Partitioner接口
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;pre&gt;&lt;code&gt; 2. 重写方法
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;pre&gt;&lt;code&gt;    partition : 返回分区编号，从0开始
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;pre&gt;&lt;code&gt;    close
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;pre&gt;&lt;code&gt;    configure
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;_/
public class KafkaPartitionerMock implements Partitioner {
/**
_ 分区算法 - 根据业务自行定义即可
_ @param topic The topic name
_ @param key The key to partition on (or null if no key)
_ @param keyBytes The serialized key to partition on( or null if no key)
_ @param value The value to partition on or null
_ @param valueBytes The serialized value to partition on or null
_ @param cluster The current cluster metadata
_ @return 分区编号，从 0 开始
_/
@Override
public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
return 0;
}&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@Override
public void close() {

}

@Override
public void configure(Map&amp;lt;String, ?&amp;gt; configs) {

}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;code&gt;```
配置分区器
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;kn&#34;&gt;package&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;com.atguigu.test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;import org.apache.kafka.clients.producer.*;
import org.apache.kafka.common.serialization.StringSerializer;&lt;/p&gt;
&lt;p&gt;import java.util.HashMap;
import java.util.Map;
import java.util.concurrent.Future;&lt;/p&gt;
&lt;p&gt;public class ProducerPartitionTest {
public static void main(String[] args) {
Map&amp;lt;String, Object&amp;gt; configMap = new HashMap&amp;lt;&amp;gt;();
configMap.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &amp;ldquo;localhost:9092&amp;rdquo;);
configMap.put( ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
configMap.put( ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
configMap.put( ProducerConfig.PARTITIONER_CLASS_CONFIG, KafkaPartitionerMock.class.getName());&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    KafkaProducer&amp;lt;String, String&amp;gt; producer = null;
    try {
        producer = new KafkaProducer&amp;lt;&amp;gt;(configMap);
        for ( int i = 0; i &amp;lt; 1; i++ ) {
            ProducerRecord&amp;lt;String, String&amp;gt; record = new ProducerRecord&amp;lt;String, String&amp;gt;(&amp;quot;test&amp;quot;, &amp;quot;key&amp;quot; + i, &amp;quot;value&amp;quot; + i);
            final Future&amp;lt;RecordMetadata&amp;gt; send = producer.send(record, new Callback() {
                public void onCompletion(RecordMetadata recordMetadata, Exception e) {
                    if ( e != null ) {
                        e.printStackTrace();
                    } else {
                        System.out.println(&amp;quot;数据发送成功：&amp;quot; + record.key() + &amp;quot;,&amp;quot; + record.value());
                    }
                }
            });
        }
    } catch ( Exception e ) {
        e.printStackTrace();
    } finally {
        if ( producer != null ) {
            producer.close();
        }
    }

}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;code&gt;```
&lt;/code&gt;&lt;/pre&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;文件存储-segment&#34;&gt;&lt;a href=&#34;#%e6%96%87%e4%bb%b6%e5%ad%98%e5%82%a8-segment&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;文件存储 Segment
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;每个 partition 对应一个 log 文件，该&lt;strong&gt;log 文件存储的就是生产的数据&lt;/strong&gt;，生产的数据不断&lt;strong&gt;追加&lt;/strong&gt;到 log 文件，为了&lt;strong&gt;防止 log 文件过大导致数据定位效率低下，kafka 采取了分片和索引&lt;/strong&gt;，&lt;strong&gt;把每个 log 文件分成多个 segment 文件段&lt;/strong&gt;，每个 segment 包括 index 文件、log 文件、timeindex 文件等等，&lt;strong&gt;统一放在一个文件夹下，文件夹命名规则是：topic 名+分区序号&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;kafka 消费完数据之后不会立刻删除，而是有专门的清理机制，默认保存数据 7 天，7 天后删除，而 timeindex 文件就记录了数据的时间&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-13.png&#34;
	width=&#34;1657&#34;
	height=&#34;924&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-13_hu_dddc1de7164a2390.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-13_hu_40162094e329ca10.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;179&#34;
		data-flex-basis=&#34;430px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;index 是稀疏索引&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-14.png&#34;
	width=&#34;1544&#34;
	height=&#34;915&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-14_hu_472f5d267ffbf545.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-14_hu_10ee90cd84204807.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;168&#34;
		data-flex-basis=&#34;404px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;偏移量是一个 64 位的长整形数，固定是 20 位数字，长度未达到，用 0 进行填补，索引文件和日志文件都由该作为文件名命名规则：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;00000000000000000000.index&lt;/strong&gt;：索引文件，记录偏移量映射到 .log 文件的字节偏移量，此映射用于从任何特定偏移量读取记录&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;0000000000000000000.timeindex&lt;/strong&gt;：时间戳索引文件，此文件包含时间戳到记录偏移量的映射，该映射使用.index 文件在内部映射到记录的字节偏移量。这有助于从特定时间戳访问记录&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;00000000000000000000.log&lt;/strong&gt;：此文件包含实际记录，并将记录保持到特定偏移量,文件名描述了添加到此文件的起始偏移量，如果日志文件名为   00000000000000000004.log ，则当前日志文件的第一条数据偏移量就是 4（偏移量从 0 开始）&lt;/li&gt;
&lt;/ol&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;分区的副本&#34;&gt;&lt;a href=&#34;#%e5%88%86%e5%8c%ba%e7%9a%84%e5%89%af%e6%9c%ac&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;分区的副本
&lt;/h2&gt;&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;在创建主题时，Kafka 会首先决定如何在 broker 间分配分区副本，它遵循以下原则：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在所有 broker 上&lt;strong&gt;尽可能均匀地分配&lt;/strong&gt;分区副本，&lt;strong&gt;负载均衡&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;确保分区的每个副本分布在不同的 broker 上；&lt;/li&gt;
&lt;li&gt;如果使用了 broker.rack 参数为 broker 指定了机架信息，那么会尽可能的把每个分区的副本分配到不同机架的 broker 上，以避免一个机架不可用而导致整个分区不可用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分区数可以&amp;gt;bro**&lt;strong&gt;kers*&lt;/strong&gt;*数，但是副本因子必须&amp;lt;=可用 broker 数，这样才能保证每个副本分布在不同的 broker 上，进而保证数据的完整性。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;why-分区副本&#34;&gt;&lt;a href=&#34;#why-%e5%88%86%e5%8c%ba%e5%89%af%e6%9c%ac&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Why 分区副本
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;为了保证&lt;strong&gt;高可用（提高负载均衡和系统伸缩性）&lt;/strong&gt;，kafka 的分区是多副本的，如果一个副本丢失了，还可以从其他 borker 的副本中获取分区数据。&lt;strong&gt;但这要求对应副本数据必须是完整的&lt;/strong&gt;，这是 Kafka 数据一致性的基础，所以才需要使用 controller broker 来进行专门的管理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意！follower 副本会周期性地同步 leader 副本的数据，同步数据的过程是有一定延迟的，所以副本之间的数据可能是不同的。&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Kafka 的单个主题被分为多个分区，每个分区可以有多个副本 (可以在创建主题时使用 replication-factor 参数进行指定)。&lt;strong&gt;其中一个副本是 Leader 副本，所有的读写请求都直接发送给 Leader 副本；其他副本是 Follower 副本，分布在不同的 broker 上，需要通过复制来保持与 Leader 副本数据一致，当 Leader 副本不可用时，会从 ISR 中选一个 Follower 副本成为新 Leader。Leader 选举依赖 Controller。&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;手动调整分区副本存储&#34;&gt;&lt;a href=&#34;#%e6%89%8b%e5%8a%a8%e8%b0%83%e6%95%b4%e5%88%86%e5%8c%ba%e5%89%af%e6%9c%ac%e5%ad%98%e5%82%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;手动调整分区副本存储
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-15.png&#34;
	width=&#34;1636&#34;
	height=&#34;778&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-15_hu_953ee717e743402c.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-15_hu_6d8103c0498db0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;210&#34;
		data-flex-basis=&#34;504px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;kafka 默认均匀分布在所有 broker 上
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-16.png&#34;
	width=&#34;1667&#34;
	height=&#34;198&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-16_hu_d528029ca5248aad.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-16_hu_a0d90dda6653c2eb.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;841&#34;
		data-flex-basis=&#34;2020px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;手动调整副本存储，需要创建存储计划  json 文件，然后在创建主题分区及副本的时候，指定存储计划文件。&lt;/p&gt;
&lt;h3 id=&#34;副本-leader-分区自动平衡&#34;&gt;&lt;a href=&#34;#%e5%89%af%e6%9c%ac-leader-%e5%88%86%e5%8c%ba%e8%87%aa%e5%8a%a8%e5%b9%b3%e8%a1%a1&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;副本 Leader 分区自动平衡
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-17.png&#34;
	width=&#34;1669&#34;
	height=&#34;923&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-17_hu_80d3dcd4b04fc36.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-17_hu_215b24fbdbea3b46.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;180&#34;
		data-flex-basis=&#34;433px&#34;
	
&gt;
  但是自动平衡会消耗大量资源，影响性能，不建议频繁触发自动平衡。&lt;/p&gt;
&lt;h3 id=&#34;增加副本数量&#34;&gt;&lt;a href=&#34;#%e5%a2%9e%e5%8a%a0%e5%89%af%e6%9c%ac%e6%95%b0%e9%87%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;增加副本数量  
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;增加副本因子不能通过命令行直接增加，需要创建副本存储计划 json 文件并执行副本计划。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;副本-leader-选举&#34;&gt;&lt;a href=&#34;#%e5%89%af%e6%9c%ac-leader-%e9%80%89%e4%b8%be&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;副本 Leader 选举
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-18.png&#34;
	width=&#34;1660&#34;
	height=&#34;926&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-18_hu_ee2d9868c2dd76e.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-18_hu_ac8163d332111cc6.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;179&#34;
		data-flex-basis=&#34;430px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;副本-leader-故障恢复&#34;&gt;&lt;a href=&#34;#%e5%89%af%e6%9c%ac-leader-%e6%95%85%e9%9a%9c%e6%81%a2%e5%a4%8d&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;副本 Leader 故障恢复
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;leader 故障后会从 ISR 踢出，从 follower 产生新的 leader，此时可能出现其他的 follower 数据比新的 leader 多，那么多的数据就会截掉，保证和 leader 数据一致。但是&lt;strong&gt;只能保证数据一致，不能保证不丢失。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-19.png&#34;
	width=&#34;1670&#34;
	height=&#34;853&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-19_hu_4e61f3787fa5e606.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-19_hu_7baf566fce21040e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;195&#34;
		data-flex-basis=&#34;469px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;副本-follower-故障恢复&#34;&gt;&lt;a href=&#34;#%e5%89%af%e6%9c%ac-follower-%e6%95%85%e9%9a%9c%e6%81%a2%e5%a4%8d&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;副本 Follower 故障恢复  
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;follower2 故障，被踢出 ISR&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-20.png&#34;
	width=&#34;1500&#34;
	height=&#34;840&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-20_hu_4697a1d0b90af2e.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-20_hu_a787faa54ee20ac7.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;178&#34;
		data-flex-basis=&#34;428px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;follower2 恢复之后截掉 HW 之后的数据&lt;br&gt;
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-21.png&#34;
	width=&#34;1670&#34;
	height=&#34;946&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-21_hu_23e0f846daf1577d.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-21_hu_a498339f19ed6aa4.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;176&#34;
		data-flex-basis=&#34;423px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;follower 从 HW 位置开始向 Leader 同步数据，等 follower 的 LEO&amp;gt;=该分区的 HW，也就是追上 Leader，就可以重新加入 ISR。&lt;br&gt;
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-22.png&#34;
	width=&#34;1661&#34;
	height=&#34;923&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-22_hu_32234962f2825c07.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-22_hu_36c9c8352e1f209.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;179&#34;
		data-flex-basis=&#34;431px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;isr-机制&#34;&gt;&lt;a href=&#34;#isr-%e6%9c%ba%e5%88%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt; ISR 机制
&lt;/h3&gt;&lt;p&gt;每个分区都有一个 ISR(in-sync Replica) 列表，用于维护所有同步的、可用的副本。&lt;strong&gt;Leader 副本必然是同步副本&lt;/strong&gt;，而对于 Follower 副本来说，它需要满足以下条件才能被认为是同步副本：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;与 Zookeeper 之间有一个活跃的会话，即必须定时向 Zookeeper 发送心跳；&lt;/li&gt;
&lt;li&gt;在规定的时间（replica.lag.time.max.ms，默认 30s）内从 Leader 副本那里低延迟地获取过消息。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;如果副本不满足上面条件的话，就会被从 ISR 列表中&lt;strong&gt;移除&lt;/strong&gt;，直到满足条件才会被再次加入。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;OSR&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;不在 ISR 中的副本就在 OSR，OSR 和 ISR 统称 AR（assigned Repllicas）&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;不完全首领选举&#34;&gt;&lt;a href=&#34;#%e4%b8%8d%e5%ae%8c%e5%85%a8%e9%a6%96%e9%a2%86%e9%80%89%e4%b8%be&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;不完全首领选举
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;对于副本机制，在 broker 级别有一个可选的配置参数 unclean.leader.election.enable ，默认值 为 fasle，代表禁止不完全的首领选举。这是针对当 Leader 副本挂掉且 ISR 中没有其他可用副本时，&lt;strong&gt;是否允许某个不完全同步的副本成为 Leader 副本，这可能会导致数据丢失或者数据不一致&lt;/strong&gt;，在某些对数据一致 性要求较高的场景 (如金融领域)，这可能无法容忍的，所以其默认值为 false，如果你能够允许部分数据 不一致的话，可以配置为 true。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;最少同步副本&#34;&gt;&lt;a href=&#34;#%e6%9c%80%e5%b0%91%e5%90%8c%e6%ad%a5%e5%89%af%e6%9c%ac&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;最少同步副本
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ISR 机制&lt;/strong&gt;的另外一个相关参数是 min.insync.replicas , 可以在 broker 或者主题级别进行配置，代表 ISR 列表中至少要有几个可用副本。这里假设设置为 2，&lt;strong&gt;那么当可用副本数量小于该值时，就认为整个分区处于不可用状态&lt;/strong&gt;。此时客户端再向分区写入数据时候就会抛出异常 org.apache.kafka.common.errors.NotEnoughReplicasExceptoin: Messages are rejected since there are fewer in-sync replicas than required。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-23.png&#34;
	width=&#34;1064&#34;
	height=&#34;442&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-23_hu_764dc26531f5f132.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-23_hu_97ffe5702b7f21e6.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;240&#34;
		data-flex-basis=&#34;577px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;副本数（replication-factor）：消息保存在几个 broker（服务器）上， &lt;strong&gt;一般情况下副本数等于 broker 的个数&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;follower 通过拉的方式从 leader 同步数据。 &lt;strong&gt;消费者和生产者都是从 leader 读写数据，不与 follower 交互&lt;/strong&gt;。&lt;strong&gt;如果 follower 副本也对外提供服务那会怎么样呢？首先，性能是肯定会有所提升的。但同时，会出现一系列问题。类似数据库事务中的幻读，脏读。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;副本因子的作用：让 kafka 读取数据和写入数据时的可靠性。 副本因子是包含本身，&lt;strong&gt;相同的副本因子不能放在同一个 broker。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;如果某一个分区有三个副本因子，就算其中一个挂掉，那么只会剩下的两个中， 选择一个 leader&lt;/strong&gt;。 如果所有的副本都挂了，生产者如果生产数据到指定分区的话，将写入不成功。 1sr 表示：当前可用的副本。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;数据请求&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e6%8d%ae%e8%af%b7%e6%b1%82&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;数据请求  
&lt;/h2&gt;&lt;h3 id=&#34;请求机制&#34;&gt;&lt;a href=&#34;#%e8%af%b7%e6%b1%82%e6%9c%ba%e5%88%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;请求机制
&lt;/h3&gt;&lt;p&gt;在所有副本中，&lt;strong&gt;只有 leader 副本才能进行消息的读写处理&lt;/strong&gt;。由于不同分区的&lt;strong&gt;leader&lt;/strong&gt;副本可能在不同的 broker 上，&lt;strong&gt;如果某个 broker 收到了一个分区请求，但是该分区的领导副本并不在该 broker 上，那么 它就会向客户端返回一个 Not a Leader for Partition 的错误响应&lt;/strong&gt;。 为了解决这个问题，Kafka 提供了&lt;strong&gt;元数据请求机制&lt;/strong&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;首先集群中的每个 broker 都会缓存所有主题的分区副本信息，客户端会定期发送元数据请求，然后将获取的元数据进行缓存。定时刷新元数据的时间间隔可以通过为客户端配置 metadata.max.age.ms 来进行指定。有了元数据信息后，客户端就知道了领导副本所在的 broker，之后直接将读写请求发送给对应的 broker 即可。&lt;/li&gt;
&lt;li&gt;如果在定时请求的时间间隔内发生的分区副本的选举，则意味着原来缓存的信息可能已经过时了，此时 还有可能会收到 Not a Leader for Partition 的错误响应，这种情况下客户端会再次求发出元数据请求，然后刷新本地缓存，之后再去正确的 broker 上执行对应的操作。&lt;/li&gt;
&lt;li&gt;需要注意的是，并不是所有保存在分区首领上的数据都可以被客户端读取到，&lt;strong&gt;为了保证数据一致性，只有被所有同步副本 (ISR 中所有副本) 都保存了的数据才能被客户端读取到。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Kafka 所有数据的写入和读取都是通过&lt;strong&gt;零拷贝&lt;/strong&gt;来实现的&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;生产者详解&#34;&gt;&lt;a href=&#34;#%e7%94%9f%e4%ba%a7%e8%80%85%e8%af%a6%e8%a7%a3&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;生产者详解
&lt;/h2&gt;&lt;h3 id=&#34;生产者发送消息的过程&#34;&gt;&lt;a href=&#34;#%e7%94%9f%e4%ba%a7%e8%80%85%e5%8f%91%e9%80%81%e6%b6%88%e6%81%af%e7%9a%84%e8%bf%87%e7%a8%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;生产者发送消息的过程
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Kafka 的&lt;strong&gt;main 线程&lt;/strong&gt;会将发送消息&lt;strong&gt;包装为 ProducerRecord 对象&lt;/strong&gt;， ProducerRecord 对象包含了目标主题和要发 送的内容，同时还&lt;strong&gt;可以指定键和分区&lt;/strong&gt;。在发送 ProducerRecord 对象前，生产者会先&lt;strong&gt;把键和值对象序列化成字节数组&lt;/strong&gt;，这样它们才能够在网络上传输。&lt;/li&gt;
&lt;li&gt;接下来，&lt;strong&gt;数据被传给分区器&lt;/strong&gt;。如果之前已经在 ProducerRecord 对象里指定了分区，那么分区器 就不会再做任何事情。如果没有指定分区 ，那么分区器会根据 ProducerRecord 对象的键来选择一个分区。&lt;/li&gt;
&lt;li&gt;紧接着，这条记录被添加到一个记录批次里，该批次数据积累到一定值（batch.size）后，这个批次里的所有消息会被&lt;strong&gt;sender 线程&lt;/strong&gt;发送到相同的主题和分区上。如果在规定时间（linger.ms）内该批次没有达到规定的 batch.size，sender 线程同样会把数据发送。linger.ms 单位是 ms，默认 0ms&lt;/li&gt;
&lt;li&gt;服务器在收到这些消息时会返回一个响应。如果消息成功写入 Kafka，就&lt;strong&gt;返回一个 RecordMetaData 对象&lt;/strong&gt;，它包含了主题和分区信息，以及记录在分区里的偏移量。如果写入失败，则会返回一个错误。sender 线程会重新执行写入请求，如果达到指定的重试次数后还没有成功，则直接抛出异常，不再重试。写入成功后，请求会从 sender 线程中删除。&lt;strong&gt;（后面消息可靠性会详解）&lt;/strong&gt; &amp;gt; &lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-24.png&#34;
	width=&#34;1859&#34;
	height=&#34;1057&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-24_hu_81ae201c71bbf2b4.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-24_hu_7a981bd9f5a87292.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;175&#34;
		data-flex-basis=&#34;422px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-25.png&#34;
	width=&#34;1056&#34;
	height=&#34;941&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-25_hu_c1fe699059ebe65f.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-25_hu_94ca64a3481bdf86.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;112&#34;
		data-flex-basis=&#34;269px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;消息可靠性&#34;&gt;&lt;a href=&#34;#%e6%b6%88%e6%81%af%e5%8f%af%e9%9d%a0%e6%80%a7&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;消息可靠性  
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;对于生产者发送的数据，我们有的时候是不关心数据是否已经发送成功的，我们只要发送就可以了。在这种场景中，&lt;strong&gt;消息可能会因为某些故障或问题导致丢失&lt;/strong&gt;，我们将这种情况称之为&lt;strong&gt;消息不可靠&lt;/strong&gt;。虽然消息数据可能会丢失，但是在某些需要&lt;strong&gt;高吞吐，低可靠&lt;/strong&gt;的系统场景中，这种方式也是可以接受的，甚至是必须的。&lt;/p&gt;
&lt;p&gt;但是在更多的场景中，&lt;strong&gt;需要确定数据是否发送成功且 Kafka 是否接收到数据&lt;/strong&gt;，也就是要&lt;strong&gt;保证数据不丢失&lt;/strong&gt;，这就是所谓的&lt;strong&gt;消息可靠性保证&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;而这个确定的过程一般是通过 Kafka 给我们返回的响应确认结果（Acknowledgement）来决定的，这里的响应确认结果简称为 ACK 应答。&lt;/p&gt;
&lt;p&gt;根据场景，Kafka 提供了 3 种应答处理，可以通过配置对象进行配置。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;ack-应答&#34;&gt;&lt;a href=&#34;#ack-%e5%ba%94%e7%ad%94&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;ACK 应答  
&lt;/h4&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ACK=0&lt;/strong&gt;&lt;br&gt;
当生产数据时，生产者将数据通过网络客户端&lt;strong&gt;将数据发送到网络数据流中的时候，Kafka 就对当前的数据请求进行了响应（确认应答）&lt;/strong&gt;，如果是同步发送数据，此时就可以发送下一条数据了。如果是异步发送数据，回调方法就会被触发。但这其实并不能保证 Kafka 能正确地接收到数据，&lt;strong&gt;消息不可靠，但是通信效率高，消息吞吐量也高&lt;/strong&gt;。&lt;br&gt;
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-26.png&#34;
	width=&#34;719&#34;
	height=&#34;429&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-26_hu_f5089ad1f24b766b.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-26_hu_5b14f01ed8f66ae3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;167&#34;
		data-flex-basis=&#34;402px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ACK=1&lt;/strong&gt;&lt;br&gt;
当生产数据时，&lt;strong&gt;Leader 副本将数据接收到并写入到了日志文件后，就会对当前的数据请求进行响应（确认应答）&lt;/strong&gt;，如果是同步发送数据，此时就可以发送下一条数据了。如果是异步发送数据，回调方法就会被触发。&lt;strong&gt;这种方式消息可靠性较高&lt;/strong&gt;，但是此时只有 Leader 节点存储了数据，&lt;strong&gt;还没有备份到 follower 副本&lt;/strong&gt;，那么一旦当前存储数据的 broker 节点出现了故障，数据也依然会丢失。&lt;br&gt;
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-27.png&#34;
	width=&#34;661&#34;
	height=&#34;394&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-27_hu_13da89a4d52ea0cb.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-27_hu_187ffd6110ba53d0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;167&#34;
		data-flex-basis=&#34;402px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ACK=-1（默认）&lt;/strong&gt;&lt;br&gt;
当生产数据时，&lt;strong&gt;Leader 副本和 Follower 副本都已经将数据接收到并写入到了日志文件后，再对当前的数据请求进行响应（确认应答）&lt;/strong&gt;，如果是同步发送数据，此时就可以发送下一条数据了。如果是异步发送数据，回调方法就会被触发。&lt;strong&gt;这种是消息最可靠的，但是吞吐量有所下降。注意！这里同步的是 ISR 中的 follower 副本，只要 ISR 中的所有副本接收到了数据就会响应。&lt;/strong&gt;&lt;br&gt;
&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-28.png&#34;
	width=&#34;690&#34;
	height=&#34;409&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-28_hu_3f6bdb8dcc34eec7.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-28_hu_674d28909627b5ca.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;168&#34;
		data-flex-basis=&#34;404px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;数据重试&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e6%8d%ae%e9%87%8d%e8%af%95&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;  数据重试
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;由于网络或服务节点的故障，Kafka 在传输数据时，可能会导致数据丢失，所以我们才会设置 ACK 应答机制，尽可能提高数据的可靠性。但其实在某些场景中，数据的丢失并不是真正地丢失，而是“虚假丢失”，比如 ACK 应答设置为 1，也就是说一旦 Leader 副本将数据写入文件后，Kafka 就可以对请求进行响应了。&lt;/p&gt;
&lt;p&gt;此时，如果由于网络故障的原因，Kafka 并没有成功将 ACK 应答信息发送给 Producer，那么此时对于 Producer 来讲，以为 kafka 没有收到数据，所以就会一直等待响应，一旦超过某个时间阈值，就会发生超时错误，Producer 就会认为数据已经丢了。&lt;/p&gt;
&lt;p&gt;此时，Producer 会尝试对超时的请求数据进行**重试(retry)操作，**将数据再次发送给 Kafka，&lt;strong&gt;就可能出现数据重复&lt;/strong&gt;。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;数据乱序&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e6%8d%ae%e4%b9%b1%e5%ba%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;数据乱序  
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;数据重试(&lt;strong&gt;retry&lt;/strong&gt;)功能除了可能会导致数据重复以外，还可能会导致数据乱序。假设需要将编号为 1，2，3 的三条连续数据发送给 Kafka。每条数据会对应于一个连接请求，此时，如果第一个数据的请求出现了故障，而第二个数据和第三个数据的请求正常，那么 Broker 就收到了第二个数据和第三个数据，并进行了应答。&lt;/p&gt;
&lt;p&gt;为了保证数据的可靠性，Producer 会将第一条数据重新放回到缓冲区的第一个。进行重试操作，如果重试成功，Broker 就会收到第一条数据，数据的顺序已经被打乱了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-29.png&#34;
	width=&#34;1975&#34;
	height=&#34;1121&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-29_hu_9f15cb9331353d14.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-29_hu_96a16bfdc585b8ba.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;176&#34;
		data-flex-basis=&#34;422px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;如上图，在 1.x 版本之前，为了保证数据有序性，每个 broker 只能缓存一个请求，在 1.x 之后，开启幂等性，可以缓存多个请求，请求会在 kafka 服务端重新排序。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;同步发送&#34;&gt;&lt;a href=&#34;#%e5%90%8c%e6%ad%a5%e5%8f%91%e9%80%81&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;同步发送
&lt;/h3&gt;&lt;h3 id=&#34;异步发送&#34;&gt;&lt;a href=&#34;#%e5%bc%82%e6%ad%a5%e5%8f%91%e9%80%81&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;异步发送
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;异步发送是生产者和 RecordAccumulator 的异步，上面的同步发送，是生产者把每批次数据发送给 RecordAccumulator，该批次满足要求后由 sender 线程拉取发送到 kafka 集群，然后才是下一批次，按批次一批批发送给 kafka 集群，而异步则是不管上一批有没有发送到 kafka 集群，下一批直接由生产者发送到 RecordAccumulator。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;生产者提高吞吐量&#34;&gt;&lt;a href=&#34;#%e7%94%9f%e4%ba%a7%e8%80%85%e6%8f%90%e9%ab%98%e5%90%9e%e5%90%90%e9%87%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;生产者提高吞吐量
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-30.png&#34;
	width=&#34;2142&#34;
	height=&#34;1208&#34;
	srcset=&#34;/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-30_hu_22f2a69d6f42ea0c.png 480w, /zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/image-30_hu_a4a8fa75a4cec60e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;425px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;压缩算法&#34;&gt;&lt;a href=&#34;#%e5%8e%8b%e7%bc%a9%e7%ae%97%e6%b3%95&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;压缩算法  
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;配置参数 compression.type，默认为 none，支持 snappy、gzip、lz4、zstd 压缩算法&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;消费者详解&#34;&gt;&lt;a href=&#34;#%e6%b6%88%e8%b4%b9%e8%80%85%e8%af%a6%e8%a7%a3&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;消费者详解
&lt;/h2&gt;&lt;p&gt;消费者通常是消费者群组的一部分，多个消费者群组共同读取同一个主题时，彼此之间互不影响。&lt;strong&gt;Kafka 之所以要引入消费者群组这个概念是因为 Kafka 消费者经常会做一些高延迟的操作，比如把数据写到数据库或 HDFS ，或者进行耗时的计算，在这些情况下，单个消费者无法跟上数据生成的速度。此时可以增加更多的消费者，让它们分担负载，分别处理部分分区的消息，这就是 Kafka 实现横向伸缩的主要手段。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;pushpull&#34;&gt;&lt;a href=&#34;#pushpull&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;strong&gt;push&amp;amp;pull&lt;/strong&gt;
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;如果数据由 Kafka 进行推送（push），那么多个分区的数据同时推送给消费者进行处理，明显一个消费者的消费能力是有限的，那么消费者无法快速处理数据，就会导致数据的积压，从而导致网络，存储等资源造成极大的压力，影响吞吐量和数据传输效率。&lt;/li&gt;
&lt;li&gt;如果 kafka 的分区数据在内部可以存储的时间更长一些，再由消费者根据自己的消费能力向 kafka 申请（拉取）数据，那么整个数据处理的通道就会更顺畅一些。&lt;strong&gt;Kafka 的 Consumer 就采用的这种拉取数据的方式。&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;消费者组调度器&#34;&gt;&lt;a href=&#34;#%e6%b6%88%e8%b4%b9%e8%80%85%e7%bb%84%e8%b0%83%e5%ba%a6%e5%99%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;消费者组调度器  
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;消费者想要拉取数据，首先必须要加入到一个组中，成为消费组中的一员，同样道理，如果消费者出现了问题，也应该从消费者组中剥离。而这种加入组和退出组的处理，都应该由&lt;strong&gt;专门的管理组件进行处理&lt;/strong&gt;，这个组件在 kafka 中，我们称之为消费者组调度器（Group Coordinator）&lt;/p&gt;
&lt;p&gt;Group Coordinator 是 Broker 上的一个组件，用于管理和调度消费者组的成员、状态、分区分配、偏移量等信息。每个 Broker 都有一个 Group Coordinator 对象，负责管理多个消费者组，但&lt;strong&gt;每个消费者组只有一个 Group Coordinator&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;消费者分配分区策略&#34;&gt;&lt;a href=&#34;#%e6%b6%88%e8%b4%b9%e8%80%85%e5%88%86%e9%85%8d%e5%88%86%e5%8c%ba%e7%ad%96%e7%95%a5&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;消费者分配分区策略  
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;同一个消费者组的消费者都订阅同一个主题，所以消费者组中的多个消费者可以共同消费一个主题中的所有数据。&lt;/li&gt;
&lt;li&gt;为了避免数据被重复消费，&lt;strong&gt;一个分区的数据只能被同组中的一个消费者消费&lt;/strong&gt;，但是反过来，一个消费者是可以消费多个分区数据的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;消费者组中的消费者数量最好不要超出主题分区数量&lt;/strong&gt;，就会导致多出的消费者是无法消费数据的，造成了资源的浪费。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;消费者-leader&#34;&gt;&lt;a href=&#34;#%e6%b6%88%e8%b4%b9%e8%80%85-leader&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;消费者 Leader 
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;消费者中的每个消费者到底消费哪一个主题分区，这个分配策略其实是由&lt;strong&gt;消费者的 Leader&lt;/strong&gt;决定的，这个 Leader 称之为群主。群主是多个消费者中，&lt;strong&gt;第一个加入组中的消费者&lt;/strong&gt;，其他消费者称之为 Follower，称呼上有点类似与分区副本的 Leader 和 Follower。&lt;/p&gt;
&lt;p&gt;当消费者加入群组的时候，会发送一个 JoinGroup 请求。群主负责给每一个消费者分配分区。&lt;strong&gt;每个消费者只知道自己的分配信息，只有群主知道群组内所有消费者的分配信息。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;指定分配策略的基本流程&lt;/strong&gt;：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;第一个消费者设定 group.id 为 test，向当前负载最小的节点发送请求查找消费调度器&lt;/li&gt;
&lt;li&gt;找到消费调度器后，消费者向调度器节点发出 JOIN_GROUP 请求，加入消费者组。&lt;/li&gt;
&lt;li&gt;当前消费者当选为群主后，根据消费者配置中分配策略设计分区分配方案，并将分配好的方案告知调度器&lt;/li&gt;
&lt;li&gt;此时第二个消费者申请加入消费者组&lt;/li&gt;
&lt;li&gt;加入成功后，kafka 将消费者组状态切换到准备 rebalance，关闭和消费者的所有链接，等待它们重新加入。客户端重新申请加入，kafka 从消费者组中挑选一个作为 leader，其它的作为 follower。&lt;/li&gt;
&lt;li&gt;Leader 会按照分配策略对分区进行重分配，并将方案发送给调度器，由调度器通知所有的成员新的分配方案。组成员会按照新的方案重新消费数据&lt;/li&gt;
&lt;/ol&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;分区再均衡&#34;&gt;&lt;a href=&#34;#%e5%88%86%e5%8c%ba%e5%86%8d%e5%9d%87%e8%a1%a1&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;分区再均衡
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;因为群组里的消费者共同读取主题的分区，&lt;strong&gt;所以当一个消费者被关闭或发生崩溃时，它就离开了群组，&lt;/strong&gt; &lt;strong&gt;原本由它读取的分区将由群组里的其他消费者来读取&lt;/strong&gt;。同时在主题发生变化时 ， 比如&lt;strong&gt;添加了新的分区，也会发生分区与消费者的重新分配&lt;/strong&gt;，分区的所有权从一个消费者转移到另一个消费者，这样的行为被称为再均衡。正是因为再均衡，所以消费费者群组才能保证高可用性和伸缩性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;消费者通过向群组协调器所在的 broker 发送心跳来维持它们和群组的从属关系以及它们对分区的所有权&lt;/strong&gt;。只要消费者以正常的时间间隔发送心跳，就被认为是活跃的，说明它还在读取分区里的消息。消费 者会在轮询消息或提交偏移量时发送心跳。如果消费者停止发送心跳的时间足够长，会话就会过期，群组协调器认为它已经死亡，就会触发再均衡。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;监听分区再均衡&#34;&gt;&lt;a href=&#34;#%e7%9b%91%e5%90%ac%e5%88%86%e5%8c%ba%e5%86%8d%e5%9d%87%e8%a1%a1&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;监听分区再均衡  
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;因为分区再均衡会导致分区与消费者的重新划分，有时候希望在再均衡前执行一些操作：比如提交已经处理但是尚未提交的偏移量，关闭数据库连接等。此时可以在订阅主题时候，调用 subscribe 的重载方法传入自定义的分区再均衡监听器。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;偏移量-offset&#34;&gt;&lt;a href=&#34;#%e5%81%8f%e7%a7%bb%e9%87%8f-offset&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;偏移量 Offset
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;Kafka 的每一条消息都有一个偏移量属性，记录了其在分区中的位置，偏移量是一个单调递增的整数。 消费者通过往一个叫作 &lt;strong&gt;＿consumer_offset 的特殊主题&lt;/strong&gt;发送消息，消息里包含每个分区的偏移量。 如果消费者一直处于运行状态，那么偏移量就没有什么用处。不过，&lt;strong&gt;如果有消费者退出或者新分区加入，此时就会触发再均衡&lt;/strong&gt;。完成再均衡之后，每个消费者可能分配到新的分区，而不是之前处理的那个。为了能够继续之前的工作，&lt;strong&gt;消费者需要读取每个分 区最后一次提交的偏移量，然后从偏移量指定的地方继续处理&lt;/strong&gt;。 因为这个原因，所以如果不能正确提交偏移量，就可能会导致数据丢失或者重复出现消费。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;h3 id=&#34;lso&#34;&gt;&lt;a href=&#34;#lso&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;LSO
&lt;/h3&gt;&lt;p&gt;起始偏移量（Log Start Offset），每个分区副本都有起始偏移量，用于表示副本数据的起始偏移位置，初始值为 0。&lt;/p&gt;
&lt;p&gt;LSO 一般情况下无需更新，但是如果数据过期，或用户手动删除数据时，Leader 的 Log Start Offset 可能发生变化，Follower 副本的日志需要和 Leader 保持严格的一致，因此，如果 Leader 的该值发生变化，Follower 自然也要发生变化保持一致。&lt;/p&gt;
&lt;h3 id=&#34;leo&#34;&gt;&lt;a href=&#34;#leo&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;LEO
&lt;/h3&gt;&lt;p&gt;日志末端位移（Log End Offset），表示下一条待写入消息的 offset，每个分区副本都会记录自己的 LEO。对于 Follower 副本而言，它&lt;strong&gt;能读取到 Leader 副本 LEO 值以下的所有消息&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;hw&#34;&gt;&lt;a href=&#34;#hw&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HW
&lt;/h3&gt;&lt;p&gt;高水位值（High Watermark），定义了&lt;strong&gt;消息可见性（对于消费者而言）&lt;/strong&gt;，标识了一个特定的消息偏移量，消费者只能读取到水位线以下的的数据。同时这个偏移量还可以帮助 Kafka 完成副本数据同步操作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;这就是所谓的木桶理论：木桶中容纳水的高度，只能是水桶中最短的那块木板的高度&lt;/strong&gt;。这里将整个分区看成一个木桶，其中的数据看成水，而每一个副本就是木桶上的一块木板，那么这个分区（木桶）可以被消费者消费的数据（容纳的水）其实就是&lt;strong&gt;数据最少的那个副本的最后数据位置（木板高度）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;HW 高水位线会随着 follower 的数据同步操作，而不断上涨，也就是说，follower 同步的数据越多，那么水位线也就越高，那么消费者能访问的数据也就越多。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（详见上面的 follower 故障）&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;手动提交偏移量&#34;&gt;&lt;a href=&#34;#%e6%89%8b%e5%8a%a8%e6%8f%90%e4%ba%a4%e5%81%8f%e7%a7%bb%e9%87%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;手动提交偏移量
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;用户可以通过将 enable.auto.commit 设为 false ，然后手动提交偏移量。基于用户需求手动提交偏移量可以分为两大类：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;手动提交当前偏移量&lt;/strong&gt;：即手动提交当前轮询的最大偏移量；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;手动提交固定偏移量&lt;/strong&gt;：即按照业务需求，提交某一个固定的偏移量。&lt;/p&gt;
&lt;p&gt;按照 Kafka API，手动提交偏移量又可以分为&lt;strong&gt;同步提交和异步提交&lt;/strong&gt;。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;同步提交&#34;&gt;&lt;a href=&#34;#%e5%90%8c%e6%ad%a5%e6%8f%90%e4%ba%a4&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;同步提交
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;通过调用 consumer.commitSync() 来进行同步提交，不传递任何参数时提交的是当前轮询的最大偏 移量。&lt;/p&gt;&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;while&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ConsumerRecords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;records&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;consumer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;poll&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Duration&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;of&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ChronoUnit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;MILLIS&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ConsumerRecord&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;record&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;records&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;System&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;record&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;/*同步提交*/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;consumer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;commitSync&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;如果某个提交失败，同步提交还会进行重试，这可以保证数据能够最大限度提交成功，但是同时也会降 低程序的吞吐量。基于这个原因，Kafka 还提供了异步提交的 API。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;异步提交&#34;&gt;&lt;a href=&#34;#%e5%bc%82%e6%ad%a5%e6%8f%90%e4%ba%a4&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;异步提交
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;异步提交可以提高程序的吞吐量，因为此时你可以尽管请求数据，而不用等待 Broker 的响应。代码如下：&lt;/p&gt;&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;while&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ConsumerRecords&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;records&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;consumer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;poll&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Duration&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;of&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ChronoUnit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;MILLIS&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ConsumerRecord&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;record&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;records&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;System&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;record&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;/*异步提交并定义回调*/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;consumer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;commitAsync&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;OffsetCommitCallback&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Override&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;onComplete&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;TopicPartition&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;OffsetAndMetadata&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;offsets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Exception&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;exception&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;exception&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;null&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;System&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;错误处理&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;offsets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;forEach&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;System&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;topic = %s,partition =
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s&#34;&gt;    %d, offset = %s \n&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;                                                                &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;topic&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;partition&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;offset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()));&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;});&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;异步提交存在的问题是，在提交失败的时候不会进行自动重试，实际上也不能进行自动重试。假设程序 同时提交了 200 和 300 的偏移量，此时 200 的偏移量失败的，但是紧随其后的 300 的偏移量成功了， 此时如果重试就会存在 200 覆盖 300 偏移量的可能。同步提交就不存在这个问题，因为在同步提交的 情况下，300 的提交请求必须等待服务器返回 200 提交请求的成功反馈后才会发出。基于这个原因，某 些情况下，需要同时组合同步和异步两种提交方式。&lt;/li&gt;
&lt;li&gt;虽然程序不能在失败时候进行自动重试，但是我们是可以手动进行重试的，你可以通过一个 Map offsets 来维护你提交的每个分区的偏移量，然后当失败时候，你 可以判断失败的偏移量是否小于你维护的同主题同分区的最后提交的偏移量，如果小于则代表你 已经提交了更大的偏移量请求，此时不需要重试，否则就可以进行手动重试。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;自动提交偏移量&#34;&gt;&lt;a href=&#34;#%e8%87%aa%e5%8a%a8%e6%8f%90%e4%ba%a4%e5%81%8f%e7%a7%bb%e9%87%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;自动提交偏移量
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;将消费者的 enable.auto.commit 属性配置为 true 即可完成自动提交的配置。 此时每隔固定 的时间，消费者就会把 poll() 方法接收到的最大偏移量进行提交，提交间隔由 auto.commit.interval.ms 属性进行配置，默认值是 5s。&lt;/p&gt;
&lt;p&gt;使用自动提交是&lt;strong&gt;存在隐患的&lt;/strong&gt;，假设我们使用默认的 5s 提交时间间隔，在最近一次提交之后的 3s 发生了 再均衡，再均衡之后，消费者从最后一次提交的偏移量位置开始读取消息。这个时候偏移量已经落后了 3s ，所以在这 3s 内到达的消息&lt;strong&gt;会被重复处理&lt;/strong&gt;。可以通过修改提交时间间隔来更频繁地提交偏移量，减 小可能出现重复消息的时间窗，不过这种情况是无法完全避免的。基于这个原因，Kafka 也提供了手动提交偏移量的 API，使得用户可以更为灵活的提交偏移量。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;截至-尚硅谷-kafka3x-p39&#34;&gt;&lt;a href=&#34;#%e6%88%aa%e8%87%b3-%e5%b0%9a%e7%a1%85%e8%b0%b7-kafka3x-p39&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;截至 尚硅谷 kafka3.x P39
&lt;/h3&gt;</description>
        </item>
        <item>
        <title>Flume进阶--万字详解【老大爷也能学会】</title>
        <link>/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/</link>
        <pubDate>Sun, 28 Apr 2024 21:47:38 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/</guid>
        <description>&lt;h2 id=&#34;事务puttake&#34;&gt;&lt;a href=&#34;#%e4%ba%8b%e5%8a%a1puttake&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;事务（Put、Take）
&lt;/h2&gt;&lt;p&gt;put 事务把数据批处理写入临时缓冲区 putList，，然后 doCommit 去检查 Channel 内存队列是否足够合并，如果不够，就回滚数据，如果够，就把 putList 的数据写入到 Channel，然后由 take 事务从 channel 中拉取，写入到临时缓冲区 takeList，然后把数据从 takeList 发送到 HDFS，发送完毕后清空缓冲区，如果某个数据发送失败，就回滚到 channel。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image.png&#34;
	width=&#34;1582&#34;
	height=&#34;660&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image_hu_7583199c224fc93c.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image_hu_bdd73baa980f4760.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;239&#34;
		data-flex-basis=&#34;575px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;架构原理&#34;&gt;&lt;a href=&#34;#%e6%9e%b6%e6%9e%84%e5%8e%9f%e7%90%86&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;架构原理
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-1.png&#34;
	width=&#34;1521&#34;
	height=&#34;758&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-1_hu_124a7a8d78fb58bb.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-1_hu_8ff7e6529fb82c82.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;200&#34;
		data-flex-basis=&#34;481px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;在拦截阶段可以进行数据过滤清洗，洗掉脏数据。&lt;/p&gt;
&lt;h3 id=&#34;channelselector&#34;&gt;&lt;a href=&#34;#channelselector&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;ChannelSelector
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;因为一个 source 可以对应对各 channel&lt;/strong&gt; ，ChannelSelector 的作用就是选出 Event 将要被发往哪个 Channel。其共有两种类型， 分别是 Replicating（复制）和 Multiplexing（多路复用）。 ReplicatingSelector 会将同一个 Event &lt;strong&gt;发往所有&lt;/strong&gt;的 Channel，Multiplexing 会根据自定义的配置，将不同的 Event 发往不同的 Channel，Multiplexing 要结合拦截器使用，Multiplexing 会根据数据的头信息来决定发送到哪个 channel。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;sinkprocessor&#34;&gt;&lt;a href=&#34;#sinkprocessor&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;strong&gt;SinkProcessor&lt;/strong&gt;
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;一个 sink 只能绑定一个 channel，一个 channel 能绑定多个 sink。SinkProcessor 共 有 三 种 类 型 ， 分 别 是 DefaultSinkProcessor 、LoadBalancingSinkProcessor 和 FailoverSinkProcessor。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DefaultSinkProcessor 对 应 的 是 单个的 Sink&lt;/strong&gt; ， LoadBalancingSinkProcessor 和 FailoverSinkProcessor 对应的是 &lt;strong&gt;Sink Group&lt;/strong&gt;,LoadBalancingSinkProcessor 可以实现负载均衡的功能，FailoverSinkProcessor 可以错误恢复的功能。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;LoadBalancingSinkProcessor 负载均衡：&lt;/p&gt;
&lt;p&gt;一个 channel 会发给多个 sink&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-2.png&#34;
	width=&#34;990&#34;
	height=&#34;420&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-2_hu_6c49285a3e103af7.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-2_hu_a1bebb17cae83f23.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;235&#34;
		data-flex-basis=&#34;565px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;FailoverSinkProcessor 故障转移：&lt;/p&gt;
&lt;p&gt;当一个 sink 故障，任务会转移到其他 sink&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-3.png&#34;
	width=&#34;988&#34;
	height=&#34;400&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-3_hu_c71197231becb534.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-3_hu_355edecb5689cd82.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;247&#34;
		data-flex-basis=&#34;592px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;拓扑结构&#34;&gt;&lt;a href=&#34;#%e6%8b%93%e6%89%91%e7%bb%93%e6%9e%84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;拓扑结构
&lt;/h2&gt;&lt;h3 id=&#34;简单串联&#34;&gt;&lt;a href=&#34;#%e7%ae%80%e5%8d%95%e4%b8%b2%e8%81%94&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;简单串联
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-4.png&#34;
	width=&#34;1559&#34;
	height=&#34;773&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-4_hu_b3bf8623ae367e4c.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-4_hu_d5fef3d1650295f0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;201&#34;
		data-flex-basis=&#34;484px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;复制和多路复用&#34;&gt;&lt;a href=&#34;#%e5%a4%8d%e5%88%b6%e5%92%8c%e5%a4%9a%e8%b7%af%e5%a4%8d%e7%94%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;复制和多路复用
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-5.png&#34;
	width=&#34;1511&#34;
	height=&#34;1105&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-5_hu_83763143df0f54db.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-5_hu_96e82b6105502e3e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;136&#34;
		data-flex-basis=&#34;328px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;负载均衡和故障转移&#34;&gt;&lt;a href=&#34;#%e8%b4%9f%e8%bd%bd%e5%9d%87%e8%a1%a1%e5%92%8c%e6%95%85%e9%9a%9c%e8%bd%ac%e7%a7%bb&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;负载均衡和故障转移
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-6.png&#34;
	width=&#34;1412&#34;
	height=&#34;990&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-6_hu_bc1860421569b8f8.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-6_hu_778684d95d808a13.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;142&#34;
		data-flex-basis=&#34;342px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;聚合&#34;&gt;&lt;a href=&#34;#%e8%81%9a%e5%90%88&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;聚合
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-7.png&#34;
	width=&#34;1116&#34;
	height=&#34;960&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-7_hu_ee6f522aef6ef785.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-7_hu_76aeb26deaed92a8.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;116&#34;
		data-flex-basis=&#34;279px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;单源多出口案例&#34;&gt;&lt;a href=&#34;#%e5%8d%95%e6%ba%90%e5%a4%9a%e5%87%ba%e5%8f%a3%e6%a1%88%e4%be%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;单源多出口案例
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-8.png&#34;
	width=&#34;1248&#34;
	height=&#34;653&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-8_hu_23cd4d6dd707d84d.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-8_hu_53d52d0fb571962a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;191&#34;
		data-flex-basis=&#34;458px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;前置条件：&lt;/strong&gt;
linux01 上启动 hive，hdfs，在 linux03 上部署 3 个 flume 任务，启动 hdfs。linux01 和 linux03 配置 ssh 免密登录。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;要求：&lt;/strong&gt;
flume1 在 linux03 监听 linux01 的 hive 日志，把 hive 日志的新内容发送给 linux03 上的 flume2 和 flume3，flume2 把内容写到 hdfs，flume3 把内容写到 linux03 的本地文件/export/server/flume/job/group1/datas 文件夹中。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;剧透：&lt;/strong&gt;
flume3 成功把 hive 日志的新内容写到 datas 文件夹，说明 linux03 确实监听到了 linux01 的 hive 日志并且成功把日志从 linux01 弄到了 linux03，但是 flume2 却没有把新内容写到 hdfs，猜想的可能是因为在 linux03 上写 flume2 的配置文件**sinks.k1.hdfs.path = hdfs://linux01:9820/flume/group1/%Y%m%d/%H，**linux01 和 linux03 是不同的服务器，跨服务器没写进去，所以建议在同一台服务器搞。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;在 flume/job 目录中新建文件夹 group1 来存放本次案例的任务配置文件&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;mkdir group1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cd group1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;vim flume-file-flume.conf
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;vim flume-flume-hdfs.conf
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;vim flume-flume-dir.conf
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;三个 conf 配置如下：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;flume-file-flume.conf&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Name the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks = k1 k2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels = c1 c2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # 将数据流复制给所有 channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.selector.type = replicating
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.type = exec
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.command = ssh root&lt;span class=&#34;ni&#34;&gt;@linux01&lt;/span&gt; &amp;#39;tail -F /export/server/hive/logs/hive.log&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#因为hive在linux01&lt;/span&gt;，flume在linux03，为了跨服务器监听，这里用了ssh免密登录
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.shell = /bin/bash -c
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # sink 端的 avro 是一个数据发送者
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.hostname = linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.port = 4141
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.hostname = linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.port = 4142
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c2.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c2.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c2.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.channels = c1 c2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.channel = c2
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;flume-flume-hdfs.conf&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#Name&lt;/span&gt; the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks = k1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#Describe/configure&lt;/span&gt; the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#source&lt;/span&gt; 端的 avro 是一个数据接收服务
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r1.bind = linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r1.port = 4141
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#Describe&lt;/span&gt; the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.type = hdfs
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.hdfs.path = hdfs://linux01:9820/flume/group1/%Y%m%d/%H &lt;span class=&#34;ni&#34;&gt;#这里在&lt;/span&gt; linux03 把路径配置为 linux01 的 hdfs，可能就是出错原因
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#上传文件的前缀&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.hdfs.filePrefix = group1- &lt;span class=&#34;ni&#34;&gt;#是否按照时间滚动文件夹&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.hdfs.round = true &lt;span class=&#34;ni&#34;&gt;#多少时间单位创建一个新的文件夹&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.hdfs.roundValue = 1 &lt;span class=&#34;ni&#34;&gt;#重新定义时间单位&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.hdfs.roundUnit = hour &lt;span class=&#34;ni&#34;&gt;#是否使用本地时间戳&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.hdfs.useLocalTimeStamp = true &lt;span class=&#34;ni&#34;&gt;#积攒多少个&lt;/span&gt; Event 才 flush 到 HDFS 一次
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.hdfs.batchSize = 100 &lt;span class=&#34;ni&#34;&gt;#设置文件类型&lt;/span&gt;，可支持压缩
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.hdfs.fileType = DataStream &lt;span class=&#34;ni&#34;&gt;#多久生成一个新的文件&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.hdfs.rollInterval = 30 &lt;span class=&#34;ni&#34;&gt;#设置每个文件的滚动大小大概是&lt;/span&gt; 128M
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.hdfs.rollSize = 134217700 &lt;span class=&#34;ni&#34;&gt;#文件的滚动与&lt;/span&gt; Event 数量无关
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.hdfs.rollCount = 0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#Describe&lt;/span&gt; the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels.c1.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels.c1.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels.c1.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#Bind&lt;/span&gt; the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;flume-flume-dir.conf&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#Name&lt;/span&gt; the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks = k1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels = c2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r1.bind = linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r1.port = 4142
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k1.type = file_roll
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k1.sink.directory = /export/server/flume/job/group1/datas
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c2.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c2.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c2.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r1.channels = c2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k1.channel = c2
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;3 个配置文件写好后，在 linux03 启动 hdfs，然后在 flume 文件夹下启动三个 flume 任务&lt;/p&gt;
&lt;p&gt;flume-ng agent -c conf/ -n a3 -f job/group1/flume-flume-dir.conf&lt;/p&gt;
&lt;p&gt;flume-ng agent -c conf/ -n a2 -f job/group1/flume-flume-hdfs.conf&lt;/p&gt;
&lt;p&gt;flume-ng agent -c conf/ -n a1 -f job/group1/flume-file-flume.conf&lt;/p&gt;
&lt;p&gt;在 linux01 启动 hdfs ，然后启动 hivemetastore 和 hive，开始操作 hive，就会产生 hive 日志记录在 hive.log。&lt;/p&gt;
&lt;p&gt;注意！hive.log 没产生新内容可能是因为 hive 日志配置出错，去 conf 文件夹找 hive-log4j2.properties，找到 hive.log.dir。修改成自己的 logs 路径，默认路径可能要用到 hive 环境变量，如果环境变量没有就直接写绝对路径。
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-9.png&#34;
	width=&#34;1119&#34;
	height=&#34;201&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-9_hu_df5e0baa2f798ff5.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-9_hu_72b5c4bbf3d757dd.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;556&#34;
		data-flex-basis=&#34;1336px&#34;
	
&gt;
datas 确实产生了新文件，但是有很多空的，不知道咋回事，可能是任务配置问题。
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-10.png&#34;
	width=&#34;1044&#34;
	height=&#34;804&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-10_hu_186d3528c8b8279f.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-10_hu_3ad360ad4ecae4c9.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;129&#34;
		data-flex-basis=&#34;311px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;故障转移案例&#34;&gt;&lt;a href=&#34;#%e6%95%85%e9%9a%9c%e8%bd%ac%e7%a7%bb%e6%a1%88%e4%be%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;故障转移案例
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-11.png&#34;
	width=&#34;1436&#34;
	height=&#34;734&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-11_hu_18a2ea47c6ee537e.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-11_hu_af2f6474dc226e45.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;195&#34;
		data-flex-basis=&#34;469px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;前置：确保 4142、4141、44444 端口没被占用
在 linux03 的 flume/job 目录建 group2 文件夹，里面有如下 3 个配置文件：&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;flume-flume-console1.conf&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Name the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks = k1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r1.bind = linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r1.port = 4141
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.type = logger
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels.c1.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels.c1.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels.c1.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;flume-flume-console2.conf&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#Name&lt;/span&gt; the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks = k1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels = c2 # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r1.bind = linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r1.port = 4142 # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k1.type = logger # Describe the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c2.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c2.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c2.transactionCapacity = 100 # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r1.channels = c2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k1.channel = c2
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;flume-netcat-flume.conf&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Name the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinkgroups = g1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks = k1 k2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.type = netcat
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.bind = localhost
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.port = 44444
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinkgroups.g1.processor.type = failover
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinkgroups.g1.processor.priority.k1 = 5
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinkgroups.g1.processor.priority.k2 = 10
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#配置优先级&lt;/span&gt;，k1=5，优先级更高，因此数据会优先发给k1,当k1故障时，才会转移到k2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinkgroups.g1.processor.maxpenalty = 10000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.hostname = linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.port = 4141
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.hostname = linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.port = 4142
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinkgroups.g1.sinks = k1 k2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;分别启动 3 个任务&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1）flume-ng agent -c conf/ -n a3 -f job/group2/flume-flume-console2.conf -Dflume.root.logger=INFO,console&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;2）flume-ng agent -c conf/ -n a2 -f job/group2/flume-flume-console1.conf -Dflume.root.logger=INFO,console&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;3）flume-ng agent -c conf/ -n a1 -f job/group2/flume-netcat-flume.conf
运行 nc localhost 44444 并发送内容:
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-12.png&#34;
	width=&#34;758&#34;
	height=&#34;357&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-12_hu_4695483e0537af40.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-12_hu_1136186937ad7577.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;212&#34;
		data-flex-basis=&#34;509px&#34;
	
&gt;
在 console2 接收到（发送的汉字显示&amp;hellip;&amp;hellip;）
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-13.png&#34;
	width=&#34;2439&#34;
	height=&#34;392&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-13_hu_bd5e02c4de5283eb.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-13_hu_b60a000c4cd61376.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;622&#34;
		data-flex-basis=&#34;1493px&#34;
	
&gt;
找到 flume 进程，制造故障杀死 console2 任务，此时发生故障 ，任务会转移到 console1：
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-14.png&#34;
	width=&#34;1519&#34;
	height=&#34;565&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-14_hu_47c7b0836ddc751b.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-14_hu_7747d4b70d76b6c3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;268&#34;
		data-flex-basis=&#34;645px&#34;
	
&gt;
可以看到 console2 被杀死
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-15.png&#34;
	width=&#34;1777&#34;
	height=&#34;327&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-15_hu_78568c4c2a5d924c.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-15_hu_a1bc7eef27ecb403.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;543&#34;
		data-flex-basis=&#34;1304px&#34;
	
&gt;
继续发送数据，数据被 console1 接收
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-16.png&#34;
	width=&#34;734&#34;
	height=&#34;481&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-16_hu_27fec984d5ace5cf.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-16_hu_da10d12b697cf94.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;152&#34;
		data-flex-basis=&#34;366px&#34;
	
&gt;
console1 接收成功 。
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-17.png&#34;
	width=&#34;2424&#34;
	height=&#34;264&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-17_hu_f94472efee72010a.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-17_hu_a3d4cbf8982a213e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;918&#34;
		data-flex-basis=&#34;2203px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;负载均衡案例&#34;&gt;&lt;a href=&#34;#%e8%b4%9f%e8%bd%bd%e5%9d%87%e8%a1%a1%e6%a1%88%e4%be%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;负载均衡案例
&lt;/h2&gt;&lt;p&gt;尚硅谷 P25&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Name the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinkgroups = g1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks = k1 k2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.type = netcat
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.bind = localhost
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.port = 44444
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinkgroups.g1.processor.type = load_balance
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.hostname = linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.port = 4141
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.hostname = linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.port = 4142
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinkgroups.g1.sinks = k1 k2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;配置文件和故障转移案例一样，只有 flume-netcat-flume.conf 需要改。&lt;/p&gt;
&lt;h2 id=&#34;flume-聚合案例&#34;&gt;&lt;a href=&#34;#flume-%e8%81%9a%e5%90%88%e6%a1%88%e4%be%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Flume 聚合案例
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-18.png&#34;
	width=&#34;1401&#34;
	height=&#34;705&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-18_hu_b52e7eb81f2f0796.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-18_hu_2c464d839e46192e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;198&#34;
		data-flex-basis=&#34;476px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;三台服务器：linux01、linux02、linux03，监控 linux03 的 job/group.log 文件和 linux02 的 44444 端口，把监测到的数据传给 linux01，在 linux01 的控制台输出。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;linux03 的任务配置文件：flume3-logger-flume.conf&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Name the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks = k1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.type = exec
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.command = tail -F /export/server/flume/job/group.log
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.shell = /bin/bash -c
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.hostname = linux01
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.port = 4141
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;linux02 的任务配置文件：flume2-netcat-flume.conf&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Name the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks = k1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r1.type = netcat
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r1.bind = linux02
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r1.port = 44444
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.hostname = linux01
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.port = 4141
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Use a channel which buffers events in memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels.c1.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels.c1.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels.c1.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;linux01 的任务配置文件：flume1-flume-logger.conf&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Name the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks = k1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r1.bind = linux01
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r1.port = 4141
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k1.type = logger
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c1.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c1.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c1.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k1.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;自定义拦截器&#34;&gt;&lt;a href=&#34;#%e8%87%aa%e5%ae%9a%e4%b9%89%e6%8b%a6%e6%88%aa%e5%99%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;自定义拦截器
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;案例需求&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;使用 Flume 采集服务器本地日志，需要按照日志类型的不同，将不同种类的日志发往不 同的分析系统。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;需求分析&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;实际的开发中，一台服务器产生的日志类型可能有很多种，不同类型的日志可能需要 发送到不同的分析系统。此时会用到 Flume 拓扑结构中的 Multiplexing 结构，Multiplexing 的原理是，根据 event 中 Header 的某个 key 的值，将不同的 event 发送到不同的 Channel，所以我们需要自定义一个 Interceptor，为不同类型的 event 的 Header 中的 key 赋予不同的值。
在该案例中，我们以端口数据模拟日志，以是否包含”atguigu”模拟不同类型的日志， 我们需要自定义 interceptor 区分数据中是否包含”atguigu”，将其分别发往不同的分析 系统（Channel）。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-19.png&#34;
	width=&#34;1426&#34;
	height=&#34;584&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-19_hu_1bc3435833ccf53e.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-19_hu_b1cfcb02dd52d9e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;244&#34;
		data-flex-basis=&#34;586px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;自定义拦截器打成-jar-包&#34;&gt;&lt;a href=&#34;#%e8%87%aa%e5%ae%9a%e4%b9%89%e6%8b%a6%e6%88%aa%e5%99%a8%e6%89%93%e6%88%90-jar-%e5%8c%85&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;自定义拦截器打成 jar 包
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;77
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;78
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;79
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;org.apache.flume.Context&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;org.apache.flume.Event&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;org.apache.flume.interceptor.Interceptor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;java.util.ArrayList&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;java.util.List&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;java.util.Map&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;/**
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt; * @Author:懒大王Smile
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt; * @Date: 2024/4/28
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt; * @Time: 19:54
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt; * @Description:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt; */&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;TypeInterceptor&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;implements&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Interceptor&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//声明一个存放事件的集合&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;private&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;List&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Event&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;addHeaderEvents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Override&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;initialize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//初始化存放事件的集合&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;addHeaderEvents&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ArrayList&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//单个事件拦截&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Override&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Event&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;intercept&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Event&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;event&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//1.获取事件中的头信息&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;headers&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;event&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getHeaders&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//2.获取事件中的 body 信息&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;body&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;event&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getBody&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;());&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//3.根据 body 中是否有&amp;#34;atguigu&amp;#34;来决定添加怎样的头信息&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;body&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;contains&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;sereins&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//4.添加头信息&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;headers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;put&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;sereins&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//4.添加头信息&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;headers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;put&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;other&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;event&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//批量事件拦截&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Override&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;List&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Event&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;intercept&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;List&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Event&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;events&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//1.清空集合&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;addHeaderEvents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;clear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//2.遍历 events&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Event&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;event&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;events&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//3.给每一个事件添加头信息&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;addHeaderEvents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;add&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;intercept&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;event&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//4.返回结果&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;addHeaderEvents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Override&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;close&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//静态内部类&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;static&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Builder&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;implements&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Interceptor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;Builder&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Override&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Interceptor&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;build&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;TypeInterceptor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Override&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;configure&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Context&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;context&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;所需依赖：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;project&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;xmlns=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;http://maven.apache.org/POM/4.0.0&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         &lt;span class=&#34;na&#34;&gt;xmlns:xsi=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;http://www.w3.org/2001/XMLSchema-instance&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         &lt;span class=&#34;na&#34;&gt;xsi:schemaLocation=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&amp;#34;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;modelVersion&amp;gt;&lt;/span&gt;4.0.0&lt;span class=&#34;nt&#34;&gt;&amp;lt;/modelVersion&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;com.smile&lt;span class=&#34;nt&#34;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;interceptor&lt;span class=&#34;nt&#34;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;1.0-SNAPSHOT&lt;span class=&#34;nt&#34;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;properties&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;maven.compiler.source&amp;gt;&lt;/span&gt;8&lt;span class=&#34;nt&#34;&gt;&amp;lt;/maven.compiler.source&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;maven.compiler.target&amp;gt;&lt;/span&gt;8&lt;span class=&#34;nt&#34;&gt;&amp;lt;/maven.compiler.target&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;project.build.sourceEncoding&amp;gt;&lt;/span&gt;UTF-8&lt;span class=&#34;nt&#34;&gt;&amp;lt;/project.build.sourceEncoding&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/properties&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;dependencies&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.flume&lt;span class=&#34;nt&#34;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;flume-ng-core&lt;span class=&#34;nt&#34;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;1.9.0&lt;span class=&#34;nt&#34;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependencies&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;/project&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;jar 包打好放到 flume 的 lib 目录下，flume 启动时会加载 lib 的所有 jar 包。&lt;/p&gt;
&lt;p&gt;注意！！自定义拦截器的 jar 包源代码是定制的，里面的过滤拦截规则需要根据实际业务来编写，并且 jdk 最好是 1.8。&lt;/p&gt;
&lt;h3 id=&#34;任务配置文件&#34;&gt;&lt;a href=&#34;#%e4%bb%bb%e5%8a%a1%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;任务配置文件
&lt;/h3&gt;&lt;p&gt;inux01 服务器的 flume 配置文件 job/group4/interceptor-flume1.conf：&lt;/p&gt;
&lt;p&gt;1 配置 1 个 netcat source，1 个 sink group（2 个 avro sink）， 并配置相应的 ChannelSelector 和 interceptor。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Name the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks = k1 k2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels = c1 c2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.type = netcat
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.bind = localhost
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.port = 44444
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.interceptors = i1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.interceptors.i1.type = TypeInterceptor$Builder
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.selector.type = multiplexing
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.selector.header = type
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.selector.mapping.sereins = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.selector.mapping.other = c2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.hostname = linux02
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.port = 4141
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.type=avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.hostname = linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.port = 4242
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Use a channel which buffers events in memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Use a channel which buffers events in memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c2.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c2.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c2.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.channels = c1 c2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.channel = c2
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;linux02 服务器的 flume 配置文件 job/group4/interceptor-flume2.conf：&lt;/p&gt;
&lt;p&gt;配置一个 avro source 和一个 logger sink&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks = k1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.bind = linux02
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.port = 4141
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.type = logger
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;linux03 服务器的 flume 配置文件 job/group4/interceptor-flume3.conf：&lt;/p&gt;
&lt;p&gt;配置一个 avro source 和一个 logger sink&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks = k1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.bind = linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.port = 4242
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.type = logger
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;以上配置完后，在 linux01 nc localhost 44444,然而&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-20.png&#34;
	width=&#34;862&#34;
	height=&#34;94&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-20_hu_e70a91c1daa17f20.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-20_hu_a03db1a18740a197.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;917&#34;
		data-flex-basis=&#34;2200px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;尚硅谷 Flume P33&lt;/strong&gt;
&lt;strong&gt;后面的以后再搞&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;自定义-source&#34;&gt;&lt;a href=&#34;#%e8%87%aa%e5%ae%9a%e4%b9%89-source&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;自定义 Source
&lt;/h2&gt;&lt;h2 id=&#34;自定义-sink&#34;&gt;&lt;a href=&#34;#%e8%87%aa%e5%ae%9a%e4%b9%89-sink&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;自定义 Sink
&lt;/h2&gt;&lt;h2 id=&#34;事务源码&#34;&gt;&lt;a href=&#34;#%e4%ba%8b%e5%8a%a1%e6%ba%90%e7%a0%81&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;事务源码
&lt;/h2&gt;</description>
        </item>
        <item>
        <title>Flume入门--万字详解</title>
        <link>/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/</link>
        <pubDate>Mon, 22 Apr 2024 15:22:55 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/</guid>
        <description>&lt;h2 id=&#34;概述&#34;&gt;&lt;a href=&#34;#%e6%a6%82%e8%bf%b0&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;概述
&lt;/h2&gt;&lt;p&gt;Flume 是 Cloudera 提供的一个高可用的，高可靠的，分布式的海量&lt;strong&gt;日志采集&lt;/strong&gt;、聚合和传 输的系统。Flume 基于流式架构，灵活简单。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image.png&#34;
	width=&#34;1218&#34;
	height=&#34;508&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image_hu_7fa87b03cd51f56f.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image_hu_86396d462a02f120.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;239&#34;
		data-flex-basis=&#34;575px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;基础架构&#34;&gt;&lt;a href=&#34;#%e5%9f%ba%e7%a1%80%e6%9e%b6%e6%9e%84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;基础架构
&lt;/h2&gt;&lt;p&gt;Flume 运行的核心是 Agent。Flume 是以 agent 为最小的独立运行单位。一个 agent 就是一个 JVM。它是 一个完整的数据收集工具，含有三个核心组件，分别是 source、 channel、 sink。通过这些组件， Event 可以从一个地方流向另一个地方。如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-1.png&#34;
	width=&#34;1210&#34;
	height=&#34;464&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-1_hu_8561a55c375264ae.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-1_hu_a84eee12f3e31d2f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;260&#34;
		data-flex-basis=&#34;625px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;agent&#34;&gt;&lt;a href=&#34;#agent&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Agent
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Agent 是一个 JVM 进程，它以事件的形式将数据从源头送至目的。&lt;/li&gt;
&lt;li&gt;Agent 主要有 3 个部分组成，Source、Channel、Sink。同一台服务器可以运行多个 Agent，每个 Agent 可以有多个 source、sink、channel。Agent 的名字可以相同但是不能同时启动任务，否则会出现冲突。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;source&#34;&gt;&lt;a href=&#34;#source&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Source
&lt;/h4&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Source 是负责接收数据到 Flume Agent 并传给 Channel 的组件。&lt;/li&gt;
&lt;li&gt;Source 组件可以处理各种类型、各种格式的日志数据，包括 avro、thrift、exec、jms、spooling directory、netcat、taildir、 sequence generator、syslog、http、legacy 这些不同的数据源。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;sink&#34;&gt;&lt;a href=&#34;#sink&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Sink
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Sink 不断地轮询 Channel 中的事件且批量地移除它们，并将这些事件批量写入到存储系统或索引系统、或者被发送到另一个 Flume Agent。&lt;/li&gt;
&lt;li&gt;Sink 组件目的地包括 hdfs、logger、avro、thrift、ipc、file、HBase、solr、自定义。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;channel&#34;&gt;&lt;a href=&#34;#channel&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Channel
&lt;/h4&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Channel 是位于 Source 和 Sink 之间的缓冲区。因此，Channel 允许 Source 和 Sink 运作在不同的速率上。&lt;/li&gt;
&lt;li&gt;Channel 是线程安全的，可以同时处理几个 Source 的写入操作和几个 Sink 的读取操作。&lt;/li&gt;
&lt;li&gt;Flume 自带两种 Channel：Memory Channel 和 File Channel。&lt;/li&gt;
&lt;li&gt;Memory Channel 是内存中的队列。Memory Channel 在不需要关心数据丢失的情景下适 用。如果需要关心数据丢失，那么 Memory Channel 就不应该使用，因为程序死亡、机器宕 机或者重启都会导致数据丢失。&lt;/li&gt;
&lt;li&gt;File Channel 将所有事件写到磁盘。因此在程序关闭或机器宕机的情况下不会丢失数 据。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;selector&#34;&gt;&lt;a href=&#34;#selector&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;selector
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;选择器，作用于 source 端，然后决定数据发往哪个目标。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;interceptor&#34;&gt;&lt;a href=&#34;#interceptor&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;interceptor
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;拦截器，flume 允许使用拦截器拦截数据。允许使用拦截器链，作用于 source 和 sink 阶段。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;event&#34;&gt;&lt;a href=&#34;#event&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Event
&lt;/h4&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;传输单元，Flume 数据传输的基本单元，以 Event 的形式将数据从源头送至目的地。&lt;/li&gt;
&lt;li&gt;Event 由 Header 和 Body 两部分组成，Header 用来存放该 event 的一些属性，为 K-V 结构， Body 用来存放该条数据，形式为字节数组。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-2.png&#34;
	width=&#34;816&#34;
	height=&#34;151&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-2_hu_3f35ec154b3b11eb.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-2_hu_10f158814c30aa1e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;540&#34;
		data-flex-basis=&#34;1296px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;安装部署&#34;&gt;&lt;a href=&#34;#%e5%ae%89%e8%a3%85%e9%83%a8%e7%bd%b2&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;安装部署
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;解压&lt;/p&gt;
&lt;p&gt;tar -zxvf /export/server/apache-flume-1.9.0-bin.tar.gz /export/server/&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;为了让 flume1.9 兼容 hadoop3.x，要删除 flume lib 包下的 guava-11.0.2.jar&lt;/p&gt;
&lt;p&gt;rm guava-11.0.2.jar&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;Netcat&#34;&gt;&lt;a href=&#34;#Netcat&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Netcat
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;安装&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;sudo yum install -y nc&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;简单案例&lt;/strong&gt;&lt;/p&gt;
&lt;br /&gt;
&lt;h2 id=&#34;flume-入门案例&#34;&gt;&lt;a href=&#34;#flume-%e5%85%a5%e9%97%a8%e6%a1%88%e4%be%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Flume 入门案例
&lt;/h2&gt;&lt;h3 id=&#34;netcat-本机端口监控&#34;&gt;&lt;a href=&#34;#netcat-%e6%9c%ac%e6%9c%ba%e7%ab%af%e5%8f%a3%e7%9b%91%e6%8e%a7&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;netcat 本机端口监控
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;在 flume 文件夹下创建工作目录 job&lt;/p&gt;
&lt;p&gt;mkdir job&lt;/p&gt;
&lt;p&gt;在 job 目录下建立任务配置文件，文件名任取，建议见名知意，net 表示数据源是端口，logger 表示数据是日志文件&lt;/p&gt;
&lt;p&gt;vim net-flume-logger.conf&lt;/p&gt;
&lt;p&gt;配置文件内容如下：&lt;/p&gt;&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Name the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources = r1 &lt;span class=&#34;ni&#34;&gt;#a1是该agent名&lt;/span&gt;，不可重复
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks = k1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.type = netcat
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.bind = localhost
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.port = 4444
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.type = logger
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Use a channel which buffers events in memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.capacity = 1000 &lt;span class=&#34;ni&#34;&gt;#最多接收1000个event&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.transactionCapacity = 100 &lt;span class=&#34;ni&#34;&gt;#100个事务&lt;/span&gt;，一次最多发送100个event，事务失败会回滚。capacity应该 &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;transactionCapacity&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;Bind&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;source&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;sink&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;channel&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;na&#34;&gt;a1&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;sources&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;r1&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;channels &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;c1&lt;/span&gt; &lt;span class=&#34;ni&#34;&gt;#一个source可以绑定多个channel&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;na&#34;&gt;a1&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;sinks&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;k1&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;channel &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;c1&lt;/span&gt; &lt;span class=&#34;ni&#34;&gt;#一个sink只能绑定一个channel&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;启动两个终端，一个终端启动监听任务：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;在 flume 目录下运行：
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;flume-ng agent -c conf/ -n a1 -f job/flume-netcat-logger.conf -D flume.root.logger=INFO,console
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;参数说明：
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--conf/-c：表示配置文件存储在 conf/目录
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--name/-n：表示给 agent 起名为 a1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--conf-file/-f：flume 本次启动读取的配置文件是在 job 文件夹下的 flume-telnet.conf 文件.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;-Dflume.root.logger=INFO,console ：-D 表示 flume 运行时动态修改 flume.root.logger 参数属性值，并将控制台日志打印级别设置为 INFO 级别。日志级别包括:log、info、warn、 error。
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-3.png&#34;
	width=&#34;1530&#34;
	height=&#34;653&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-3_hu_c99cca4dd73c04ee.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-3_hu_82ef1505922ff86c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;234&#34;
		data-flex-basis=&#34;562px&#34;
	
&gt;
另一个终端使用 netcat 向监听的端口发送内容：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;nc localhost 4444
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-4.png&#34;
	width=&#34;746&#34;
	height=&#34;258&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-4_hu_b88eeeed95de3eea.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-4_hu_76944ab34e474c55.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;289&#34;
		data-flex-basis=&#34;693px&#34;
	
&gt;
检查启动任务的端口是否收到。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;监控-hive-日志上传-hdfs&#34;&gt;&lt;a href=&#34;#%e7%9b%91%e6%8e%a7-hive-%e6%97%a5%e5%bf%97%e4%b8%8a%e4%bc%a0-hdfs&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;监控 hive 日志上传 hdfs
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-5.png&#34;
	width=&#34;1221&#34;
	height=&#34;507&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-5_hu_9d7ee6a4efc594d2.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-5_hu_d7e8bc859122f40b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;240&#34;
		data-flex-basis=&#34;577px&#34;
	
&gt;
在 job 目录下新建任务的配置文件 flume-file-hdfs.conf,内容如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Name the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources = r2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks = k2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels = c2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r2.type = exec
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r2.command = tail -F /export/server/hive/logs/metastore.log
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#这里我监控的是hive的元数据日志&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.type = hdfs
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.hdfs.path = hdfs://linux01:8020/flume/%Y%m%d/%H
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#8020端口不要搞错&lt;/span&gt;，具体查看hadoop的core-site.xml
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#上传文件的前缀&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.hdfs.filePrefix = logs-
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#是否按照时间滚动文件夹&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.hdfs.round = true
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#多少时间单位创建一个新的文件夹&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.hdfs.roundValue = 1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#重新定义时间单位&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.hdfs.roundUnit = hour
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#是否使用本地时间戳&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.hdfs.useLocalTimeStamp = true
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#注意&lt;/span&gt;：对于所有与时间相关的转义序列，Event Header 中必须存在以 “timestamp”的
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    key（除非 hdfs.useLocalTimeStamp 设置为 true，此方法会使用 TimestampInterceptor 自
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    动添加 timestamp）。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#积攒多少个&lt;/span&gt; Event 才 flush 到 HDFS 一次
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.hdfs.batchSize = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#设置文件类型&lt;/span&gt;，可支持压缩
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.hdfs.fileType = DataStream
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#多久生成一个新的文件&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.hdfs.rollInterval = 60
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#设置每个文件的滚动大小&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.hdfs.rollSize = 134217700
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#文件的滚动与&lt;/span&gt; Event 数量无关
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.hdfs.rollCount = 0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Use a channel which buffers events in memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels.c2.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels.c2.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels.c2.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r2.channels = c2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.channel = c2
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;先在 flume 文件夹下启动 flume 的监听任务：
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;bin/flume-ng agent -c conf/ -n a2 -f job/flume-file-hdfs.conf -D flume.root.logger=INFO,console
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;启动 hdfs 和 hive 的元数据服务
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;start-dfs.sh
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;start-hivemetastore.sh（自己写的脚本）
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;启动 hive 开始操作
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hive 会产生元数据记录在 metastore.log 中，然后就会被 flume 监听到，flume 就会把监听到的日志写到 hdfs 的 flume 文件夹中。浏览器打开 linux01:9870 查看 hdfs 的文件目录，发现新建了 flume 文件夹，表示操作成功。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;![](image-6.png)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;注意！监听的 metastore.log 一定要是有效的，如果无效那么 hive 的日志就不会写到里面，flume 就检测不到，具体去看 hive 的日志配置教程。另外启动的 agent 的任务名字和配置文件不要搞错了，是 a2 和 flume-file-hdfs.conf。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;实时读取目录文件到-hdfs&#34;&gt;&lt;a href=&#34;#%e5%ae%9e%e6%97%b6%e8%af%bb%e5%8f%96%e7%9b%ae%e5%bd%95%e6%96%87%e4%bb%b6%e5%88%b0-hdfs&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;实时读取目录文件到 hdfs
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-7.png&#34;
	width=&#34;1209&#34;
	height=&#34;528&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-7_hu_c1105467385bcae8.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-7_hu_4fa73e60ceb8a8e2.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;228&#34;
		data-flex-basis=&#34;549px&#34;
	
&gt;
job 目录下编写 flume-dir-hdfs.conf 配置文件：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources = r3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks = k3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels = c3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # source类型是目录
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r3.type = spooldir
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#定义监控目录&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r3.spoolDir = /export/server/flume/upload
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#定义文件上传完后缀&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r3.fileSuffix = .COMPLETED
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#是否有文件头&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r3.fileHeader = true
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#忽略所有以&lt;/span&gt;.tmp 结尾的文件，不上传
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r3.ignorePattern = ([^ ]*\.tmp)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.type = hdfs
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.path = hdfs://linux01:8020/flume/upload/%Y%m%d/%H
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#hdfs的upload文件夹要提前手动创建好&lt;/span&gt;，flume不会自己创建，否则会报错。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#上传文件的前缀&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.filePrefix = upload-
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#是否按照时间滚动文件夹&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.round = true
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#多少时间单位创建一个新的文件夹&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.roundValue = 1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#重新定义时间单位&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.roundUnit = hour
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#是否使用本地时间戳&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.useLocalTimeStamp = true
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#积攒多少个&lt;/span&gt; Event 才 flush 到 HDFS 一次
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.batchSize = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#设置文件类型&lt;/span&gt;，可支持压缩
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.fileType = DataStream
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#多久生成一个新的文件&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.rollInterval = 60
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#设置每个文件的滚动大小大概是&lt;/span&gt; 128M
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.rollSize = 134217700
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#文件的滚动与&lt;/span&gt; Event 数量无关
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.rollCount = 0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Use a channel which buffers events in memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c3.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c3.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c3.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r3.channels = c3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.channel = c3
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;flume 目录下启动 agent 任务：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;bin/flume-ng agent -c conf/ -n a3 -f job/flume-dir-hdfs.conf&lt;/p&gt;
&lt;p&gt;注意不要有多余的空格或者不可见字符，启动失败就去 logs 文件夹看日志&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;任务启动后就往监控目录/flume/upload 文件夹里面放文件 ，放了 3 个不同的文件，其中 tmp 后缀的文件没有上传到 hdfs，因为在 conf 配置文件中把 tmp 后缀的排除了，其他两个上传完毕，并且文件后缀改成 COMPLETED：
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-8.png&#34;
	width=&#34;1132&#34;
	height=&#34;287&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-8_hu_119154576442338f.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-8_hu_638b356095ba52.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;394&#34;
		data-flex-basis=&#34;946px&#34;
	
&gt;
进入 linux01:9870 查看 hdfs 文件目录， 确实上传成功了。
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-9.png&#34;
	width=&#34;2437&#34;
	height=&#34;1006&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-9_hu_2110e997d452b344.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-9_hu_2c54946dfe69fec2.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;242&#34;
		data-flex-basis=&#34;581px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意！&lt;/strong&gt; 配置文件的 a3.sinks.k3.hdfs.path 指定了 linux01:8020，那么 flume 任务就得在 linux01 上启动，在 linux02 上启动不会生效。我的 linux01 是主机，linux02 和 03 是从机，就算在 linux02 上启动 flume 任务，把 a3.sinks.k3.hdfs.path 改成 linux02:8020 也不行，必须在 linux01 上启动。
&lt;strong&gt;注意！向/flume/upload 文件夹放的文件不能是以上传完成的后缀结尾，比如文件上传成功后缀是 COMPLETED，那么向里面放的文件后缀就不能是 COMPLETED。另外不能向 upload 里放文件名相同的文件，文件名相同的文件只有第一个会上传到 hdfs，之后的不会，因为 linux 同一目录不允许同名文件产生。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;实时监控目录下的多个追加文件&#34;&gt;&lt;a href=&#34;#%e5%ae%9e%e6%97%b6%e7%9b%91%e6%8e%a7%e7%9b%ae%e5%bd%95%e4%b8%8b%e7%9a%84%e5%a4%9a%e4%b8%aa%e8%bf%bd%e5%8a%a0%e6%96%87%e4%bb%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;实时监控目录下的多个追加文件
&lt;/h3&gt;&lt;p&gt;案例 2 的 exec source 适用于监控一个实时追加的文件，不能断点续传，案例 3 的 spooldir source 适用于同步新文件，但不适用于实时监听同步追加日志的文件，而该案例的 Taildir Source 就适合于监听多个实时追加的文件，并能实现断点续传。
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-10.png&#34;
	width=&#34;1447&#34;
	height=&#34;533&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-10_hu_3bb935b9cd6bd98f.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-10_hu_20ded4dc11c4bc23.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;271&#34;
		data-flex-basis=&#34;651px&#34;
	
&gt;
job 目录下新建 flume-dir-hdfs.conf 配置文件：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources = r3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks = k3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels = c3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#定义source类型&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r3.type = TAILDIR
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r3.positionFile = /export/server/apache-flume-1.9.0-bin/tail_dir.json
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#注意&lt;/span&gt;！！这里我把软链接flume换成了本来的真实目录apache-flume-1.9.0-bin，原因后面讲
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#文件组&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r3.filegroups = f1 f2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r3.filegroups.f1 = /export/server/flume/files/.*file.*
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r3.filegroups.f2 = /export/server/flume/files2/.*log.*
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.type = hdfs
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.path = hdfs://linux01:8020/flume/upload2/%Y%m%d/%H
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#上传文件的前缀&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.filePrefix = upload-
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#是否按照时间滚动文件夹&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.round = true
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#多少时间单位创建一个新的文件夹&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.roundValue = 1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#重新定义时间单位&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.roundUnit = hour
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#是否使用本地时间戳&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.useLocalTimeStamp = true
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#积攒多少个&lt;/span&gt; Event 才 flush 到 HDFS 一次
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.batchSize = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#设置文件类型&lt;/span&gt;，可支持压缩
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.fileType = DataStream
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#多久生成一个新的文件&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.rollInterval = 60
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#设置每个文件的滚动大小大概是&lt;/span&gt; 128M
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.rollSize = 134217700
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#文件的滚动与&lt;/span&gt; Event 数量无关
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.rollCount = 0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Use a channel which buffers events in memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c3.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c3.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c3.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r3.channels = c3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.channel = c3
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;hdfs 文件中提前创建好 upload2 文件夹：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;hdfs dfs -mkdir /flume/upload2
flume 文件夹中创建 files 和 files2 文件夹，分别在里面写 file1.txt 和 log1.log 用于追加内容让 flume 任务监控。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-11.png&#34;
	width=&#34;987&#34;
	height=&#34;232&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-11_hu_3d3be8253f4ea89.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-11_hu_35e2622993d720d4.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;425&#34;
		data-flex-basis=&#34;1021px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-12.png&#34;
	width=&#34;954&#34;
	height=&#34;188&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-12_hu_ff914089d72061b5.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-12_hu_8ba92ad258b85007.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;507&#34;
		data-flex-basis=&#34;1217px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;flume 文件下启动监控任务：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;bin/flume-ng agent -c conf/ -n a3 -f job/flume-taildir-hdfs.conf&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;用 echo 命令向 file1.txt 和 log1.log 追加内容，追加的内容就会被 flume 检测到，filume 就会把追加的新内容上传到 hdfs 的 upload2 文件夹。
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-13.png&#34;
	width=&#34;2338&#34;
	height=&#34;789&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-13_hu_496ca9bcf5e7b220.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-13_hu_a6a4961d82b88ca0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;296&#34;
		data-flex-basis=&#34;711px&#34;
	
&gt;
追加的内容被检测到，上传到 hdfs，案例成功！
&lt;strong&gt;注意！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;配置文件中，之前是 a3.sources.r3.positionFile = /export/server/flume/tail_dir.json，此时启动 flume 任务能成功，但是追加的内容不会上传到 hdfs，也就是该案例没有成功。去 logs 文件中查看 flume.log 日志，发现有一段报错如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;21&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;四月&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;2024&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;22&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;52&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;16&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;844&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ERROR&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;conf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;poller&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;org&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;apache&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;flume&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;AbstractConfigurationProvider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;loadSources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;355&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Source&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;r3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;has&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;been&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;removed&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;due&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;an&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;error&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;during&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;configuration&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;org&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;apache&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;flume&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;FlumeException&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Error&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;creating&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;positionFile&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;parent&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;directories&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;org&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;apache&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;flume&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;source&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;taildir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;TaildirSource&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;configure&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;TaildirSource&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;170&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;org&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;apache&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;flume&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;conf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;Configurables&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;configure&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Configurables&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;41&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;org&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;apache&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;flume&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;AbstractConfigurationProvider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;loadSources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;AbstractConfigurationProvider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;325&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;org&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;apache&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;flume&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;AbstractConfigurationProvider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getConfiguration&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;AbstractConfigurationProvider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;105&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;org&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;apache&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;flume&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;PollingPropertiesFileConfigurationProvider$FileWatcherRunnable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;run&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;PollingPropertiesFileConfigurationProvider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;145&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;util&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;concurrent&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;Executors$RunnableAdapter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;call&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Executors&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;511&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;util&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;concurrent&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;FutureTask&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;runAndReset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;FutureTask&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;308&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;util&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;concurrent&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;ScheduledThreadPoolExecutor$ScheduledFutureTask&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;access$301&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ScheduledThreadPoolExecutor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;180&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;util&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;concurrent&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;ScheduledThreadPoolExecutor$ScheduledFutureTask&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;run&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ScheduledThreadPoolExecutor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;294&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;util&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;concurrent&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;ThreadPoolExecutor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;runWorker&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ThreadPoolExecutor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;1149&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;util&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;concurrent&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;ThreadPoolExecutor$Worker&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;run&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ThreadPoolExecutor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;624&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;lang&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;Thread&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;run&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Thread&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;750&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Caused&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;by&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;nio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;FileAlreadyExistsException&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;export&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;server&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;flume&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;nio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;fs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;UnixException&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;translateToIOException&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UnixException&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;88&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;nio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;fs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;UnixException&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;rethrowAsIOException&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UnixException&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;102&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;nio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;fs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;UnixException&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;rethrowAsIOException&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UnixException&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;107&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;nio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;fs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;UnixFileSystemProvider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;createDirectory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UnixFileSystemProvider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;384&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;nio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;Files&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;createDirectory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Files&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;674&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;nio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;Files&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;createAndCheckIsDirectory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Files&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;781&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;nio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;Files&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;createDirectories&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Files&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;727&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;org&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;apache&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;flume&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;source&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;taildir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;TaildirSource&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;configure&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;TaildirSource&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;168&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;more&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;给 chatgpt 看看：
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-14.png&#34;
	width=&#34;2367&#34;
	height=&#34;575&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-14_hu_d8ff180d4f856e7e.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-14_hu_1b7cc2868b1adaee.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;411&#34;
		data-flex-basis=&#34;987px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;大概意思是 positionfile 文件创建失败，原因是出现命名冲突。因为我的 flume 是个软链接，类似于快捷方式，但是写到配置文件里面，flume 程序就会把配置文件的 flume 当成真实目录，进而就会尝试创建名为 flume 的目录并且去进到创建的 flume 目录创建 r3，然而我已经存在了名为 flume 的软链接，程序就会创建 flume 目录失败，进而无法创建 r3。所以把配置文件的 flume 换成真实的 apache-flume-1.9.0-bin 目录就可以了，这样就可以生成 r3，也就是 positionfile = tail_dir.json 文件。当然另一种解决方法就是把 positionfile 的位置放到 flume 软链接外面。&lt;/p&gt;
&lt;p&gt;tail_dir.json 文件内容如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;inode&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;83899573&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;pos&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;44&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;file&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/export/server/flume/files/file1.txt&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;inode是文件的唯一标识&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，即使文件重命名也不会变，除非文件删除&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pos表示读到哪里&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：监控文件的绝对路径&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;json文件靠inode和file两个值表示pos位置信息&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;注意！ log4j 日志框架每天凌晨会自动把前一天的 hive.log 的文件改名，后缀加上日期，这点对我们监控空间极不友好，假如我们监控的是 hive.log，然而 hive.log 会自动更名 hive.log.2024-xx-xx,监测的文件名发生改变,而 inode 不变，然而 json 文件中记录的绝对路径仍然是 hive.log，此时的 hive.log 是新的文件，inode 变化，就无法实现断点续传。&lt;/p&gt;
&lt;p&gt;解决方案：1）不使用 log4j 2）修改 flume 源码包
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-15.png&#34;
	width=&#34;1254&#34;
	height=&#34;358&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-15_hu_ba0e6aa6ca72876.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-15_hu_7ea1071690105aa1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;350&#34;
		data-flex-basis=&#34;840px&#34;
	
&gt;
&lt;strong&gt;修改源码包的 TailFile 和 ReliableTaildirEventReader：&lt;/strong&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-16.png&#34;
	width=&#34;1832&#34;
	height=&#34;407&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-16_hu_8a8bb29403f12b75.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-16_hu_b5c7c5bcf5a462e7.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;450&#34;
		data-flex-basis=&#34;1080px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-17.png&#34;
	width=&#34;1728&#34;
	height=&#34;1402&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-17_hu_2651a7ca432bfddb.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-17_hu_f849167e43dfc987.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;123&#34;
		data-flex-basis=&#34;295px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-18.png&#34;
	width=&#34;1742&#34;
	height=&#34;1357&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-18_hu_41296967dda0ef4e.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-18_hu_b14b812135d32750.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;128&#34;
		data-flex-basis=&#34;308px&#34;
	
&gt;
修改后重新打包生成 flume-taildir-source-1.9.0.jar,进入 flume/lib 目录下，把原来的 jar 包替换掉：
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-19.png&#34;
	width=&#34;1593&#34;
	height=&#34;96&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-19_hu_9bc37188bd235dcd.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-19_hu_a5fd9ba123f64dc8.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;1659&#34;
		data-flex-basis=&#34;3982px&#34;
	
&gt;
把原来的后缀改成 bak。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>大数据—Zookeeper集群入门及使用</title>
        <link>/zh-cn/post/2024/04/%E5%A4%A7%E6%95%B0%E6%8D%AEzookeeper%E9%9B%86%E7%BE%A4%E5%85%A5%E9%97%A8%E5%8F%8A%E4%BD%BF%E7%94%A8/</link>
        <pubDate>Fri, 19 Apr 2024 16:43:51 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/04/%E5%A4%A7%E6%95%B0%E6%8D%AEzookeeper%E9%9B%86%E7%BE%A4%E5%85%A5%E9%97%A8%E5%8F%8A%E4%BD%BF%E7%94%A8/</guid>
        <description>&lt;h2 id=&#34;概述&#34;&gt;&lt;a href=&#34;#%e6%a6%82%e8%bf%b0&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;概述
&lt;/h2&gt;&lt;p&gt;ZooKeeper 是一个开源的&lt;strong&gt;分布式协调服务&lt;/strong&gt;，它的设计目标是&lt;strong&gt;为那些高吞吐的大型分布式系统提供一个高性能、高可用、且具有严格顺序访问控制 能力的分布式协调服务&lt;/strong&gt;，并以一系列简单易用的接口提供给用户使用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ZooKeeper 将数据存全量储在内存中以保持高性能&lt;/strong&gt;，并通过服务集群来实现高可用，由于 Zookeeper 的所有更新和删除都是&lt;strong&gt;基于事务&lt;/strong&gt;的，所以其在&lt;strong&gt;读多写少&lt;/strong&gt;的应用场景中有着很高的性能表现。&lt;/p&gt;
&lt;p&gt;简单来说 zookeeper 就是动物园管理者，管理协调大数据里面的一堆组件，比如 hadoop、hive、habse 等等。Zookeeper 可以用于实现分布 式系统中常见的发布/订阅、负载均衡、命令服务、分布式协调/通知、集群管理、Master 选举、分布式 锁和分布式队列等功能。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-07-55.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-07-55&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;特点&#34;&gt;&lt;a href=&#34;#%e7%89%b9%e7%82%b9&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;特点
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;-&lt;strong&gt;顺序一致性&lt;/strong&gt;：从一个客户端发起的事务请求，最终都会严格按照其发起顺序被应用到 Zookeeper 中； -&lt;strong&gt;原子性&lt;/strong&gt;：所有事务请求的处理结果在整个集群中所有机器上都是一致的；不存在部分机器应用了该事务，而另一部分没有应用的情况，一次数据更新要么成功要么失败。 -&lt;strong&gt;单一视图（全局数据一致）&lt;/strong&gt;：每个 server 保存相同的数据副本，无论 client 连接哪个 server，看到的数据一致； -&lt;strong&gt;可靠性&lt;/strong&gt;：一旦服务端成功应用了一个事务，则其引起的改变会一直保留，直到被另外一个事务所更改； -&lt;strong&gt;实时性&lt;/strong&gt;：一旦一个事务被成功应用后，在一定时间范围内，Zookeeper 可以保证客户端立即可以读取到这个事务变更后的最新状态的数据。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;集群中只要有&lt;strong&gt;半数以上节点存活&lt;/strong&gt;，zk 集群就可以正常服务，所以 zk 适合安装奇数台。&lt;/li&gt;
&lt;li&gt;一个 leader，多个 follower，&lt;strong&gt;leader 挂掉之后会从 follower 中重新选举&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;集群配置&#34;&gt;&lt;a href=&#34;#%e9%9b%86%e7%be%a4%e9%85%8d%e7%bd%ae&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;集群配置  
&lt;/h2&gt;&lt;p&gt;可以由一组 Zookeeper 服务构成 Zookeeper 集群，集群中每台机器都会单独在内存中维护自身的状 态，并且每台机器之间都保持着通讯，只要集群中有半数机器能够正常工作，那么整个集群就可以正常提供服务。对于来自客户端的每个更新请求，Zookeeper 都会分配一个全局唯一的递增 ID，这个 ID 反映了所有事 务请求的先后顺序。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-08-29.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-08-29&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;以下是集群环境搭建不是单机环境&#34;&gt;&lt;a href=&#34;#%e4%bb%a5%e4%b8%8b%e6%98%af%e9%9b%86%e7%be%a4%e7%8e%af%e5%a2%83%e6%90%ad%e5%bb%ba%e4%b8%8d%e6%98%af%e5%8d%95%e6%9c%ba%e7%8e%af%e5%a2%83&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;以下是集群环境搭建！！不是单机环境
&lt;/h3&gt;&lt;p&gt;解压、安装、配置环境变量并生效这三步省略，直接修改配置：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;进入 conf/目录下，拷贝配置样本并进行修改：&lt;/p&gt;
&lt;p&gt;cp zoo_sample.cfg zoo.cfg&lt;/p&gt;
&lt;p&gt;指定数据存储目录和日志文件目录（此时还没有目录，稍后手动创建），修改后完整配置如下：&lt;/p&gt;&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cobol&#34; data-lang=&#34;cobol&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c&#34;&gt;tickTi&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;me&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2000
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#用于计算的&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;基础时间单元。比如&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;session&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;超时：&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;tickTime&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;；
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;initLi&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;mit&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#用于集群，&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;允许从节点连接并同步到&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;master&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;节点的初始化连接时间，以&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;tickTime&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;的倍数来表示；
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;syncLi&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;mit&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#用于集群，&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;master&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;主节点与从节点之间发送消息，请求和应答时间长度（心&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;跳机制）；
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;dataDi&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=/&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;export&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;server&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;zookeeper&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;kr&#34;&gt;data
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kr&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#数据存储位&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;置；稍后手动创建
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;dataLo&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;gDir&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=/&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;export&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;server&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;zookeeper&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;logs&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#日志目录；&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;稍后手动创建
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;client&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;Port&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2181
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#用于客户端&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;连接的端口，默认&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2181
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# serv&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;er&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1 &lt;/span&gt;&lt;span class=&#34;err&#34;&gt;这个&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;是服务器的标识，可以是任意有效数字，标识这是第几个服务器节点，这个标识要写到
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;dataDi&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;r目录下面myid&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;文件里，如果没有&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;myid&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;文件要自己创建
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# 指名集群&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;间通讯端口和选举端口
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;server&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;linux01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2888&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3888
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;server&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;linux02&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2888&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3888
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;server&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;linux03&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2888&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3888
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;标识节点序号&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;分别在三台主机的 dataDir 目录下新建 myid 文件,并写入对应的节点标识。Zookeeper 集群通过 myid 文件识别集群节点，并通过上文配置的节点通信端口和选举端口来进行节点通信，选举出 Leader 节点。&lt;/p&gt;
&lt;p&gt;在&lt;strong&gt;每个服务器&lt;/strong&gt;上的/export/server/zookeeper/下创建 data 目录，在里面创建 myid 文件并写入各自序号，这个序号必须和 zoo.cfg 文件的序号相同。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;分别在三台主机上启动 ZK 集群&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;zkServer.sh start&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;集群验证&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;zkServer.sh status&lt;/p&gt;
&lt;p&gt;可以看到一个 leader，两个 follower，那么 zk 集群配置成功&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;启动客户端&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;zkCli.sh&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;集群角色&#34;&gt;&lt;a href=&#34;#%e9%9b%86%e7%be%a4%e8%a7%92%e8%89%b2&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;集群角色
&lt;/h2&gt;&lt;p&gt;ZK 集群有一个 leader 和多个 follower。&lt;/p&gt;
&lt;h3 id=&#34;leader&#34;&gt;&lt;a href=&#34;#leader&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Leader
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;为客户端提供读写服务，并维护集群状态，它是由集群选举所产生的；&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;follower&#34;&gt;&lt;a href=&#34;#follower&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Follower
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;为客户端提供读写服务，并定期向 Leader 汇报自己的节点状态。同时也参与写操作 “过半写成功”的策略和 Leader 的选举；&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;observer&#34;&gt;&lt;a href=&#34;#observer&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Observer
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;为客户端提供读写服务，并定期向 Leader 汇报自己的节点状态，但不参与写操作“过 半写成功”的策略和 Leader 的选举，因此 Observer 可以在不影响写性能的情况下提升集群的读性 能。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;会话&#34;&gt;&lt;a href=&#34;#%e4%bc%9a%e8%af%9d&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;会话
&lt;/h2&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Zookeeper 客户端通过 TCP 长连接连接到服务集群，会话 (Session) 从第一次连接开始就已经建立，之 后通过心跳检测机制来保持有效的会话状态。通过这个连接，客户端可以发送请求并接收响应，同时也 可以接收到 Watch 事件的通知。&lt;/li&gt;
&lt;li&gt;关于会话中另外一个核心的概念是&lt;strong&gt;sessionTimeOut(会话超时时间)&lt;/strong&gt;，当由于网络故障或者客户端主动 断开等原因，导致连接断开，此时只要在会话超时时间之内重新建立连接，则之前创建的会话依然有效。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;watcher&#34;&gt;&lt;a href=&#34;#watcher&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Watcher
&lt;/h2&gt;&lt;p&gt;Zookeeper 中一个常用的功能是 Watcher(事件监听器)，它允许用户在指定节点上针对感兴趣的事件注 册监听，当事件发生时，监听器会被触发，并将事件信息推送到客户端。该机制是 Zookeeper 实现分布式协调服务的重要特性。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-09-09.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-09-09&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;节点的值变化监听&#34;&gt;&lt;a href=&#34;#%e8%8a%82%e7%82%b9%e7%9a%84%e5%80%bc%e5%8f%98%e5%8c%96%e7%9b%91%e5%90%ac&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;节点的值变化监听  
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;1）在 linux01 主机上注册监听/sanguo 节点数据变化&lt;/p&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 26] get -w /sanguo&lt;/p&gt;
&lt;p&gt;2）在 linux02 主机上修改/sanguo 节点的数据&lt;/p&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 1] set /sanguo &amp;ldquo;xisi&amp;rdquo;&lt;/p&gt;
&lt;p&gt;3）观察 linux01 主机收到数据变化的监听&lt;/p&gt;
&lt;p&gt;WATCHER::&lt;/p&gt;
&lt;p&gt;WatchedEvent        state:SyncConnected         ype:NodeDataChanged&lt;/p&gt;
&lt;p&gt;path:/sanguo&lt;/p&gt;
&lt;p&gt;注意：在 linux02 再多次修改/sanguo 的值，linux01 上不会再收到监听。因为注册 一次，只能监听一次。想再次监听，需要再次注册。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;节点的子节点变化监听路径变化&#34;&gt;&lt;a href=&#34;#%e8%8a%82%e7%82%b9%e7%9a%84%e5%ad%90%e8%8a%82%e7%82%b9%e5%8f%98%e5%8c%96%e7%9b%91%e5%90%ac%e8%b7%af%e5%be%84%e5%8f%98%e5%8c%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;节点的子节点变化监听（路径变化）
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;1）在 linux01 主机上注册监听/sanguo 节点的子节点变化&lt;/p&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 1] ls -w /sanguo [shuguo, weiguo]&lt;/p&gt;
&lt;p&gt;2）在 linux02  主机/sanguo 节点上创建子节点&lt;/p&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 2] create /sanguo/jin &amp;ldquo;simayi&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Created /sanguo/jin&lt;/p&gt;
&lt;p&gt;3）观察  linux01 主机收到子节点变化的监听&lt;/p&gt;
&lt;p&gt;WATCHER::&lt;/p&gt;
&lt;p&gt;WatchedEvent        state:SyncConnected        type:NodeChildrenChanged&lt;/p&gt;
&lt;p&gt;path:/sanguo&lt;/p&gt;
&lt;p&gt;注意：节点的路径变化，也是注册一次，生效一次。想多次生效，就需要多次注册&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;工作机制&#34;&gt;&lt;a href=&#34;#%e5%b7%a5%e4%bd%9c%e6%9c%ba%e5%88%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;工作机制
&lt;/h2&gt;&lt;p&gt;从设计模式的角度来理解，zk 是基于观察者模式设计的分布式服务管理框架，它负责存储和管理大家都关心的数据，然后接受观察者的注册，一旦这些数据的状态发生变化，Zookeeper 就将负责通知已经在 Zookeeper 上注册的那些观察者做出相应的反应。&lt;/p&gt;
&lt;p&gt;集群中只要有半数以上节点存活，Zookeeper 集群就能正常服务。所以 Zookeeper 适合安装奇数台服务器。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-09-29.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-09-29&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;客户端向服务端写数据流程&#34;&gt;&lt;a href=&#34;#%e5%ae%a2%e6%88%b7%e7%ab%af%e5%90%91%e6%9c%8d%e5%8a%a1%e7%ab%af%e5%86%99%e6%95%b0%e6%8d%ae%e6%b5%81%e7%a8%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;客户端向服务端写数据流程
&lt;/h3&gt;&lt;h4 id=&#34;写请求发给-leader&#34;&gt;&lt;a href=&#34;#%e5%86%99%e8%af%b7%e6%b1%82%e5%8f%91%e7%bb%99-leader&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;写请求发给 leader
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-09-51.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-09-51&#34;
	
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;写请求发给-follower&#34;&gt;&lt;a href=&#34;#%e5%86%99%e8%af%b7%e6%b1%82%e5%8f%91%e7%bb%99-follower&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;写请求发给 follower
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-10-05.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-10-05&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;客户端向服务端读数据流程&#34;&gt;&lt;a href=&#34;#%e5%ae%a2%e6%88%b7%e7%ab%af%e5%90%91%e6%9c%8d%e5%8a%a1%e7%ab%af%e8%af%bb%e6%95%b0%e6%8d%ae%e6%b5%81%e7%a8%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;客户端向服务端读数据流程
&lt;/h3&gt;&lt;p&gt;由于 ZK 满足的是 CAP 中的 CP，，没有满足 Available，因此读出的数据可能是老数据。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-10-15.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-10-15&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;选举机制&#34;&gt;&lt;a href=&#34;#%e9%80%89%e4%b8%be%e6%9c%ba%e5%88%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;选举机制
&lt;/h2&gt;&lt;h3 id=&#34;初次启动&#34;&gt;&lt;a href=&#34;#%e5%88%9d%e6%ac%a1%e5%90%af%e5%8a%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;初次启动
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-10-26.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-10-26&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;非处次启动&#34;&gt;&lt;a href=&#34;#%e9%9d%9e%e5%a4%84%e6%ac%a1%e5%90%af%e5%8a%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;非处次启动
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-10-33.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-10-33&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;集群脑裂&#34;&gt;&lt;a href=&#34;#%e9%9b%86%e7%be%a4%e8%84%91%e8%a3%82&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;集群脑裂
&lt;/h3&gt;&lt;p&gt;对于一个集群，通常多台机器会部署在不同机房，来提高这个集群的可用性。保证可用性的同时，会发生一种机房间网络线路故障，导致机房间网络不通，而集群被割裂成几个小集群。这时候子集群各自选主导致“脑裂”的情况。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;过半机制是如何防止脑裂现象产生的？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;ZooKeeper 的过半机制导致不可能产生 2 个 leader，因为少于等于一半是不可能产生 leader 的，这就使得不论机房的机器如何分配都不可能发生脑裂。&lt;/p&gt;
&lt;h2 id=&#34;数据模型&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e6%8d%ae%e6%a8%a1%e5%9e%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;数据模型
&lt;/h2&gt;&lt;p&gt;Zookeeper 数据模型是由一系列基本数据单元 Znode (数据节点) 组成的节点树，其中根节点为 / ，每个节点上都会保存自己的数据和节点信息。不过和常见的文件系统不同，Zookeeper 将数据全量存储在内存中，以此来实现高吞吐，减少访 问延迟。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-10-44.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-10-44&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;节点类型&#34;&gt;&lt;a href=&#34;#%e8%8a%82%e7%82%b9%e7%b1%bb%e5%9e%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;节点类型
&lt;/h3&gt;&lt;p&gt;Zookeeper 中节点可以分为两大类：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;持久节点&lt;/strong&gt;：节点一旦创建，除非被主动删除，否则一直存在；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;临时节点&lt;/strong&gt;：一旦创建该节点的客户端会话失效，则所有该客户端创建的临时节点都会被删除。&lt;/p&gt;
&lt;p&gt;临时节点和持久节点都可以添加一个特殊的属性： SEQUENTIAL ，代表该节点是否具有递增属性。如果指定该属性，那么在这个节点创建时，Zookeeper 会自动在其节点名称后面追加一个由父节点维护的递增数字。这个递增数字可以被用于为所有的事件进行全局排序，这样客户端可以通过顺序号推断事件的顺序。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;节点信息&#34;&gt;&lt;a href=&#34;#%e8%8a%82%e7%82%b9%e4%bf%a1%e6%81%af&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;节点信息
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-10-57.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-10-57&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;集群操作&#34;&gt;&lt;a href=&#34;#%e9%9b%86%e7%be%a4%e6%93%8d%e4%bd%9c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;集群操作
&lt;/h2&gt;&lt;h3 id=&#34;创建节点&#34;&gt;&lt;a href=&#34;#%e5%88%9b%e5%bb%ba%e8%8a%82%e7%82%b9&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;创建节点
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;create [-s] [-e] path data acl   #其中-s 为有序节点，-e 临时节点&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;创建有序节点，此时创建的节点名为指定节点名 + 自增序号：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 23] create -s /a  &amp;ldquo;aaa&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Created /a0000000022&lt;/p&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 24] create -s /b  &amp;ldquo;bbb&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Created /b0000000023&lt;/p&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 25] create -s /c  &amp;ldquo;ccc&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Created /c0000000024&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;创建临时节点，临时节点会在会话过期后被删除：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 26] create -e /tmp  &amp;ldquo;tmp&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Created /tmp&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;查看节点&#34;&gt;&lt;a href=&#34;#%e6%9f%a5%e7%9c%8b%e8%8a%82%e7%82%b9&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;查看节点  
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;get path [watch]&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 31] get /hadoop&lt;/p&gt;
&lt;p&gt;123456   #节点数据&lt;/p&gt;
&lt;p&gt;cZxid = 0x14b&lt;/p&gt;
&lt;p&gt;ctime = Fri May 24 17:03:06 CST 2019&lt;/p&gt;
&lt;p&gt;mZxid = 0x14b&lt;/p&gt;
&lt;p&gt;mtime = Fri May 24 17:03:06 CST 2019&lt;/p&gt;
&lt;p&gt;pZxid = 0x14b&lt;/p&gt;
&lt;p&gt;cversion = 0&lt;/p&gt;
&lt;p&gt;dataVersion = 0&lt;/p&gt;
&lt;p&gt;aclVersion = 0&lt;/p&gt;
&lt;p&gt;ephemeralOwner = 0x0&lt;/p&gt;
&lt;p&gt;dataLength = 6&lt;/p&gt;
&lt;p&gt;numChildren = 0&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;节点各个属性如下表。其中一个重要的概念是 Zxid(ZooKeeper Transaction Id)，ZooKeeper 节点的 每一次更改都具有唯一的 Zxid，如果 Zxid1 小于 Zxid2，则 Zxid1 的更改发生在 Zxid2 更改之前。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-11-14.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-11-14&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;查看节点状态&#34;&gt;&lt;a href=&#34;#%e6%9f%a5%e7%9c%8b%e8%8a%82%e7%82%b9%e7%8a%b6%e6%80%81&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;查看节点状态  
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;stat path [watch]&lt;/p&gt;
&lt;p&gt;它和 get 类似，但不会返回节点数据内容&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;更新节点&#34;&gt;&lt;a href=&#34;#%e6%9b%b4%e6%96%b0%e8%8a%82%e7%82%b9&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;更新节点  
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 33] set /hadoop 345&lt;/p&gt;
&lt;p&gt;cZxid = 0x14b&lt;/p&gt;
&lt;p&gt;ctime = Fri May 24 17:03:06 CST 2019&lt;/p&gt;
&lt;p&gt;mZxid = 0x14c&lt;/p&gt;
&lt;p&gt;mtime = Fri May 24 17:13:05 CST 2019&lt;/p&gt;
&lt;p&gt;pZxid = 0x14b&lt;/p&gt;
&lt;p&gt;cversion = 0&lt;/p&gt;
&lt;p&gt;dataVersion = 1  # 注意更改后此时版本号为 1，默认创建时为 0&lt;/p&gt;
&lt;p&gt;aclVersion = 0&lt;/p&gt;
&lt;p&gt;ephemeralOwner = 0x0&lt;/p&gt;
&lt;p&gt;dataLength = 3&lt;/p&gt;
&lt;p&gt;numChildren = 0&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;也可以基于版本号进行更改，此时类似于乐观锁机制，当你传入的数据版本号 (dataVersion) 和当前节 点的数据版本号不符合时，zookeeper 会拒绝本次修改：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 34] set /hadoop 678 0&lt;/p&gt;
&lt;p&gt;version No is not valid : /hadoop    #无效的版本号&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;删除节点&#34;&gt;&lt;a href=&#34;#%e5%88%a0%e9%99%a4%e8%8a%82%e7%82%b9&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;删除节点
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;delete path [version]&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;和更新节点数据一样，也可以传入版本号，当你传入的数据版本号 (dataVersion) 和当前节点的数据版 本号不符合时，zookeeper 不会执行删除操作。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 36] delete /hadoop 0&lt;/p&gt;
&lt;p&gt;version No is not valid : /hadoop   #无效的版本号&lt;/p&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 37] delete /hadoop 1&lt;/p&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 38]&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;要想删除某个节点及其所有后代节点，可以使用递归删除，命令为&lt;strong&gt;rmr path&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;退出-zk&#34;&gt;&lt;a href=&#34;#%e9%80%80%e5%87%ba-zk&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;退出 ZK 
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 12] quit&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;应用场景&#34;&gt;&lt;a href=&#34;#%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;应用场景
&lt;/h2&gt;&lt;h3 id=&#34;统一命名服务&#34;&gt;&lt;a href=&#34;#%e7%bb%9f%e4%b8%80%e5%91%bd%e5%90%8d%e6%9c%8d%e5%8a%a1&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;统一命名服务
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-11-27.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-11-27&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;统一配置管理&#34;&gt;&lt;a href=&#34;#%e7%bb%9f%e4%b8%80%e9%85%8d%e7%bd%ae%e7%ae%a1%e7%90%86&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;统一配置管理
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-11-36.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-11-36&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;统一集群管理&#34;&gt;&lt;a href=&#34;#%e7%bb%9f%e4%b8%80%e9%9b%86%e7%be%a4%e7%ae%a1%e7%90%86&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;统一集群管理
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-11-46.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-11-46&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;服务器动态上下线&#34;&gt;&lt;a href=&#34;#%e6%9c%8d%e5%8a%a1%e5%99%a8%e5%8a%a8%e6%80%81%e4%b8%8a%e4%b8%8b%e7%ba%bf&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;服务器动态上下线
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-11-56.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-11-56&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;软负载均衡&#34;&gt;&lt;a href=&#34;#%e8%bd%af%e8%b4%9f%e8%bd%bd%e5%9d%87%e8%a1%a1&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;软负载均衡
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-12-03.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-12-03&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;分布式锁&#34;&gt;&lt;a href=&#34;#%e5%88%86%e5%b8%83%e5%bc%8f%e9%94%81&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;分布式锁
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-12-10.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-12-10&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;拜占庭将军问题paxos-算法&#34;&gt;&lt;a href=&#34;#%e6%8b%9c%e5%8d%a0%e5%ba%ad%e5%b0%86%e5%86%9b%e9%97%ae%e9%a2%98paxos-%e7%ae%97%e6%b3%95&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;拜占庭将军问题（Paxos 算法）
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-12-20.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-12-20&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;Paxos 算法是一种基于消息传递且具有高度容错特性的一致性算法。解决如何快速正确的在一个分布式系统中对某个数据值达成一致，并且保证任何异常都不会破坏整个系统的一致性。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-12-34.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-12-34&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;算法描述&#34;&gt;&lt;a href=&#34;#%e7%ae%97%e6%b3%95%e6%8f%8f%e8%bf%b0&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;算法描述
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-12-42.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-12-42&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;算法流程&#34;&gt;&lt;a href=&#34;#%e7%ae%97%e6%b3%95%e6%b5%81%e7%a8%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;  算法流程
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-12-51.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-12-51&#34;
	
	
&gt;
&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-13-02.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-13-02&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;zab-协议&#34;&gt;&lt;a href=&#34;#zab-%e5%8d%8f%e8%ae%ae&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;ZAB 协议
&lt;/h2&gt;&lt;p&gt;ZAB 协议并不像 Paxos 算法那样是一种通用的分布式一致性算法，ZAB 是一种特别为 Zookeeper 设计的崩溃可恢复的原子消息广播算法。在 ZooKeeper 中，主要依赖 ZAB 协议来实现分布式数据一致性，基于该协议，ZooKeeper 实现了一种主备模式的系统架构来保持集群中各个副本之间的数据一致性。ZAB 包括以下两种模式:&lt;/p&gt;
&lt;h3 id=&#34;崩溃恢复&#34;&gt;&lt;a href=&#34;#%e5%b4%a9%e6%ba%83%e6%81%a2%e5%a4%8d&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;崩溃恢复
&lt;/h3&gt;&lt;p&gt;当整个服务框架在启动过程中，或是当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB 协议就会进入恢复模式并选举产生新的 Leader 服务器。当选举产生了新的 Leader 服务器，同时集群中已经有过半的机器与该 Leader 服务器完成了状态同步之后，ZAB 协议就会退出恢复模式。其中，&lt;strong&gt;所谓的状态同步是指数据同步，用来保证集群中存在过半的机器能够和 Leader 服务器的数据状态保持一致&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-13-26.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-13-26&#34;
	
	
&gt;
&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-13-54.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-13-54&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;消息广播&#34;&gt;&lt;a href=&#34;#%e6%b6%88%e6%81%af%e5%b9%bf%e6%92%ad&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;消息广播
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;当集群中已经有过半的 Follower 服务器完成了和 Leader 服务器的状态同步，那么整个服务框架就可以进入消息广播模式了。&lt;/strong&gt; 当一台同样遵守 ZAB 协议的服务器启动后加入到集群中时，如果此时集群中已经存在一个 Leader 服务器在负责进行消息广播，那么新加入的服务器就会自觉地进入数据恢复模式：找到 Leader 所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去。
&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-14-26.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-14-26&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-14-52.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-14-52&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;cap-理论&#34;&gt;&lt;a href=&#34;#cap-%e7%90%86%e8%ae%ba&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;CAP 理论
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-15-34.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-15-34&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;zk-源码图示&#34;&gt;&lt;a href=&#34;#zk-%e6%ba%90%e7%a0%81%e5%9b%be%e7%a4%ba&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;ZK 源码图示  
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-15-43.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-15-43&#34;
	
	
&gt;
&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-17-12.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-17-12&#34;
	
	
&gt;
&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-17-01.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-17-01&#34;
	
	
&gt;
&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-16-53.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-16-53&#34;
	
	
&gt;
&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-16-36.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-16-36&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;小小面试题&#34;&gt;&lt;a href=&#34;#%e5%b0%8f%e5%b0%8f%e9%9d%a2%e8%af%95%e9%a2%98&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;小小面试题
&lt;/h2&gt;&lt;h3 id=&#34;选举机制-1&#34;&gt;&lt;a href=&#34;#%e9%80%89%e4%b8%be%e6%9c%ba%e5%88%b6-1&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;选举机制
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;半数机制，超过半数的投票通过，即通过。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;第一次启动选举规则： 投票过半数时，服务器 id 大的胜出&lt;/li&gt;
&lt;li&gt;第二次启动选举规则：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;EPOCH 大的直接胜出&lt;/p&gt;
&lt;p&gt;EPOCH 相同，事务 id 大的胜出&lt;/p&gt;
&lt;p&gt;事务 id 相同，服务器 id 大的胜出&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;生产集群安装多少-zk-合适&#34;&gt;&lt;a href=&#34;#%e7%94%9f%e4%ba%a7%e9%9b%86%e7%be%a4%e5%ae%89%e8%a3%85%e5%a4%9a%e5%b0%91-zk-%e5%90%88%e9%80%82&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;  生产集群安装多少 zk 合适？
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;安装奇数台。&lt;/p&gt;
&lt;p&gt;生产经验：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;10 台服务器：3 台 zk；&lt;/li&gt;
&lt;li&gt;20 台服务器：5 台 zk；&lt;/li&gt;
&lt;li&gt;100 台服务器：11 台 zk；&lt;/li&gt;
&lt;li&gt;200 台服务器：11 台 zk&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>HA—Hadoop高可用</title>
        <link>/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/</link>
        <pubDate>Mon, 15 Apr 2024 19:23:57 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/</guid>
        <description>&lt;h2 id=&#34;ha-概述&#34;&gt;&lt;a href=&#34;#ha-%e6%a6%82%e8%bf%b0&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HA 概述
&lt;/h2&gt;&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;1）所谓 HA（High Availablity），即高可用（7*24 小时不中断服务）。&lt;/p&gt;
&lt;p&gt;2）实现高可用最关键的策略是消除单点故障（传统的主从模式集群单个节点发生故障会影响整个集群）。HA 严格来说应该分成各个组件的 HA 机制：&lt;strong&gt;HDFS 的 HA 和 YARN 的 HA&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;3）NameNode 主要在以下两个方面影响 HDFS 集群&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NameNode 机器发生意外，如宕机，集群将无法使用，直到管理员重启&lt;/li&gt;
&lt;li&gt;NameNode 机器需要升级，包括软件、硬件升级，此时集群也将无法使用&lt;/li&gt;
&lt;li&gt;HDFS HA 功能通过配置多个 NameNode(Active/Standby)实现在集群中对 NameNode 的热备来解决上述问题。如果出现故障，如机器崩溃或机器需要升级维护，这时可以启动另一台机器上的 NameNode 继续维护整个集群的运行（&lt;strong&gt;集群中同时只能有一台 active 的 NN，其他 NN 处于 standby（备用）&lt;/strong&gt; ）。而这种启动方式&lt;strong&gt;分为手动和自动（推荐）&lt;/strong&gt;，但是在这之前，我们&lt;strong&gt;必须通过某种方式保证所有 NN 的元数据一致&lt;/strong&gt;，这样才能保证 active 状态的 NN 故障后，另一个处于 standby 状态的 NN 激活为 active 能够正常维持集群运行，类似于公司员工的任务的交接。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;hdfs-高可用&#34;&gt;&lt;a href=&#34;#hdfs-%e9%ab%98%e5%8f%af%e7%94%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HDFS 高可用
&lt;/h2&gt;&lt;hr&gt;
&lt;h3 id=&#34;保证所有-nn-的数据一致性&#34;&gt;&lt;a href=&#34;#%e4%bf%9d%e8%af%81%e6%89%80%e6%9c%89-nn-%e7%9a%84%e6%95%b0%e6%8d%ae%e4%b8%80%e8%87%b4%e6%80%a7&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;保证所有 NN 的数据一致性
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;在处于 active 的 NN 正常运行时，他会生成 Fsimage 文件，让其他处于 standby 的 NN 同步，同时引入 JournalNode 节点来保证 edits 文件数据的一致性&lt;/strong&gt;，JournalNode 作为 active 的 NN 和 standby 的 NN 的中间节点，activeNN 会把 edits 发送给 JournalNode，然后 standbyNN 从 JournalNode 获取 edits。同时为了保证 JournalNode 的可靠性，JournalNode 本身也是一个多节点的集群。&lt;/p&gt;
&lt;p&gt;JournalNode 节点会在集群自动的选择一个&amp;quot;主&amp;quot;节点出来，Active 节点会和 JournalNode 的主节点通信，然后 JournalNode 集群的主节点会将数据发送给其他的节点，只要有过半的节点完成了数据的存储（&lt;strong&gt;过半写成功&lt;/strong&gt;），JournalNode 集群的主节点，就会将成功信息返回给 Active 节点。当 JournalNode 集群的主节点挂掉，其他的 JournalNode 节点会快速选举出新的&amp;quot;主&amp;quot;节点来。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;同时在 HA 架构中，并没有 SecondaryNameNode&lt;/strong&gt;，那么定期合并 fsimage 的 eedits 的任务是由 standby 的 NN 来完成的。&lt;/p&gt;
&lt;h3 id=&#34;手动模式&#34;&gt;&lt;a href=&#34;#%e6%89%8b%e5%8a%a8%e6%a8%a1%e5%bc%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;手动模式
&lt;/h3&gt;&lt;p&gt;配置 core-site.xml&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定hdfs的nameservice为ns1 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;fs.defaultFS&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hdfs://mycluster/&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定hadoop临时目录 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.tmp.dir&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;配置 hdfs-site.xml&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;77
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!--指定hdfs的nameservice为mycluster，需要和core-site.xml中的保持一致 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.nameservices&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;mycluster&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- hadoop-ha下面有两个NameNode，分别是nn1，nn2 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.ha.namenodes.mycluster&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;nn1,nn2,nn3&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- nn1的RPC通信地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.rpc-address.mycluster.nn1&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux01:8020&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- nn1的http通信地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.http-address.mycluster.nn1&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux01:9870&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- nn2的RPC通信地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.rpc-address.mycluster.nn2&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux02:8020&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- nn2的http通信地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.http-address.mycluster.nn2&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux02:9870&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- nn3的RPC通信地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.rpc-address.mycluster.nn3&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux03:8020&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- nn3的http通信地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.http-address.mycluster.nn3&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux03:9870&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定NameNode的edits元数据在JournalNode上的存放位置 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.shared.edits.dir&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;qjournal://linux01:8485;linux02:8485;linux03:8485/mycluster&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- NameNode 数据存储目录 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;             &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.name.dir&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;             &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;file://${hadoop.tmp.dir}/name&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- DataNode 数据存储目录 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;             &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.data.dir&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;             &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;file://${hadoop.tmp.dir}/data&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- JournalNode数据存储目录 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.journalnode.edits.dir&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;${hadoop.tmp.dir}/data&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 配置失败自动切换实现方式 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.client.failover.proxy.provider.mycluster&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行--&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.ha.fencing.methods&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;sshfence&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 使用sshfence隔离机制时需要ssh免登陆 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.ha.fencing.ssh.private-key-files&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/root/.ssh/id_rsa&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;HA 集群的相关文件配置省略。以 3 台服务器的 HA 为例：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;在各个节点上，输入以下命令启动该节点的journalNode服务：
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hdfs --daemon start journalnode
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;在NN1上进行格式化并启动
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hdfs namenode -format
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hdfs --daemon start namenode
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;分别在NN2和NN3上运行如下命令，同步NN1的元数据信息
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hdfs namenode -bootstrapStandby
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;启动NN2，NN3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hdfs --daemon start namenode
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;此时所有NN处于standby，启动所有节点的datanode
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hdfs --daemon start datanode
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;切换NN1为active
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hdfs haadmin start -transitionToActive linux01
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;修改后重新分发文件！
&lt;img src=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image.png&#34;
	width=&#34;1326&#34;
	height=&#34;401&#34;
	srcset=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image_hu_c985863806ed0edc.png 480w, /zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image_hu_47a713227fbaa2e7.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;330&#34;
		data-flex-basis=&#34;793px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;自动模式&#34;&gt;&lt;a href=&#34;#%e8%87%aa%e5%8a%a8%e6%a8%a1%e5%bc%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;自动模式
&lt;/h3&gt;&lt;p&gt;自动模式需要引入 zookeeper 和 ZKFailoverController（ZKFC）&lt;/p&gt;
&lt;p&gt;配置 hdfs-site.xml&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 启用 nn 故障自动转移 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.ha.automatic-failover.enabled&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;配置 core-site.xml&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定 zkfc 要连接的 zkServer 地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ha.zookeeper.quorum&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux01:2181,linux02:2181,linux03:2181&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;修改后重新分发文件！&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;在每台服务器运行以下命令启动zookeeper集群：
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;zkServer.sh start
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;启动后初始化HA在zookeeper中的状态：
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hdfs zkfc -formatZK
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;杀死active namenode查看是否有standby namenode激活：
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kill -9 namenode的进程id
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;运行zkCli.sh查看namenode选举内容：
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;zkCli.sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-1.png&#34;
	width=&#34;1518&#34;
	height=&#34;847&#34;
	srcset=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-1_hu_3f372e4e88ec4427.png 480w, /zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-1_hu_fe1c88a95b8ebe06.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;179&#34;
		data-flex-basis=&#34;430px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;解决-nn-连接不上-jn-的问题&#34;&gt;&lt;a href=&#34;#%e8%a7%a3%e5%86%b3-nn-%e8%bf%9e%e6%8e%a5%e4%b8%8d%e4%b8%8a-jn-%e7%9a%84%e9%97%ae%e9%a2%98&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;解决 NN 连接不上 JN 的问题
&lt;/h4&gt;&lt;p&gt;自动故障转移配置好以后，然后使用 start-dfs.sh 群起脚本启动 hdfs 集群，有可能 会遇到 NameNode 起来一会后，进程自动关闭的问题。查看 NameNode 日志，报错信息如下：
&lt;img src=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-2.png&#34;
	width=&#34;1176&#34;
	height=&#34;767&#34;
	srcset=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-2_hu_3c6ab8b29a630e2.png 480w, /zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-2_hu_ebfdb8f34cef0750.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;153&#34;
		data-flex-basis=&#34;367px&#34;
	
&gt;
查看报错日志，可分析出报错原因是因为 NameNode 连接不上 JournalNode，而利 用 jps 命令查看到三台 JN 都已经正常启动，为什么 NN 还是无法正常连接到 JN 呢？这 是因为 start-dfs.sh 群起脚本默认的启动顺序是先启动 NN，再启动 DN，然后再启动 JN， 并且默认的 rpc 连接参数是重试次数为 10，每次重试的间隔是 1s，也就是说启动完 NN 以后的 10s 中内，JN 还启动不起来，NN 就会报错了。&lt;/p&gt;
&lt;p&gt;core-default.xml 里面有两个参数如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!--NN连接JN重试次数，默认10次--&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ipc.client.connect.max.retries&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;10&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!--重试时间间隔，默认1s--&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ipc.client.connect.retry.interval&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;1000&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;解决方案：可以先 JN 成功启动，然后启动三台 NN 或者 在 core-site.xml 调大上面的参数：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!--NN连接JN重试次数，默认10次--&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ipc.client.connect.max.retries&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;20&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!--重试时间间隔，默认1s--&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ipc.client.connect.retry.interval&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;5000&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-3.png&#34;
	width=&#34;1318&#34;
	height=&#34;521&#34;
	srcset=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-3_hu_8de74b54e2c37152.png 480w, /zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-3_hu_f608aba8a29a6929.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;252&#34;
		data-flex-basis=&#34;607px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;yarn-高可用&#34;&gt;&lt;a href=&#34;#yarn-%e9%ab%98%e5%8f%af%e7%94%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Yarn 高可用
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-4.png&#34;
	width=&#34;876&#34;
	height=&#34;510&#34;
	srcset=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-4_hu_d1ccc4c7a5fe1c5a.png 480w, /zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-4_hu_193a236c9a33d153.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;171&#34;
		data-flex-basis=&#34;412px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-5.png&#34;
	width=&#34;1141&#34;
	height=&#34;273&#34;
	srcset=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-5_hu_9c0be25044f76717.png 480w, /zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-5_hu_ab9c930170399a7a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;417&#34;
		data-flex-basis=&#34;1003px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;核心问题&#34;&gt;&lt;a href=&#34;#%e6%a0%b8%e5%bf%83%e9%97%ae%e9%a2%98&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;核心问题
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;如果当前 active rm 挂了，其他 rm 怎么将其他 standby rm 上位
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;核心原理跟 hdfs 一样，利用了 zk 的临时节点
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;当前 rm 上有很多的计算程序在等待运行,其他的 rm 怎么将这些程序接手过来接着跑
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;rm会将当前的所有计算程序的状态存储在 zk 中,其他 rm 上位后会去读取，然后接着跑
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;配置 yarn-site.xml&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;  1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 77
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 78
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 79
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 80
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 81
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 82
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 83
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 84
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 85
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 86
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 87
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 88
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 89
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 90
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 91
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 92
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 93
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 94
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 95
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 96
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 97
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 98
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 99
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;100
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;101
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;102
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;103
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;104
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;105
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;106
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;107
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;108
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;109
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;110
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;111
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;112
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;113
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;114
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;115
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;116
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;117
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;118
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;119
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;120
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;121
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;122
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.nodemanager.aux-services&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;mapreduce_shuffle&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 启用 resourcemanager ha --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.ha.enabled&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 声明两台 resourcemanager 的地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.cluster-id&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;cluster-yarn1&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!--指定 resourcemanager 的逻辑列表--&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.ha.rm-ids&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;rm1,rm2,rm3&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- ========== rm1 的配置 ========== --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定 rm1 的主机名 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.hostname.rm1&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux01&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定 rm1 的 web 端地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.webapp.address.rm1&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux01:8088&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定 rm1 的内部通信地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.address.rm1&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux01:8032&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定 AM 向 rm1 申请资源的地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.scheduler.address.rm1&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux01:8030&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定供 NM 连接的地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.resource-tracker.address.rm1&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux01:8031&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- ========== rm2 的配置 ========== --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定 rm2 的主机名 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.hostname.rm2&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux02&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.webapp.address.rm2&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux02:8088&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.address.rm2&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux02:8032&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.scheduler.address.rm2&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux02:8030&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.resource-tracker.address.rm2&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux02:8031&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- ========== rm3 的配置 ========== --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定 rm3 的主机名 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.hostname.rm3&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux03&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定 rm3 的 web 端地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.webapp.address.rm3&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux03:8088&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定 rm3 的内部通信地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.address.rm3&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux03:8032&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定 AM 向 rm3 申请资源的地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.scheduler.address.rm3&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux03:8030&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定供 NM 连接的地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.resource-tracker.address.rm3&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux03:8031&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定 zookeeper 集群的地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.zk-address&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux01:2181,linux02:2181,linux03:2181&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 启用自动恢复 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.recovery.enabled&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定 resourcemanager 的状态信息存储在 zookeeper 集群 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.store.class&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateSt
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ore&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 环境变量的继承 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.nodemanager.env-whitelist&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLAS
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    SPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;配置后重新分发配置文件！&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;启动Yarn
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;start-yarn.sh
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;查看服务状态
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;yarn rmadmin -getServiceState rm1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;运行zkCli.sh查看RM选举内容
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;zkCli.sh
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;可以通过8088端口查看Yarn状态
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;HA 最终规划
&lt;img src=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-6.png&#34;
	width=&#34;1131&#34;
	height=&#34;1058&#34;
	srcset=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-6_hu_e606529a6d9b9fd8.png 480w, /zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-6_hu_c206762bb76f4e7c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;106&#34;
		data-flex-basis=&#34;256px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;以上来自尚硅谷 Hadoop HA 高可用&lt;/strong&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Hadoop入门—HDFS、MR、Yarn</title>
        <link>/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/</link>
        <pubDate>Mon, 15 Apr 2024 14:38:50 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/</guid>
        <description>&lt;h2 id=&#34;hadoop-简介&#34;&gt;&lt;a href=&#34;#hadoop-%e7%ae%80%e4%bb%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hadoop 简介
&lt;/h2&gt;&lt;hr&gt;
&lt;p&gt;狭义来说，hadoop 是 Apache 基金会开发的分布式系统基础架构，用来解决海量数据的存储和海量数据的分析计算问题。广义上来说，Hadoop 通常是指一个更广泛的概念 &amp;mdash;&amp;mdash; Hadoop 生态圈。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image.png&#34;
	width=&#34;849&#34;
	height=&#34;406&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image_hu_ae871aaf7cbe79af.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image_hu_abb20e2b328fbc6b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;209&#34;
		data-flex-basis=&#34;501px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;hadoop-三大发行版本&#34;&gt;&lt;a href=&#34;#hadoop-%e4%b8%89%e5%a4%a7%e5%8f%91%e8%a1%8c%e7%89%88%e6%9c%ac&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hadoop 三大发行版本
&lt;/h3&gt;&lt;p&gt;Apache、Cloudera、Hortonworks&lt;/p&gt;
&lt;p&gt;Apache 版本最原始（最基础）的版本，对于入门学习最好。&lt;/p&gt;
&lt;p&gt;Cloudera 在大型互联网企业中用的较多。其主要产品有 CDH、Cloudera Manager，Cloudera Support&lt;/p&gt;
&lt;h3 id=&#34;hadoop-优势&#34;&gt;&lt;a href=&#34;#hadoop-%e4%bc%98%e5%8a%bf&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hadoop 优势
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;高可靠性：&lt;/strong&gt; Hadoop 底层维护多个数据副本，所以即使 Hadoop 某个计算元素或存储出现故障，也不会导致数据的丢失。&lt;br&gt;
&lt;strong&gt;高扩展性：&lt;/strong&gt; 在集群间分配任务数据，可方便的扩展数以千计的节点。&lt;br&gt;
高效性： 在 MapReduce 的思想下，Hadoop 是并行工作的，以加快任务处理速度。&lt;br&gt;
&lt;strong&gt;高容错性：&lt;/strong&gt; 能够自动将失败的任务重新分配。&lt;/p&gt;
&lt;p&gt;**低成本：**Hadoop 不要求机器的配置达到极高的标准，大部分普通商用服务器即可满足要求，通过提供多个副本和容错机制提高集群的可靠性&lt;/p&gt;
&lt;h3 id=&#34;hadoop-基本组成&#34;&gt;&lt;a href=&#34;#hadoop-%e5%9f%ba%e6%9c%ac%e7%bb%84%e6%88%90&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hadoop 基本组成
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/fd575291df78b55069687df62b245798.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;常用-shell-命令&#34;&gt;&lt;a href=&#34;#%e5%b8%b8%e7%94%a8-shell-%e5%91%bd%e4%bb%a4&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;常用 Shell 命令
&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;hdfs dfs -ls &amp;lt;path&amp;gt;：列出指定 HDFS 路径下的文件和目录
hdfs dfs -mkdir &amp;lt;path&amp;gt;：在 HDFS 中创建新目录
hdfs dfs -put &amp;lt;localsrc&amp;gt; &amp;lt;dst&amp;gt;：将本地文件（或目录）复制到 HDFS
hdfs dfs -get &amp;lt;src&amp;gt; &amp;lt;localdst&amp;gt;：将 HDFS 上的文件（或目录）复制到本地
hdfs dfs -mv &amp;lt;src&amp;gt; &amp;lt;dst&amp;gt;：移动 HDFS 中的文件目录或重命名文件目录
hdfs dfs -cp &amp;lt;src&amp;gt; &amp;lt;dst&amp;gt;：复制 HDFS 中的文件或目录
hdfs dfs -rm &amp;lt;path&amp;gt;：删除 HDFS 中的文件
hdfs dfs -cat &amp;lt;path&amp;gt;：在控制台显示 HDFS 文件的内容
hdfs dfs -du &amp;lt;path&amp;gt;：显示 HDFS 文件或目录的大小
hdfs dfs -df &amp;lt;path&amp;gt;：显示 HDFS 的可用空间
hdfs fsck path [-files [-blocks [-location]]]
-files列出路径内的文件状态
-files -blocks输出文件块报告（几个块，几个副本）
-files -blocks -locations 输出每个block的详情
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;hdfs-分布存储&#34;&gt;&lt;a href=&#34;#hdfs-%e5%88%86%e5%b8%83%e5%ad%98%e5%82%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HDFS 分布存储
&lt;/h2&gt;&lt;hr&gt;
&lt;p&gt;HDFS 是一个分布式文件系统，具有高容错、高吞吐 量等特性，&lt;strong&gt;分布在多个集群节点上的文件系统。有 NN、DN、SNN 三种角色。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;hdfs-启停&#34;&gt;&lt;a href=&#34;#hdfs-%e5%90%af%e5%81%9c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HDFS 启停
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-1.png&#34;
	width=&#34;1296&#34;
	height=&#34;368&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-1_hu_9f50d72e4713275a.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-1_hu_e892968554c81460.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;352&#34;
		data-flex-basis=&#34;845px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;namenodenn&#34;&gt;&lt;a href=&#34;#namenodenn&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;NameNode（NN）
&lt;/h3&gt;&lt;p&gt;HDFS 的主角色，负责管理每个文件的块所在的 DataNode、整个 HDFS 文件系统、存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限）等。&lt;/p&gt;
&lt;h3 id=&#34;datanodedn&#34;&gt;&lt;a href=&#34;#datanodedn&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;DataNode（DN）
&lt;/h3&gt;&lt;p&gt;HDFS 从角色，负责处理客户端的读写请求，存储删除文件块，以及块数据校验和。&lt;/p&gt;
&lt;h3 id=&#34;secondarynamenodesnn&#34;&gt;&lt;a href=&#34;#secondarynamenodesnn&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;SecondaryNameNode（SNN）
&lt;/h3&gt;&lt;p&gt;NN 的辅助角色，帮 NN 打杂，监控 HDFS 状态的辅助后台程序，每隔一段时间获取 HDFS 元数据的快照。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可通过 9870 端口（默认 9870）访问 web 界面，查看集群各节点状态及信息&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-2.png&#34;
	width=&#34;2880&#34;
	height=&#34;1620&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-2_hu_57d3224414c2e837.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-2_hu_d5435fb5eaa6d337.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;文件写入流程&#34;&gt;&lt;a href=&#34;#%e6%96%87%e4%bb%b6%e5%86%99%e5%85%a5%e6%b5%81%e7%a8%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;文件写入流程
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-3.png&#34;
	width=&#34;1462&#34;
	height=&#34;644&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-3_hu_fbf8ea63e84c9d64.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-3_hu_cd5ef232b66b9c88.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;227&#34;
		data-flex-basis=&#34;544px&#34;
	
&gt;
发送的写入请求通过后，客户端会根据 NN 返回的信息自动把数据分块，向&lt;strong&gt;网络距离最近&lt;/strong&gt;的 DN 写入数据。同时，DN 会完成备份操作，把备份传到其他的 DN，然后由其他的 DN 再次做备份传播，直到满足设置的备份数量。当数据写入完成后，客户端会通知 NN，由 NN 完成元数据记录。
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-4.png&#34;
	width=&#34;1070&#34;
	height=&#34;1148&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-4_hu_493c72faaa0d005a.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-4_hu_ba3abf22a2a6c6b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;93&#34;
		data-flex-basis=&#34;223px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;hdfs-架构的稳定性&#34;&gt;&lt;a href=&#34;#hdfs-%e6%9e%b6%e6%9e%84%e7%9a%84%e7%a8%b3%e5%ae%9a%e6%80%a7&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HDFS 架构的稳定性
&lt;/h3&gt;&lt;h4 id=&#34;心跳机制和重新复制&#34;&gt;&lt;a href=&#34;#%e5%bf%83%e8%b7%b3%e6%9c%ba%e5%88%b6%e5%92%8c%e9%87%8d%e6%96%b0%e5%a4%8d%e5%88%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;心跳机制和重新复制
&lt;/h4&gt;&lt;p&gt;每个 DataNode 定期向 NameNode 发送心跳消息，如果超过指定时间没有收到心跳消息，则将 DataNode 标记为死亡。NameNode 不会将任何新的 IO 请求转发给标记为死亡的 DataNode，也不会 再使用这些 DataNode 上的数据。 由于数据不再可用，可能会导致某些块的复制因子小于其指定值， NameNode 会跟踪这些块，并在必要的时候进行重新复制。&lt;/p&gt;
&lt;h4 id=&#34;数据的完整性&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e6%8d%ae%e7%9a%84%e5%ae%8c%e6%95%b4%e6%80%a7&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;数据的完整性
&lt;/h4&gt;&lt;p&gt;由于存储设备故障等原因，存储在 DataNode 上的数据块也会发生损坏。为了避免读取到已经损坏的数 据而导致错误，HDFS 提供了数据完整性校验机制来保证数据的完整性，具体操作如下： 当客户端创建 HDFS 文件时，它会计算文件的每个块的 校验和 ，并将 校验和 存储在同一 HDFS 命名空 间下的单独的隐藏文件中。当客户端检索文件内容时，它会验证从每个 DataNode 接收的数据是否与存 储在关联校验和文件中的 校验和 匹配。如果匹配失败，则证明数据已经损坏，此时客户端会选择从其 他 DataNode 获取该块的其他可用副本。&lt;/p&gt;
&lt;h3 id=&#34;元数据的磁盘故障&#34;&gt;&lt;a href=&#34;#%e5%85%83%e6%95%b0%e6%8d%ae%e7%9a%84%e7%a3%81%e7%9b%98%e6%95%85%e9%9a%9c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;元数据的磁盘故障
&lt;/h3&gt;&lt;p&gt;FsImage 和 EditLog 是 HDFS 的核心数据，这些数据的意外丢失可能会导致整个 HDFS 服务不可 用。为了避免这个问题，可以配置 NameNode 使其支持 FsImage 和 EditLog 多副本同步，这样 FsImage 或 EditLog 的任何改变都会引起每个副本 FsImage 和 EditLog 的同步更新。&lt;/p&gt;
&lt;h4 id=&#34;支持快照&#34;&gt;&lt;a href=&#34;#%e6%94%af%e6%8c%81%e5%bf%ab%e7%85%a7&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;支持快照
&lt;/h4&gt;&lt;p&gt;快照支持在特定时刻存储数据副本，在数据意外损坏时，可以通过回滚操作恢复到健康的数据状态。&lt;/p&gt;
&lt;h3 id=&#34;文件读取流程&#34;&gt;&lt;a href=&#34;#%e6%96%87%e4%bb%b6%e8%af%bb%e5%8f%96%e6%b5%81%e7%a8%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;文件读取流程
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-5.png&#34;
	width=&#34;1920&#34;
	height=&#34;887&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-5_hu_4d4e26163a453731.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-5_hu_66e2c8639fa1ca70.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;216&#34;
		data-flex-basis=&#34;519px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;存储方式&#34;&gt;&lt;a href=&#34;#%e5%ad%98%e5%82%a8%e6%96%b9%e5%bc%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;存储方式
&lt;/h3&gt;&lt;h4 id=&#34;block-块和多副本&#34;&gt;&lt;a href=&#34;#block-%e5%9d%97%e5%92%8c%e5%a4%9a%e5%89%af%e6%9c%ac&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Block 块和多副本
&lt;/h4&gt;&lt;p&gt;由于文件大小不一，不利于统一管理，hdfs 设定了统一的存储单位 Block 块，Block 块是 hdfs 最小存储单位，通常每个 128MB（可修改 dfs.blocksize）。hdfs 会按照 Block 块大小把文件切分成多份存储在多个 datanode 上也就是多个服务器上，同时为了保证整个文件的完成性（防止 Block 块丢失或损坏），hdfs 会对每个 Block 块做多个备份存储在其他节点上，备份的数量默认是 3，可以在 hdfs-site.xml 中配置数量，修改后要重新分发该文件，保证每个服务器的配置文件相同！&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.replication&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;3&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;同时还可以&lt;strong&gt;临时决定&lt;/strong&gt;上传文件的副本数量：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;hdfs fs -D dfs.replication=5 -put test.tst /data/test&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;还可以修改已存在的 hdfs 文件的副本数量：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;hdfs fs -setrep [-R] 5 path
path 是指定文件路径，-R 表示对子目录也生效&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;edits-和-fsimage-文件&#34;&gt;&lt;a href=&#34;#edits-%e5%92%8c-fsimage-%e6%96%87%e4%bb%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;edits 和 fsimage 文件
&lt;/h4&gt;&lt;p&gt;hdfs 中文件被划分成一堆堆 block 块，为了方便整理记录文件和 block 的关系，namenode 基于一批 edits 文件和一个 fsimage 文件完成整个文件系统的维护管理。&lt;/p&gt;
&lt;p&gt;edits 文件是一个流水账文件，记录了 hdfs 的每一次操作以及该次操作影响的文件及其对应的 block。为了保证 edits 文件检索性能，会有多个 edits 文件，每一个 edits 文件存储到达一定数量会开启新的 edits，保证不出现超大的 edits 文件。最终所有 edits 文件会合并为一个 fsimage 文件，这个 fsimage 文件就记录了最终状态的文件操作信息。如果已经有了 fsimage，就会把全部的 edits 和已存在的 fsimage 进行新的合并，生成新的 fsimage。
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-6.png&#34;
	width=&#34;1296&#34;
	height=&#34;481&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-6_hu_52dfd5d1e1ebfb29.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-6_hu_11dd4332aaa90aaa.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;269&#34;
		data-flex-basis=&#34;646px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-7.png&#34;
	width=&#34;1069&#34;
	height=&#34;588&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-7_hu_2625dce4698b9464.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-7_hu_de1611f6402ed05e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;181&#34;
		data-flex-basis=&#34;436px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-8.png&#34;
	width=&#34;1891&#34;
	height=&#34;688&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-8_hu_52c0bd3ecacf8461.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-8_hu_cefe06dc3ddf1ff3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;274&#34;
		data-flex-basis=&#34;659px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;元数据合并及控制参数&#34;&gt;&lt;a href=&#34;#%e5%85%83%e6%95%b0%e6%8d%ae%e5%90%88%e5%b9%b6%e5%8f%8a%e6%8e%a7%e5%88%b6%e5%8f%82%e6%95%b0&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;元数据合并及控制参数
&lt;/h4&gt;&lt;p&gt;**注意！**元数据（eidts 和 fsimage）的合并不是由 NN 完成的，而是 SNN，NN 只是基于元数据对整个文件系统进行维护管理，负责元数据记录和权限审批，NN 是管理者，不是员工。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;SNN 会通过 http 从 NN 拉取 edits 和 fsimage 然后合并元数据并提供给 NN 使用&lt;/strong&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-9.png&#34;
	width=&#34;1322&#34;
	height=&#34;573&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-9_hu_fdcc81a3d0edfece.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-9_hu_c4d2baad5f67d482.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;230&#34;
		data-flex-basis=&#34;553px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;hdfs-漫画&#34;&gt;&lt;a href=&#34;#hdfs-%e6%bc%ab%e7%94%bb&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HDFS 漫画
&lt;/h3&gt;&lt;h4 id=&#34;读写数据&#34;&gt;&lt;a href=&#34;#%e8%af%bb%e5%86%99%e6%95%b0%e6%8d%ae&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;读写数据
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-10.png&#34;
	width=&#34;1121&#34;
	height=&#34;1256&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-10_hu_157753679e8ec94b.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-10_hu_128645316d4622f6.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;89&#34;
		data-flex-basis=&#34;214px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-11.png&#34;
	width=&#34;1134&#34;
	height=&#34;639&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-11_hu_5749475ab96244d1.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-11_hu_fdb712f4675e0e4c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;425px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-12.png&#34;
	width=&#34;1140&#34;
	height=&#34;696&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-12_hu_cbb94e5392c1e693.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-12_hu_3fa0523a2f6f2f2b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;163&#34;
		data-flex-basis=&#34;393px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;hdfs-故障类型和检测方法&#34;&gt;&lt;a href=&#34;#hdfs-%e6%95%85%e9%9a%9c%e7%b1%bb%e5%9e%8b%e5%92%8c%e6%a3%80%e6%b5%8b%e6%96%b9%e6%b3%95&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HDFS 故障类型和检测方法
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-13.png&#34;
	width=&#34;1194&#34;
	height=&#34;1261&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-13_hu_4b1cee605bbbf67f.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-13_hu_58e809ec424f960c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;94&#34;
		data-flex-basis=&#34;227px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-14.png&#34;
	width=&#34;1174&#34;
	height=&#34;781&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-14_hu_f1b4c4dcb189bb05.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-14_hu_ca4e5674b708f30f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;150&#34;
		data-flex-basis=&#34;360px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-15.png&#34;
	width=&#34;1032&#34;
	height=&#34;1308&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-15_hu_3c0d662c6bd6c4dc.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-15_hu_3c58c6056ad8f8ae.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;78&#34;
		data-flex-basis=&#34;189px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-16.png&#34;
	width=&#34;1032&#34;
	height=&#34;1308&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-16_hu_3c0d662c6bd6c4dc.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-16_hu_3c58c6056ad8f8ae.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;78&#34;
		data-flex-basis=&#34;189px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;mapreduce-分布式并行计算框架&#34;&gt;&lt;a href=&#34;#mapreduce-%e5%88%86%e5%b8%83%e5%bc%8f%e5%b9%b6%e8%a1%8c%e8%ae%a1%e7%ae%97%e6%a1%86%e6%9e%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;MapReduce 分布式并行计算框架
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;MapReduce 是基于 Yarn 运行的，没有 Yarn 就无法运行 MapReduce，MapReduce 有 RM、NM、AM 三种角色。&lt;/p&gt;
&lt;p&gt;MR 不适合实时计算，不适合流式计算，不适合有向图计算。&lt;/p&gt;
&lt;p&gt;可通过 8042 端口（默认 8042）访问 web 界面，查看 MR 任务的执行信息
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-17.png&#34;
	width=&#34;2880&#34;
	height=&#34;1620&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-17_hu_f4034a3b5f774256.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-17_hu_c2d144baf5c37545.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;计算模式&#34;&gt;&lt;a href=&#34;#%e8%ae%a1%e7%ae%97%e6%a8%a1%e5%bc%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;计算模式
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;MapReduce 属于分散汇总。spark、flink 属于中心调度.&lt;/strong&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-18.png&#34;
	width=&#34;2005&#34;
	height=&#34;844&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-18_hu_8fee4c51ba5bc4bc.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-18_hu_233fa6c8244e1f4c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;237&#34;
		data-flex-basis=&#34;570px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-19.png&#34;
	width=&#34;1668&#34;
	height=&#34;955&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-19_hu_e796581b28647e17.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-19_hu_a7bfd4eb965f4d88.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;174&#34;
		data-flex-basis=&#34;419px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;map-和-reduce&#34;&gt;&lt;a href=&#34;#map-%e5%92%8c-reduce&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Map 和 Reduce
&lt;/h3&gt;&lt;p&gt;Map 接口提供“分散”功能，Reduce 提供“汇总聚合”功能，用户可以通过 Java、python 等编程调用 mapreduce 接口完成开发，不过现在已经有了 Hive on MR（稍微过时），sparkSQL 等客户端。不懂编程仅用 SQL 就能完成开发，使用更方便，逐渐成为主流。&lt;/p&gt;
&lt;h3 id=&#34;mr-执行原理&#34;&gt;&lt;a href=&#34;#mr-%e6%89%a7%e8%a1%8c%e5%8e%9f%e7%90%86&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;MR 执行原理
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-20.png&#34;
	width=&#34;1403&#34;
	height=&#34;1232&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-20_hu_68e96f09be2f3bc.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-20_hu_58f862bcd0565186.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;113&#34;
		data-flex-basis=&#34;273px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;yarn-作业调度资源管理&#34;&gt;&lt;a href=&#34;#yarn-%e4%bd%9c%e4%b8%9a%e8%b0%83%e5%ba%a6%e8%b5%84%e6%ba%90%e7%ae%a1%e7%90%86&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Yarn 作业调度、资源管理
&lt;/h2&gt;&lt;p&gt;Yarn 管控整个集群的资源调度，MR 程序运行时，是在 Yarn 的监督下运行的，MR 程序会把计算任务分成若干个 map 和 reduce，然后向 Yarn 申请资源并运行任务。Yarn 有四种角色：ResourceManager（RM）、NodeManager（NM）、ProxyServer（PS）、JobHistoryServer（JHS）
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-21.png&#34;
	width=&#34;889&#34;
	height=&#34;513&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-21_hu_54781fad034c5888.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-21_hu_c4ac2a9b591cc19d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;173&#34;
		data-flex-basis=&#34;415px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;yarn-启停&#34;&gt;&lt;a href=&#34;#yarn-%e5%90%af%e5%81%9c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Yarn 启停
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-22.png&#34;
	width=&#34;1253&#34;
	height=&#34;291&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-22_hu_7b46bce3de21f748.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-22_hu_775d8f0fe7403c04.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;430&#34;
		data-flex-basis=&#34;1033px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;resourcemanager&#34;&gt;&lt;a href=&#34;#resourcemanager&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;ResourceManager
&lt;/h3&gt;&lt;p&gt;集群资源总管家，整个集群资源调度者，负责协调调度各个程序所需资源。&lt;/p&gt;
&lt;h3 id=&#34;nodemanager&#34;&gt;&lt;a href=&#34;#nodemanager&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;NodeManager
&lt;/h3&gt;&lt;p&gt;单机资源管家，单个服务器的资源调度者，负责协调调度单个服务器的资源供程序使用。同时负责该节点内所有容器的生命周期的管 理，监视资源和跟踪节点健康。具体如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;启动时向 ResourceManager 注册并定时发送心跳消息，等待 ResourceManager 的指令；
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;维护 Container 的生命周期，监控 Container 的资源使用情况；
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;管理任务运行时的相关依赖，根据 ApplicationMaster 的需要，在启动 Container 之前将需 要的程序及其依赖拷贝到本地。
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;applicationmaster&#34;&gt;&lt;a href=&#34;#applicationmaster&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;ApplicationMaster
&lt;/h3&gt;&lt;p&gt;在用户提交一个应用程序时，YARN 会启动一个轻量级的进程 ApplicationMaster 。 ApplicationMaster 负责协调来自 ResourceManager 的资源，并通过 NodeManager 监视容器内资 源的使用情况，同时还负责任务的监控与容错。具体如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;根据应用的运行状态来决定动态计算资源需求；
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;向 ResourceManager 申请资源，监控申请的资源的使用情况；
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;跟踪任务状态和进度，报告资源的使用情况和应用的进度信息；
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;负责任务的容错。
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;运行时可通过服务器的 8088 端口（默认 8088）访问 web 界面&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;jobhistoryserver&#34;&gt;&lt;a href=&#34;#jobhistoryserver&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;JobHistoryServer
&lt;/h3&gt;&lt;p&gt;记录历史运行程序的信息及产生的日志，把每个程序的运行日志统一收集到 hdfs，可通过 19888 端口访问 web 界面
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-23.png&#34;
	width=&#34;2880&#34;
	height=&#34;1620&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-23_hu_30a5329cc559fcde.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-23_hu_d5dd26fb9b003a81.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;container&#34;&gt;&lt;a href=&#34;#container&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Container
&lt;/h3&gt;&lt;p&gt;Container 是 Yarn 中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等。&lt;/p&gt;
&lt;h2 id=&#34;hadoop-一键启停&#34;&gt;&lt;a href=&#34;#hadoop-%e4%b8%80%e9%94%ae%e5%90%af%e5%81%9c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hadoop 一键启停
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-24.png&#34;
	width=&#34;1483&#34;
	height=&#34;658&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-24_hu_f5e5925f43b6c9ad.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-24_hu_e523a5cfc8834ca0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;225&#34;
		data-flex-basis=&#34;540px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Hive本质、架构、玩法</title>
        <link>/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/</link>
        <pubDate>Sun, 14 Apr 2024 12:23:06 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/</guid>
        <description>&lt;h2 id=&#34;hive-本质&#34;&gt;&lt;a href=&#34;#hive-%e6%9c%ac%e8%b4%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;strong&gt;Hive 本质&lt;/strong&gt;
&lt;/h2&gt;&lt;p&gt;Hive 是构建在 hadoop 上的数据仓库，也可以说是一个&lt;strong&gt;操作 hdfs 文件&lt;/strong&gt; 的客户端，它&lt;strong&gt;可以将结构化的数据文件映射成表&lt;/strong&gt;，并提供类 SQL 查询功能，用于查询的 SQL 语句会被转化为 MapReduce 作业，然后提交到 Hadoop 上运行。&lt;strong&gt;Hive 执行引擎可以是 MapReduce、Spark、Tez，如果是 MR，Hive 就会把 HQL 翻译成 MR 进行数据计算。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;由于 Hive 是针对数据仓库应⽤设计的，⽽数据仓库的内容是读多写少的。因此，Hive 中不⽀持 对数据的改写和添加，所有的数据都是在加载的时候中确定好的。&lt;/p&gt;
&lt;p&gt;Hive 不适合⽤于联机事务处理(OLTP)，也不提供实时查询功能。它最适合应⽤在基于⼤量不可变数据的批处理 作业。Hive 的特点是可伸缩（在 Hadoop 的集群上动态的添加设备），可扩展、容错、输⼊格式的松散耦合。 Hive 的⼊⼝是 DRIVER ，执⾏的 SQL 语句⾸先提交到 DRIVER 驱动，然后调 COMPILER 解释驱动，最终解释成 MapReduce 任务执⾏，最后将结果返回。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;优点：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;简单、容易上手 (提供了类似 sql 的查询语言 hql)，使得精通 sql 但是不了解 Java 编程的人也能很 好地进行大数据分析；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;灵活性高，可以自定义用户函数 (UDF) 和存储格式；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;为超大的数据集设计的计算和存储能力，集群扩展容易;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;4.&lt;strong&gt;统一的元数据管理&lt;/strong&gt;，可与 presto／impala／sparksql 等共享数据；&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;执行延迟高，不适合做数据的实时处理，但适合做海量数据的离线处理。&lt;/li&gt;
&lt;/ol&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image.png&#34;
	width=&#34;1415&#34;
	height=&#34;997&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image_hu_56e46a4d2510f5d9.png 480w, /zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image_hu_8393fd4979f71c19.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;141&#34;
		data-flex-basis=&#34;340px&#34;
	
&gt;
&lt;br /&gt;&lt;/p&gt;
&lt;h2 id=&#34;hive-主要有以下-3-个模块&#34;&gt;&lt;a href=&#34;#hive-%e4%b8%bb%e8%a6%81%e6%9c%89%e4%bb%a5%e4%b8%8b-3-%e4%b8%aa%e6%a8%a1%e5%9d%97&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hive 主要有以下 3 个模块:
&lt;/h2&gt;&lt;h3 id=&#34;户接模块&#34;&gt;&lt;a href=&#34;#%e6%88%b7%e6%8e%a5%e6%a8%a1%e5%9d%97&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;⽤户接⼝模块
&lt;/h3&gt;&lt;p&gt;含 CLI、HWI、JDBC、Thrift Server 等，⽤来实现对 Hive 的访问。CLI 是 Hive ⾃带 的命令⾏界⾯；HWI 是 Hive 的⼀个简单⽹⻚界⾯；JDBC、ODBC 以及 Thrift Server 可向⽤户提供进 ⾏编程的接⼝，其中 Thrift Server 是基于 Thrift 软件框架开发的，提供&lt;/p&gt;
&lt;h3 id=&#34;hive-的-rpc-通信接&#34;&gt;&lt;a href=&#34;#hive-%e7%9a%84-rpc-%e9%80%9a%e4%bf%a1%e6%8e%a5&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hive 的 RPC 通信接⼝
&lt;/h3&gt;&lt;p&gt;驱动模块（Driver）：含编译器 compiler、优化器 optimizer、执⾏器 executor 等，负责把 HiveQL 语句转换成⼀系列 MR 作业， 所有命令和查询都会进⼊驱动模块，通过该模块的解析变异，对计算过程进⾏优化，然后按照指定 的步骤执⾏。&lt;/p&gt;
&lt;h3 id=&#34;元数据存储模块metastore&#34;&gt;&lt;a href=&#34;#%e5%85%83%e6%95%b0%e6%8d%ae%e5%ad%98%e5%82%a8%e6%a8%a1%e5%9d%97metastore&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;strong&gt;元数据存储模块（Metastore）&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;是⼀个独⽴的关系型数据库，通常与 MySQL 数据库连接后创建的 ⼀个 MySQL 实例，也可以是 Hive ⾃带的 Derby 数据库实例。此模块主要保存表模式和其他系统元数 据，如表的名称、表的列及其属性、表的分区及其属性、表的属性、表中数据所在位置信息等。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;metastore 是 Hive 最重要的部件，在 Hive 中，表名、表结构、字段名、字段类型、表的分隔符等统一被称为元数据。所有的元数据默认存储在 Hive 内置的 derby 数据库中，但由于 derby 只能有一个实例，也就是说不能有多个命令行客户端同时访问，所以在实际生产环境中，通常使用 MySQL 中的自建数据库代替 derby。Hive 进行的是统一的元数据管理，就是说你在 Hive 上创建了一张表，然后在 presto、impala、sparksql 中都是可以直接使用的，它们会从 Metastore 中获取统一的元数据信息，同样的你在 presto、impala、sparksql 中创建一张表，在 Hive 中也可以直接使用。
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;hive 创建的内部表，默认放在 hdfs 的/usr/hive/warehouse 文件夹下
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-1.png&#34;
	width=&#34;882&#34;
	height=&#34;902&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-1_hu_a450e0f272720c15.png 480w, /zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-1_hu_f2d454cd1d9857ac.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;97&#34;
		data-flex-basis=&#34;234px&#34;
	
&gt;
可以看到 db_msg.db、myhive.db 是数据库，其他的是表，而这些表创建时默认放在另一个 default 库中只是在 hdfs 中没有显示，在 hive 中才能显示出来。由此可见 hive 的表和库其实就是一个个 hdfs 文件夹，表和库可以是并列同级关系。表有内外之分，创建时默认是内部表，而 external_stu1 是外部表，外部表和内部表的区别就在于外部表只是把 hdfs 的文件数据和 hive 的表相关联，在 hive 中删除外部表，hdfs 的文件数据依然存在不会被删除，而删除内部表，表的文件数据和表本身会一同删除。
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-2.png&#34;
	width=&#34;931&#34;
	height=&#34;730&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-2_hu_b0464d693e7c6130.png 480w, /zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-2_hu_425bc9dbf21459fc.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;127&#34;
		data-flex-basis=&#34;306px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;架构&#34;&gt;&lt;a href=&#34;#%e6%9e%b6%e6%9e%84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;架构
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-3.png&#34;
	width=&#34;883&#34;
	height=&#34;449&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-3_hu_bf3e07e9994421d7.png 480w, /zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-3_hu_391526594d3c51ad.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;196&#34;
		data-flex-basis=&#34;471px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;hive-日志配置&#34;&gt;&lt;a href=&#34;#hive-%e6%97%a5%e5%bf%97%e9%85%8d%e7%bd%ae&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hive 日志配置
&lt;/h2&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;-- Hive中的日志分为两种
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;1. 系统日志，记录了hive的运行情况，错误状况。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;2. Job 日志，记录了Hive 中job的执行的历史过程。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;系统日志存储在什么地方呢 ？
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;在hive/conf/hive-log4j.properties 文件中记录了Hive日志的存储情况，
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;如果没有hive-log4j.properties。那么需要找到该文件夹下的hive-log4j.properties.templete,这个是模板文件，运行mv命令把templete重命名成properties文件即可。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;properties文件默认的存储情况：
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;property.hive.root.logger=WARN,DRFA
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;property.hive.log.dir=/tmp/${user.name} # 默认的存储位置,一般是/tmp/root，此处改成hive/logs
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;property.hive.log.file=hive.log  # 默认的文件名
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Job日志又存储在什么地方呢 ？
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;//Location of Hive run time structured log file
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    HIVEHISTORYFILELOC(&amp;#34;hive.querylog.location&amp;#34;, &amp;#34;/tmp/&amp;#34; + System.getProperty(&amp;#34;user.name&amp;#34;)),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;默认存储与在/tmp/{user.name}目录下。但是我没找到。。。
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;properties 文件的日志存放目录修改之后如下：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-4.png&#34;
	width=&#34;837&#34;
	height=&#34;353&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-4_hu_4520e8acf4e7fef4.png 480w, /zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-4_hu_a65bc72b2afcc3fc.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;237&#34;
		data-flex-basis=&#34;569px&#34;
	
&gt;
日志目录是后来配置的，于是又把/tmp/root 目录下的 hive 日志手动移到了 hive/logs 下：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-5.png&#34;
	width=&#34;1274&#34;
	height=&#34;367&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-5_hu_172101a3a70a1991.png 480w, /zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-5_hu_9d8401827ae7467f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;347&#34;
		data-flex-basis=&#34;833px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;hql-执行过程&#34;&gt;&lt;a href=&#34;#hql-%e6%89%a7%e8%a1%8c%e8%bf%87%e7%a8%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HQL 执行过程
&lt;/h2&gt;&lt;p&gt;Hive 在执行一条 HQL 的时候，会经过以下步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;语法解析：Antlr 定义 SQL 的语法规则，完成 SQL 词法，语法解析，将 SQL 转化为抽象 语法树 AST Tree；&lt;/li&gt;
&lt;li&gt;语义解析：遍历 AST Tree，抽象出查询的基本组成单元 QueryBlock；&lt;/li&gt;
&lt;li&gt;生成逻辑执行计划：遍历 QueryBlock，翻译为执行操作树 OperatorTree；&lt;/li&gt;
&lt;li&gt;优化逻辑执行计划：逻辑层优化器进行 OperatorTree 变换，合并不必要的 * ReduceSinkOperator，减少 shuffle 数据量；&lt;/li&gt;
&lt;li&gt;生成物理执行计划：遍历 OperatorTree，翻译为 MapReduce 任务；&lt;/li&gt;
&lt;li&gt;优化物理执行计划：物理层优化器进行 MapReduce 任务的变换，生成最终的执行计划。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;hive-四种玩法&#34;&gt;&lt;a href=&#34;#hive-%e5%9b%9b%e7%a7%8d%e7%8e%a9%e6%b3%95&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hive 四种玩法：
&lt;/h2&gt;&lt;h3 id=&#34;cli&#34;&gt;&lt;a href=&#34;#cli&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;CLI
&lt;/h3&gt;&lt;p&gt;配置 hive 环境变量（通常是/etc/profile 文件）后，在任意目录下直接输入命令 hive 即可启动（或者 hive &amp;ndash;service cli），前提是要启动 hdfs（start-dfs.sh）和 hive 元数据服务（start-hivemetastore.sh 自己写的脚本配置到环境变量），因为 hive 就是操作 hdfs 的文件的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意！！！&lt;/strong&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-6.png&#34;
	width=&#34;1421&#34;
	height=&#34;191&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-6_hu_e8fcf768d70661e7.png 480w, /zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-6_hu_96ea3df9b92e66e2.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;743&#34;
		data-flex-basis=&#34;1785px&#34;
	
&gt;
注意第一行提到 Hive-on -MR is deprecated 在 2.x 版本已经废弃不推荐使用，后续都是 hive on spark （on Tez），但是 MapReduce 的 hive 优化还是建议学一下。
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-7.png&#34;
	width=&#34;1423&#34;
	height=&#34;150&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-7_hu_52aaf1bc603a5f5a.png 480w, /zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-7_hu_5454dee5108ecc8a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;948&#34;
		data-flex-basis=&#34;2276px&#34;
	
&gt;
上面这种情况可能就是没启动元数据服务。
hive 通常是在集群环境中使用的，如果只启动了一台服务器，那么在启动 hive 时会报错，如下：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-8.png&#34;
	width=&#34;1771&#34;
	height=&#34;235&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-8_hu_780d886e66dd009a.png 480w, /zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-8_hu_c5c8b2a013ac174e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;753&#34;
		data-flex-basis=&#34;1808px&#34;
	
&gt;
name node 处于安全模式，服务器数量少于最小要求数量，这种情况要么等 18s 后重新启动 cli，要么启动第二台服务器并启动上面的 hdfs。&lt;/p&gt;
&lt;h3 id=&#34;hiveserver2&#34;&gt;&lt;a href=&#34;#hiveserver2&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HiveServer2
&lt;/h3&gt;&lt;p&gt;启动 hiveserver2 服务，提供 thrift 端口供其他客户连接，启动之后就可以使用 hive 之外的其他工具操作 hdfs 文件，比如 DBserver，IDEA 的数据库插件&lt;/p&gt;
&lt;p&gt;需要在 hdfs 的 core-site.xml 文件中加如下配置：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.proxyuser.root.groups&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;*&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;允许root用户代理任何其他用户&lt;span class=&#34;nt&#34;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.proxyuser.root.hosts&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;*&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;允许代理任意服务器的请求&lt;span class=&#34;nt&#34;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    root也可以换成hadoop等其他用户，我这里设置成了超级用户root
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;任意目录下启动 hiveserver2（前台）或者切换到后台。
自己写的后台脚本，配置到环境变量中&lt;/p&gt;
&lt;p&gt;[root@linux01 bin]# cat start-hiveserver2.sh&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#!/bin/bash
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;nohup &lt;span class=&#34;nv&#34;&gt;$HIVE_HOME&lt;/span&gt;/bin/hive --service hiveserver2 &amp;gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;$HIVE_HOME&lt;/span&gt;/logs/hiveserver2.log 2&amp;gt;&lt;span class=&#34;p&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;amp;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#启动hiveserver2服务，提供thrift端口供其他客户连接&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;beeline&#34;&gt;&lt;a href=&#34;#beeline&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Beeline
&lt;/h3&gt;&lt;p&gt;启动 beeline 必须先启动 hiveserver2，启动 beeline 后，键入&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;!connect jdbc:hive2://linux01:10000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;并输入用户名密码即可，这里的登录用户可以是任意用户因为 hadoop 的 core-site.xml 设置了 root 用户可以代理任意用户。linux01 是我的服务器名。
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-9.png&#34;
	width=&#34;1089&#34;
	height=&#34;459&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-9_hu_2a432c89e502a252.png 480w, /zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-9_hu_a19ee912d4b86804.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;237&#34;
		data-flex-basis=&#34;569px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;web-ui&#34;&gt;&lt;a href=&#34;#web-ui&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Web UI
&lt;/h3&gt;&lt;p&gt;在 hive-site-xml 中添加 hive 配置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hive.server2.webui.host&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c&#34;&gt;&amp;lt;!--主机名或ip--&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux01&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hive.server2.webui.port&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;10002&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/propert&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;启动 hive，浏览器即可访问 10002 端口&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Hive调优</title>
        <link>/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/</link>
        <pubDate>Sat, 13 Apr 2024 20:49:38 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/</guid>
        <description>&lt;h2 id=&#34;yarn-和-mr-资源配置&#34;&gt;&lt;a href=&#34;#yarn-%e5%92%8c-mr-%e8%b5%84%e6%ba%90%e9%85%8d%e7%bd%ae&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Yarn 和 MR 资源配置
&lt;/h2&gt;&lt;p&gt;配置项参考官网：&lt;a class=&#34;link&#34; href=&#34;https://apache.github.io/hadoop/&#34;  title=&#34;https://apache.github.io/hadoop/&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://apache.github.io/hadoop/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;yarn-资源配置&#34;&gt;&lt;a href=&#34;#yarn-%e8%b5%84%e6%ba%90%e9%85%8d%e7%bd%ae&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Yarn 资源配置
&lt;/h3&gt;&lt;p&gt;修改 yarn-site.xml,调整的 Yarn 参数均与 CPU、内存等资源有关，配置如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.nodemanager.resource.memory-mb&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;65536&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;一个NodeManager节点分配给Container使用的内存。该参数的配置，取决于NodeManager所在节点的总内存容量和该节点运行的其他服务的数量&lt;span class=&#34;nt&#34;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.nodemanager.resource.cpu-vcores&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;16&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;一个NodeManager节点分配给Container使用的CPU核数。该参数的配置，同样取决于NodeManager所在节点的总CPU核数和该节点运行的其他服务。&lt;span class=&#34;nt&#34;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.scheduler.maximum-allocation-mb&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;16384&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;单个Container能够使用的最大内存。&lt;span class=&#34;nt&#34;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.scheduler.minimum-allocation-mb&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;512&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;单个Container能够使用的最小内存。&lt;span class=&#34;nt&#34;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;修改后重新分发该配置文件并重启 Yarn&lt;/p&gt;
&lt;h3 id=&#34;mr-资源配置&#34;&gt;&lt;a href=&#34;#mr-%e8%b5%84%e6%ba%90%e9%85%8d%e7%bd%ae&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;MR 资源配置
&lt;/h3&gt;&lt;p&gt;MapReduce 资源配置主要包括 Map Task 的内存和 CPU 核数，以及 Reduce Task 的内存和 CPU 核数。核心配置参数如下：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;mapreduce.map.memory.mb&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;该参数的含义是，单个 Map Task 申请的 container 容器内存大小，其默认值为 1024。该值不能超出 yarn.scheduler.maximum-allocation-mb 和 yarn.scheduler.minimum-allocation-mb 规定的范围。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;该参数需要根据不同的计算任务单独进行配置，在 hive 中，可直接使用如下方式为每个 SQL 语句单独进行配置：set mapreduce.map.memory.mb=2048;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;mapreduce.map.cpu.vcores&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;该参数的含义是，单个 Map Task 申请的 container 容器 cpu 核数，其默认值为 1。该值一般无需调整。如需调整要修改 mapred-site.xml 文件（mapred-default.xml）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;mapreduce.reduce.cpu.vcores&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;该参数的含义是，单个 Reduce Task 申请的 container 容器 cpu 核数，其默认值为 1。该值一般无需调整。如需调整要修改 mapred-site.xml 文件（mapred-default.xml）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;mapreduce.reduce.memory.mb&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;该参数的含义是，单个 Reduce Task 申请的 container 容器内存大小，其默认值为 1024。该值同样不能超出 yarn.scheduler.maximum-allocation-mb 和 yarn.scheduler.minimum-allocation-mb 规定的范围。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;该参数需要根据不同的计算任务单独进行配置，在 hive 中，可直接使用如下方式为每个 SQL 语句单独进行配置：set mapreduce.reduce.memory.mb=2048;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;explain-查看执行计划&#34;&gt;&lt;a href=&#34;#explain-%e6%9f%a5%e7%9c%8b%e6%89%a7%e8%a1%8c%e8%ae%a1%e5%88%92&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Explain 查看执行计划
&lt;/h2&gt;&lt;p&gt;Explain 用于呈现 HQL 语句的详细执行步骤，由一系列 Stage 组成，简单的理解为 HQL 查询语句的不同执行阶段，这一系列 Stage 具有依赖关系，每个 Stage 对应一个 MapReduce Job 或一个文件系统操作等。&lt;/p&gt;
&lt;p&gt;若某个 Stage 对应的一个 MapReduce Job，则其 Map 端和 Reduce 端的计算逻辑分别由 Map Operator Tree 和 Reduce Operator Tree 进行描述，Operator Tree 由一系列的 Operator 组成，一个 Operator 代表在 Map 或 Reduce 阶段的一个单一的逻辑操作，例如 TableScan Operator，Select Operator，Join Operator 等。具体如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image.png&#34;
	width=&#34;213&#34;
	height=&#34;681&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image_hu_47b669486afcd8ad.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image_hu_6f7640515ae32138.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;31&#34;
		data-flex-basis=&#34;75px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;常见的 Operator 及其作用如下&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;TableScan：表扫描操作，通常 map 端第一个操作肯定是表扫描操作&lt;/p&gt;
&lt;p&gt;Select Operator：选取操作&lt;/p&gt;
&lt;p&gt;Group By Operator：map 端的分组聚合操作，在后面的分组聚合中会讲到&lt;/p&gt;
&lt;p&gt;Reduce Output Operator：输出到 reduce 操作&lt;/p&gt;
&lt;p&gt;Filter Operator：过滤操作&lt;/p&gt;
&lt;p&gt;Join Operator：join 操作&lt;/p&gt;
&lt;p&gt;File Output Operator：文件输出操作&lt;/p&gt;
&lt;p&gt;Fetch Operator 客户端获取数据操作&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Explain 语法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;EXPLAIN [FORMATTED | EXTENDED | DEPENDENCY]&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;FORMATTED：将执行计划以 JSON 字符串的形式输出&lt;/li&gt;
&lt;li&gt;EXTENDED：输出执行计划中的额外信息，通常是读写的文件名等信息&lt;/li&gt;
&lt;li&gt;DEPENDENCY：输出执行计划读取的表及分区&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;例：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;hive (default)&amp;gt;&lt;/p&gt;
&lt;p&gt;explain formatted&lt;/p&gt;
&lt;p&gt;select user_id,count(*) from order_detail group by user_id;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-1.png&#34;
	width=&#34;1435&#34;
	height=&#34;886&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-1_hu_df40e0082aa7426d.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-1_hu_38c1b7e1fc123ebc.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;161&#34;
		data-flex-basis=&#34;388px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;分组聚合优化&#34;&gt;&lt;a href=&#34;#%e5%88%86%e7%bb%84%e8%81%9a%e5%90%88%e4%bc%98%e5%8c%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;strong&gt;分组聚合优化&lt;/strong&gt;
&lt;/h2&gt;&lt;p&gt;分组聚合是通过 MR Job 实现的，map 端读取数据，并按照分组字段分区，通过 shuffle，把数据发到 reduce，各组数据在 reduce 端完成最终的聚合运算。&lt;/p&gt;
&lt;p&gt;分组聚合的优化主要围绕减少 shuffle 数据量进行，具体做法是 map-side 聚合。map-side 聚合是在 map 端维护一个 hash table，先利用其完成数据的部分聚合，再把聚合的结果按照分组字段分区，发到 reduce 端完成最终聚合，以此提高分组聚合运算效率。简而言之就是增加了一个 map 端的部分聚合过程，以减少 shuffle 的工作量，进而减少 reduce 端的聚合工作量。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;map-side 聚合相关参数如下&lt;/p&gt;
&lt;p&gt;&amp;ndash;启用 map-side 聚合，默认是 true&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;set hive.map.aggr=true;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&amp;ndash;用于检测源表数据是否适合进行 map-side 聚合。检测的方法是：系统自动先对若干条数据进行 map-side 聚合，若聚合后的条数和聚合前的条数比值小于该值，则认为该表适合进行 map-side 聚合；否则，认为该表数据不适合进行 map-side 聚合，后续数据便不再进行 map-side 聚合。0.5 意味着平均有 2 条数据可以聚合成 1 条，1 意味着没有出现任何的聚合&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;set hive.map.aggr.hash.min.reduction=0.5;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&amp;ndash;用于&lt;strong&gt;hive.map.aggr.hash.min.reduction=0.5&lt;/strong&gt; 检测源表是否适合 map-side 聚合的条数。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;set hive.groupby.mapaggr.checkinterval=100000;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&amp;ndash;map-side 聚合所用的 hash table 占用 map task 堆内存的最大比例，若超出该值，则会对 hash table 进行一次 flush。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;set hive.map.aggr.hash.force.flush.memory.threshold=0.7;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;优化前-vs-优化后&#34;&gt;&lt;a href=&#34;#%e4%bc%98%e5%8c%96%e5%89%8d-vs-%e4%bc%98%e5%8c%96%e5%90%8e&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;优化前 VS 优化后
&lt;/h3&gt;&lt;p&gt;set hive.map.aggr=false 关闭分组聚合优化，查看执行效果，在 Map 端没有了 Group By Operator&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-2.png&#34;
	width=&#34;538&#34;
	height=&#34;871&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-2_hu_d4e494b7ea248a44.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-2_hu_c61e4d2575f0ab2a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;61&#34;
		data-flex-basis=&#34;148px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;set hive.map.aggr=true 开启分组聚合优化，查看执行效果，在 Map 端有了 Group By Operator，&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-3.png&#34;
	width=&#34;493&#34;
	height=&#34;888&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-3_hu_53044b8f5a377993.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-3_hu_ae68419ad1ada840.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;55&#34;
		data-flex-basis=&#34;133px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;若发生 map-side 优化，优化后比优化前的 HQL 执行耗时应该有所减少，且 map 的 output 数量明显小于 input 数量。&lt;/p&gt;
&lt;p&gt;若没有触发 map-side，则 map 的 output 数量虽然比 input 数量有所减少但可以忽略不计。具体有没有触发 map-side 可以去 web UI 界面查看 map 日志。&lt;/p&gt;
&lt;p&gt;注意！！map-side 聚合不够智能，即 map 端的分组聚合是否执行一定程度上会受到分组字段在表中存储的位置和分布的影响，这是底层存储问题，未必是因为数据真的不适合分组聚合。要解决此问题可以提前对数据&lt;strong&gt;分区分桶&lt;/strong&gt;，使用分区分桶表，使得同一区域存储的数据分布具有一定的相似性，这样聚合结果会有所提升。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;例：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1）select province_id,count(*) from order_detail group by province_id;&lt;/p&gt;
&lt;p&gt;该语句查询所有订单，根据省份 id 分组聚合，省份只有 34 个，这样 map 后的数据应该只有 34 条，所以聚合结果是应该是比较可观的。所以 group by 的基数越小，一般越适合聚合。&lt;/p&gt;
&lt;p&gt;2）select product_id,count(*) from order_detail group by product_id;&lt;/p&gt;
&lt;p&gt;若 product_id 这一分组字段在 order_detail 表中分布比较散，那么可能会导致 hive 在表中切片抽样进行 map-side 检测的时候测试聚合结果&amp;gt;0.5，那么最终就没有使用 map-side 聚合。所以说如果能保证抽样数据的测试结果&amp;lt;=0.5，就会实现分组聚合，当然也可以调整&lt;strong&gt;hive.map.aggr.hash.min.reduction&lt;/strong&gt; 的值以提高 map-side 的命中率。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;若 100w 的数据集分组聚合之后的输出&amp;gt;100w,可能的原因是多次触发了 hash table 的 flush&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;join-优化&#34;&gt;&lt;a href=&#34;#join-%e4%bc%98%e5%8c%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Join 优化
&lt;/h2&gt;&lt;p&gt;Join 优化就是控制 HQL 语句走哪种 join 算法，这些 join 算法有的快，有的慢，有的激进，有的保守。我们要做的就是让 HQL 走最适合自己的 join 算法。&lt;/p&gt;
&lt;h3 id=&#34;common-join普通-join&#34;&gt;&lt;a href=&#34;#common-join%e6%99%ae%e9%80%9a-join&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Common Join(普通 join)
&lt;/h3&gt;&lt;h4 id=&#34;原理&#34;&gt;&lt;a href=&#34;#%e5%8e%9f%e7%90%86&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;原理
&lt;/h4&gt;&lt;p&gt;hive 中最稳定的 join 算法，其通过一个 MapReduce Job 完成一个 join 操作。Map 端负责读取 join 操作所需表的数据，并按照关联字段进行分区，通过 Shuffle，将其发送到 Reduce 端，相同 key 的数据在 Reduce 端完成最终的 Join 操作。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-4.png&#34;
	width=&#34;641&#34;
	height=&#34;479&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-4_hu_d8fba809e1779fb4.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-4_hu_d946e815b71cef4d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;321px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;需要注意的是，HQL 语句中的 join 操作和执行计划中的 Common Join 任务并非一对一的关系，即 HQL 中的 A 表 join B 表 join C 表在 common join 中未必也是两个 join 操作，一个 HQL 语句中的相邻的且关联字段相同的多个 join 操作可以合并为一个 Common Join 任务。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;例：
1）hive (default)&lt;/p&gt;
&lt;p&gt;select a.val, b.val, c.val from&lt;/p&gt;
&lt;p&gt;a join b on (a.key = b.key1) join c on (c.key = b.key1)&lt;/p&gt;
&lt;p&gt;上述 sql 语句中两个 join 操作的关联字段均为 b 表的 key1 字段，则该语句中的两个 join 操作可由一个 Common Join 任务实现，也就是可通过 1 个 Map Reduce 任务实现。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;2）hive (default)&amp;gt; select a.val, b.val, c.val from&lt;/p&gt;
&lt;p&gt;a join b on (a.key = b.key1) join c on (c.key = b.key2)&lt;/p&gt;
&lt;p&gt;上述 sql 语句中的两个 join 操作关联字段各不相同，则该语句的两个 join 操作需要各自通过一个 Common Join 任务实现，也就是通过 2 个 Map Reduce 任务实现。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;map-join&#34;&gt;&lt;a href=&#34;#map-join&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Map Join
&lt;/h3&gt;&lt;h4 id=&#34;原理-1&#34;&gt;&lt;a href=&#34;#%e5%8e%9f%e7%90%86-1&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;原理
&lt;/h4&gt;&lt;p&gt;Map Join 算法可以通过一个 MR 和一个 MapJoin 阶段完成一个 join 操作，省去了 shuffle 和 reduce，在第二个 map 阶段进行表的 join，不需要进入 reduce 阶段。其适用场景为大表 join 小表。第一个 Job 会读取小表数据，将其制作为 hash table，并上传至 Hadoop 分布式缓存（本质上是上传至 HDFS）。第二个 Job 会先从分布式缓存中读取小表数据，并缓存在 Map Task 的内存中，然后扫描大表数据，这样在 map 端即可完成关联操作。如下图所示：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-5.png&#34;
	width=&#34;865&#34;
	height=&#34;514&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-5_hu_c9f21c1f5ca0940b.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-5_hu_1529fb5d47ecf2d4.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;168&#34;
		data-flex-basis=&#34;403px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;mapreduce local task 是本地任务，读取小表数据，因为小表数据占用内存资源少，所以不上传到 yarn，直接在本地读取效率更高 ，读取后序列化生成 hash table 并上传到 hdfs 的 cache 中。&lt;/p&gt;
&lt;p&gt;其中 Mapper 是实现 Map 阶段功能的代码组件。它接受原始数据作为输入，执行某种转换操作，然后输出一组键值对。这些键值对会作为 Reduce 阶段的输入。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;例：SELECT a.key, a.value FROM a JOIN b ON a.key = b.key&lt;/p&gt;
&lt;p&gt;前提 b 表是一张小表，具体小表有多小，由参数 hive.mapjoin.smalltable.filesize 来决定，默认值是 25M。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;参数列表：&lt;/p&gt;
&lt;p&gt;1）小表自动选择 Mapjoin&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join=true;&lt;/p&gt;
&lt;p&gt;默认值：false。该参数为 true 时，Hive 自动对左边的表统计量，若是小表就加入内存，即对小表使用 Map join
2）小表阀值
set hive.mapjoin.smalltable.filesize=25000000;
?默认值：25M&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;优化&#34;&gt;&lt;a href=&#34;#%e4%bc%98%e5%8c%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;优化
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;法一：hint 提示&lt;/strong&gt;
手动指定通过 map join 算法，该方式已经过时，不推荐使用。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;hive (default)&amp;gt; select /_+ map join(ta) _/&lt;/p&gt;
&lt;p&gt;ta.id, tb.id from table_a ta join table_b tb on ta.id=tb.id;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;法二：自动触发&lt;/strong&gt;
Hive 在编译 HQL 语句阶段，起初所有的 join 操作均采用 Common Join 算法实现。&lt;/p&gt;
&lt;p&gt;之后在物理优化阶段，Hive 会根据每个 Common Join 任务所需表的大小判断该 Common Join 任务是否能够转换为 Map Join 任务，若满足要求（小表大小&amp;lt;指定的阈值），便将 Common Join 任务自动转换为 Map Join 任务。&lt;/p&gt;
&lt;p&gt;但有些 Common Join 任务所需的表大小，在 HQL 的编译阶段是未知的（例如对子查询进行 join 操作），所以这种 Common Join 任务是否能转换成 Map Join 任务在编译阶是无法确定的。&lt;/p&gt;
&lt;p&gt;针对这种情况，Hive 会在编译阶段生成一个条件任务（Conditional Task），其下会包含一个计划列表，计划列表中包含转换后的 Map Join 任务以及原有的 Common Join 任务。最终具体采用哪个计划，是在运行时决定的。大致思路如下图所示：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-6.png&#34;
	width=&#34;865&#34;
	height=&#34;609&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-6_hu_9b1e73b062f06732.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-6_hu_ba70a549f87b60b1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;142&#34;
		data-flex-basis=&#34;340px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;Map join 自动转换的具体判断逻辑如下图所示：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-7.png&#34;
	width=&#34;863&#34;
	height=&#34;680&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-7_hu_ab3561a231e66273.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-7_hu_122f568ab470925a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;126&#34;
		data-flex-basis=&#34;304px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;图片详情看尚硅谷 P135&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;寻找大表候选人时还不知道每张表的大小&lt;/strong&gt;，那么选择规则是看 join 方式，有 innner join、left join、right join 等等。&lt;/p&gt;
&lt;p&gt;inner join：每个表都可能是大表候选人。&lt;/p&gt;
&lt;p&gt;left join：默认左表为大表候选人，右表当作小表，这样小表会缓存到内存中，以大表为主，从大表中一条条 join 内存中的小表，如果反过来把大表缓存到内存中，以小表为主，从小表中一条条 join 内存中的大表，若出现大表有该字段而小表没有的情况，这种情况下就会出现大量数据 join 失败，小表数据少，大表数据多，那么会因为小表浪费很多数据，所以通常是左表为大表，右表为小表。&lt;/p&gt;
&lt;p&gt;right join：左表当作小表，右表为大表候选人。&lt;/p&gt;
&lt;p&gt;full outer join：找不到大表候选人，因为全外联要返回两个表的全部数据，两个表都要去遍历，就无法 map join 优化。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;涉及参数：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&amp;ndash;启动 Map Join 自动转换&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join=true;&lt;/p&gt;
&lt;p&gt;&amp;ndash;一个 Common Join operator 转为 Map Join operator 的判断条件：若该 Common Join 相关的表中,把每一个表都当作大表候选人，若除大表之外的任意一张已知大小的表的大小&amp;gt;大表候选人，则该组合不成立，不生成 map join，反之生成一个 Map Join 计划。此时可能存在多种组合均满足该条件,则 hive 会为每种满足条件的组合均生成一个 Map Join 计划,同时还会保留原有的 Common Join 计划作为后备(back up)计划,实际运行时,优先执行 Map Join 计划，若不能执行成功，则启动 Common Join 后备计划。&lt;/p&gt;
&lt;p&gt;set hive.mapjoin.smalltable.filesize=250000;&lt;/p&gt;
&lt;p&gt;&amp;ndash;开启无条件转 Map Join&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join.noconditionaltask=true; -无条件转 Map Join 时的小表之和阈值,若一个 Common Join operator 相关的表中，存在 n-1 张表的大小总和&amp;lt;=该值,此时 hive 便不会再为每种 n-1 张表的组合均生成 Map Join 计划,同时也不会保留 Common Join 作为后备计划。而是只生成一个最优的 Map Join 计划。
set hive.auto.convert.join.noconditionaltask.size=10000000;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;优化案例&#34;&gt;&lt;a href=&#34;#%e4%bc%98%e5%8c%96%e6%a1%88%e4%be%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;优化案例
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;hive (default)&amp;gt; select * from order_detail od&lt;/p&gt;
&lt;p&gt;join product_info product on od.product_id = product.id&lt;/p&gt;
&lt;p&gt;join province_info province on od.province_id = province.id;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;优化前&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;上述 SQL 语句共有三张表进行两次 join 操作，且两次 join 操作的关联字段不同。故优化前的执行计划应该包含两个 Common Join operator，也就是由两个 MapReduce 任务实现。执行计划如下图所示：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-8.png&#34;
	width=&#34;445&#34;
	height=&#34;1391&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-8_hu_3e6bbe204819d3d6.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-8_hu_63b78982ef539f4b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;31&#34;
		data-flex-basis=&#34;76px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;优化思路&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;使用如下语句获取表/分区的大小信息：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;hive (default)&amp;gt;&lt;/p&gt;
&lt;p&gt;desc formatted table_name partition(partition_col=&amp;lsquo;partition&amp;rsquo;);&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;经分析，参与 join 的三张表，数据量如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-9.png&#34;
	width=&#34;1474&#34;
	height=&#34;371&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-9_hu_53b2492ddd32221d.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-9_hu_a661e9dca70d29c4.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;397&#34;
		data-flex-basis=&#34;953px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;方案一：&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;启用 Map Join 自动转换。&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join=true;&lt;/p&gt;
&lt;p&gt;不使用无条件转 Map Join。&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join.noconditionaltask=false;&lt;/p&gt;
&lt;p&gt;调整 hive.mapjoin.smalltable.filesize 参数，使其大于等于 product_info。&lt;/p&gt;
&lt;p&gt;set hive.mapjoin.smalltable.filesize=25285707;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;这样可保证将两个 Common Join operator 均可转为 Map Join operator，并保留 Common Join 作为后备计划，保证计算任务的稳定。调整完的执行计划如下图：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-10.png&#34;
	width=&#34;541&#34;
	height=&#34;1422&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-10_hu_4df7790955068a83.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-10_hu_75b79a59c50968c3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;38&#34;
		data-flex-basis=&#34;91px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;方案二：&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;启用 Map Join 自动转换。&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join=true;&lt;/p&gt;
&lt;p&gt;使用无条件转 Map Join。&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join.noconditionaltask=true;&lt;/p&gt;
&lt;p&gt;调整 hive.auto.convert.join.noconditionaltask.size 参数，使其大于等于 product_info 和 province_info 之和。&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join.noconditionaltask.size=25286076;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;这样可直接将两个 Common Join operator 转为两个 Map Join operator，并且由于两个 Map Join operator 的小表大小之和小于等于 hive.auto.convert.join.noconditionaltask.size，故两个 Map Join operator 任务可合并为同一个。这个方案计算效率最高，但需要的内存也是最多的。&lt;/p&gt;
&lt;p&gt;调整完的执行计划如下图：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-11.png&#34;
	width=&#34;334&#34;
	height=&#34;805&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-11_hu_d1095692a79431fe.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-11_hu_7607218a1c33454a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;41&#34;
		data-flex-basis=&#34;99px&#34;
	
&gt;
&lt;strong&gt;方案三：&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;启用 Map Join 自动转换。&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join=true;&lt;/p&gt;
&lt;p&gt;使用无条件转 Map Join。&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join.noconditionaltask=true;&lt;/p&gt;
&lt;p&gt;调整 hive.auto.convert.join.noconditionaltask.size 参数，使其等于 product_info。&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join.noconditionaltask.size=25285707;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;这样可直接将两个 Common Join operator 转为 Map Join operator，但不会将两个 Map Join 的任务合并。该方案计算效率比方案二低，但需要的内存也更少。
调整完的执行计划如下图：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-12.png&#34;
	width=&#34;191&#34;
	height=&#34;1408&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-12_hu_c31777942e896c7e.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-12_hu_10df58072d93e378.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;13&#34;
		data-flex-basis=&#34;32px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;bucket-map-join&#34;&gt;&lt;a href=&#34;#bucket-map-join&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Bucket Map Join
&lt;/h3&gt;&lt;h4 id=&#34;原理-2&#34;&gt;&lt;a href=&#34;#%e5%8e%9f%e7%90%86-2&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;原理
&lt;/h4&gt;&lt;p&gt;Bucket Map Join 是对 Map Join 算法的改进，其打破了 Map Join 只适用于大表 join 小表的限制，可用于大表 join 大表的场景。分桶其实就是把大表化成了“小表”，然后 Map-Side Join 解决。&lt;/p&gt;
&lt;p&gt;Bucket Map Join 的核心思想是：若能保证参与 join 的表均为分桶表，且关联字段为分桶字段，且其中一张表的分桶数量是另外一张表分桶数量的整数倍，就能保证参与 join 的两张表的分桶之间具有明确的关联关系，所以就可以在两表的分桶间进行 Map Join 操作了。这样一来，第二个 Job 的 Map 端就无需再缓存小表的全表数据了，而只需缓存其所需的分桶即可。其原理如图所示：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-13.png&#34;
	width=&#34;1235&#34;
	height=&#34;705&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-13_hu_cb5f7dc2b3847456.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-13_hu_f86c97fcd542db0d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;175&#34;
		data-flex-basis=&#34;420px&#34;
	
&gt;
第一个 map 对较小的表 tableB 的每个 bucket 序列化成 hash table，上传到 hdfs cache 中，第二个 map 对较大的表 tableA 的每个桶单独切片，有几个桶就有几个 mapper&lt;/p&gt;
&lt;h4 id=&#34;优化-1&#34;&gt;&lt;a href=&#34;#%e4%bc%98%e5%8c%96-1&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;优化
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;hint 提示&lt;/strong&gt;
Bucket Map Join 不支持自动转换，啊！原来是 hive 团队在 hive2.x 已经放弃维护 MR 计算引擎，建议使用 spark 等计算引擎（看到这乐死我了 tmd 白学了）。
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-14.png&#34;
	width=&#34;2160&#34;
	height=&#34;190&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-14_hu_aa3268172124e9c2.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-14_hu_ef09d34419541475.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;1136&#34;
		data-flex-basis=&#34;2728px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;参数：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&amp;ndash;关闭 cbo 优化，cbo 会导致 hint 信息被忽略&lt;/p&gt;
&lt;p&gt;set hive.cbo.enable=false;&lt;/p&gt;
&lt;p&gt;&amp;ndash;map join hint 默认会被忽略(因为已经过时)，需将如下参数设置为 false&lt;/p&gt;
&lt;p&gt;set hive.ignore.mapjoin.hint=false;&lt;/p&gt;
&lt;p&gt;&amp;ndash;启用 bucket map join 优化功能&lt;/p&gt;
&lt;p&gt;set hive.optimize.bucketmapjoin = true;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;优化案例-1&#34;&gt;&lt;a href=&#34;#%e4%bc%98%e5%8c%96%e6%a1%88%e4%be%8b-1&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;优化案例
&lt;/h4&gt;&lt;p&gt;hive (default)&amp;gt; select _ from( select _ from order_detail where dt=&amp;lsquo;2020-06-14&amp;rsquo;) od&lt;/p&gt;
&lt;p&gt;join( select * from payment_detail where dt=&amp;lsquo;2020-06-14&amp;rsquo;) pd on od.id=pd.order_detail_id;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;优化前&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;上述 SQL 语句共有两张表一次 join 操作，故优化前的执行计划应包含一个 Common Join 任务，通过一个 MapReduce Job 实现。执行计划如下图所示：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-15.png&#34;
	width=&#34;556&#34;
	height=&#34;1002&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-15_hu_d6b5c402d156a695.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-15_hu_3ccb68d6dbe1bffb.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;55&#34;
		data-flex-basis=&#34;133px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;优化思路&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;经分析，参与 join 的两张表，数据量如下。
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-16.png&#34;
	width=&#34;1467&#34;
	height=&#34;301&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-16_hu_86b016ba9c62bbb1.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-16_hu_b55ec376440037ac.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;487&#34;
		data-flex-basis=&#34;1169px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;两张表都相对较大，若采用普通的 Map Join 算法，则 Map 端需要较多的内存来缓存数据，可以选择为 Map 段分配更多的内存，来保证任务运行成功。但是，Map 端的内存不可能无上限的分配，所以当参与 Join 的表数据量均过大时，可以考虑采用 Bucket Map Join 算法。&lt;/p&gt;
&lt;p&gt;创建两个分桶表，order_detail 建议分 16 个 bucket，payment_detail 建议分 8 个 bucket,注意分桶个数的倍数关系以及分桶字段。然后向其中导入数据。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;设置优化参数：&lt;/p&gt;
&lt;p&gt;&amp;ndash;关闭 cbo 优化，cbo 会导致 hint 信息被忽略，需将如下参数修改为 false&lt;/p&gt;
&lt;p&gt;set hive.cbo.enable=false;&lt;/p&gt;
&lt;p&gt;&amp;ndash;map join hint 默认会被忽略(因为已经过时)，需将如下参数修改为 false&lt;/p&gt;
&lt;p&gt;set hive.ignore.mapjoin.hint=false;&lt;/p&gt;
&lt;p&gt;&amp;ndash;启用 bucket map join 优化功能,默认不启用，需将如下参数修改为 true&lt;/p&gt;
&lt;p&gt;set hive.optimize.bucketmapjoin = true;&lt;/p&gt;
&lt;p&gt;重写 SQL 语句：&lt;/p&gt;
&lt;p&gt;hive (default)&amp;gt;&lt;/p&gt;
&lt;p&gt;select /_+ mapjoin(pd) _/ * from order_detail_bucketed od&lt;/p&gt;
&lt;p&gt;join payment_detail_bucketed pd on od.id = pd.order_detail_id;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;执行结果如下：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-17.png&#34;
	width=&#34;256&#34;
	height=&#34;1015&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-17_hu_2ff263283659683b.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-17_hu_557c941ca036804f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;25&#34;
		data-flex-basis=&#34;60px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;使用&lt;/p&gt;
&lt;p&gt;hive (default)&amp;gt;&lt;/p&gt;
&lt;p&gt;explain extended select /_+ mapjoin(pd) _/ *&lt;/p&gt;
&lt;p&gt;from order_detail_bucketed od&lt;/p&gt;
&lt;p&gt;join payment_detail_bucketed pd on od.id = pd.order_detail_id;查看执行计划，在 Map Join Operator 中看到 “BucketMapJoin: true”&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;sort-merge-bucket-map-joinsmb-map-join&#34;&gt;&lt;a href=&#34;#sort-merge-bucket-map-joinsmb-map-join&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Sort Merge Bucket Map Join(SMB map join)
&lt;/h3&gt;&lt;h4 id=&#34;原理-3&#34;&gt;&lt;a href=&#34;#%e5%8e%9f%e7%90%86-3&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;原理
&lt;/h4&gt;&lt;p&gt;SMB Map Join 基于 Bucket Map Join。SMB Map Join 要求，参与 join 的表均为分桶表，且需保证分桶内的数据是有序的，且分桶字段、排序字段和关联字段为相同字段，且其中一张表的分桶数量是另外一张表分桶数量的整数倍。&lt;/p&gt;
&lt;p&gt;SMB Map Join 同 Bucket Join 一样，同样是利用两表各分桶之间的关联关系，在分桶之间进行 join 操作，不同的是，分桶之间的 join 操作的实现原理。Bucket Map Join，两个分桶之间的 join 实现原理为 Hash Join 算法；而 SMB Map Join，两个分桶之间的 join 实现原理为 Sort Merge Join 算法。&lt;/p&gt;
&lt;p&gt;Hash Join 和 Sort Merge Join 均为关系型数据库中常见的 Join 实现算法。Hash Join 的原理相对简单，就是对参与 join 的一张表构建 hash table，然后扫描另外一张表，然后进行逐行匹配。Sort Merge Join 需要在两张按照关联字段排好序的表中进行，其原理如图所示：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-18.png&#34;
	width=&#34;1234&#34;
	height=&#34;709&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-18_hu_cd814555b30c2367.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-18_hu_7676e8dcb67afaab.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;174&#34;
		data-flex-basis=&#34;417px&#34;
	
&gt;
Hive 中的 SMB Map Join 就是对两个分桶的数据按照上述思路进行 Join 操作。可以看出，SMB Map Join 与 Bucket Map Join 相比，在进行 Join 操作时，Map 端是无需对整个 Bucket 构建 hash table，也无需在 Map 端缓存整个 Bucket 数据的，每个 Mapper 只需按顺序逐个 key 读取两个分桶的数据进行 join 即可。&lt;/p&gt;
&lt;h4 id=&#34;优化-2&#34;&gt;&lt;a href=&#34;#%e4%bc%98%e5%8c%96-2&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;优化
&lt;/h4&gt;&lt;p&gt;Sort Merge Bucket Map Join 有两种触发方式，包括 Hint 提示和自动转换。Hint 提示已过时，不推荐使用。下面是自动转换的相关参数：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ndash;启动 Sort Merge Bucket Map Join 优化&lt;/p&gt;
&lt;p&gt;set hive.optimize.bucketmapjoin.sortedmerge=true;&lt;/p&gt;
&lt;p&gt;&amp;ndash;使用自动转换 SMB Join&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.sortmerge.join=true;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;和 bucket map join 一样，创建分桶表并导入数据 ，设置参数，运行 HQL，结果如下：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-19.png&#34;
	width=&#34;317&#34;
	height=&#34;654&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-19_hu_9e5a0b4b5771431a.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-19_hu_a812c6d9b6d4878f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;48&#34;
		data-flex-basis=&#34;116px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;数据倾斜优化&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e6%8d%ae%e5%80%be%e6%96%9c%e4%bc%98%e5%8c%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;数据倾斜优化
&lt;/h2&gt;&lt;p&gt;数据倾斜问题，通常是指参与计算的数据分布不均，即某个 key 或者某些 key 的数据量远超其他 key，导致在 shuffle 阶段，大量相同 key 的数据被发往同一个 Reduce，进而导致该 Reduce 所需的时间远超其他 Reduce，成为整个任务的瓶颈。&lt;/p&gt;
&lt;p&gt;Hive 中的数据倾斜常出现在分组聚合和 join 操作的场景中，下面分别介绍在上述两种场景下的优化思路。&lt;/p&gt;
&lt;h3 id=&#34;分组聚合导致的数据倾斜&#34;&gt;&lt;a href=&#34;#%e5%88%86%e7%bb%84%e8%81%9a%e5%90%88%e5%af%bc%e8%87%b4%e7%9a%84%e6%95%b0%e6%8d%ae%e5%80%be%e6%96%9c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;分组聚合导致的数据倾斜
&lt;/h3&gt;&lt;p&gt;Hive 中未经优化的分组聚合，是通过一个 MapReduce Job 实现的。Map 端负责读取数据，并按照分组字段分区，通过 Shuffle，将数据发往 Reduce 端，各组数据在 Reduce 端完成最终的聚合运算。&lt;/p&gt;
&lt;p&gt;如果 group by 分组字段的值分布不均，就可能导致大量相同的 key 进入同一 Reduce，从而导致数据倾斜问题。&lt;/p&gt;
&lt;p&gt;由分组聚合导致的数据倾斜问题，有以下两种解决思路：&lt;/p&gt;
&lt;h4 id=&#34;map-side-聚合&#34;&gt;&lt;a href=&#34;#map-side-%e8%81%9a%e5%90%88&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Map-Side 聚合
&lt;/h4&gt;&lt;p&gt;前文提过，此处略过&lt;/p&gt;
&lt;h4 id=&#34;skew-groupby-优化&#34;&gt;&lt;a href=&#34;#skew-groupby-%e4%bc%98%e5%8c%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Skew-GroupBy 优化
&lt;/h4&gt;&lt;p&gt;原理是启动两个 MR 任务，第一个 MR 按照随机数分区，将数据分散发送到 Reduce，完成部分聚合，第二个 MR 把打散的数据按照分组字段分区，完成最终聚合。&lt;/p&gt;
&lt;h5 id=&#34;优化前&#34;&gt;&lt;a href=&#34;#%e4%bc%98%e5%8c%96%e5%89%8d&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;优化前
&lt;/h5&gt;&lt;p&gt;该表数据中的 province_id 字段是存在倾斜的，若不经过优化，通过观察任务的执行过程，是能够看出数据倾斜现象的。
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-20.png&#34;
	width=&#34;869&#34;
	height=&#34;245&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-20_hu_4c7b5ee5d955b18c.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-20_hu_4bd4157092ae801d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;354&#34;
		data-flex-basis=&#34;851px&#34;
	
&gt;&lt;/p&gt;
&lt;h5 id=&#34;优化后&#34;&gt;&lt;a href=&#34;#%e4%bc%98%e5%8c%96%e5%90%8e&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;优化后
&lt;/h5&gt;&lt;blockquote&gt;
&lt;p&gt;&amp;ndash;启用 skew-groupby&lt;/p&gt;
&lt;p&gt;set hive.groupby.skewindata=true;&lt;/p&gt;
&lt;p&gt;&amp;ndash;关闭 map-side 聚合（map side 聚合默认是开启的）&lt;/p&gt;
&lt;p&gt;set hive.map.aggr=false;&lt;/p&gt;
&lt;p&gt;开启 Skew-GroupBy 优化后，可以很明显看到该 sql 执行在 yarn 上启动了两个 mr 任务，第一个 mr 打散数据，第二个 mr 把打散后的数据进行分组聚合。
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-21.png&#34;
	width=&#34;869&#34;
	height=&#34;204&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-21_hu_a9f85e157a440921.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-21_hu_41134c8a7aa5bf1f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;425&#34;
		data-flex-basis=&#34;1022px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;join-导致的数据倾斜&#34;&gt;&lt;a href=&#34;#join-%e5%af%bc%e8%87%b4%e7%9a%84%e6%95%b0%e6%8d%ae%e5%80%be%e6%96%9c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Join 导致的数据倾斜
&lt;/h3&gt;&lt;p&gt;未经优化的 join 操作，默认是使用 common join 算法，也就是通过一个 MapReduce Job 完成计算。Map 端负责读取 join 操作所需表的数据，并按照关联字段进行分区，通过 Shuffle，将其发送到 Reduce 端，相同 key 的数据在 Reduce 端完成最终的 Join 操作。&lt;/p&gt;
&lt;p&gt;如果关联字段的值分布不均，就可能导致大量相同的 key 进入同一 Reduce，从而导致数据倾斜问题。由 join 导致的数据倾斜问题，有如下三种解决方案：&lt;/p&gt;
&lt;h4 id=&#34;map-join-1&#34;&gt;&lt;a href=&#34;#map-join-1&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;map join
&lt;/h4&gt;&lt;p&gt;略过&lt;/p&gt;
&lt;h4 id=&#34;skew-join&#34;&gt;&lt;a href=&#34;#skew-join&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;skew join
&lt;/h4&gt;&lt;p&gt;原理是为倾斜的大 key 单独启动一个 map join 任务进行计算，其余 key 进行正常的 common join。原理图如下：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-22.png&#34;
	width=&#34;865&#34;
	height=&#34;453&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-22_hu_56fdabed3e095d99.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-22_hu_ce6b8a273fee43e9.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;190&#34;
		data-flex-basis=&#34;458px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ndash;启用 skew join 优化&lt;/p&gt;
&lt;p&gt;set hive.optimize.skewjoin=true;&lt;/p&gt;
&lt;p&gt;&amp;ndash;触发 skew join 的阈值，若某个 key 的行数超过该参数值，则触发&lt;/p&gt;
&lt;p&gt;set hive.skewjoin.key=100000;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;这种方案对参与 join 的源表大小没有要求，但是对两表中倾斜的 key 的数据量有要求，要求一张表中的倾斜 key 的数据量比较小（方便走 map join）。&lt;/p&gt;
&lt;h2 id=&#34;任务并行度优化&#34;&gt;&lt;a href=&#34;#%e4%bb%bb%e5%8a%a1%e5%b9%b6%e8%a1%8c%e5%ba%a6%e4%bc%98%e5%8c%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;任务并行度优化
&lt;/h2&gt;&lt;p&gt;Hive 的计算任务由 MapReduce 完成，故并行度的调整需要分为 Map 端和 Reduce 端。&lt;/p&gt;
&lt;h3 id=&#34;map-端并行度&#34;&gt;&lt;a href=&#34;#map-%e7%ab%af%e5%b9%b6%e8%a1%8c%e5%ba%a6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Map 端并行度
&lt;/h3&gt;&lt;p&gt;Map 端的并行度，也就是 Map 的个数。是由输入文件的切片数决定的。一般情况下，Map 端的并行度无需手动调整。&lt;/p&gt;
&lt;p&gt;以下特殊情况可考虑调整 map 端并行度：
&lt;strong&gt;1）查询的表中存在大量小文件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;按照 Hadoop 默认的切片策略，一个小文件会单独启动一个 map task 负责计算。若查询的表中存在大量小文件，则会启动大量 map task，造成计算资源的浪费。这种情况下，可以使用 Hive 提供的 CombineHiveInputFormat，多个小文件合并为一个切片，从而控制 map task 个数。相关参数如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;2）map 端有复杂的查询逻辑&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;若 SQL 语句中有正则替换、json 解析等复杂耗时的查询逻辑时，map 端的计算会相对慢一些。若想加快计算速度，在计算资源充足的情况下，可考虑增大 map 端的并行度，令 map task 多一些，每个 map task 计算的数据少一些。相关参数如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ndash;一个切片的最大值&lt;/p&gt;
&lt;p&gt;set mapreduce.input.fileinputformat.split.maxsize=256000000;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;reduce-端并行度&#34;&gt;&lt;a href=&#34;#reduce-%e7%ab%af%e5%b9%b6%e8%a1%8c%e5%ba%a6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Reduce 端并行度
&lt;/h3&gt;&lt;p&gt;Reduce 端的并行度，可由用户自己指定，也可由 Hive 自行根据该 MR Job 输入的文件大小进行估算。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Reduce 端的并行度的相关参数如下：&lt;/p&gt;
&lt;p&gt;&amp;ndash;指定 Reduce 端并行度，默认值为-1，表示用户未指定&lt;/p&gt;
&lt;p&gt;set mapreduce.job.reduces;&lt;/p&gt;
&lt;p&gt;&amp;ndash;Reduce 端并行度最大值&lt;/p&gt;
&lt;p&gt;set hive.exec.reducers.max;&lt;/p&gt;
&lt;p&gt;&amp;ndash;单个 Reduce Task 计算的数据量，用于估算 Reduce 并行度&lt;/p&gt;
&lt;p&gt;set hive.exec.reducers.bytes.per.reducer;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Reduce 端并行度的确定逻辑如下：&lt;/p&gt;
&lt;p&gt;若指定参数 mapreduce.job.reduces 的值为一个非负整数，则 Reduce 并行度为指定值。否则，Hive 自行估算 Reduce 并行度，估算逻辑如下：&lt;/p&gt;
&lt;p&gt;假设 Job 输入的文件大小为 totalInputBytes&lt;/p&gt;
&lt;p&gt;参数 hive.exec.reducers.bytes.per.reducer 的值为 bytesPerReducer。&lt;/p&gt;
&lt;p&gt;参数 hive.exec.reducers.max 的值为 maxReducers。&lt;/p&gt;
&lt;p&gt;则 Reduce 端的并行度为：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-23.png&#34;
	width=&#34;638&#34;
	height=&#34;98&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-23_hu_21010bf6e8750fb7.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-23_hu_4938c6195bbe484e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;651&#34;
		data-flex-basis=&#34;1562px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;根据上述描述，可以看出，Hive 自行估算 Reduce 并行度时，是以整个 MR Job 输入的文件大小作为依据的。因此，在某些情况下其估计的并行度很可能并不准确，此时就需要用户根据实际情况来指定 Reduce 并行度了。&lt;/p&gt;
&lt;p&gt;在默认情况下，是会进行 map-side 聚合的，也就是 Reduce 端接收的数据，实际上是 map 端完成聚合之后的结果。观察任务的执行过程，会发现，每个 map 端输出的数据只有 34 条记录，共有 5 个 map task。
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-24.png&#34;
	width=&#34;869&#34;
	height=&#34;374&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-24_hu_f3c3a8909f90ec92.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-24_hu_8d200be734c58711.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;232&#34;
		data-flex-basis=&#34;557px&#34;
	
&gt;
也就是说 Reduce 端实际只会接收 170（34*5）条记录，故理论上 Reduce 端并行度设置为 1 就足够了。这种情况下，用户可通过以下参数，自行设置 Reduce 端并行度为 1，这样把 5 个文件合并为只输出 1 个文件。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ndash;指定 Reduce 端并行度，默认值为-1，表示用户未指定&lt;/p&gt;
&lt;p&gt;set mapreduce.job.reduces=1;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;小文件合并优化&#34;&gt;&lt;a href=&#34;#%e5%b0%8f%e6%96%87%e4%bb%b6%e5%90%88%e5%b9%b6%e4%bc%98%e5%8c%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;小文件合并优化
&lt;/h2&gt;&lt;p&gt;Map 端输入的小文件合并，和 Reduce 端输出的小文件合并。&lt;/p&gt;
&lt;h3 id=&#34;合并-map-端输入的小文件&#34;&gt;&lt;a href=&#34;#%e5%90%88%e5%b9%b6-map-%e7%ab%af%e8%be%93%e5%85%a5%e7%9a%84%e5%b0%8f%e6%96%87%e4%bb%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;合并 Map 端输入的小文件
&lt;/h3&gt;&lt;p&gt;将多个小文件划分到一个切片中，进而由一个 Map Task 去处理。目的是防止为单个小文件启动一个 Map Task，浪费计算资源。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;相关参数为：&lt;/p&gt;
&lt;p&gt;&amp;ndash;可将多个小文件切片，合并为一个切片，进而由一个 map 任务处理（默认）
set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;合并-reduce-端输出的小文件&#34;&gt;&lt;a href=&#34;#%e5%90%88%e5%b9%b6-reduce-%e7%ab%af%e8%be%93%e5%87%ba%e7%9a%84%e5%b0%8f%e6%96%87%e4%bb%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;合并 Reduce 端输出的小文件
&lt;/h3&gt;&lt;p&gt;将多个小文件合并成大文件。目的是减少 HDFS 小文件数量。其原理是根据计算任务输出文件的平均大小进行判断，若符合条件，则单独启动 1 个额外的任务进行合并。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;相关参数为：&lt;/p&gt;
&lt;p&gt;&amp;ndash;开启合并 map only 任务输出的小文件，默认 false&lt;/p&gt;
&lt;p&gt;set hive.merge.mapfiles=true;&lt;/p&gt;
&lt;p&gt;&amp;ndash;开启合并 map reduce 任务输出的小文件，默认 false&lt;/p&gt;
&lt;p&gt;set hive.merge.mapredfiles=true;&lt;/p&gt;
&lt;p&gt;&amp;ndash;合并后的文件大小&lt;/p&gt;
&lt;p&gt;set hive.merge.size.per.task=256000000;&lt;/p&gt;
&lt;p&gt;&amp;ndash;触发小文件合并任务的阈值，若某计算任务输出的文件平均大小低于该值，则触发合并&lt;/p&gt;
&lt;p&gt;set hive.merge.smallfiles.avgsize=16000000;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;若 reduce 端设置并行度为 5，则输出 5 个文件。下图为输出文件，可以看出，5 个均为小文件：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-25.png&#34;
	width=&#34;869&#34;
	height=&#34;379&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-25_hu_87c8501899639239.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-25_hu_19398f78240c4efd.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;229&#34;
		data-flex-basis=&#34;550px&#34;
	
&gt;
要避免 5 个小文件产生，可以设置 reduce 端并行度为 1，有几个 reduce 并行就有几个文件产生，保证其输出结果只有一个文件或启用 hive 合并小文件优化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;启用 Hive 合并小文件优化&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;设置以下参数：&lt;/p&gt;
&lt;p&gt;&amp;ndash;开启合并 map reduce 任务输出的小文件&lt;/p&gt;
&lt;p&gt;set hive.merge.mapredfiles=true;&lt;/p&gt;
&lt;p&gt;&amp;ndash;合并后的文件大小&lt;/p&gt;
&lt;p&gt;set hive.merge.size.per.task=256000000;&lt;/p&gt;
&lt;p&gt;&amp;ndash;触发小文件合并任务的阈值，若某计算任务输出的文件平均大小低于该值，则触发合并&lt;/p&gt;
&lt;p&gt;set hive.merge.smallfiles.avgsize=16000000;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;这样输出文件就合并为一个了
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-26.png&#34;
	width=&#34;869&#34;
	height=&#34;303&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-26_hu_7e0b9aa0a00b8312.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-26_hu_3d9e91230e8317b1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;286&#34;
		data-flex-basis=&#34;688px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;其他优化&#34;&gt;&lt;a href=&#34;#%e5%85%b6%e4%bb%96%e4%bc%98%e5%8c%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;其他优化
&lt;/h2&gt;&lt;h3 id=&#34;cbo-优化&#34;&gt;&lt;a href=&#34;#cbo-%e4%bc%98%e5%8c%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;CBO 优化
&lt;/h3&gt;&lt;p&gt;CBO 是指 Cost based Optimizer，即基于计算成本的优化。&lt;/p&gt;
&lt;p&gt;在 Hive 中，计算成本模型考虑到了：数据的行数、CPU、本地 IO、HDFS IO、网络 IO 等方面。Hive 会计算同一 SQL 语句的不同执行计划的计算成本，并选出成本最低的执行计划。目前 CBO 在 hive 的 MR 引擎下主要用于 join 的优化，例如多表 join 的 join 顺序。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;相关参数为：&lt;/p&gt;
&lt;p&gt;&amp;ndash;是否启用 cbo 优化&lt;/p&gt;
&lt;p&gt;set hive.cbo.enable=true;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;1）示例 HQL&lt;/p&gt;
&lt;p&gt;hive (default)&amp;gt; select * from order_detail od&lt;/p&gt;
&lt;p&gt;join product_info product on od.product_id=product.id&lt;/p&gt;
&lt;p&gt;join province_info province on od.province_id=province.id;&lt;/p&gt;
&lt;p&gt;2）关闭 CBO 优化&lt;/p&gt;
&lt;p&gt;&amp;ndash;关闭 cbo 优化&lt;/p&gt;
&lt;p&gt;set hive.cbo.enable=false;&lt;/p&gt;
&lt;p&gt;&amp;ndash;为了测试效果更加直观，关闭 map join 自动转换&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join=false;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;根据执行计划，可以看出，三张表的 join 顺序如下：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-27.png&#34;
	width=&#34;660&#34;
	height=&#34;294&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-27_hu_40e2f0ee95980f6.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-27_hu_1e3b627e737906da.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;224&#34;
		data-flex-basis=&#34;538px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;3）开启 CBO 优化&lt;/p&gt;
&lt;p&gt;&amp;ndash;开启 cbo 优化&lt;/p&gt;
&lt;p&gt;set hive.cbo.enable=true;&lt;/p&gt;
&lt;p&gt;&amp;ndash;为了测试效果更加直观，关闭 map join 自动转换&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join=false;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;根据执行计划，可以看出，三张表的 join 顺序如下：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-28.png&#34;
	width=&#34;669&#34;
	height=&#34;298&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-28_hu_7ceeab9ab8aa26e.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-28_hu_45dd3c1250222a77.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;224&#34;
		data-flex-basis=&#34;538px&#34;
	
&gt;
CBO 优化对于执行计划中 join 顺序是有影响的，其之所以会将 province_info 的 join 顺序提前，是因为 province info 的数据量较小，将其提前，会有更大的概率使得中间结果的数据量变小，从而使整个计算任务的数据量减小，也就是使计算成本变小。&lt;/p&gt;
&lt;h3 id=&#34;谓词下推&#34;&gt;&lt;a href=&#34;#%e8%b0%93%e8%af%8d%e4%b8%8b%e6%8e%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;谓词下推
&lt;/h3&gt;&lt;p&gt;谓词下推（predicate pushdown）是指，尽量将过滤操作前移，以减少后续计算步骤的数据量。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;相关参数为：&lt;/p&gt;
&lt;p&gt;&amp;ndash;是否启动谓词下推（predicate pushdown）优化&lt;/p&gt;
&lt;p&gt;set hive.optimize.ppd = true;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;需要注意的是：CBO 优化也会完成一部分的谓词下推优化工作，因为在执行计划中，谓词越靠前，整个计划的计算成本就会越低。
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-29.png&#34;
	width=&#34;684&#34;
	height=&#34;568&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-29_hu_e70a14f380e3cc42.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-29_hu_87d64db6b104c96b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;120&#34;
		data-flex-basis=&#34;289px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;矢量化查询&#34;&gt;&lt;a href=&#34;#%e7%9f%a2%e9%87%8f%e5%8c%96%e6%9f%a5%e8%af%a2&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;矢量化查询
&lt;/h3&gt;&lt;p&gt;Hive 的矢量化查询优化，依赖于 CPU 的矢量化计算，CPU 的矢量化计算的基本原理如下图：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-30.png&#34;
	width=&#34;960&#34;
	height=&#34;540&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-30_hu_e362fffa2298c231.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-30_hu_aeb22a57936a7ac0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;相关参数如下：&lt;/p&gt;
&lt;p&gt;set hive.vectorized.execution.enabled=true;&lt;/p&gt;
&lt;p&gt;若执行计划中，出现“Execution mode: vectorized”字样，即表明使用了矢量化计算。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;fetch-抓取&#34;&gt;&lt;a href=&#34;#fetch-%e6%8a%93%e5%8f%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Fetch 抓取
&lt;/h3&gt;&lt;p&gt;Fetch 抓取是指，Hive 中对某些情况的查询可以不必使用 MapReduce 计算。例如：select * from emp;在这种情况下，Hive 可以简单地读取 emp 对应的存储目录下的文件，然后输出查询结果到控制台。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;相关参数如下：&lt;/p&gt;
&lt;p&gt;&amp;ndash;是否在特定场景转换为 fetch 任务&lt;/p&gt;
&lt;p&gt;&amp;ndash;设置为 none 表示不转换&lt;/p&gt;
&lt;p&gt;&amp;ndash;设置为 minimal 表示支持 select *，分区字段过滤，Limit 等&lt;/p&gt;
&lt;p&gt;&amp;ndash;设置为 more 表示支持 select 任意字段,包括函数，过滤，和 limit 等&lt;/p&gt;
&lt;p&gt;set hive.fetch.task.conversion=more;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;本地模式&#34;&gt;&lt;a href=&#34;#%e6%9c%ac%e5%9c%b0%e6%a8%a1%e5%bc%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;本地模式
&lt;/h3&gt;&lt;p&gt;大多数的 Hadoop Job 是需要 Hadoop 提供的完整的可扩展性来处理大数据集的。不过，有时 Hive 的输入数据量是非常小的。在这种情况下，为查询触发执行任务消耗的时间可能会比实际 job 的执行时间要多的多。对于大多数这种情况，Hive 可以通过本地模式在单台机器上处理所有的任务，不必提交到 Yarn。对于小数据集，执行时间可以明显被缩短。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;相关参数如下：&lt;/p&gt;
&lt;p&gt;&amp;ndash;开启自动转换为本地模式&lt;/p&gt;
&lt;p&gt;set hive.exec.mode.local.auto=true;&lt;/p&gt;
&lt;p&gt;&amp;ndash;设置 local MapReduce 的最大输入数据量，当输入数据量小于这个值时采用 local MapReduce 的方式，默认为 134217728，即 128M&lt;/p&gt;
&lt;p&gt;set hive.exec.mode.local.auto.inputbytes.max=50000000;&lt;/p&gt;
&lt;p&gt;&amp;ndash;设置 local MapReduce 的最大输入文件个数，当输入文件个数小于这个值时采用 local MapReduce 的方式，默认为 4&lt;/p&gt;
&lt;p&gt;set hive.exec.mode.local.auto.input.files.max=10;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;并行执行&#34;&gt;&lt;a href=&#34;#%e5%b9%b6%e8%a1%8c%e6%89%a7%e8%a1%8c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;并行执行
&lt;/h3&gt;&lt;p&gt;Hive 会将一个 SQL 语句转化成一个或者多个 Stage，每个 Stage 对应一个 MR Job。默认情况下，Hive 同时只会执行一个 Stage。但是某 SQL 语句可能会包含多个 Stage，但这多个 Stage 可能并非完全互相依赖，也就是说有些 Stage 是可以并行执行的。此处提到的并行执行就是指这些 Stage 的并行执行。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;相关参数如下：&lt;/p&gt;
&lt;p&gt;&amp;ndash;启用并行执行优化&lt;/p&gt;
&lt;p&gt;set hive.exec.parallel=true;&lt;/p&gt;
&lt;p&gt;&amp;ndash;同一个 sql 允许最大并行度，默认为 8&lt;/p&gt;
&lt;p&gt;set hive.exec.parallel.thread.number=8;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;严格模式&#34;&gt;&lt;a href=&#34;#%e4%b8%a5%e6%a0%bc%e6%a8%a1%e5%bc%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;严格模式
&lt;/h3&gt;&lt;p&gt;Hive 可以通过设置某些参数防止危险操作：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1）分区表不使用分区过滤&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;将 hive.strict.checks.no.partition.filter 设置为 true 时，对于分区表，除非 where 语句中含有分区字段过滤条件来限制范围，否则不允许执行。换句话说，就是用户不允许扫描所有分区。进行这个限制的原因是，通常分区表都拥有非常大的数据集，而且数据增加迅速。没有进行分区限制的查询可能会消耗令人不可接受的巨大资源来处理这个表。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2）使用 order by 没有 limit 过滤&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;将 hive.strict.checks.orderby.no.limit 设置为 true 时，对于使用了 order by 语句的查询，要求必须使用 limit 语句。因为 order by 为了执行排序过程会将所有的结果数据分发到同一个 Reduce 中进行处理，强制要求用户增加这个 limit 语句可以防止 Reduce 额外执行很长一段时间（开启了 limit 可以在数据进入到 Reduce 之前就减少一部分数据）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3）笛卡尔积&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;将 hive.strict.checks.cartesian.product 设置为 true 时，会限制笛卡尔积的查询。对关系型数据库非常了解的用户可能期望在执行 JOIN 查询的时候不使用 ON 语句而是使用 where 语句，这样关系数据库的执行优化器就可以高效地将 WHERE 语句转化成那个 ON 语句。不幸的是，Hive 并不会执行这种优化，因此，如果表足够大，那么这个查询就会出现不可控的情况。&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
