<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>大数据 on 青秋博客</title>
        <link>/zh-cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/</link>
        <description>Recent content in 大数据 on 青秋博客</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>青秋博客</copyright>
        <lastBuildDate>Thu, 05 Sep 2024 23:07:21 +0000</lastBuildDate><atom:link href="/zh-cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>一文搞懂大数据流式计算引擎Flink【万字详解，史上最全】</title>
        <link>/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8Eflink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/</link>
        <pubDate>Thu, 05 Sep 2024 23:07:21 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8Eflink%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8/</guid>
        <description>&lt;blockquote&gt;
&lt;h2 id=&#34;往期推荐-e5be80e69c9fe68ea8e88d90&#34;&gt;&lt;a href=&#34;#%e5%be%80%e6%9c%9f%e6%8e%a8%e8%8d%90-e5be80e69c9fe68ea8e88d90&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;往期推荐 {#%E5%BE%80%E6%9C%9F%E6%8E%A8%E8%8D%90}
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/141861919&#34;  title=&#34;一文入门大数据准流式计算引擎Spark【万字详解，全网最新】-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;一文入门大数据准流式计算引擎Spark【万字详解，全网最新】-CSDN博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/140787541&#34;  title=&#34;浅谈维度建模、数据分析模型，何为数据仓库，与数据库的区别_统一数仓 数据库用户名-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;浅谈维度建模、数据分析模型，何为数据仓库，与数据库的区别_统一数仓 数据库用户名-CSDN博客&lt;/a&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/141761563&#34;  title=&#34;数仓架构：离线数仓、实时数仓Lambda和Kappa、湖仓一体数据湖-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;数仓架构：离线数仓、实时数仓Lambda和Kappa、湖仓一体数据湖-CSDN博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/140786773&#34;  title=&#34;数仓分层ODS、DWD、DWM、DWS、DIM、DM、ADS_ods dwd dws ads dm-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;数仓分层ODS、DWD、DWM、DWS、DIM、DM、ADS_ods dwd dws ads dm-CSDN博客&lt;/a&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/140787541&#34;  title=&#34;浅谈维度建模、数据分析模型，何为数据仓库，与数据库的区别_统一数仓 数据库用户名-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;浅谈维度建模、数据分析模型，何为数据仓库，与数据库的区别_统一数仓 数据库用户名-CSDN博客&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;目录&lt;/strong&gt;{#main-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#0.%20Flink%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1&#34; &gt;0. Flink知识图谱&lt;/a&gt;{#0.%20Flink%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#1.%C2%A0Flink%E5%8F%91%E5%B1%95&#34; &gt;1. Flink发展&lt;/a&gt;{#1.%C2%A0Flink%E5%8F%91%E5%B1%95-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#1.1%20%E5%9B%9B%E4%BB%A3%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E&#34; &gt;1.1 四代计算引擎&lt;/a&gt;{#1.1%20%E5%9B%9B%E4%BB%A3%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.%20Flink%E7%AE%80%E4%BB%8B&#34; &gt;2. Flink简介&lt;/a&gt;{#2.%20Flink%E7%AE%80%E4%BB%8B-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1%20Flink%E7%89%B9%E7%82%B9%C2%A0&#34; &gt;2.1 Flink特点&lt;/a&gt;{#2.1%20Flink%E7%89%B9%E7%82%B9%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.2%20%E6%89%B9%E5%A4%84%E7%90%86%E5%92%8C%E6%B5%81%E5%A4%84%E7%90%86%C2%A0&#34; &gt;2.2 批处理和流处理&lt;/a&gt;{#2.2%20%E6%89%B9%E5%A4%84%E7%90%86%E5%92%8C%E6%B5%81%E5%A4%84%E7%90%86%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.3%20%E6%9C%89%E7%95%8C%E6%B5%81%E5%92%8C%E6%97%A0%E7%95%8C%E6%B5%81&#34; &gt;2.3 有界流和无界流&lt;/a&gt;{#2.3%20%E6%9C%89%E7%95%8C%E6%B5%81%E5%92%8C%E6%97%A0%E7%95%8C%E6%B5%81-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.4%20Flink%E5%92%8CSpark%20Streaming&#34; &gt;2.4 Flink和Spark Streaming&lt;/a&gt;{#2.4%20Flink%E5%92%8CSpark%20Streaming-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#3.%20Flink%E4%B8%89%E5%B1%82%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84&#34; &gt;3. Flink三层核心架构&lt;/a&gt;{#3.%20Flink%E4%B8%89%E5%B1%82%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#3.1%20API%20%26%20Libraries%E5%B1%82%E8%AF%A6%E8%A7%A3&#34; &gt;3.1 API &amp;amp; Libraries层详解&lt;/a&gt;{#3.1%20API%20%26%20Libraries%E5%B1%82%E8%AF%A6%E8%A7%A3-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#3.1.1%20SQL%26Table%20API%E5%B1%82&#34; &gt;3.1.1 SQL&amp;amp;Table API层&lt;/a&gt;{#3.1.1%20SQL%26Table%20API%E5%B1%82-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#3.1.2%C2%A0DataStream%20%26%20DataSet%20API%E5%B1%82&#34; &gt;3.1.2 DataStream &amp;amp; DataSet API层&lt;/a&gt;{#3.1.2%C2%A0DataStream%20%26%20DataSet%20API%E5%B1%82-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#3.1.3%C2%A0Stateful%20Stream%20Processing%E5%B1%82&#34; &gt;3.1.3 Stateful Stream Processing层&lt;/a&gt;{#3.1.3%C2%A0Stateful%20Stream%20Processing%E5%B1%82-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#4.%20%E4%B8%89%E7%A7%8DTime%E6%A6%82%E5%BF%B5&#34; &gt;4. 三种Time概念&lt;/a&gt;{#4.%20%E4%B8%89%E7%A7%8DTime%E6%A6%82%E5%BF%B5-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#4.1%C2%A0WaterMark%E6%B0%B4%E5%8D%B0&#34; &gt;4.1 WaterMark水印&lt;/a&gt;{#4.1%C2%A0WaterMark%E6%B0%B4%E5%8D%B0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#5.%20Windows%E7%AA%97%E5%8F%A3%E7%B1%BB%E5%9E%8B&#34; &gt;5. Windows窗口类型&lt;/a&gt;{#5.%20Windows%E7%AA%97%E5%8F%A3%E7%B1%BB%E5%9E%8B-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#5.1%20%E6%97%B6%E9%97%B4%E7%AA%97%E5%8F%A3&#34; &gt;5.1 时间窗口&lt;/a&gt;{#5.1%20%E6%97%B6%E9%97%B4%E7%AA%97%E5%8F%A3-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#5.1.1%20%E6%BB%9A%E5%8A%A8%E7%AA%97%E5%8F%A3Tumbling%20Windows&#34; &gt;5.1.1 滚动窗口Tumbling Windows&lt;/a&gt;{#5.1.1%20%E6%BB%9A%E5%8A%A8%E7%AA%97%E5%8F%A3Tumbling%20Windows-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#5.1.2%20%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3Sliding%20Windows&#34; &gt;5.1.2 滑动窗口Sliding Windows&lt;/a&gt;{#5.1.2%20%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3Sliding%20Windows-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#5.1.3%20%E4%BC%9A%E8%AF%9D%E7%AA%97%E5%8F%A3Session%20Windows&#34; &gt;5.1.3 会话窗口Session Windows&lt;/a&gt;{#5.1.3%20%E4%BC%9A%E8%AF%9D%E7%AA%97%E5%8F%A3Session%20Windows-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#5.1.4%20%E5%85%A8%E5%B1%80%E7%AA%97%E5%8F%A3Global%20Windows&#34; &gt;5.1.4 全局窗口Global Windows&lt;/a&gt;{#5.1.4%20%E5%85%A8%E5%B1%80%E7%AA%97%E5%8F%A3Global%20Windows-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#5.2%20%E8%AE%A1%E6%95%B0%E7%AA%97%E5%8F%A3&#34; &gt;5.2 计数窗口&lt;/a&gt;{#5.2%20%E8%AE%A1%E6%95%B0%E7%AA%97%E5%8F%A3-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#6.%20%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86&#34; &gt;6. 状态管理&lt;/a&gt;{#6.%20%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#6.1%C2%A0%E7%8A%B6%E6%80%81%E7%9A%84Flink%E5%AE%98%E6%96%B9%E5%AE%9A%E4%B9%89&#34; &gt;6.1 状态的Flink官方定义&lt;/a&gt;{#6.1%C2%A0%E7%8A%B6%E6%80%81%E7%9A%84Flink%E5%AE%98%E6%96%B9%E5%AE%9A%E4%B9%89-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#6.2%C2%A0%E7%8A%B6%E6%80%81%E5%88%86%E7%B1%BB%E5%8F%8A%E7%8A%B6%E6%80%81%E5%AD%98%E5%82%A8%E7%B1%BB%E5%9E%8B&#34; &gt;6.2 状态分类及状态存储类型&lt;/a&gt;{#6.2%C2%A0%E7%8A%B6%E6%80%81%E5%88%86%E7%B1%BB%E5%8F%8A%E7%8A%B6%E6%80%81%E5%AD%98%E5%82%A8%E7%B1%BB%E5%9E%8B-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#6.2.1%20%E7%AE%97%E5%AD%90%E7%8A%B6%E6%80%81&#34; &gt;6.2.1 算子状态&lt;/a&gt;{#6.2.1%20%E7%AE%97%E5%AD%90%E7%8A%B6%E6%80%81-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#6.2.2%20%E9%94%AE%E6%8E%A7%E7%8A%B6%E6%80%81&#34; &gt;6.2.2 键控状态&lt;/a&gt;{#6.2.2%20%E9%94%AE%E6%8E%A7%E7%8A%B6%E6%80%81-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#6.2.3%C2%A0Broadcast%20State&#34; &gt;6.2.3 Broadcast State&lt;/a&gt;{#6.2.3%C2%A0Broadcast%20State-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#6.3.%20%E7%8A%B6%E6%80%81%E5%90%8E%E7%AB%AF%EF%BC%88%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%EF%BC%89&#34; &gt;6.3. 状态后端（持久化存储）&lt;/a&gt;{#6.3.%20%E7%8A%B6%E6%80%81%E5%90%8E%E7%AB%AF%EF%BC%88%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%EF%BC%89-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#7.%20Flink%E7%AE%97%E5%AD%90&#34; &gt;7. Flink算子&lt;/a&gt;{#7.%20Flink%E7%AE%97%E5%AD%90-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#7.1%20DataSet%E6%89%B9%E5%A4%84%E7%90%86%E7%AE%97%E5%AD%90&#34; &gt;7.1 DataSet批处理算子&lt;/a&gt;{#7.1%20DataSet%E6%89%B9%E5%A4%84%E7%90%86%E7%AE%97%E5%AD%90-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#7.1.1%20Source%E7%AE%97%E5%AD%90&#34; &gt;7.1.1 Source算子&lt;/a&gt;{#7.1.1%20Source%E7%AE%97%E5%AD%90-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#7.1.2%C2%A0Transform%20%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90&#34; &gt;7.1.2 Transform 转换算子&lt;/a&gt;{#7.1.2%C2%A0Transform%20%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#7.1.3%C2%A0Sink%20%E8%BE%93%E5%87%BA%E7%AE%97%E5%AD%90&#34; &gt;7.1.3 Sink 输出算子&lt;/a&gt;{#7.1.3%C2%A0Sink%20%E8%BE%93%E5%87%BA%E7%AE%97%E5%AD%90-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#7.2%20DataStream%E6%B5%81%E5%A4%84%E7%90%86%E7%AE%97%E5%AD%90&#34; &gt;7.2 DataStream流处理算子&lt;/a&gt;{#7.2%20DataStream%E6%B5%81%E5%A4%84%E7%90%86%E7%AE%97%E5%AD%90-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#8.%20Flink%E5%AE%B9%E9%94%99&#34; &gt;8. Flink容错&lt;/a&gt;{#8.%20Flink%E5%AE%B9%E9%94%99-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#8.1%C2%A0Checkpoint%E6%9C%BA%E5%88%B6&#34; &gt;8.1 Checkpoint机制&lt;/a&gt;{#8.1%C2%A0Checkpoint%E6%9C%BA%E5%88%B6-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#9.%20Flink%20CEP&#34; &gt;9. Flink CEP&lt;/a&gt;{#9.%20Flink%20CEP-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#9.1%20%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%C2%A0&#34; &gt;9.1 使用场景&lt;/a&gt;{#9.1%20%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#9.2%C2%A0CEP%20API&#34; &gt;9.2 CEP API&lt;/a&gt;{#9.2%C2%A0CEP%20API-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#10.%20Flink%20CDC&#34; &gt;10. Flink CDC&lt;/a&gt;{#10.%20Flink%20CDC-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#10.1%20CDC%E7%A7%8D%E7%B1%BB&#34; &gt;10.1 CDC种类&lt;/a&gt;{#10.1%20CDC%E7%A7%8D%E7%B1%BB-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#11.%20Flink%20SQL&#34; &gt;11. Flink SQL&lt;/a&gt;{#11.%20Flink%20SQL-toc}&lt;/p&gt;
&lt;hr&gt;
&lt;ol start=&#34;0&#34;&gt;
&lt;li&gt;Flink知识图谱&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/direct/6d8c45618d4c4585b10441448471b332.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Flink发展 {#1.%C2%A0Flink%E5%8F%91%E5%B1%95}&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;Apache Flink 诞生于柏林工业大学的一个研究性项目，&lt;strong&gt;原名 StratoSphere&lt;/strong&gt; 。2014 年，由 StratoSphere 项目孵化出 Flink，并于同年捐赠 Apache，之后成为 Apache 的顶级项目。2019 年 1 年，&lt;strong&gt;阿里巴巴收购了 Flink 的母公司 Data Artisans，并宣布开源内部的 Blink&lt;/strong&gt;，Blink 是阿里巴巴基于 Flink 优化后的版本，增加了大量的新功能，并在性能和稳定性上进行了各种优化，经历过阿里内部多种复杂业务的挑战和检验。同时阿里巴巴也表示会逐步将这些新功能和特性 Merge 回社区版本的 Flink 中，因此 Flink 成为目前最为火热的大数据处理框架。&lt;/p&gt;
&lt;h3 id=&#34;11-四代计算引擎-1120e59b9be4bba3e8aea1e7ae97e5bc95e6938e&#34;&gt;&lt;a href=&#34;#11-%e5%9b%9b%e4%bb%a3%e8%ae%a1%e7%ae%97%e5%bc%95%e6%93%8e-1120e59b9be4bba3e8aea1e7ae97e5bc95e6938e&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;1.1 四代计算引擎 {#1.1%20%E5%9B%9B%E4%BB%A3%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E}
&lt;/h3&gt;&lt;p&gt;在国外一些社区，有很多人&lt;strong&gt;将大数据的计算引擎分成了 4 代&lt;/strong&gt;，当然，也有很多人不会认同。我们先姑且这么认为和讨论。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先&lt;strong&gt;第一代的计算引擎，无疑就是 Hadoop 承载的 MapReduce&lt;/strong&gt;。这里大家应该都 不会对 MapReduce 陌生，它将计算分为两个阶段，分别为 Map 和 Reduce。对于上层应用来说，就不得不想方设法去拆分算法，甚至于不得不在上层应用实现 多个 Job 的&lt;strong&gt;串联&lt;/strong&gt;，以完成一个完整的算法，例如&lt;strong&gt;迭代计算&lt;/strong&gt; 。 由于这样的弊端，&lt;strong&gt;催生了支持 DAG 框架的产生&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;因此，&lt;strong&gt;支持 DAG 的框架被划分为第二代计算引擎&lt;/strong&gt;。如 Tez 以及更上层的 Oozie。这里我们不去细究各种 DAG 实现之间的区别，不过对于当时的 Tez 和 Oozie 来说，&lt;strong&gt;大多还是批处理的任务&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;接下来就是&lt;strong&gt;以 Spark 为代表的第三代的计算引擎&lt;/strong&gt;。第三代计算引擎的特点主要 是 Job 内部的 DAG 支持（不跨越 Job），以及强调的&lt;strong&gt;准实时计算&lt;/strong&gt;。在这里，很多人也会认为第三代计算引擎也能够很好的运行批处理的 Job。 随着第三代计算引擎的出现，促进了上层应用快速发展，例如各种迭代计算的性能以及对流计算和 SQL 等的支持。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Flink 的诞生就被归在了第四代&lt;/strong&gt;。这应该主 要表现在 Flink 对流计算的支持，以及更一步的实时性上面。当然 Flink 也可 以支持 Batch 的任务，以及 DAG 的运算。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Flink简介 {#2.%20Flink%E7%AE%80%E4%BB%8B}&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Flink 是一个分布式、高性能、&lt;strong&gt;&lt;strong&gt;有状态&lt;/strong&gt;&lt;/strong&gt;的流处理框架&lt;/strong&gt;，它能够对&lt;strong&gt;有界和无界&lt;/strong&gt;的数据流进行高效的处理。Flink 的 **核心是流处理（DataStream），当然也支持批处理（DataSet），Flink 将批处理看成是流处理的一种特殊情况，即数据流是有 明确界限的。**这和 Spark Streaming 的思想是完全相反的，Spark Streaming 的核心是批处理，它将流处理看成是批处理的一种特殊情况， 即把数据流进行极小粒度的拆分，拆分为多个微批处理。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;21-flink特点-2120flinke789b9e782b9c2a0&#34;&gt;&lt;a href=&#34;#21-flink%e7%89%b9%e7%82%b9-2120flinke789b9e782b9c2a0&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;2.1 Flink特点 {#2.1%20Flink%E7%89%B9%E7%82%B9%C2%A0}
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;支持高吞吐、低延迟、高性能的流处理&lt;/li&gt;
&lt;li&gt;结果准确，Flink提供了事件时间和处理时间，对乱序数据仍能提供一直准确的结果&lt;/li&gt;
&lt;li&gt;支持高度灵活的窗口（Window）操作，支持基于 time、count、session， 以及 data-driven 的窗口操作&lt;/li&gt;
&lt;li&gt;支持基于轻量级分布式快照（Snapshot）实现的容错&lt;/li&gt;
&lt;li&gt;一个运行时&lt;strong&gt;同时支持&lt;/strong&gt; Batch on Streaming 处理和 Streaming 处理&lt;/li&gt;
&lt;li&gt;Flink 在 JVM 内部实现了自己的内存管理&lt;/li&gt;
&lt;li&gt;支持迭代计算，Spark也支持&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;支持程序自动优化&lt;/strong&gt;：避免特定情况下 Shuffle、排序等昂贵操作，中间结果有必要进行缓存&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;22-批处理和流处理-2220e689b9e5a484e79086e5928ce6b581e5a484e79086c2a0&#34;&gt;&lt;a href=&#34;#22-%e6%89%b9%e5%a4%84%e7%90%86%e5%92%8c%e6%b5%81%e5%a4%84%e7%90%86-2220e689b9e5a484e79086e5928ce6b581e5a484e79086c2a0&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;2.2 批处理和流处理 {#2.2%20%E6%89%B9%E5%A4%84%E7%90%86%E5%92%8C%E6%B5%81%E5%A4%84%E7%90%86%C2%A0}
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;批处理&lt;br&gt;
有界、持久、大量，一般用于离线计算&lt;/li&gt;
&lt;li&gt;流处理&lt;br&gt;
无界、实时，流处理方式无需对整个数据集执行操作，而是&lt;strong&gt;对通过系统传输的每个数据项执行操作&lt;/strong&gt;，一般用于实时统计&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在 Spark 生态体系中，对于批处理和流处理采用了不同的技术框架，&lt;strong&gt;批处理由 SparkSQL 实现，流处理由 Spark Streaming 实现&lt;/strong&gt;，这也是大部分框架采用的策略，使用独立的处理器实现批处理和流处理，而 Flink 可以同时实现批处理和流处理，Flink 将批处理（即处理 有限的静态数据）视作一种特殊的流处理，即&lt;strong&gt;把数据看作是有界的 ！&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;23-有界流和无界流-2320e69c89e7958ce6b581e5928ce697a0e7958ce6b581&#34;&gt;&lt;a href=&#34;#23-%e6%9c%89%e7%95%8c%e6%b5%81%e5%92%8c%e6%97%a0%e7%95%8c%e6%b5%81-2320e69c89e7958ce6b581e5928ce697a0e7958ce6b581&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;2.3 有界流和无界流 {#2.3%20%E6%9C%89%E7%95%8C%E6%B5%81%E5%92%8C%E6%97%A0%E7%95%8C%E6%B5%81}
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;无界数据流：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;有定义流的开始，但没有定义流的结束&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;它们会无休止的产生数据&lt;/li&gt;
&lt;li&gt;无界流的数据必须&lt;strong&gt;持续处理&lt;/strong&gt;，即数据被摄取后需要立刻处理&lt;/li&gt;
&lt;li&gt;我们不能等到所有数据都到达再处理，因为输入是无限的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;有界数据流：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;有定义流的开始，也有定义流的结束&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;有界流可以在摄取所有数据后再进行计算&lt;/li&gt;
&lt;li&gt;有界流所有数据可以被排序，所以并不需要有序摄取&lt;/li&gt;
&lt;li&gt;有界流处理通常被称为批处理。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;24-flink和spark-streaming-2420flinke5928cspark20streaming&#34;&gt;&lt;a href=&#34;#24-flink%e5%92%8cspark-streaming-2420flinke5928cspark20streaming&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;2.4 Flink和Spark Streaming {#2.4%20Flink%E5%92%8CSpark%20Streaming}
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Spark本质是批处理&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spark数据模型：Spak采用RDD模型，Spark Streaming的&lt;strong&gt;DStream实际上也就是一组组小批据RDD的集合&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Spark运行时架构：Spark是批计算，将DAG划分为不同的stage,一个完成后才可以计算下一个&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Flink以流处理为根本&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Flink数据模型：Flink基本据模型是数据流，以及事件(Event)序列&lt;/li&gt;
&lt;li&gt;Flink运行时架构：Flink是标准的流执行模式，一个事件在一个节点处理完后可以直接发往下一个节点进行处理&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/direct/827856b2eddc4f55bbb7a9f47af7e75c.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Flink三层核心架构 {#3.%20Flink%E4%B8%89%E5%B1%82%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84}&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;下图为 Flink 技术栈的核心组成部分，由上而下分别是 &lt;strong&gt;API &amp;amp; Libraries 层、Runtime 核心层以及物理部署层。&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>一文入门大数据准流式计算引擎Spark【万字详解，全网最新】</title>
        <link>/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8Espark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/</link>
        <pubDate>Wed, 04 Sep 2024 00:12:24 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/09/%E4%B8%80%E6%96%87%E5%85%A5%E9%97%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8Espark%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%85%A8%E7%BD%91%E6%9C%80%E6%96%B0/</guid>
        <description>&lt;blockquote&gt;
&lt;h2 id=&#34;往期推荐-e5be80e69c9fe68ea8e88d90&#34;&gt;&lt;a href=&#34;#%e5%be%80%e6%9c%9f%e6%8e%a8%e8%8d%90-e5be80e69c9fe68ea8e88d90&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;往期推荐 {#%E5%BE%80%E6%9C%9F%E6%8E%A8%E8%8D%90}
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/140787541&#34;  title=&#34;浅谈维度建模、数据分析模型，何为数据仓库，与数据库的区别-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;浅谈维度建模、数据分析模型，何为数据仓库，与数据库的区别-CSDN博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/141761563&#34;  title=&#34;数仓架构：离线数仓、实时数仓Lambda和Kappa、湖仓一体数据湖-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;数仓架构：离线数仓、实时数仓Lambda和Kappa、湖仓一体数据湖-CSDN博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/140783320&#34;  title=&#34;DW层的数仓建模：范式建模、维度建模及数据分析模型、实体建模-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DW层的数仓建模：范式建模、维度建模及数据分析模型、实体建模-CSDN博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/140786773&#34;  title=&#34;数仓分层ODS、DWD、DWM、DWS、DIM、DM、ADS_dm ads-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;数仓分层ODS、DWD、DWM、DWS、DIM、DM、ADS_dm ads-CSDN博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;后续考虑，会出Spark调优、shuffle、数据倾斜优化等&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;目录&lt;/strong&gt;{#main-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%BE%80%E6%9C%9F%E6%8E%A8%E8%8D%90&#34; &gt;往期推荐&lt;/a&gt;{#%E5%BE%80%E6%9C%9F%E6%8E%A8%E8%8D%90-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#1.%20Spark%E7%AE%80%E4%BB%8B&#34; &gt;1. Spark简介&lt;/a&gt;{#1.%20Spark%E7%AE%80%E4%BB%8B-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#1.1%20Spark%E7%89%B9%E7%82%B9&#34; &gt;1.1 Spark特点&lt;/a&gt;{#1.1%20Spark%E7%89%B9%E7%82%B9-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#1.2%20Spark%E5%92%8CMR%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E5%AF%B9%E6%AF%94&#34; &gt;1.2 Spark和MR处理任务对比&lt;/a&gt;{#1.2%20Spark%E5%92%8CMR%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E5%AF%B9%E6%AF%94-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.%20Spark%E7%BB%84%E4%BB%B6&#34; &gt;2. Spark组件&lt;/a&gt;{#2.%20Spark%E7%BB%84%E4%BB%B6-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1%20Spark%20Core&#34; &gt;2.1 Spark Core&lt;/a&gt;{#2.1%20Spark%20Core-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.1%20RDD%E7%AE%97%E5%AD%90&#34; &gt;2.1.1 RDD算子&lt;/a&gt;{#2.1.1%20RDD%E7%AE%97%E5%AD%90-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.1.1%20%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89RDD%EF%BC%9F&#34; &gt;2.1.1.1 为什么有RDD？&lt;/a&gt;{#2.1.1.1%20%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89RDD%EF%BC%9F-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.1.2%20RDD%E4%BB%8B%E7%BB%8D&#34; &gt;2.1.1.2 RDD介绍&lt;/a&gt;{#2.1.1.2%20RDD%E4%BB%8B%E7%BB%8D-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.2%20RDD%20%E7%89%B9%E7%82%B9&#34; &gt;2.1.2 RDD 特点&lt;/a&gt;{#2.1.2%20RDD%20%E7%89%B9%E7%82%B9-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.3%20RDD%E5%81%9A%E4%BA%86%E4%BB%80%E4%B9%88&#34; &gt;2.1.3 RDD做了什么&lt;/a&gt;{#2.1.3%20RDD%E5%81%9A%E4%BA%86%E4%BB%80%E4%B9%88-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.4%20RDD%E7%9A%84%E8%BD%AC%E6%8D%A2%E5%92%8C%E8%A1%8C%E5%8A%A8%E6%93%8D%E4%BD%9C&#34; &gt;2.1.4 RDD的转换和行动操作&lt;/a&gt;{#2.1.4%20RDD%E7%9A%84%E8%BD%AC%E6%8D%A2%E5%92%8C%E8%A1%8C%E5%8A%A8%E6%93%8D%E4%BD%9C-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.4.1%C2%A0%20Transformation%EF%BC%88%E8%BD%AC%E6%8D%A2%EF%BC%89%E7%AE%97%E5%AD%90%E6%A6%82%E8%BF%B0&#34; &gt;2.1.4.1 Transformation（转换）算子概述&lt;/a&gt;{#2.1.4.1%C2%A0%20Transformation%EF%BC%88%E8%BD%AC%E6%8D%A2%EF%BC%89%E7%AE%97%E5%AD%90%E6%A6%82%E8%BF%B0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.4.2%C2%A0%20Action%EF%BC%88%E8%A1%8C%E5%8A%A8%EF%BC%89%E7%AE%97%E5%AD%90%E6%A6%82%E8%BF%B0%C2%A0&#34; &gt;2.1.4.2 Action（行动）算子概述&lt;/a&gt;{#2.1.4.2%C2%A0%20Action%EF%BC%88%E8%A1%8C%E5%8A%A8%EF%BC%89%E7%AE%97%E5%AD%90%E6%A6%82%E8%BF%B0%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.5%20RDD%E6%8C%81%E4%B9%85%E5%8C%96%E5%92%8C%E7%BC%93%E5%AD%98&#34; &gt;2.1.5 RDD持久化和缓存&lt;/a&gt;{#2.1.5%20RDD%E6%8C%81%E4%B9%85%E5%8C%96%E5%92%8C%E7%BC%93%E5%AD%98-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.6%20%E5%AD%98%E5%82%A8%E7%BA%A7%E5%88%AB&#34; &gt;2.1.6 存储级别&lt;/a&gt;{#2.1.6%20%E5%AD%98%E5%82%A8%E7%BA%A7%E5%88%AB-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.7%20Checkpoint%E6%A3%80%E6%9F%A5%E7%82%B9%E6%9C%BA%E5%88%B6%C2%A0&#34; &gt;2.1.7 Checkpoint检查点机制&lt;/a&gt;{#2.1.7%20Checkpoint%E6%A3%80%E6%9F%A5%E7%82%B9%E6%9C%BA%E5%88%B6%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.8%20RDD%E5%AE%BD%E7%AA%84%E4%BE%9D%E8%B5%96&#34; &gt;2.1.8 RDD宽窄依赖&lt;/a&gt;{#2.1.8%20RDD%E5%AE%BD%E7%AA%84%E4%BE%9D%E8%B5%96-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.8.1%20%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%AE%BE%E8%AE%A1%E5%AE%BD%E7%AA%84%E4%BE%9D%E8%B5%96&#34; &gt;2.1.8.1 为什么要设计宽窄依赖&lt;/a&gt;{#2.1.8.1%20%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%AE%BE%E8%AE%A1%E5%AE%BD%E7%AA%84%E4%BE%9D%E8%B5%96-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.8.2%20DAG%E7%94%9F%E6%88%90%E5%92%8C%E5%88%92%E5%88%86Stage&#34; &gt;2.1.8.2 DAG生成和划分Stage&lt;/a&gt;{#2.1.8.2%20DAG%E7%94%9F%E6%88%90%E5%92%8C%E5%88%92%E5%88%86Stage-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.2%20Spark%20SQL&#34; &gt;2.2 Spark SQL&lt;/a&gt;{#2.2%20Spark%20SQL-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.2.1%20Spark%20SQL%E5%8F%91%E5%B1%95%EF%BC%88%E7%B2%BE%E5%BD%A9%EF%BC%89&#34; &gt;2.2.1 Spark SQL发展（精彩）&lt;/a&gt;{#2.2.1%20Spark%20SQL%E5%8F%91%E5%B1%95%EF%BC%88%E7%B2%BE%E5%BD%A9%EF%BC%89-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.2.2%20Spark%20SQL%E6%A6%82%E8%BF%B0&#34; &gt;2.2.2 Spark SQL概述&lt;/a&gt;{#2.2.2%20Spark%20SQL%E6%A6%82%E8%BF%B0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.2.3%20Spark%20SQL%E7%89%B9%E7%82%B9&#34; &gt;2.2.3 Spark SQL特点&lt;/a&gt;{#2.2.3%20Spark%20SQL%E7%89%B9%E7%82%B9-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.2.4%20Spark%20SQL%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%20DataFrame%E5%92%8CDataset&#34; &gt;2.2.4 Spark SQL数据模型 DataFrame和Dataset&lt;/a&gt;{#2.2.4%20Spark%20SQL%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%20DataFrame%E5%92%8CDataset-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.2.5%20%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8CSparkSQL%E7%BC%96%E7%A8%8B&#34; &gt;2.2.5 如何进行SparkSQL编程&lt;/a&gt;{#2.2.5%20%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8CSparkSQL%E7%BC%96%E7%A8%8B-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.3%20Spark%20Streaming&#34; &gt;2.3 Spark Streaming&lt;/a&gt;{#2.3%20Spark%20Streaming-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.3.1%20%E7%AE%80%E4%BB%8B&#34; &gt;2.3.1 简介&lt;/a&gt;{#2.3.1%20%E7%AE%80%E4%BB%8B-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.3.2%20%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E7%89%B9%E7%82%B9&#34; &gt;2.3.2 流式计算特点&lt;/a&gt;{#2.3.2%20%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E7%89%B9%E7%82%B9-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.3.3%20%E5%B8%B8%E8%A7%81%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%92%8C%E7%A6%BB%E7%BA%BF%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6&#34; &gt;2.3.3 常见流式计算和离线计算框架&lt;/a&gt;{#2.3.3%20%E5%B8%B8%E8%A7%81%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%92%8C%E7%A6%BB%E7%BA%BF%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.3.4%20SparkStreaming%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86&#34; &gt;2.3.4 SparkStreaming的基本工作原理&lt;/a&gt;{#2.3.4%20SparkStreaming%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.3.5%20SparkStreaming%E7%9A%84%E7%BC%93%E5%AD%98&#34; &gt;2.3.5 SparkStreaming的缓存&lt;/a&gt;{#2.3.5%20SparkStreaming%E7%9A%84%E7%BC%93%E5%AD%98-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.3.6%20SparkStreaming%E7%9A%84%E5%AE%B9%E9%94%99&#34; &gt;2.3.6 SparkStreaming的容错&lt;/a&gt;{#2.3.6%20SparkStreaming%E7%9A%84%E5%AE%B9%E9%94%99-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.3.7%20DStream%E6%93%8D%E4%BD%9C&#34; &gt;2.3.7 DStream操作&lt;/a&gt;{#2.3.7%20DStream%E6%93%8D%E4%BD%9C-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.4%20MLlib&#34; &gt;2.4 MLlib&lt;/a&gt;{#2.4%20MLlib-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.5%20Graphx&#34; &gt;2.5 Graphx&lt;/a&gt;{#2.5%20Graphx-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Spark%E5%A4%9A%E7%A7%8D%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F&#34; &gt;Spark多种部署模式&lt;/a&gt;{#Spark%E5%A4%9A%E7%A7%8D%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F-toc}&lt;/p&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li&gt;Spark简介 {#1.%20Spark%E7%AE%80%E4%BB%8B}&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;Spark 于 2009 年诞生于加州大学伯克利分校 AMPLab，2013 年被捐赠给 Apache 软件基金会，2014 年 2 月成为 Apache 的顶级项目。&lt;/p&gt;
&lt;p&gt;相对于 MapReduce 的批处理计算，&lt;strong&gt;Spark基于内存计算&lt;/strong&gt;，可以带来上百倍的性能提升，因此它成为继 MapReduce 之后，最为广泛使用的&lt;strong&gt;分布式计算框架、大数据分析引擎&lt;/strong&gt;。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;11-spark特点-1120sparke789b9e782b9&#34;&gt;&lt;a href=&#34;#11-spark%e7%89%b9%e7%82%b9-1120sparke789b9e782b9&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;1.1 Spark特点 {#1.1%20Spark%E7%89%B9%E7%82%B9}
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;快&lt;/strong&gt;：采用&lt;strong&gt;DAG执行引擎，支持循环数据流和内存计算&lt;/strong&gt;，使得 Spark 速度更快，在内存中的速度 是Hadoop MR的百倍，在磁盘上的速度是Hadoop MR的十倍(官网数据)。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;通用&lt;/strong&gt;：Spark提供了统一的解决方案。Spark可以⽤于批处理、交互式查询（Spark SQL）、实时流处理（Spark Streaming）、机器学习（Spark MLlib）和图计算（GraphX）。这些不同类型的处理都可以在同⼀个应用中无缝使用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;易用&lt;/strong&gt;：Spark支持Java、Python、Scala的API和超过80种⾼级算法，⽽且⽀持交互式的Python和Scala的shell。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;兼容&lt;/strong&gt;：Spark可以使⽤Hadoop的YARN和Apache Mesos作为它的资源管理和调度器，器，并且不需要任何数据迁移就可以处理所有Hadoop支持的数据，包括HDFS、HBase和Cassandra等。Spark也可以不依赖于第三⽅的资源管理和调度器，它实现了Standalone作为其内置的资源管理和调度框架。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;12-spark和mr处理任务对比-1220sparke5928cmre5a484e79086e4bbbbe58aa1e5afb9e6af94&#34;&gt;&lt;a href=&#34;#12-spark%e5%92%8cmr%e5%a4%84%e7%90%86%e4%bb%bb%e5%8a%a1%e5%af%b9%e6%af%94-1220sparke5928cmre5a484e79086e4bbbbe58aa1e5afb9e6af94&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;1.2 Spark和MR处理任务对比 {#1.2%20Spark%E5%92%8CMR%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E5%AF%B9%E6%AF%94}
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/direct/598e70154d4147deb1269a7566774e6c.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/direct/404b28dcc6494c1fad6636a3e2c2450b.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Spark组件 {#2.%20Spark%E7%BB%84%E4%BB%B6}&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id=&#34;21-spark-core-2120spark20core&#34;&gt;&lt;a href=&#34;#21-spark-core-2120spark20core&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;2.1 Spark Core {#2.1%20Spark%20Core}
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;Spark Core实现了 Spark 的基本功能，包含任务调度、内存管理、错误恢复、与存储系统 交互等模块。Spark Core 中还包含 了对弹性分布式数据集(resilient distributed dataset，简称RDD)的 API 定义。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;211-rdd算子-21120rdde7ae97e5ad90&#34;&gt;&lt;a href=&#34;#211-rdd%e7%ae%97%e5%ad%90-21120rdde7ae97e5ad90&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;2.1.1 RDD算子 {#2.1.1%20RDD%E7%AE%97%E5%AD%90}
&lt;/h4&gt;&lt;h5 id=&#34;2111-为什么有rdd-211120e4b8bae4bb80e4b988e69c89rddefbc9f&#34;&gt;&lt;a href=&#34;#2111-%e4%b8%ba%e4%bb%80%e4%b9%88%e6%9c%89rdd-211120e4b8bae4bb80e4b988e69c89rddefbc9f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;2.1.1.1 为什么有RDD？ {#2.1.1.1%20%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89RDD%EF%BC%9F}
&lt;/h5&gt;&lt;blockquote&gt;
&lt;p&gt;在许多迭代式算法(比如机器学习、图算法等)和交互式数据挖掘中，不同计算阶段之间会重用中间结果，即&lt;strong&gt;一个阶段的输出结果会作为下一个阶段的输入&lt;/strong&gt;。但是， 之前的 &lt;strong&gt;MapReduce 框架采用非循环式的数据流模型&lt;/strong&gt;，把中间结果写入到 HDFS 中，带来了大量的数据复制、磁盘 IO 和序列化开销，且这些框架只能支持一些 特定的计算模式(map/reduce)，并没有提供一种&lt;strong&gt;通用的数据抽象&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;RDD 提供了一个抽象的数据模型，让我们不必担心底层数据的分布式特性，只需&lt;strong&gt;将具体的应用逻辑表达为一系列转换操作(函数)&lt;/strong&gt; ，不同 RDD 之间的转换操作之间还可以形成依赖关系，进而实现&lt;strong&gt;管道化&lt;/strong&gt;，从而&lt;strong&gt;避免了中间结果的存储&lt;/strong&gt;，大大降低数据复制、磁盘 IO 和序列化开销，并且还提供了更多的 API操作！&lt;/p&gt;&lt;/blockquote&gt;
&lt;h5 id=&#34;2112-rdd介绍-211220rdde4bb8be7bb8d&#34;&gt;&lt;a href=&#34;#2112-rdd%e4%bb%8b%e7%bb%8d-211220rdde4bb8be7bb8d&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;2.1.1.2 RDD介绍 {#2.1.1.2%20RDD%E4%BB%8B%E7%BB%8D}
&lt;/h5&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;RDD（Resilient Distributed Dataset）叫做&lt;strong&gt;弹性分布式数据集&lt;/strong&gt;，是Spark中&lt;strong&gt;最基本的数据抽象&lt;/strong&gt;，是Spark计算的基石，它代表⼀个不可变、可分区、里面的元素可并行计算的集合。&lt;/li&gt;
&lt;li&gt;RDD具有数据流模型的特点：自动容错、位置感知性调度和可伸缩性。RDD允许用户在执⾏多个查询时显式地将⼯作集缓存在内存中，后续的查询能够&lt;strong&gt;重⽤⼯作集&lt;/strong&gt;，这极⼤地提升了查询速度。&lt;/li&gt;
&lt;li&gt;MR中对数据是没有进行抽象的，而在Spark中对数据进行了抽象，提供⼀些列处理⽅法也就是 RDD，为用户屏蔽了底层对数据的复杂抽象和处理，为⽤户提供了⼀组⽅便 的数据转换与求值方法，好比Java中类的封装。&lt;/li&gt;
&lt;/ul&gt;
&lt;br /&gt;
&lt;p&gt;&lt;strong&gt;注意 : RDD本身是不存储数据，而是记录了数据的位置，数据的转换关系(调用什么方法、传入什么函数)！！！&lt;/strong&gt;&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;&lt;strong&gt;以下是RDD源码翻译解读：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/direct/8b0a801743be4b50a960e23592f8e3b2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;212-rdd-特点-21220rdd20e789b9e782b9&#34;&gt;&lt;a href=&#34;#212-rdd-%e7%89%b9%e7%82%b9-21220rdd20e789b9e782b9&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;2.1.2 RDD 特点 {#2.1.2%20RDD%20%E7%89%B9%E7%82%B9}
&lt;/h4&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;弹性体现：
&lt;ol&gt;
&lt;li&gt;存储的弹性：内存与磁盘的自动切换；&lt;/li&gt;
&lt;li&gt;容错的弹性：RDD的血统（Lineag）会&lt;strong&gt;记录RDD的元数据信息和转换行为&lt;/strong&gt; ，当RDD的部分分区数据丢失时，它可以根据这些信息来重新运算并恢复丢失的数据分区。&lt;/li&gt;
&lt;li&gt;计算的弹性：计算出错重试机制；&lt;/li&gt;
&lt;li&gt;分片的弹性：可根据需要重新分片；&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;分布式：数据存储在大数据集群不同节点上&lt;/li&gt;
&lt;li&gt;数据集：RDD&lt;strong&gt;封装了计算逻辑&lt;/strong&gt;，并不保存数据&lt;/li&gt;
&lt;li&gt;数据抽象：RDD是⼀个抽象，需要具体实现&lt;/li&gt;
&lt;li&gt;不可变：RDD封装的&lt;strong&gt;计算逻辑不可改变&lt;/strong&gt;，想要改变只能产⽣新的RDD&lt;/li&gt;
&lt;li&gt;可分区、并行计算&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;213-rdd做了什么-21320rdde5819ae4ba86e4bb80e4b988&#34;&gt;&lt;a href=&#34;#213-rdd%e5%81%9a%e4%ba%86%e4%bb%80%e4%b9%88-21320rdde5819ae4ba86e4bb80e4b988&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;2.1.3 RDD做了什么 {#2.1.3%20RDD%E5%81%9A%E4%BA%86%E4%BB%80%E4%B9%88}
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;从计算的角度来讲，数据处理过程中需要计算资源（内存 &amp;amp; CPU）和计算模型（逻辑）。执⾏时，需要&lt;strong&gt;将计算资源&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>浅谈维度建模、数据分析模型，何为数据仓库，与数据库的区别</title>
        <link>/zh-cn/post/2024/09/%E6%B5%85%E8%B0%88%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E4%BD%95%E4%B8%BA%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%8C%BA%E5%88%AB/</link>
        <pubDate>Sun, 01 Sep 2024 21:34:40 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/09/%E6%B5%85%E8%B0%88%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%E4%BD%95%E4%B8%BA%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%8C%BA%E5%88%AB/</guid>
        <description>&lt;blockquote&gt;
&lt;h2 id=&#34;往期推荐-e5be80e69c9fe68ea8e88d90&#34;&gt;&lt;a href=&#34;#%e5%be%80%e6%9c%9f%e6%8e%a8%e8%8d%90-e5be80e69c9fe68ea8e88d90&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;strong&gt;往期推荐&lt;/strong&gt; {#%E5%BE%80%E6%9C%9F%E6%8E%A8%E8%8D%90}
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/140753124&#34;  title=&#34;大数据HBase图文简介-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;大数据HBase图文简介-CSDN博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/140786773&#34;  title=&#34;数仓分层ODS、DWD、DWM、DWS、DIM、DM、ADS-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;数仓分层ODS、DWD、DWM、DWS、DIM、DM、ADS-CSDN博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/140798330&#34;  title=&#34;数仓常见名词解析和名词之间的关系-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;数仓常见名词解析和名词之间的关系-CSDN博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/141761563&#34;  title=&#34;数仓架构：离线数仓、实时数仓Lambda和Kappa、湖仓一体数据湖-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;数仓架构：离线数仓、实时数仓Lambda和Kappa、湖仓一体数据湖-CSDN博客&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;br /&gt;
&lt;ol start=&#34;0&#34;&gt;
&lt;li&gt;前言 {#0.%20%E5%89%8D%E8%A8%80}&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;1991年，数据仓库之父 比尔·恩门 著书《Building the DataWarehouse》，要求&lt;strong&gt;构建数据仓库&lt;/strong&gt; 时，遵循&lt;strong&gt;范式建模&lt;/strong&gt;，即从关系型数据库中提取的范式数据，仍按范式存储到数据仓库中，这样就导致&lt;strong&gt;数仓中有很多小表，查询的时候必然会有很多表的关联&lt;/strong&gt;，极大地影响查询效率和性能。&lt;/li&gt;
&lt;li&gt;1994年，拉尔夫·金博尔 著书《The DataWarehouse Toolkit》，提出&lt;strong&gt;维度建模和数据集市的概念&lt;/strong&gt;，&lt;strong&gt;维度建模是反范式建模，自下而上&lt;/strong&gt; ，然而这种方式仍有缺点：那就是每个业务平台的数据有各自的数据集市，集市之间&lt;strong&gt;数据隔离，存在数据不一致、重复&lt;/strong&gt;的情况。&lt;/li&gt;
&lt;li&gt;1998-2001年，比尔·恩门派和金博尔派合并，比尔·恩门提出&lt;strong&gt;CIF架构：数仓分层&lt;/strong&gt;，不同层采用不同的建模方式，同时解决了数据不一致和查询效率低的问题。
&lt;strong&gt;基于以上，有了范式建模、维度建模、实体建模三种主要建模方式&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;01-浅谈维度建模-0120e6b585e8b088e7bbb4e5baa6e5bbbae6a8a1&#34;&gt;&lt;a href=&#34;#01-%e6%b5%85%e8%b0%88%e7%bb%b4%e5%ba%a6%e5%bb%ba%e6%a8%a1-0120e6b585e8b088e7bbb4e5baa6e5bbbae6a8a1&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;0.1 浅谈维度建模 {#0.1%20%E6%B5%85%E8%B0%88%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1}
&lt;/h3&gt;&lt;h2 id=&#34;维度建模主要面向&#34;&gt;&lt;a href=&#34;#%e7%bb%b4%e5%ba%a6%e5%bb%ba%e6%a8%a1%e4%b8%bb%e8%a6%81%e9%9d%a2%e5%90%91&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;维度建模主要&lt;strong&gt;面向&lt;/strong&gt;
&lt;/h2&gt;</description>
        </item>
        <item>
        <title>数仓架构：离线数仓、实时数仓Lambda和Kappa、湖仓一体数据湖</title>
        <link>/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/</link>
        <pubDate>Sun, 01 Sep 2024 00:53:40 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/09/%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93lambda%E5%92%8Ckappa%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93%E6%95%B0%E6%8D%AE%E6%B9%96/</guid>
        <description>&lt;blockquote&gt;
&lt;h2 id=&#34;往期推荐-e5be80e69c9fe68ea8e88d90&#34;&gt;&lt;a href=&#34;#%e5%be%80%e6%9c%9f%e6%8e%a8%e8%8d%90-e5be80e69c9fe68ea8e88d90&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;strong&gt;往期推荐&lt;/strong&gt; {#%E5%BE%80%E6%9C%9F%E6%8E%A8%E8%8D%90}
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/140753124&#34;  title=&#34;大数据HBase图文简介-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;大数据HBase图文简介-CSDN博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/140786773&#34;  title=&#34;数仓分层ODS、DWD、DWM、DWS、DIM、DM、ADS-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;数仓分层ODS、DWD、DWM、DWS、DIM、DM、ADS-CSDN博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/140798330&#34;  title=&#34;数仓常见名词解析和名词之间的关系-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;数仓常见名词解析和名词之间的关系-CSDN博客&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;=========================================================================&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;目录&lt;/strong&gt;{#main-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%BE%80%E6%9C%9F%E6%8E%A8%E8%8D%90&#34; &gt;往期推荐&lt;/a&gt;{#%E5%BE%80%E6%9C%9F%E6%8E%A8%E8%8D%90-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#0.%20%E5%89%8D%E8%A8%80&#34; &gt;1. 数仓架构&lt;/a&gt;{#0.%20%E5%89%8D%E8%A8%80-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#1.1%C2%A0%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84&#34; &gt;1.1 离线数仓架构&lt;/a&gt;{#1.1%C2%A0%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1%20%E6%95%B0%E6%8D%AE%E9%9B%86%E5%B8%82%E6%9E%B6%E6%9E%84&#34; &gt;1.1.1 数据集市架构&lt;/a&gt;{#2.1%20%E6%95%B0%E6%8D%AE%E9%9B%86%E5%B8%82%E6%9E%B6%E6%9E%84-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.1%20%E7%8B%AC%E7%AB%8B%E6%95%B0%E6%8D%AE%E9%9B%86%E5%B8%82&#34; &gt;1.1.1.2 独立数据集市&lt;/a&gt;{#2.1.1%20%E7%8B%AC%E7%AB%8B%E6%95%B0%E6%8D%AE%E9%9B%86%E5%B8%82-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.1.2%20%E4%BB%8E%E5%B1%9E%E6%95%B0%E6%8D%AE%E9%9B%86%E5%B8%82&#34; &gt;1.1.1.2 从属数据集市&lt;/a&gt;{#2.1.2%20%E4%BB%8E%E5%B1%9E%E6%95%B0%E6%8D%AE%E9%9B%86%E5%B8%82-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.2%20Inmon%E4%BC%81%E4%B8%9A%E4%BF%A1%E6%81%AF%E5%B7%A5%E5%8E%82%E6%9E%B6%E6%9E%84&#34; &gt;1.1.2 Inmon企业信息工厂架构&lt;/a&gt;{#2.2%20Inmon%E4%BC%81%E4%B8%9A%E4%BF%A1%E6%81%AF%E5%B7%A5%E5%8E%82%E6%9E%B6%E6%9E%84-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.3%20Kimball%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%9E%B6%E6%9E%84&#34; &gt;1.1.3 Kimball数据仓库架构&lt;/a&gt;{#2.3%20Kimball%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%9E%B6%E6%9E%84-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.4%20%E6%B7%B7%E5%90%88%E5%9E%8B%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%9E%B6%E6%9E%84&#34; &gt;1.1.4 混合型数据仓库架构&lt;/a&gt;{#2.4%20%E6%B7%B7%E5%90%88%E5%9E%8B%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%9E%B6%E6%9E%84-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.2%20%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%C2%A0&#34; &gt;1.2 实时数仓架构&lt;/a&gt;{#2.2%20%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.2.1%20Lambda%E6%9E%B6%E6%9E%84&#34; &gt;1.2.1 Lambda架构&lt;/a&gt;{#2.2.1%20Lambda%E6%9E%B6%E6%9E%84-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.2.1.1%20%E4%BC%A0%E7%BB%9F%E7%9A%84Lambda%E5%AE%9E%E6%97%B6%E5%BC%80%E5%8F%91&#34; &gt;1.2.1.1 传统的Lambda实时开发&lt;/a&gt;{#2.2.1.1%20%E4%BC%A0%E7%BB%9F%E7%9A%84Lambda%E5%AE%9E%E6%97%B6%E5%BC%80%E5%8F%91-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.2.1.2%C2%A0%E5%8D%87%E7%BA%A7%E7%9A%84Lambda%E5%AE%9E%E6%97%B6%E5%BC%80%E5%8F%91&#34; &gt;1.2.1.2 升级的Lambda实时开发&lt;/a&gt;{#2.2.1.2%C2%A0%E5%8D%87%E7%BA%A7%E7%9A%84Lambda%E5%AE%9E%E6%97%B6%E5%BC%80%E5%8F%91-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#1.2.1.3%C2%A0%E4%B8%BA%E4%BB%80%E4%B9%88Lambda%E6%9E%B6%E6%9E%84%E5%90%8C%E6%97%B6%E5%AD%98%E5%9C%A8%E6%B5%81%E5%A4%84%E7%90%86%E5%92%8C%E6%89%B9%E5%A4%84%E7%90%86%EF%BC%9F&#34; &gt;1.2.1.3 为什么Lambda架构同时存在流处理和批处理？&lt;/a&gt;{#1.2.1.3%C2%A0%E4%B8%BA%E4%BB%80%E4%B9%88Lambda%E6%9E%B6%E6%9E%84%E5%90%8C%E6%97%B6%E5%AD%98%E5%9C%A8%E6%B5%81%E5%A4%84%E7%90%86%E5%92%8C%E6%89%B9%E5%A4%84%E7%90%86%EF%BC%9F-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#1.2.1.4%20Lambda%E6%9E%B6%E6%9E%84%E7%BC%BA%E7%82%B9&#34; &gt;1.2.1.4 Lambda架构缺点&lt;/a&gt;{#1.2.1.4%20Lambda%E6%9E%B6%E6%9E%84%E7%BC%BA%E7%82%B9-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.2.2%20Kappa%E6%9E%B6%E6%9E%84&#34; &gt;1.2.2 Kappa架构&lt;/a&gt;{#2.2.2%20Kappa%E6%9E%B6%E6%9E%84-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#1.2.2.1%20Kappa%E6%9E%B6%E6%9E%84%E7%BC%BA%E7%82%B9%C2%A0&#34; &gt;1.2.2.1 Kappa架构缺点&lt;/a&gt;{#1.2.2.1%20Kappa%E6%9E%B6%E6%9E%84%E7%BC%BA%E7%82%B9%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Kappa%E5%92%8CLambda%E5%AF%B9%E6%AF%94&#34; &gt;1.2.3 Kappa和Lambda对比&lt;/a&gt;{#Kappa%E5%92%8CLambda%E5%AF%B9%E6%AF%94-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2.2.3%20%E6%95%B0%E6%8D%AE%E6%B9%96%E5%87%BA%E7%8E%B0%E5%8E%9F%E5%9B%A0%EF%BC%9A%E6%89%B9%E6%B5%81%E4%B8%80%E4%BD%93&#34; &gt;1.2.4 湖仓一体&amp;mdash;数据湖&lt;/a&gt;{#2.2.3%20%E6%95%B0%E6%8D%AE%E6%B9%96%E5%87%BA%E7%8E%B0%E5%8E%9F%E5%9B%A0%EF%BC%9A%E6%89%B9%E6%B5%81%E4%B8%80%E4%BD%93-toc}&lt;/p&gt;
&lt;p&gt;=========================================================================&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;数仓架构 {#0.%20%E5%89%8D%E8%A8%80}&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/direct/3777f513a36341459145f21b7a2e5e37.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;​&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数仓架构大致分为离线数仓架构和实时数仓架构&lt;/strong&gt;，数仓架构可以简单理解为构成数仓的各层关系，如ODS、DWM、DWD、DWS，具体分层这里不赘述。&lt;/p&gt;
&lt;h3 id=&#34;11-离线数仓架构-11c2a0e7a6bbe7babfe695b0e4bb93e69eb6e69e84&#34;&gt;&lt;a href=&#34;#11-%e7%a6%bb%e7%ba%bf%e6%95%b0%e4%bb%93%e6%9e%b6%e6%9e%84-11c2a0e7a6bbe7babfe695b0e4bb93e69eb6e69e84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;1.1 离线数仓架构 {#1.1%C2%A0%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E6%9E%B6%E6%9E%84}
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/direct/2671ec1cfe104f8f8a115b0c195715ee.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;​&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;显而易见，这种架构不能处理实时数据，那么必然会有数据的流失。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;任何事物都是随着时间的演进变得越来越完善，当然也是越来越复杂，数仓也不例外。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;离线数仓架构&lt;/strong&gt; 包括&lt;strong&gt;数据集市架构、Inmon企业信息工厂架构、Kimball数据仓库架构、混合型数据仓库架构&lt;/strong&gt;，接下来就详细说说这几种架构。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;111-数据集市架构-2120e695b0e68daee99b86e5b882e69eb6e69e84&#34;&gt;&lt;a href=&#34;#111-%e6%95%b0%e6%8d%ae%e9%9b%86%e5%b8%82%e6%9e%b6%e6%9e%84-2120e695b0e68daee99b86e5b882e69eb6e69e84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;1.1.1 数据集市架构 {#2.1%20%E6%95%B0%E6%8D%AE%E9%9B%86%E5%B8%82%E6%9E%B6%E6%9E%84}
&lt;/h4&gt;&lt;p&gt;数据集市架构重点在于&lt;strong&gt;集市&lt;/strong&gt; 二字，数据集市是按&lt;strong&gt;主题域&lt;/strong&gt; 组织的数据集合，用于支持&lt;strong&gt;部门级的决策&lt;/strong&gt;。有两种类型的数据集市：独立数据集市 和 从属数据集市。&lt;/p&gt;
&lt;br /&gt;
&lt;blockquote&gt;
&lt;h5 id=&#34;1112-独立数据集市-21120e78bace7ab8be695b0e68daee99b86e5b882&#34;&gt;&lt;a href=&#34;#1112-%e7%8b%ac%e7%ab%8b%e6%95%b0%e6%8d%ae%e9%9b%86%e5%b8%82-21120e78bace7ab8be695b0e68daee99b86e5b882&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;1.1.1.2 独立数据集市 {#2.1.1%20%E7%8B%AC%E7%AB%8B%E6%95%B0%E6%8D%AE%E9%9B%86%E5%B8%82}
&lt;/h5&gt;&lt;p&gt;独立数据集市集中于部门所关心的&lt;strong&gt;单一主题域&lt;/strong&gt; ，&lt;strong&gt;数据以部门为基础&lt;/strong&gt;，例如制造部门、人力资源部门和其他部门都各自有他们自己的数据集市。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/direct/067762e2511c4969911e4343147186b2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;​&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;优点：因为一个部门的业务相对于整个企业要简单，数据量也小得多，所以部门的独立数据集市&lt;strong&gt;周期短、见效快&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;缺点：独立数据集市各自为政。从业务角度看，当部门的分析&lt;strong&gt;需求扩展&lt;/strong&gt; 或者&lt;strong&gt;跨部门跨主题域分析&lt;/strong&gt; 时，独立数据市场会力不从心。 当&lt;strong&gt;数据存在歧义&lt;/strong&gt; ，比如同一个产品在A部门和B部门的定义不同，将无法在部门间进行信息比较。 每个部门使用不同的技术，建立不同的ETL的过程，处理不同的事务系统，而在多个独立的数据集市之间还会存在数据的交叉与重叠，甚至会有&lt;strong&gt;数据不一致&lt;/strong&gt;的情况！&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;br /&gt;
&lt;blockquote&gt;
&lt;h5 id=&#34;1112-从属数据集市-21220e4bb8ee5b19ee695b0e68daee99b86e5b882&#34;&gt;&lt;a href=&#34;#1112-%e4%bb%8e%e5%b1%9e%e6%95%b0%e6%8d%ae%e9%9b%86%e5%b8%82-21220e4bb8ee5b19ee695b0e68daee99b86e5b882&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;1.1.1.2 从属数据集市 {#2.1.2%20%E4%BB%8E%E5%B1%9E%E6%95%B0%E6%8D%AE%E9%9B%86%E5%B8%82}
&lt;/h5&gt;&lt;p&gt;从属数据集市的数据&lt;strong&gt;来源于数据仓库&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>数仓分层ODS、DWD、DWM、DWS、DIM、DM、ADS</title>
        <link>/zh-cn/post/2024/08/%E6%95%B0%E4%BB%93%E5%88%86%E5%B1%82odsdwddwmdwsdimdmads/</link>
        <pubDate>Thu, 01 Aug 2024 11:00:00 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/08/%E6%95%B0%E4%BB%93%E5%88%86%E5%B1%82odsdwddwmdwsdimdmads/</guid>
        <description>&lt;blockquote&gt;
&lt;h2 id=&#34;往期推荐&#34;&gt;&lt;a href=&#34;#%e5%be%80%e6%9c%9f%e6%8e%a8%e8%8d%90&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;strong&gt;往期推荐&lt;/strong&gt;
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/140787541?csdn_share_tail=%7B%22type%22%3A%22blog%22%2C%22rType%22%3A%22article%22%2C%22rId%22%3A%22140787541%22%2C%22source%22%3A%22qq_73181349%22%7D&#34;  title=&#34;数仓入门：数据分析模型、数仓建模、离线实时数仓、Lambda、Kappa、湖仓一体-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;数仓入门：数据分析模型、数仓建模、离线实时数仓、Lambda、Kappa、湖仓一体-CSDN博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/140798330&#34;  title=&#34;数仓常见名词解析和名词之间的关系-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;数仓常见名词解析和名词之间的关系-CSDN博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/140787541&#34;  title=&#34;数据仓库及数仓架构概述-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;数据仓库及数仓架构概述-CSDN博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/140753124&#34;  title=&#34;大数据HBase图文简介-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;大数据HBase图文简介-CSDN博客&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;目录&lt;/strong&gt;{#main-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#1.%20%E6%95%B0%E4%BB%93%E5%88%86%E5%B1%82%C2%A0&#34; &gt;1. 数仓分层&lt;/a&gt;{#1.%20%E6%95%B0%E4%BB%93%E5%88%86%E5%B1%82%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#1.1%20%E6%95%B0%E6%8D%AE%E6%BA%90%E5%B1%82%EF%BC%9AODS%EF%BC%88Operational%20Data%20Store%EF%BC%89&#34; &gt;1.1 数据源层：ODS（Operational Data Store）&lt;/a&gt;{#1.1%20%E6%95%B0%E6%8D%AE%E6%BA%90%E5%B1%82%EF%BC%9AODS%EF%BC%88Operational%20Data%20Store%EF%BC%89-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#1.2%20%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%B1%82%EF%BC%9ADW%EF%BC%88Data%20Warehouse%EF%BC%89&#34; &gt;1.2 数据仓库层：DW（Data Warehouse）&lt;/a&gt;{#1.2%20%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%B1%82%EF%BC%9ADW%EF%BC%88Data%20Warehouse%EF%BC%89-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#1.2.1%20%E6%95%B0%E6%8D%AE%E6%98%8E%E7%BB%86%E5%B1%82%EF%BC%9ADWD%EF%BC%88Data%20Warehouse%20Detail%EF%BC%89&#34; &gt;1.2.1 数据明细层：DWD（Data Warehouse Detail）&lt;/a&gt;{#1.2.1%20%E6%95%B0%E6%8D%AE%E6%98%8E%E7%BB%86%E5%B1%82%EF%BC%9ADWD%EF%BC%88Data%20Warehouse%20Detail%EF%BC%89-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#1.2.2%20%E6%95%B0%E6%8D%AE%E4%B8%AD%E9%97%B4%E5%B1%82%EF%BC%9ADWM%EF%BC%88Data%20WareHouse%20Midddle%EF%BC%89&#34; &gt;1.2.2 数据中间层：DWM（Data WareHouse Midddle）&lt;/a&gt;{#1.2.2%20%E6%95%B0%E6%8D%AE%E4%B8%AD%E9%97%B4%E5%B1%82%EF%BC%9ADWM%EF%BC%88Data%20WareHouse%20Midddle%EF%BC%89-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#1.2.3%20%E6%95%B0%E6%8D%AE%E6%9C%8D%E5%8A%A1%E5%B1%82%EF%BC%9ADWS%EF%BC%88Data%20WareHouse%20Service%EF%BC%89&#34; &gt;1.2.3 数据服务层：DWS（Data WareHouse Service）&lt;/a&gt;{#1.2.3%20%E6%95%B0%E6%8D%AE%E6%9C%8D%E5%8A%A1%E5%B1%82%EF%BC%9ADWS%EF%BC%88Data%20WareHouse%20Service%EF%BC%89-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#1.3%20%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%B1%82%EF%BC%9AADS%EF%BC%88Application%20Data%20Service%EF%BC%89&#34; &gt;1.3 数据应用层：ADS（Application Data Service）&lt;/a&gt;{#1.3%20%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%B1%82%EF%BC%9AADS%EF%BC%88Application%20Data%20Service%EF%BC%89-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#1.4%20%E7%BB%B4%E8%A1%A8%E5%B1%82%EF%BC%9ADIM%EF%BC%88Dimension%EF%BC%89&#34; &gt;1.4 维表层：DIM（Dimension）&lt;/a&gt;{#1.4%20%E7%BB%B4%E8%A1%A8%E5%B1%82%EF%BC%9ADIM%EF%BC%88Dimension%EF%BC%89-toc}&lt;/p&gt;
&lt;hr&gt;
&lt;br /&gt;
&lt;ol&gt;
&lt;li&gt;数仓分层 {#1.%20%E6%95%B0%E4%BB%93%E5%88%86%E5%B1%82%C2%A0}&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;那么为什么要数据仓库进行分层呢？&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;用空间换时间&lt;/strong&gt;，通过大量的预处理来提升应用系统的用户体验（效率），因此数据仓库会存在&lt;strong&gt;大量冗余的数据&lt;/strong&gt;；&lt;strong&gt;不分层的话，如果源业务系统的业务规则发生变化将会影响整个数据清洗过程，工作量巨大&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;通过&lt;strong&gt;数据分层管理可以简化数据清洗&lt;/strong&gt;的过程，把一个复杂的工作拆成了多个简单的工作，把一个大的黑盒变成了一个白盒，每一层的处理逻辑都相对简单和容易理解，这样比较容易保证每一个步骤的正确性，当数据发生错误的时候，往往我们只需要&lt;strong&gt;溯源&lt;/strong&gt;并局部调整某个步骤即可。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分层是以解决当前业务快速的数据支撑为目的&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;抽象出共性的框架并能够赋能给其他业务线，同时为业务发展提供稳定、准确的数据支撑&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;并能够按照已有的模型为新业务发展提供方向，也就是数据驱动和赋能&lt;/strong&gt;
&lt;strong&gt;一个好的分层架构，要有以下好处：&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;1. 清晰数据结构&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. 数据血缘追踪：数据ETL转化过程中的流动变化&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. 减少重复开发，提高数据复用性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4. 数据关系条理化&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5. 屏蔽原始数据的影响&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;数仓分层要结合公司业务进行，并且需要清晰明确各层职责，&lt;strong&gt;一般&lt;/strong&gt;采用如下分层结构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/direct/e895cdb04e9645a59d90d89a57d585a6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;数仓建模在哪层建设呢？我们以&lt;strong&gt;维度建模&lt;/strong&gt; 为例，建模是在数据源层的下一层进行建设，在上图中，就是在 &lt;strong&gt;DW 层进行数仓建模&lt;/strong&gt;，所以 DW 层是数仓建设的核心层。 下面详细阐述下每层建设规范！&lt;/p&gt;
&lt;h3 id=&#34;11-数据源层odsoperational-data-store-1120e695b0e68daee6ba90e5b182efbc9aodsefbc88operational20data20storeefbc89&#34;&gt;&lt;a href=&#34;#11-%e6%95%b0%e6%8d%ae%e6%ba%90%e5%b1%82odsoperational-data-store-1120e695b0e68daee6ba90e5b182efbc9aodsefbc88operational20data20storeefbc89&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;1.1 数据源层：ODS（Operational Data Store） {#1.1%20%E6%95%B0%E6%8D%AE%E6%BA%90%E5%B1%82%EF%BC%9AODS%EF%BC%88Operational%20Data%20Store%EF%BC%89}
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;ODS 层是最接近数据源的一层，又叫&lt;strong&gt;贴源层&lt;/strong&gt; ，考虑后续可能需要&lt;strong&gt;追溯数据&lt;/strong&gt; 问题， 因此对于这一层就&lt;strong&gt;不建议做过多的数据清洗工作&lt;/strong&gt;，原封不动地接入原始数据即可， 至于&lt;strong&gt;数据去噪、去重、异常值处理等过程可以放在后面的 DWD 层&lt;/strong&gt;来做！&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;12-数据仓库层dwdata-warehouse-1220e695b0e68daee4bb93e5ba93e5b182efbc9adwefbc88data20warehouseefbc89&#34;&gt;&lt;a href=&#34;#12-%e6%95%b0%e6%8d%ae%e4%bb%93%e5%ba%93%e5%b1%82dwdata-warehouse-1220e695b0e68daee4bb93e5ba93e5b182efbc9adwefbc88data20warehouseefbc89&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;1.2 数据仓库层：DW（Data Warehouse） {#1.2%20%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%B1%82%EF%BC%9ADW%EF%BC%88Data%20Warehouse%EF%BC%89}
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;数据仓库层是数据仓库核心层，在这里把从 ODS 层中获得的数据按照主题建立各种数据模型。该层又依次&lt;strong&gt;细分为DWD、DWM、DWS&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;121-数据明细层dwddata-warehouse-detail-12120e695b0e68daee6988ee7bb86e5b182efbc9adwdefbc88data20warehouse20detailefbc89&#34;&gt;&lt;a href=&#34;#121-%e6%95%b0%e6%8d%ae%e6%98%8e%e7%bb%86%e5%b1%82dwddata-warehouse-detail-12120e695b0e68daee6988ee7bb86e5b182efbc9adwdefbc88data20warehouse20detailefbc89&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;1.2.1 数据明细层：DWD（Data Warehouse Detail） {#1.2.1%20%E6%95%B0%E6%8D%AE%E6%98%8E%E7%BB%86%E5%B1%82%EF%BC%9ADWD%EF%BC%88Data%20Warehouse%20Detail%EF%BC%89}
&lt;/h4&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;该层一般&lt;strong&gt;保持和 ODS 层一样的数据粒度&lt;/strong&gt;，并且提供&lt;strong&gt;一定的数据质量保证&lt;/strong&gt; 。&lt;strong&gt;DWD层要做的就是将数据清理、整合、规范化，把脏数据、垃圾数据、规范不一致的、状态定义不一致的、命名不规范的数据处理掉。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;同时，为了提高数据明细层的易用性，该层会采用一些&lt;strong&gt;维度退化&lt;/strong&gt;手法，将维度退化至事实表中，减少事实表和维表的关联。&lt;/li&gt;
&lt;li&gt;另外，在该层也会做&lt;strong&gt;一部分的数据聚合&lt;/strong&gt;，将相同主题的数据汇集到一张表中，提高数据的可用性 。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;122-数据中间层dwmdata-warehouse-midddle-12220e695b0e68daee4b8ade997b4e5b182efbc9adwmefbc88data20warehouse20midddleefbc89&#34;&gt;&lt;a href=&#34;#122-%e6%95%b0%e6%8d%ae%e4%b8%ad%e9%97%b4%e5%b1%82dwmdata-warehouse-midddle-12220e695b0e68daee4b8ade997b4e5b182efbc9adwmefbc88data20warehouse20midddleefbc89&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;1.2.2 数据中间层：DWM（Data WareHouse Midddle） {#1.2.2%20%E6%95%B0%E6%8D%AE%E4%B8%AD%E9%97%B4%E5%B1%82%EF%BC%9ADWM%EF%BC%88Data%20WareHouse%20Midddle%EF%BC%89}
&lt;/h4&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;该层会在 DWD 层的数据基础上，数据做&lt;strong&gt;轻度聚合&lt;/strong&gt; ，生成一系列的&lt;strong&gt;中间表&lt;/strong&gt; ， &lt;strong&gt;提升公共指标的复用性&lt;/strong&gt;，减少重复加工。&lt;/li&gt;
&lt;li&gt;直观来讲，就是对通用的核心维度进行聚合操作，算出相应的统计指标。&lt;/li&gt;
&lt;li&gt;在实际计算中，如果直接从 DWD 或者 ODS 计算出宽表的统计指标，会存在计算量太大并且维度太少的问题，因此一般的做法是，&lt;strong&gt;在 DWM 层先计算出多个小的中间表，然后再拼接成一张 DWS 的宽表&lt;/strong&gt;。由于宽和窄的界限不易界定，&lt;strong&gt;也可以去掉 DWM&lt;/strong&gt; 这一层，只留 DWS 层，将所有的数据再放在DWS也可。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;123-数据服务层dwsdata-warehouse-service-12320e695b0e68daee69c8de58aa1e5b182efbc9adwsefbc88data20warehouse20serviceefbc89&#34;&gt;&lt;a href=&#34;#123-%e6%95%b0%e6%8d%ae%e6%9c%8d%e5%8a%a1%e5%b1%82dwsdata-warehouse-service-12320e695b0e68daee69c8de58aa1e5b182efbc9adwsefbc88data20warehouse20serviceefbc89&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;1.2.3 数据服务层：DWS（Data WareHouse Service） {#1.2.3%20%E6%95%B0%E6%8D%AE%E6%9C%8D%E5%8A%A1%E5%B1%82%EF%BC%9ADWS%EF%BC%88Data%20WareHouse%20Service%EF%BC%89}
&lt;/h4&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;DWS 层为公共汇总层，会进行&lt;strong&gt;轻度汇总&lt;/strong&gt; ，&lt;strong&gt;粒度比明细数据稍粗&lt;/strong&gt;，基于 DWD 层上的基础数据，整合汇总成分析某一个主题域的服务数据。&lt;/li&gt;
&lt;li&gt;DWS 层应覆 盖 80% 的应用场景。又&lt;strong&gt;称数据集市或宽表&lt;/strong&gt;。 按照业务划分，如主题域流量、订单、用户等，生成字段比较多的宽表，用于提供后续的业务查询，OLAP 分析，数据分发等。&lt;/li&gt;
&lt;li&gt;一般来讲，该层的数据表会相对比较少，一张表会涵盖比较多的业务内容，由于其&lt;strong&gt;字段较多&lt;/strong&gt;，因此一般也会称该层的表为&lt;strong&gt;宽表&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;13-数据集市层dmdata-mart-1320e695b0e68daee5ba94e794a8e5b182efbc9aadsefbc88application20data20serviceefbc89&#34;&gt;&lt;a href=&#34;#13-%e6%95%b0%e6%8d%ae%e9%9b%86%e5%b8%82%e5%b1%82dmdata-mart-1320e695b0e68daee5ba94e794a8e5b182efbc9aadsefbc88application20data20serviceefbc89&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;1.3 数据集市层：DM（Data Mart） {#1.3%20%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%B1%82%EF%BC%9AADS%EF%BC%88Application%20Data%20Service%EF%BC%89}
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;基于DW的基础数据，整合汇总成一个个数据集市，数据集市通常是面向部门的某个主题域的报表数据。比如用户留存表、用户活跃表、商品销量表、商品营收表等等。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;14-维表层dimdimension-1420e7bbb4e8a1a8e5b182efbc9adimefbc88dimensionefbc89&#34;&gt;&lt;a href=&#34;#14-%e7%bb%b4%e8%a1%a8%e5%b1%82dimdimension-1420e7bbb4e8a1a8e5b182efbc9adimefbc88dimensionefbc89&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;1.4 维表层：DIM（Dimension） {#1.4%20%E7%BB%B4%E8%A1%A8%E5%B1%82%EF%BC%9ADIM%EF%BC%88Dimension%EF%BC%89}
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;如果维表过多，也可针对维表设计单独一层，维表层主要包含两部分数据：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;高基数维度数据：一般是用户资料表、商品资料表类似的资料表。数据量可能是千万级或者上亿级别。&lt;/li&gt;
&lt;li&gt;低基数维度数据：一般是配置表，比如枚举值对应的中文含义，或者日期维表。 数据量可能是个位数或者几千几万&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;15-数据应用层adsapplication-data-service&#34;&gt;&lt;a href=&#34;#15-%e6%95%b0%e6%8d%ae%e5%ba%94%e7%94%a8%e5%b1%82adsapplication-data-service&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;1.5 数据应用层：ADS（Application Data Service）
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;在这里，主要是&lt;strong&gt;提供给数据产品和数据分析使用的数据&lt;/strong&gt; ，一般会存放在 ES、 PostgreSql、Redis 等系统中供线上系统使用，也可能会存在 Hive 或者 Druid 中供数据分析和数据挖掘使用。比如我们经常说的&lt;strong&gt;报表数据&lt;/strong&gt;，一般就放在这里。&lt;/p&gt;&lt;/blockquote&gt;
&lt;br /&gt;
---
</description>
        </item>
        <item>
        <title>大数据HBase图文简介及Phoenix</title>
        <link>/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/</link>
        <pubDate>Mon, 29 Jul 2024 11:30:00 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/07/%E5%A4%A7%E6%95%B0%E6%8D%AEhbase%E5%9B%BE%E6%96%87%E7%AE%80%E4%BB%8B%E5%8F%8Aphoenix/</guid>
        <description>&lt;blockquote&gt;
&lt;h2 id=&#34;往期推荐&#34;&gt;&lt;a href=&#34;#%e5%be%80%e6%9c%9f%e6%8e%a8%e8%8d%90&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;往期推荐
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/140787541?csdn_share_tail=%7B%22type%22%3A%22blog%22%2C%22rType%22%3A%22article%22%2C%22rId%22%3A%22140787541%22%2C%22source%22%3A%22qq_73181349%22%7D&#34;  title=&#34;数据仓库及数仓架构概述-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;数据仓库及数仓架构概述-CSDN博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_73181349/article/details/140798330&#34;  title=&#34;数仓常见名词解析和名词之间的关系-CSDN博客&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;数仓常见名词解析和名词之间的关系-CSDN博客&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;引言&#34;&gt;&lt;a href=&#34;#%e5%bc%95%e8%a8%80&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;引言
&lt;/h2&gt;&lt;p&gt;要想明白为什么HBase的产生，就需要先了解一下 Hadoop。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Hadoop 可以通过 HDFS 来存 储结构化、半结构甚至非结构化的数据，是传统数据库的补充，是海量数据存储的最佳方法，它针对大文件的存储、批量访问和流式访问都做了优化，同时也通过多副本解决了容灾问题。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;但是 Hadoop 的缺陷在于它&lt;strong&gt;只能执行批处理&lt;/strong&gt;，并且只能以&lt;strong&gt;顺序方式访问数据&lt;/strong&gt;，这意味着即使是最简单的工作也必须搜索整个数据集，&lt;strong&gt;无法实现对数据的随机访问&lt;/strong&gt;。实现数据的&lt;strong&gt;随机访问是传统的关系型数据库所擅长的&lt;/strong&gt;，但它们却不能用于海量数据的存储。在这种情况下，必须有一种新的方案来&lt;strong&gt;同时解决海量数据存储和随机访问的问题&lt;/strong&gt;，HBase 就是其中之一 (HBase，Cassandra，couchDB，Dynamo 和 MongoDB 都能存储海量数据并支持随机访问)。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;数据结构分类：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;结构化数据：即以关系型数据库表形式管理的数据；&lt;/li&gt;
&lt;li&gt;半结构化数据：非关系模型的，有基本固定结构模式的数据，例如日志文件、XML 文档、 JSON 文档、Email 等；&lt;/li&gt;
&lt;li&gt;非结构化数据：没有固定模式的数据，如 WORD、PDF、PPT、EXL，各种格式的图片、视 频等。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;HBase简介&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;HBase全称Hadoop Database ，是一个基于HDFS的分布式的、面向列的开源数据库，但是这个数据库没有SQL，只提供了API，需要API编程来使用HBase，而后面提到的Phoenix才使得可以用SQL操作HBase！&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;HBase有如下特点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;容量大：一个表可以有数十亿行，上百万列，这也和它的扩展性息息相关；&lt;/li&gt;
&lt;li&gt;面向列：数据是按照列存储，每一列都单独存放，数据即索引，在查询时可以只访问指定列的数据，有效地降低了系统的 I/O 负担；&lt;/li&gt;
&lt;li&gt;稀疏性：空 (null) 列并不占用存储空间，表可以设计的非常稀疏 ；&lt;/li&gt;
&lt;li&gt;易扩展：的扩展性主要体现在两个方面，一个是基于上层处理能力（RegionServer） 的扩展，一个是基于存储的扩展（HDFS）。通过横向添加 RegionSever 的机器， 进行水平扩展，提升 Hbase 上层的处理能力，提升 Hbsae 服务更多 Region 的 能力。&lt;/li&gt;
&lt;li&gt;数据多版本：每个单元中的数据可以有多个版本，按照时间戳排序，新的数据在最上面；&lt;/li&gt;
&lt;li&gt;采用 HDFS 作为底层存储，支持结构化、半结构化和非结构化的存储；&lt;/li&gt;
&lt;li&gt;支持数据分片；&lt;/li&gt;
&lt;li&gt;易于使用的 Java 客户端 API，客户端可以通过 HBase 实现对 HDFS 上数据的随机访问；&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/direct/9bfd7d519e2446d7903861122c1eee1e.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;HBase的表&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;表-schema-仅定义列族表&#34;&gt;&lt;a href=&#34;#%e8%a1%a8-schema-%e4%bb%85%e5%ae%9a%e4%b9%89%e5%88%97%e6%97%8f%e8%a1%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;strong&gt;表 schema 仅定义列族，表&lt;/strong&gt;
&lt;/h2&gt;</description>
        </item>
        <item>
        <title>kafka实战 集群搭建-Kraft模式</title>
        <link>/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/</link>
        <pubDate>Sun, 05 May 2024 20:57:35 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/05/kafka%E5%AE%9E%E6%88%98-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-kraft%E6%A8%A1%E5%BC%8F/</guid>
        <description>&lt;p&gt;&lt;strong&gt;目录&lt;/strong&gt;{#main-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE&#34; &gt;集群配置&lt;/a&gt;{#%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8&#34; &gt;集群启动&lt;/a&gt;{#%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E8%84%9A%E6%9C%AC%E5%90%AF%E5%8A%A8zk%E9%9B%86%E7%BE%A4%C2%A0&#34; &gt;脚本启动zk集群&lt;/a&gt;{#%E8%84%9A%E6%9C%AC%E5%90%AF%E5%8A%A8zk%E9%9B%86%E7%BE%A4%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E8%84%9A%E6%9C%AC%E5%90%AF%E5%8A%A8kafka%E9%9B%86%E7%BE%A4%C2%A0&#34; &gt;脚本启动kafka集群&lt;/a&gt;{#%E8%84%9A%E6%9C%AC%E5%90%AF%E5%8A%A8kafka%E9%9B%86%E7%BE%A4%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%90%AF%E5%8A%A8%E6%88%90%E5%8A%9F%C2%A0&#34; &gt;启动成功&lt;/a&gt;{#%E5%90%AF%E5%8A%A8%E6%88%90%E5%8A%9F%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Kafka%E6%93%8D%E4%BD%9C&#34; &gt;Kafka操作&lt;/a&gt;{#Kafka%E6%93%8D%E4%BD%9C-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%88%9B%E5%BB%BATopic&#34; &gt;命令行创建Topic&lt;/a&gt;{#%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%88%9B%E5%BB%BATopic-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E2%80%8B%E7%BC%96%E8%BE%91&#34; &gt;​编辑&lt;/a&gt;{#%E2%80%8B%E7%BC%96%E8%BE%91-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%B6%88%E8%B4%B9%E8%80%85%E7%94%9F%E4%BA%A7%E8%80%85%E8%81%94%E5%8A%A8&#34; &gt;消费者生产者联动&lt;/a&gt;{#%E6%B6%88%E8%B4%B9%E8%80%85%E7%94%9F%E4%BA%A7%E8%80%85%E8%81%94%E5%8A%A8-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E2%80%8B%E7%BC%96%E8%BE%91&#34; &gt;​编辑&lt;/a&gt;{#%E2%80%8B%E7%BC%96%E8%BE%91-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Linux%E9%85%8D%E7%BD%AEEFAK3.0.1&#34; &gt;Linux配置EFAK3.0.1&lt;/a&gt;{#Linux%E9%85%8D%E7%BD%AEEFAK3.0.1-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Kraft%E6%A8%A1%E5%BC%8F%E9%9B%86%E7%BE%A4&#34; &gt;Kraft模式集群&lt;/a&gt;{#Kraft%E6%A8%A1%E5%BC%8F%E9%9B%86%E7%BE%A4-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E9%85%8D%E7%BD%AE&#34; &gt;配置&lt;/a&gt;{#%E9%85%8D%E7%BD%AE-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%90%AF%E5%8A%A8%E5%89%8D%E5%88%9D%E5%A7%8B%E5%8C%96%E9%9B%86%E7%BE%A4&#34; &gt;启动前初始化集群&lt;/a&gt;{#%E5%90%AF%E5%8A%A8%E5%89%8D%E5%88%9D%E5%A7%8B%E5%8C%96%E9%9B%86%E7%BE%A4-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%B5%85%E6%B5%85%E6%8A%8A%E7%8E%A9Kraft&#34; &gt;浅浅把玩Kraft&lt;/a&gt;{#%E6%B5%85%E6%B5%85%E6%8A%8A%E7%8E%A9Kraft-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Flume%E8%81%94%E5%8A%A8kafka&#34; &gt;Flume联动kafka&lt;/a&gt;{#Flume%E8%81%94%E5%8A%A8kafka-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Flume%E4%BD%9C%E4%B8%BA%E7%94%9F%E4%BA%A7%E8%80%85&#34; &gt;Flume作为生产者&lt;/a&gt;{#Flume%E4%BD%9C%E4%B8%BA%E7%94%9F%E4%BA%A7%E8%80%85-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Flume%E4%BD%9C%E4%B8%BA%E6%B6%88%E8%B4%B9%E8%80%85%C2%A0%E2%80%8B%E7%BC%96%E8%BE%91&#34; &gt;Flume作为消费者 ​编辑&lt;/a&gt;{#Flume%E4%BD%9C%E4%B8%BA%E6%B6%88%E8%B4%B9%E8%80%85%C2%A0%E2%80%8B%E7%BC%96%E8%BE%91-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#SpringBoot%E8%81%94%E5%8A%A8kakfa&#34; &gt;SpringBoot联动kakfa&lt;/a&gt;{#SpringBoot%E8%81%94%E5%8A%A8kakfa-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#SpringBoot%E4%BD%9C%E4%B8%BA%E7%94%9F%E4%BA%A7%E8%80%85&#34; &gt;SpringBoot作为生产者&lt;/a&gt;{#SpringBoot%E4%BD%9C%E4%B8%BA%E7%94%9F%E4%BA%A7%E8%80%85-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#SpringBoot%E4%BD%9C%E4%B8%BA%E6%B6%88%E8%B4%B9%E8%80%85%C2%A0&#34; &gt;SpringBoot作为消费者&lt;/a&gt;{#SpringBoot%E4%BD%9C%E4%B8%BA%E6%B6%88%E8%B4%B9%E8%80%85%C2%A0-toc}&lt;/p&gt;
&lt;hr&gt;
&lt;br /&gt;
&lt;h2 id=&#34;集群配置-e99b86e7bea4e9858de7bdae&#34;&gt;&lt;a href=&#34;#%e9%9b%86%e7%be%a4%e9%85%8d%e7%bd%ae-e99b86e7bea4e9858de7bdae&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;集群配置 {#%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE}
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;三台服务器：linux01、linux02、linux03&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;每台服务器均安装了zookeeper、kafka，服务器之间做了ssh免密登录（集群启停脚本用）&lt;/p&gt;
&lt;p&gt;kafka虽然内置了zk，但是这里用的是自己安装的zk。&lt;/p&gt;
&lt;p&gt;服务器之间加了ip映射，如hosts文件所示，这样就不需要p地址，只需要服务器名字就可以了&lt;br&gt;
&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/eb408c7885cbb8c35f6dea4a8c1a371b.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;集群启动-e99b86e7bea4e590afe58aa8&#34;&gt;&lt;a href=&#34;#%e9%9b%86%e7%be%a4%e5%90%af%e5%8a%a8-e99b86e7bea4e590afe58aa8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;集群启动 {#%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8}
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;注意事项&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;启动时先启动zk，再启动kafka&lt;/li&gt;
&lt;li&gt;关闭时先关闭kafka，再关闭zk，因为kafka需要zk来维护数据信息，再关闭前kafka要和zk通讯。&lt;/li&gt;
&lt;li&gt;kafka-server-start.sh -daemon config/server.properties&lt;/li&gt;
&lt;li&gt;kafka-server-stop.sh&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;脚本启动zk集群-e8849ae69cace590afe58aa8zke99b86e7bea4c2a0&#34;&gt;&lt;a href=&#34;#%e8%84%9a%e6%9c%ac%e5%90%af%e5%8a%a8zk%e9%9b%86%e7%be%a4-e8849ae69cace590afe58aa8zke99b86e7bea4c2a0&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;脚本启动zk集群 {#%E8%84%9A%E6%9C%AC%E5%90%AF%E5%8A%A8zk%E9%9B%86%E7%BE%A4%C2%A0}
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/5146d22dd61bdd0dca7a6c97444a450c.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;脚本启动kafka集群-e8849ae69cace590afe58aa8kafkae99b86e7bea4c2a0&#34;&gt;&lt;a href=&#34;#%e8%84%9a%e6%9c%ac%e5%90%af%e5%8a%a8kafka%e9%9b%86%e7%be%a4-e8849ae69cace590afe58aa8kafkae99b86e7bea4c2a0&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;脚本启动kafka集群 {#%E8%84%9A%E6%9C%AC%E5%90%AF%E5%8A%A8kafka%E9%9B%86%E7%BE%A4%C2%A0}
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/3388a4063e460ccc351ca9c74ba28d43.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;启动成功-e590afe58aa8e68890e58a9fc2a0&#34;&gt;&lt;a href=&#34;#%e5%90%af%e5%8a%a8%e6%88%90%e5%8a%9f-e590afe58aa8e68890e58a9fc2a0&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;启动成功 {#%E5%90%AF%E5%8A%A8%E6%88%90%E5%8A%9F%C2%A0}
&lt;/h3&gt;&lt;p&gt;启动成功，三台服务器均显示如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/4fff028a6f054f402a9e2df63b1b7810.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;查看zk客户端，根节点下已经有了kafka节点&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;默认直接在根节点下生成admin、brokers、cluster等节点，但是不方便维护，因此在server.properties文件中改了配置，让所有节点统一生成在kafka节点。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/b9f8872873986c923e3f1862808bd5b2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;zk集群启停脚本&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#!/bin/bash
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;#zookeeper集群启停及状态查看脚本&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;ZOOKEEPER&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/export/server/zookeeper&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;case&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;$1&lt;/span&gt; in
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;start&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; i in linux01 linux02 linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;do&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; ---------- zookeeper &lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; 启动 ------------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		ssh &lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$ZOOKEEPER&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;/bin/zkServer.sh start&amp;#34;&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;p&#34;&gt;;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;stop&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; i in linux01 linux02 linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;do&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; ---------- zookeeper &lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; 停止 ------------ 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		ssh &lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$ZOOKEEPER&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;/bin/zkServer.sh stop&amp;#34;&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;p&#34;&gt;;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;status&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; i in linux01 linux02 linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;do&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; ---------- zookeeper &lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; 状态 ------------ 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		ssh &lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$ZOOKEEPER&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;/bin/zkServer.sh status&amp;#34;&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;p&#34;&gt;;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;esac&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;kafka集群启停脚本&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#!/bin/bash
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;case&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;$1&lt;/span&gt; in
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;start&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; i in linux01 linux02 linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;k&#34;&gt;do&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        &lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; --------&lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; 启动kafka---------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        ssh &lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;source /etc/profile;/export/server/kafka/bin/kafka-server-start.sh -daemon /export/server/kafka/config/server.properties&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;stop&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; i in linux01 linux02 linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;k&#34;&gt;do&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        &lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; --------&lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; 停止kafka---------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        ssh &lt;span class=&#34;nv&#34;&gt;$i&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;source /etc/profile;/export/server/kafka/bin/kafka-server-stop.sh stop&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;esac&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;kafka操作-kafkae6938de4bd9c&#34;&gt;&lt;a href=&#34;#kafka%e6%93%8d%e4%bd%9c-kafkae6938de4bd9c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Kafka操作 {#Kafka%E6%93%8D%E4%BD%9C}
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;&amp;ndash;bootstrap-server是连接kafka，对于集群而言，连接任何一台服务器的kafka都是一样的&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;命令行创建topic-e591bde4bba4e8a18ce5889be5bbbatopic&#34;&gt;&lt;a href=&#34;#%e5%91%bd%e4%bb%a4%e8%a1%8c%e5%88%9b%e5%bb%batopic-e591bde4bba4e8a18ce5889be5bbbatopic&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;命令行创建Topic {#%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%88%9B%E5%BB%BATopic}
&lt;/h3&gt;&lt;h3 id=&#34;e2808be7bc96e8be91&#34;&gt;&lt;a href=&#34;#e2808be7bc96e8be91&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/49403c709dce40f931823c3b0cf5ea0d.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt; {#%E2%80%8B%E7%BC%96%E8%BE%91}
&lt;/h3&gt;&lt;h3 id=&#34;消费者生产者联动-e6b688e8b4b9e88085e7949fe4baa7e88085e88194e58aa8&#34;&gt;&lt;a href=&#34;#%e6%b6%88%e8%b4%b9%e8%80%85%e7%94%9f%e4%ba%a7%e8%80%85%e8%81%94%e5%8a%a8-e6b688e8b4b9e88085e7949fe4baa7e88085e88194e58aa8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;消费者生产者联动 {#%E6%B6%88%E8%B4%B9%E8%80%85%E7%94%9F%E4%BA%A7%E8%80%85%E8%81%94%E5%8A%A8}
&lt;/h3&gt;&lt;h3 id=&#34;&#34;&gt;&lt;a href=&#34;#&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/686e2fdd6b20743399269793f8e77a0b.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/42262fff1a46f4831e04f1b7ed768939.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;先启动生产者，生产hello、hahaha，再启动消费者，生产者再生产aaaaa、bbbb。此时hello、hahaha属于历史消息，不会显示，只显示aaaaa、bbbb，若想显示历史消息，需要如下，此时消息是乱序的：&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/ffc0bdc441ef90df3b370852d05af4c1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;linux配置efak301-linuxe9858de7bdaeefak301&#34;&gt;&lt;a href=&#34;#linux%e9%85%8d%e7%bd%aeefak301-linuxe9858de7bdaeefak301&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Linux配置EFAK3.0.1 {#Linux%E9%85%8D%E7%BD%AEEFAK3.0.1}
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;1. 配置EFAK的环境变量&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ke.sh文件中引用的efak变量名是KE_HOME，所以环境变量名一定是KE_HOME，否则efak无法启动&lt;br&gt;
&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/ad81fe1df803cc2ba77a2487d420cd63.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;br&gt;
source /etc/profile&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;2. 修改kafka的bin/kafka-server-start.sh的内存配置，如果不修改，可能无法启动efak&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/9496f1566089cf16bee4bd251a664fef.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;内容如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;x&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$KAFKA_HEAP_OPTS&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;x&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;then&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;#export KAFKA_HEAP_OPTS=&amp;#34;-Xmx1G -Xms1G&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;KAFKA_HEAP_OPTS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;-server     -Xms2G   -Xmx2G   -XX:PermSize=128m   -XX:+UseG1GC   -XX:MaxGCPauseMillis=200  -XX:ParallelGCThreads=8   -XX:ConcGCThreads=5   -XX:InitiatingHeapOccupancyPercent=70&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;#监控kafka运行的端口号9999&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;JMX_PORT&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;9999&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;fi&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/blockquote&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>Kafka入门到入土——万字详解，图文并茂</title>
        <link>/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/</link>
        <pubDate>Sun, 05 May 2024 17:42:50 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/</guid>
        <description>&lt;p&gt;&lt;strong&gt;目录&lt;/strong&gt;{#main-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%EF%BC%88MQ%EF%BC%89&#34; &gt;消息队列（MQ）&lt;/a&gt;{#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%EF%BC%88MQ%EF%BC%89-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%80%E8%88%AC%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF&#34; &gt;消息队列一般应用场景&lt;/a&gt;{#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%80%E8%88%AC%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#JMS&#34; &gt;JMS&lt;/a&gt;{#JMS-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%C2%A0JMS%E6%A8%A1%E5%9E%8B&#34; &gt;JMS模型&lt;/a&gt;{#%C2%A0JMS%E6%A8%A1%E5%9E%8B-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E7%82%B9%E5%AF%B9%E7%82%B9%E6%A8%A1%E5%9E%8B%EF%BC%88peer%20to%20peer%EF%BC%89&#34; &gt;点对点模型（peer to peer）&lt;/a&gt;{#%E7%82%B9%E5%AF%B9%E7%82%B9%E6%A8%A1%E5%9E%8B%EF%BC%88peer%20to%20peer%EF%BC%89-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%A8%A1%E5%9E%8B&#34; &gt;发布订阅模型&lt;/a&gt;{#%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%A8%A1%E5%9E%8B-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Kafka%E6%9E%B6%E6%9E%84&#34; &gt;Kafka架构&lt;/a&gt;{#Kafka%E6%9E%B6%E6%9E%84-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Broker&#34; &gt;Broker&lt;/a&gt;{#Broker-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Controller%E9%80%89%E4%B8%BE&#34; &gt;Controller选举&lt;/a&gt;{#Controller%E9%80%89%E4%B8%BE-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Broker%E4%B8%8A%E4%B8%8B%E7%BA%BF%C2%A0&#34; &gt;Broker上下线&lt;/a&gt;{#Broker%E4%B8%8A%E4%B8%8B%E7%BA%BF%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Broker%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B&#34; &gt;Broker工作流程&lt;/a&gt;{#Broker%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Producer&#34; &gt;Producer&lt;/a&gt;{#Producer-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Consumer&#34; &gt;Consumer&lt;/a&gt;{#Consumer-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Consumer%20Group&#34; &gt;Consumer Group&lt;/a&gt;{#Consumer%20Group-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Topic&#34; &gt;Topic&lt;/a&gt;{#Topic-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Partition%E5%88%86%E5%8C%BA&#34; &gt;Partition分区&lt;/a&gt;{#Partition%E5%88%86%E5%8C%BA-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%88%86%E5%8C%BA%E5%A5%BD%E5%A4%84%C2%A0&#34; &gt;分区好处&lt;/a&gt;{#%E5%88%86%E5%8C%BA%E5%A5%BD%E5%A4%84%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%C2%A0%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E7%9A%84%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5&#34; &gt;生产者发送消息的分区策略&lt;/a&gt;{#%C2%A0%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E7%9A%84%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8Segment&#34; &gt;文件存储Segment&lt;/a&gt;{#%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8Segment-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%88%86%E5%8C%BA%E7%9A%84%E5%89%AF%E6%9C%AC&#34; &gt;分区的副本&lt;/a&gt;{#%E5%88%86%E5%8C%BA%E7%9A%84%E5%89%AF%E6%9C%AC-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Why%E5%88%86%E5%8C%BA%E5%89%AF%E6%9C%AC&#34; &gt;Why分区副本&lt;/a&gt;{#Why%E5%88%86%E5%8C%BA%E5%89%AF%E6%9C%AC-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%89%8B%E5%8A%A8%E8%B0%83%E6%95%B4%E5%88%86%E5%8C%BA%E5%89%AF%E6%9C%AC%E5%AD%98%E5%82%A8%E2%80%8B%E7%BC%96%E8%BE%91&#34; &gt;手动调整分区副本存储​编辑&lt;/a&gt;{#%E6%89%8B%E5%8A%A8%E8%B0%83%E6%95%B4%E5%88%86%E5%8C%BA%E5%89%AF%E6%9C%AC%E5%AD%98%E5%82%A8%E2%80%8B%E7%BC%96%E8%BE%91-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%89%AF%E6%9C%ACLeader%E5%88%86%E5%8C%BA%E8%87%AA%E5%8A%A8%E5%B9%B3%E8%A1%A1&#34; &gt;副本Leader分区自动平衡&lt;/a&gt;{#%E5%89%AF%E6%9C%ACLeader%E5%88%86%E5%8C%BA%E8%87%AA%E5%8A%A8%E5%B9%B3%E8%A1%A1-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%A2%9E%E5%8A%A0%E5%89%AF%E6%9C%AC%E6%95%B0%E9%87%8F%C2%A0&#34; &gt;增加副本数量&lt;/a&gt;{#%E5%A2%9E%E5%8A%A0%E5%89%AF%E6%9C%AC%E6%95%B0%E9%87%8F%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%89%AF%E6%9C%ACLeader%E9%80%89%E4%B8%BE&#34; &gt;副本Leader选举&lt;/a&gt;{#%E5%89%AF%E6%9C%ACLeader%E9%80%89%E4%B8%BE-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%89%AF%E6%9C%ACLeader%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D&#34; &gt;副本Leader故障恢复&lt;/a&gt;{#%E5%89%AF%E6%9C%ACLeader%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%89%AF%E6%9C%ACFollower%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D%C2%A0&#34; &gt;副本Follower故障恢复&lt;/a&gt;{#%E5%89%AF%E6%9C%ACFollower%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%C2%A0ISR%E6%9C%BA%E5%88%B6&#34; &gt;ISR机制&lt;/a&gt;{#%C2%A0ISR%E6%9C%BA%E5%88%B6-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E4%B8%8D%E5%AE%8C%E5%85%A8%E9%A6%96%E9%A2%86%E9%80%89%E4%B8%BE&#34; &gt;不完全首领选举&lt;/a&gt;{#%E4%B8%8D%E5%AE%8C%E5%85%A8%E9%A6%96%E9%A2%86%E9%80%89%E4%B8%BE-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%9C%80%E5%B0%91%E5%90%8C%E6%AD%A5%E5%89%AF%E6%9C%AC&#34; &gt;最少同步副本&lt;/a&gt;{#%E6%9C%80%E5%B0%91%E5%90%8C%E6%AD%A5%E5%89%AF%E6%9C%AC-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%95%B0%E6%8D%AE%E8%AF%B7%E6%B1%82%C2%A0&#34; &gt;数据请求&lt;/a&gt;{#%E6%95%B0%E6%8D%AE%E8%AF%B7%E6%B1%82%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E8%AF%B7%E6%B1%82%E6%9C%BA%E5%88%B6&#34; &gt;请求机制&lt;/a&gt;{#%E8%AF%B7%E6%B1%82%E6%9C%BA%E5%88%B6-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E7%94%9F%E4%BA%A7%E8%80%85%E8%AF%A6%E8%A7%A3&#34; &gt;生产者详解&lt;/a&gt;{#%E7%94%9F%E4%BA%A7%E8%80%85%E8%AF%A6%E8%A7%A3-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E7%9A%84%E8%BF%87%E7%A8%8B&#34; &gt;生产者发送消息的过程&lt;/a&gt;{#%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E7%9A%84%E8%BF%87%E7%A8%8B-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%B6%88%E6%81%AF%E5%8F%AF%E9%9D%A0%E6%80%A7%C2%A0&#34; &gt;消息可靠性&lt;/a&gt;{#%E6%B6%88%E6%81%AF%E5%8F%AF%E9%9D%A0%E6%80%A7%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#ACK%E5%BA%94%E7%AD%94%C2%A0&#34; &gt;ACK应答&lt;/a&gt;{#ACK%E5%BA%94%E7%AD%94%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%C2%A0%E6%95%B0%E6%8D%AE%E9%87%8D%E8%AF%95&#34; &gt;数据重试&lt;/a&gt;{#%C2%A0%E6%95%B0%E6%8D%AE%E9%87%8D%E8%AF%95-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%95%B0%E6%8D%AE%E4%B9%B1%E5%BA%8F%C2%A0&#34; &gt;数据乱序&lt;/a&gt;{#%E6%95%B0%E6%8D%AE%E4%B9%B1%E5%BA%8F%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%90%8C%E6%AD%A5%E5%8F%91%E9%80%81&#34; &gt;同步发送&lt;/a&gt;{#%E5%90%8C%E6%AD%A5%E5%8F%91%E9%80%81-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%BC%82%E6%AD%A5%E5%8F%91%E9%80%81&#34; &gt;异步发送&lt;/a&gt;{#%E5%BC%82%E6%AD%A5%E5%8F%91%E9%80%81-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E7%94%9F%E4%BA%A7%E8%80%85%E6%8F%90%E9%AB%98%E5%90%9E%E5%90%90%E9%87%8F&#34; &gt;生产者提高吞吐量&lt;/a&gt;{#%E7%94%9F%E4%BA%A7%E8%80%85%E6%8F%90%E9%AB%98%E5%90%9E%E5%90%90%E9%87%8F-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95%C2%A0&#34; &gt;压缩算法&lt;/a&gt;{#%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%B6%88%E8%B4%B9%E8%80%85%E8%AF%A6%E8%A7%A3&#34; &gt;消费者详解&lt;/a&gt;{#%E6%B6%88%E8%B4%B9%E8%80%85%E8%AF%A6%E8%A7%A3-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#push%26pull&#34; &gt;push&amp;amp;pull&lt;/a&gt;{#push%26pull-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E8%B0%83%E5%BA%A6%E5%99%A8%C2%A0&#34; &gt;消费者组调度器&lt;/a&gt;{#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E8%B0%83%E5%BA%A6%E5%99%A8%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%B6%88%E8%B4%B9%E8%80%85%E5%88%86%E9%85%8D%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5%C2%A0&#34; &gt;消费者分配分区策略&lt;/a&gt;{#%E6%B6%88%E8%B4%B9%E8%80%85%E5%88%86%E9%85%8D%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%B6%88%E8%B4%B9%E8%80%85Leader%C2%A0&#34; &gt;消费者Leader&lt;/a&gt;{#%E6%B6%88%E8%B4%B9%E8%80%85Leader%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%88%86%E5%8C%BA%E5%86%8D%E5%9D%87%E8%A1%A1&#34; &gt;分区再均衡&lt;/a&gt;{#%E5%88%86%E5%8C%BA%E5%86%8D%E5%9D%87%E8%A1%A1-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E7%9B%91%E5%90%AC%E5%88%86%E5%8C%BA%E5%86%8D%E5%9D%87%E8%A1%A1%C2%A0&#34; &gt;监听分区再均衡&lt;/a&gt;{#%E7%9B%91%E5%90%AC%E5%88%86%E5%8C%BA%E5%86%8D%E5%9D%87%E8%A1%A1%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%81%8F%E7%A7%BB%E9%87%8FOffset&#34; &gt;偏移量Offset&lt;/a&gt;{#%E5%81%8F%E7%A7%BB%E9%87%8FOffset-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#LSO&#34; &gt;LSO&lt;/a&gt;{#LSO-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#LEO&#34; &gt;LEO&lt;/a&gt;{#LEO-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#HW&#34; &gt;HW&lt;/a&gt;{#HW-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%89%8B%E5%8A%A8%E6%8F%90%E4%BA%A4%E5%81%8F%E7%A7%BB%E9%87%8F&#34; &gt;手动提交偏移量&lt;/a&gt;{#%E6%89%8B%E5%8A%A8%E6%8F%90%E4%BA%A4%E5%81%8F%E7%A7%BB%E9%87%8F-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%90%8C%E6%AD%A5%E6%8F%90%E4%BA%A4&#34; &gt;同步提交&lt;/a&gt;{#%E5%90%8C%E6%AD%A5%E6%8F%90%E4%BA%A4-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%BC%82%E6%AD%A5%E6%8F%90%E4%BA%A4&#34; &gt;异步提交&lt;/a&gt;{#%E5%BC%82%E6%AD%A5%E6%8F%90%E4%BA%A4-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E8%87%AA%E5%8A%A8%E6%8F%90%E4%BA%A4%E5%81%8F%E7%A7%BB%E9%87%8F&#34; &gt;自动提交偏移量&lt;/a&gt;{#%E8%87%AA%E5%8A%A8%E6%8F%90%E4%BA%A4%E5%81%8F%E7%A7%BB%E9%87%8F-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%88%AA%E8%87%B3%20%E5%B0%9A%E7%A1%85%E8%B0%B7kafka3.x%20P39&#34; &gt;截至 尚硅谷kafka3.x P39&lt;/a&gt;{#%E6%88%AA%E8%87%B3%20%E5%B0%9A%E7%A1%85%E8%B0%B7kafka3.x%20P39-toc}&lt;/p&gt;
&lt;hr&gt;
&lt;br /&gt;
&lt;p&gt;Kafka是一个由Scala和Java语言开发的，经典高吞吐量的分布式消息发布和订阅系统，也是大数据技术领域中用作数据交换的核心组件之一。它具有以下特点：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;支持消息的发布和订阅，类似于 RabbtMQ、ActiveMQ 等消息队列；&lt;/li&gt;
&lt;li&gt;支持数据实时处理；&lt;/li&gt;
&lt;li&gt;能保证消息的可靠性投递；&lt;/li&gt;
&lt;li&gt;支持消息的持久化存储，并通过多副本分布式的存储方案来保证消息的容错；&lt;/li&gt;
&lt;li&gt;高吞吐率，单 Broker 可以轻松处理数千个分区以及每秒百万级的消息量；&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;消息队列mq-e6b688e681afe9989fe58897efbc88mqefbc89&#34;&gt;&lt;a href=&#34;#%e6%b6%88%e6%81%af%e9%98%9f%e5%88%97mq-e6b688e681afe9989fe58897efbc88mqefbc89&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;消息队列（MQ） {#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%EF%BC%88MQ%EF%BC%89}
&lt;/h2&gt;&lt;p&gt;Kafka软件最初的设计就是专门用于数据传输的消息系统，类似功能的软件有RabbitMQ、ActiveMQ、RocketMQ等，这些软件的核心功能是传输数据，而Java中如果想要实现数据传输功能，那么这个软件一般需要遵循Java消息服务技术规范JMS。前面提到的ActiveMQ软件就完全遵循了JMS技术规范，而RabbitMQ是遵循了类似JMS规范并兼容JMS规范的跨平台的AMQP规范。除了上面描述的JMS，AMQP外，还有一种用于物联网小型设备之间传输消息的MQTT通讯协议。&lt;/p&gt;
&lt;p&gt;Kafka拥有作为一个消息系统应该具备的功能，但是却有着独特的设计。&lt;strong&gt;Kafka借鉴了JMS规范的思想，但是却并没有完全遵循JMS规范&lt;/strong&gt;。这也恰恰是软件名称为Kafka，而不是KafkaMQ的原因。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/9fb6defea02f0b37752ca1c4782231e4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;消息队列一般应用场景-e6b688e681afe9989fe58897e4b880e888ace5ba94e794a8e59cbae699af&#34;&gt;&lt;a href=&#34;#%e6%b6%88%e6%81%af%e9%98%9f%e5%88%97%e4%b8%80%e8%88%ac%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af-e6b688e681afe9989fe58897e4b880e888ace5ba94e794a8e59cbae699af&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;消息队列一般应用场景 {#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%80%E8%88%AC%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF}
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;**应用耦合：**多应用间通过消息队列对同一消息进行处理，避免调用接口失败导致整个过程失败。&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/2f16f6101cd2b4bb63436228734e155b.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/li&gt;
&lt;li&gt;**异步处理：**多应用对消息队列中同一消息进行处理，应用间并发处理消息，相比串行处理，减少处理时间&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/a55ab7be057ab04a981105f917581112.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;限流削峰：&lt;/strong&gt; 广泛应用于秒杀或抢购活动中，避免流量过大导致应用系统挂掉的情况。该方法有如下优点：
&lt;ul&gt;
&lt;li&gt;1.请求先入消息队列，而不是由业务处理系统直接处理，做了一次缓冲,极 大地减少了业务处理系统的压力；&lt;/li&gt;
&lt;li&gt;2.队列长度可以做限制，事实上，秒杀时，后入队列的用户无法秒杀到商品，这些请求可以直接被抛弃，返回活动已结束或商品已售完信息；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/257e558241daec39757876a0891b6458.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;消息驱动的系统：&lt;/strong&gt; 系统分为消息队列、消息生产者、消息消费者，生产者 负责产生消息，消费者(可能有多个)负责对消息进行处理。&lt;strong&gt;具体场景&lt;/strong&gt;：用户新上传了一批照片，人脸识别系统需要对这个用户的所有照片进行聚类，聚类完成后由对账系统重新生成用户的人脸索引(加快查询)。这三个子 系统间由消息队列连接起来，前一个阶段的处理结果放入队列中，后一个阶段从 队列中获取消息继续处理。&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/e7a0846fd5fe97485958c48ddb466a5d.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/li&gt;
&lt;li&gt;该方法有如下优点：1.避免了直接调用下一个系统导致当前系统失败； 2.每个子系统对于消息的处理方式可以更为灵活，可以选择收到消息时就处理，可以选择定时处理，也可以划分时间段按不同处理速度处理；&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;JMS&#34;&gt;&lt;a href=&#34;#JMS&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;JMS
&lt;/h3&gt;&lt;p&gt;JMS类似于JDBC，是java平台的消息中间件通用规范，定义了系统和系统之间传输消息的接口。&lt;/p&gt;
&lt;p&gt;为了实现系统和系统之间的数据传输，JMS规范中定义很多用于通信的组件：&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/285ce9d7a2a8f1e6ac77037c2f05e82b.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;JMS Producer&lt;/strong&gt; **：**JMS消息生产者。所谓的生产者，就是生产数据的客户端应用程序，这些应用通过JMS接口发送JMS消息。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JMS Provider&lt;/strong&gt;：JMS消息提供者。其实就是实现JMS接口和规范的消息中间件，也就是我们提供消息服务的软件系统，比如RabbitMQ、ActiveMQ、Kafka。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JMS Message&lt;/strong&gt;：JMS消息。这里的消息指的就是数据。一般采用Java数据模型进行封装，其中包含消息头，消息属性和消息主体内容。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JMS Consumer&lt;/strong&gt;：JMS消息消费者。所谓的消费者，就是从消息提供者中获取数据的客户端应用程序，这些应用通过JMS接口接收JMS消息。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;jms模型-c2a0jmse6a8a1e59e8b&#34;&gt;&lt;a href=&#34;#jms%e6%a8%a1%e5%9e%8b-c2a0jmse6a8a1e59e8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;JMS模型 {#%C2%A0JMS%E6%A8%A1%E5%9E%8B}
&lt;/h4&gt;&lt;h5 id=&#34;点对点模型peer-to-peer-e782b9e5afb9e782b9e6a8a1e59e8befbc88peer20to20peerefbc89&#34;&gt;&lt;a href=&#34;#%e7%82%b9%e5%af%b9%e7%82%b9%e6%a8%a1%e5%9e%8bpeer-to-peer-e782b9e5afb9e782b9e6a8a1e59e8befbc88peer20to20peerefbc89&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;点对点模型（peer to peer） {#%E7%82%B9%E5%AF%B9%E7%82%B9%E6%A8%A1%E5%9E%8B%EF%BC%88peer%20to%20peer%EF%BC%89}
&lt;/h5&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/fd0746d5877a27d6ecaa045fee8dc601.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特点：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个消息只有一个接收者（Consumer）(即一旦被消费，就会被删除)；&lt;/li&gt;
&lt;li&gt;发送者和接发收者间没有依赖性，发送者发送消息之后，不管有没有接收者在运行，都不会影响到发送者下次发送消息；&lt;/li&gt;
&lt;li&gt;接收者在成功接收消息之后需向队列应答成功，以便消息队列删除当前接 收的消息&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h5 id=&#34;发布订阅模型-e58f91e5b883e8aea2e99885e6a8a1e59e8b&#34;&gt;&lt;a href=&#34;#%e5%8f%91%e5%b8%83%e8%ae%a2%e9%98%85%e6%a8%a1%e5%9e%8b-e58f91e5b883e8aea2e99885e6a8a1e59e8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;发布订阅模型 {#%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%A8%A1%E5%9E%8B}
&lt;/h5&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/0bdabc2f116a00b4e787472f14c7c820.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特点：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个消息可以有多个订阅者，但是订阅者必须来自不同的消费者组；&lt;/li&gt;
&lt;li&gt;针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息。&lt;/li&gt;
&lt;li&gt;为了消费消息，订阅者需要提前订阅该角色主题，并保持在线运行；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Kafka采用就是这种模型。&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;kafka架构-kafkae69eb6e69e84&#34;&gt;&lt;a href=&#34;#kafka%e6%9e%b6%e6%9e%84-kafkae69eb6e69e84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Kafka架构 {#Kafka%E6%9E%B6%E6%9E%84}
&lt;/h2&gt;&lt;p&gt;在 Kafka 2.8.0 版本，移除了对 Zookeeper 的依赖，通过&lt;strong&gt;Kraft模式&lt;/strong&gt; 进行自己的集群管理，使用 Kafka&lt;strong&gt;内部的 Quorum 控制器&lt;/strong&gt;来取代 ZooKeeper管理元数据，这样我们无需维护zk集群，只要维护Kafka集群就可以了，节省运算资源。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;kafka基本数据单元被称为 message(消息)&lt;/strong&gt;，为减少网络开销，提高效率，多个消息会被放入同一批次(Batch) 中后再写入。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/f0678a5c5c02bd632d1b71553fd9fa4c.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;Broker&#34;&gt;&lt;a href=&#34;#Broker&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Broker
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;kafka 集群中包含多个服务实例（节点），这种服务实例被称为 broker（一个 broker 就是一个节点/一个服务器），每个 broker 都有一个唯一标识 broker.id，用于标识自己在集群中的身份，可以在配置文件 server.properties 中进行配置，或由程序自动生成。&lt;/li&gt;
&lt;li&gt;Broker 接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。Broker 为消费者提供服务，对读取分区的请求做出响应，返回已经提交到磁盘的消息。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;controller选举-controllere98089e4b8be&#34;&gt;&lt;a href=&#34;#controller%e9%80%89%e4%b8%be-controllere98089e4b8be&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Controller选举 {#Controller%E9%80%89%E4%B8%BE}
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;每一个集群都会选举出一个 Broker作为&lt;strong&gt;集群控制器&lt;/strong&gt; **(Controller)，它负责分区 Leader 选举，还负责管理主题分区及其副本的状态、元数据管理。**如果在运行过程中，Controller节点出现了故障，那么Kafka会依托于ZooKeeper软件选举其他的节点作为新的Controller，让Kafka集群实现高可用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特殊情况&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Controller节点并没有宕掉，而是因为网络的抖动，不稳定，导致和ZooKeeper之间的会话超时，那么此时，整个Kafka集群就会认为之前的Controller已经下线（退出）从而选举出新的Controller，而之前的Controller的网络又恢复了，以为自己还是Controller了，继续管理整个集群，那么此时，整个Kafka集群就有两个controller进行管理，那么其他的broker就懵了，不知道听谁的了，这种情况，我们称之为脑裂现象，为了解决这个问题，Kafka通过一个任期（epoch:纪元）的概念来解决，也就是说，每一个Broker当选Controller时，会告诉当前Broker是第几任Controller，一旦重新选举时，这个任期会自动增1，那么不同任期的Controller的epoch值是不同的，那么旧的controller一旦发现集群中有新任controller的时候，那么它就会完成退出操作（清空缓存，中断和broker的连接，并重新加载最新的缓存），让自己重新变成一个普通的Broker。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;broker上下线-brokere4b88ae4b88be7babfc2a0&#34;&gt;&lt;a href=&#34;#broker%e4%b8%8a%e4%b8%8b%e7%ba%bf-brokere4b88ae4b88be7babfc2a0&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Broker上下线 {#Broker%E4%B8%8A%E4%B8%8B%E7%BA%BF%C2%A0}
&lt;/h4&gt;&lt;p&gt;Controller 在初始化时，会利用 ZK 的 watch 机制注册很多不同类型的监听器，当监听的事件被触发时，Controller 就会触发相应的操作。Controller 在初始化时，会注册多种类型的监听器，主要有以下几种：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;/kafka/admin/reassign_partitions 节点，用于分区副本迁移的监听&lt;/li&gt;
&lt;li&gt;/kafka/isr_change_notification 节点，用于 Partition ISR 变动的监听&lt;/li&gt;
&lt;li&gt;/kafka/admin/preferred_replica_election 节点，用于需要进行 Partition 最优 leader 选举的监听&lt;/li&gt;
&lt;li&gt;/kafka/brokers/topics 节点，用于 Topic 新建的监听&lt;/li&gt;
&lt;li&gt;/kafka/brokers/topics/TOPIC_NAME 节点，用于 Topic Partition 扩容的监听&lt;/li&gt;
&lt;li&gt;/kafka/admin/delete_topics 节点，用于 Topic 删除的监听&lt;/li&gt;
&lt;li&gt;/kafka/brokers/ids 节点，用于 Broker 上下线的监听，记录有哪些kafka服务器在线。&lt;/li&gt;
&lt;li&gt;/kafka/controller节点，辅助选举leader&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/6eacf94f1216ffd1894cad366ae0a0ca.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;每台 Broker 在上线时，都会与ZK建立一个建立一个session，并在 /brokers/ids下注册一个节点，节点名字就是broker id，这个节点是临时节点，该节点内部会有这个 Broker 的详细节点信息。Controller会监听/brokers/ids这个路径下的所有子节点，如果有新的节点出现，那么就代表有新的Broker上线，如果有节点消失，就代表有broker下线，Controller会进行相应的处理，Kafka就是利用ZK的这种watch机制及临时节点的特性来完成集群 Broker的上下线。无论Controller监听到的哪一种节点的变化，都会进行相应的处理，同步整个集群元数据。&lt;/p&gt;
&lt;h4 id=&#34;broker工作流程-brokere5b7a5e4bd9ce6b581e7a88b&#34;&gt;&lt;a href=&#34;#broker%e5%b7%a5%e4%bd%9c%e6%b5%81%e7%a8%8b-brokere5b7a5e4bd9ce6b581e7a88b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Broker工作流程 {#Broker%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B}
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/afd0a4e19e5449dd0cfa84fe3c8213ed.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;Producer&#34;&gt;&lt;a href=&#34;#Producer&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Producer
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;一般情况下，生产者在把消息均衡地分布到在主题的所有分区上，而并不关心消息会被写到哪个分区。如果我们想要把消息写到指定的分区，可以通过&lt;strong&gt;自定义分区器&lt;/strong&gt;来实现。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;Consumer&#34;&gt;&lt;a href=&#34;#Consumer&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Consumer
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;消费者一定是归属于某个消费组中的&lt;/strong&gt;，消费者可以订阅一或多个主题，并按照分区中消息的顺序来读取。消费者通过检查消息的偏移量 (offset) 来区分读取过的消息。偏移量是一个不 断递增的数值，在创建消息时，Kafka 会把它添加到其中，在给定的分区里，每个消息的偏移量都是唯一的。消费者把每个分区最后读取的偏移量保存在 Zookeeper 或 Kafka 上，如果消费者关闭或者重启，它还可以重新获取该偏移量，以保证读取状态不会丢失。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;consumer-group-consumer20group&#34;&gt;&lt;a href=&#34;#consumer-group-consumer20group&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Consumer Group {#Consumer%20Group}
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;消费者组由一个或者多个消费者组成，&lt;strong&gt;同一个组中的消费者对于同一条消息只消费一次。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;每个消费者组都有一个 ID，即 group ID。组内的所有消费者协调在一起来消费 一个订阅主题的所有分区。当然，&lt;strong&gt;每个分区只能由同一个消费组内的一个消费者来消费，但可以由不同的消费组来消费。partition 数量决定了每个 consumer group 中并发消费者的最大数。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;因此要合理设置消费者组中的消费者数量，避免出现消费者闲置。&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;Topic&#34;&gt;&lt;a href=&#34;#Topic&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Topic
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;Kafka 的消息通过 Topics(主题) 进行分类，Kafka中有两个固定的，用于记录消费者偏移量和事务处理的主题，一个主题可以被分为若干个 Partitions(分区)，一个分区就是 一个提交日志 (commit log)。消息以追加的方式写入分区，然后以先入先出的顺序读取。&lt;strong&gt;Kafka 通过分区来实现数据的冗余和伸缩性，分区可以分布在不同的服务器上，这意味着一个 Topic 可以横跨多个服务器，以提供比单个服务器更强大的性能&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;由于一个 Topic 包含多个分区，因此无法在整个 Topic 范围内保证消息的顺序性，但可以保证消息在单个分区内的顺序性。&lt;/strong&gt;&lt;/p&gt;
&lt;br /&gt;&lt;/blockquote&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>Flume进阶--万字详解【老大爷也能学会】</title>
        <link>/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/</link>
        <pubDate>Sun, 28 Apr 2024 21:47:38 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/</guid>
        <description>&lt;h2 id=&#34;事务puttake&#34;&gt;&lt;a href=&#34;#%e4%ba%8b%e5%8a%a1puttake&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;事务（Put、Take）
&lt;/h2&gt;&lt;p&gt;put 事务把数据批处理写入临时缓冲区 putList，，然后 doCommit 去检查 Channel 内存队列是否足够合并，如果不够，就回滚数据，如果够，就把 putList 的数据写入到 Channel，然后由 take 事务从 channel 中拉取，写入到临时缓冲区 takeList，然后把数据从 takeList 发送到 HDFS，发送完毕后清空缓冲区，如果某个数据发送失败，就回滚到 channel。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image.png&#34;
	width=&#34;1582&#34;
	height=&#34;660&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image_hu_7583199c224fc93c.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image_hu_bdd73baa980f4760.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;239&#34;
		data-flex-basis=&#34;575px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;架构原理&#34;&gt;&lt;a href=&#34;#%e6%9e%b6%e6%9e%84%e5%8e%9f%e7%90%86&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;架构原理
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-1.png&#34;
	width=&#34;1521&#34;
	height=&#34;758&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-1_hu_124a7a8d78fb58bb.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-1_hu_8ff7e6529fb82c82.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;200&#34;
		data-flex-basis=&#34;481px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;在拦截阶段可以进行数据过滤清洗，洗掉脏数据。&lt;/p&gt;
&lt;h3 id=&#34;channelselector&#34;&gt;&lt;a href=&#34;#channelselector&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;ChannelSelector
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;因为一个 source 可以对应对各 channel&lt;/strong&gt; ，ChannelSelector 的作用就是选出 Event 将要被发往哪个 Channel。其共有两种类型， 分别是 Replicating（复制）和 Multiplexing（多路复用）。 ReplicatingSelector 会将同一个 Event &lt;strong&gt;发往所有&lt;/strong&gt;的 Channel，Multiplexing 会根据自定义的配置，将不同的 Event 发往不同的 Channel，Multiplexing 要结合拦截器使用，Multiplexing 会根据数据的头信息来决定发送到哪个 channel。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;sinkprocessor&#34;&gt;&lt;a href=&#34;#sinkprocessor&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;strong&gt;SinkProcessor&lt;/strong&gt;
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;一个 sink 只能绑定一个 channel，一个 channel 能绑定多个 sink。SinkProcessor 共 有 三 种 类 型 ， 分 别 是 DefaultSinkProcessor 、LoadBalancingSinkProcessor 和 FailoverSinkProcessor。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DefaultSinkProcessor 对 应 的 是 单个的 Sink&lt;/strong&gt; ， LoadBalancingSinkProcessor 和 FailoverSinkProcessor 对应的是 &lt;strong&gt;Sink Group&lt;/strong&gt;,LoadBalancingSinkProcessor 可以实现负载均衡的功能，FailoverSinkProcessor 可以错误恢复的功能。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;LoadBalancingSinkProcessor 负载均衡：&lt;/p&gt;
&lt;p&gt;一个 channel 会发给多个 sink&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-2.png&#34;
	width=&#34;990&#34;
	height=&#34;420&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-2_hu_6c49285a3e103af7.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-2_hu_a1bebb17cae83f23.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;235&#34;
		data-flex-basis=&#34;565px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;FailoverSinkProcessor 故障转移：&lt;/p&gt;
&lt;p&gt;当一个 sink 故障，任务会转移到其他 sink&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-3.png&#34;
	width=&#34;988&#34;
	height=&#34;400&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-3_hu_c71197231becb534.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-3_hu_355edecb5689cd82.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;247&#34;
		data-flex-basis=&#34;592px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;拓扑结构&#34;&gt;&lt;a href=&#34;#%e6%8b%93%e6%89%91%e7%bb%93%e6%9e%84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;拓扑结构
&lt;/h2&gt;&lt;h3 id=&#34;简单串联&#34;&gt;&lt;a href=&#34;#%e7%ae%80%e5%8d%95%e4%b8%b2%e8%81%94&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;简单串联
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-4.png&#34;
	width=&#34;1559&#34;
	height=&#34;773&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-4_hu_b3bf8623ae367e4c.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-4_hu_d5fef3d1650295f0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;201&#34;
		data-flex-basis=&#34;484px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;复制和多路复用&#34;&gt;&lt;a href=&#34;#%e5%a4%8d%e5%88%b6%e5%92%8c%e5%a4%9a%e8%b7%af%e5%a4%8d%e7%94%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;复制和多路复用
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-5.png&#34;
	width=&#34;1511&#34;
	height=&#34;1105&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-5_hu_83763143df0f54db.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-5_hu_96e82b6105502e3e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;136&#34;
		data-flex-basis=&#34;328px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;负载均衡和故障转移&#34;&gt;&lt;a href=&#34;#%e8%b4%9f%e8%bd%bd%e5%9d%87%e8%a1%a1%e5%92%8c%e6%95%85%e9%9a%9c%e8%bd%ac%e7%a7%bb&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;负载均衡和故障转移
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-6.png&#34;
	width=&#34;1412&#34;
	height=&#34;990&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-6_hu_bc1860421569b8f8.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-6_hu_778684d95d808a13.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;142&#34;
		data-flex-basis=&#34;342px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;聚合&#34;&gt;&lt;a href=&#34;#%e8%81%9a%e5%90%88&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;聚合
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-7.png&#34;
	width=&#34;1116&#34;
	height=&#34;960&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-7_hu_ee6f522aef6ef785.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-7_hu_76aeb26deaed92a8.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;116&#34;
		data-flex-basis=&#34;279px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;单源多出口案例&#34;&gt;&lt;a href=&#34;#%e5%8d%95%e6%ba%90%e5%a4%9a%e5%87%ba%e5%8f%a3%e6%a1%88%e4%be%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;单源多出口案例
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-8.png&#34;
	width=&#34;1248&#34;
	height=&#34;653&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-8_hu_23cd4d6dd707d84d.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-8_hu_53d52d0fb571962a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;191&#34;
		data-flex-basis=&#34;458px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;前置条件：&lt;/strong&gt;
linux01 上启动 hive，hdfs，在 linux03 上部署 3 个 flume 任务，启动 hdfs。linux01 和 linux03 配置 ssh 免密登录。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;要求：&lt;/strong&gt;
flume1 在 linux03 监听 linux01 的 hive 日志，把 hive 日志的新内容发送给 linux03 上的 flume2 和 flume3，flume2 把内容写到 hdfs，flume3 把内容写到 linux03 的本地文件/export/server/flume/job/group1/datas 文件夹中。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;剧透：&lt;/strong&gt;
flume3 成功把 hive 日志的新内容写到 datas 文件夹，说明 linux03 确实监听到了 linux01 的 hive 日志并且成功把日志从 linux01 弄到了 linux03，但是 flume2 却没有把新内容写到 hdfs，猜想的可能是因为在 linux03 上写 flume2 的配置文件**sinks.k1.hdfs.path = hdfs://linux01:9820/flume/group1/%Y%m%d/%H，**linux01 和 linux03 是不同的服务器，跨服务器没写进去，所以建议在同一台服务器搞。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;在 flume/job 目录中新建文件夹 group1 来存放本次案例的任务配置文件&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;mkdir group1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cd group1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;vim flume-file-flume.conf
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;vim flume-flume-hdfs.conf
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;vim flume-flume-dir.conf
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;三个 conf 配置如下：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;flume-file-flume.conf&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Name the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks = k1 k2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels = c1 c2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # 将数据流复制给所有 channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.selector.type = replicating
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.type = exec
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.command = ssh root&lt;span class=&#34;ni&#34;&gt;@linux01&lt;/span&gt; &amp;#39;tail -F /export/server/hive/logs/hive.log&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#因为hive在linux01&lt;/span&gt;，flume在linux03，为了跨服务器监听，这里用了ssh免密登录
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.shell = /bin/bash -c
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # sink 端的 avro 是一个数据发送者
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.hostname = linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.port = 4141
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.hostname = linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.port = 4142
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c2.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c2.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c2.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.channels = c1 c2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.channel = c2
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;flume-flume-hdfs.conf&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#Name&lt;/span&gt; the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks = k1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#Describe/configure&lt;/span&gt; the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#source&lt;/span&gt; 端的 avro 是一个数据接收服务
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r1.bind = linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r1.port = 4141
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#Describe&lt;/span&gt; the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.type = hdfs
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.hdfs.path = hdfs://linux01:9820/flume/group1/%Y%m%d/%H &lt;span class=&#34;ni&#34;&gt;#这里在&lt;/span&gt; linux03 把路径配置为 linux01 的 hdfs，可能就是出错原因
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#上传文件的前缀&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.hdfs.filePrefix = group1- &lt;span class=&#34;ni&#34;&gt;#是否按照时间滚动文件夹&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.hdfs.round = true &lt;span class=&#34;ni&#34;&gt;#多少时间单位创建一个新的文件夹&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.hdfs.roundValue = 1 &lt;span class=&#34;ni&#34;&gt;#重新定义时间单位&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.hdfs.roundUnit = hour &lt;span class=&#34;ni&#34;&gt;#是否使用本地时间戳&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.hdfs.useLocalTimeStamp = true &lt;span class=&#34;ni&#34;&gt;#积攒多少个&lt;/span&gt; Event 才 flush 到 HDFS 一次
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.hdfs.batchSize = 100 &lt;span class=&#34;ni&#34;&gt;#设置文件类型&lt;/span&gt;，可支持压缩
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.hdfs.fileType = DataStream &lt;span class=&#34;ni&#34;&gt;#多久生成一个新的文件&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.hdfs.rollInterval = 30 &lt;span class=&#34;ni&#34;&gt;#设置每个文件的滚动大小大概是&lt;/span&gt; 128M
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.hdfs.rollSize = 134217700 &lt;span class=&#34;ni&#34;&gt;#文件的滚动与&lt;/span&gt; Event 数量无关
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.hdfs.rollCount = 0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#Describe&lt;/span&gt; the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels.c1.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels.c1.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels.c1.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#Bind&lt;/span&gt; the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;flume-flume-dir.conf&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#Name&lt;/span&gt; the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks = k1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels = c2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r1.bind = linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r1.port = 4142
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k1.type = file_roll
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k1.sink.directory = /export/server/flume/job/group1/datas
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c2.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c2.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c2.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r1.channels = c2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k1.channel = c2
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;3 个配置文件写好后，在 linux03 启动 hdfs，然后在 flume 文件夹下启动三个 flume 任务&lt;/p&gt;
&lt;p&gt;flume-ng agent -c conf/ -n a3 -f job/group1/flume-flume-dir.conf&lt;/p&gt;
&lt;p&gt;flume-ng agent -c conf/ -n a2 -f job/group1/flume-flume-hdfs.conf&lt;/p&gt;
&lt;p&gt;flume-ng agent -c conf/ -n a1 -f job/group1/flume-file-flume.conf&lt;/p&gt;
&lt;p&gt;在 linux01 启动 hdfs ，然后启动 hivemetastore 和 hive，开始操作 hive，就会产生 hive 日志记录在 hive.log。&lt;/p&gt;
&lt;p&gt;注意！hive.log 没产生新内容可能是因为 hive 日志配置出错，去 conf 文件夹找 hive-log4j2.properties，找到 hive.log.dir。修改成自己的 logs 路径，默认路径可能要用到 hive 环境变量，如果环境变量没有就直接写绝对路径。
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-9.png&#34;
	width=&#34;1119&#34;
	height=&#34;201&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-9_hu_df5e0baa2f798ff5.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-9_hu_72b5c4bbf3d757dd.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;556&#34;
		data-flex-basis=&#34;1336px&#34;
	
&gt;
datas 确实产生了新文件，但是有很多空的，不知道咋回事，可能是任务配置问题。
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-10.png&#34;
	width=&#34;1044&#34;
	height=&#34;804&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-10_hu_186d3528c8b8279f.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-10_hu_3ad360ad4ecae4c9.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;129&#34;
		data-flex-basis=&#34;311px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;故障转移案例&#34;&gt;&lt;a href=&#34;#%e6%95%85%e9%9a%9c%e8%bd%ac%e7%a7%bb%e6%a1%88%e4%be%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;故障转移案例
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-11.png&#34;
	width=&#34;1436&#34;
	height=&#34;734&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-11_hu_18a2ea47c6ee537e.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-11_hu_af2f6474dc226e45.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;195&#34;
		data-flex-basis=&#34;469px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;前置：确保 4142、4141、44444 端口没被占用
在 linux03 的 flume/job 目录建 group2 文件夹，里面有如下 3 个配置文件：&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;flume-flume-console1.conf&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Name the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks = k1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r1.bind = linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r1.port = 4141
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.type = logger
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels.c1.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels.c1.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels.c1.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;flume-flume-console2.conf&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#Name&lt;/span&gt; the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks = k1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels = c2 # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r1.bind = linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r1.port = 4142 # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k1.type = logger # Describe the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c2.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c2.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c2.transactionCapacity = 100 # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r1.channels = c2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k1.channel = c2
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;flume-netcat-flume.conf&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Name the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinkgroups = g1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks = k1 k2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.type = netcat
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.bind = localhost
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.port = 44444
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinkgroups.g1.processor.type = failover
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinkgroups.g1.processor.priority.k1 = 5
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinkgroups.g1.processor.priority.k2 = 10
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#配置优先级&lt;/span&gt;，k1=5，优先级更高，因此数据会优先发给k1,当k1故障时，才会转移到k2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinkgroups.g1.processor.maxpenalty = 10000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.hostname = linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.port = 4141
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.hostname = linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.port = 4142
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinkgroups.g1.sinks = k1 k2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;分别启动 3 个任务&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1）flume-ng agent -c conf/ -n a3 -f job/group2/flume-flume-console2.conf -Dflume.root.logger=INFO,console&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;2）flume-ng agent -c conf/ -n a2 -f job/group2/flume-flume-console1.conf -Dflume.root.logger=INFO,console&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;3）flume-ng agent -c conf/ -n a1 -f job/group2/flume-netcat-flume.conf
运行 nc localhost 44444 并发送内容:
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-12.png&#34;
	width=&#34;758&#34;
	height=&#34;357&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-12_hu_4695483e0537af40.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-12_hu_1136186937ad7577.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;212&#34;
		data-flex-basis=&#34;509px&#34;
	
&gt;
在 console2 接收到（发送的汉字显示&amp;hellip;&amp;hellip;）
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-13.png&#34;
	width=&#34;2439&#34;
	height=&#34;392&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-13_hu_bd5e02c4de5283eb.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-13_hu_b60a000c4cd61376.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;622&#34;
		data-flex-basis=&#34;1493px&#34;
	
&gt;
找到 flume 进程，制造故障杀死 console2 任务，此时发生故障 ，任务会转移到 console1：
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-14.png&#34;
	width=&#34;1519&#34;
	height=&#34;565&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-14_hu_47c7b0836ddc751b.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-14_hu_7747d4b70d76b6c3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;268&#34;
		data-flex-basis=&#34;645px&#34;
	
&gt;
可以看到 console2 被杀死
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-15.png&#34;
	width=&#34;1777&#34;
	height=&#34;327&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-15_hu_78568c4c2a5d924c.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-15_hu_a1bc7eef27ecb403.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;543&#34;
		data-flex-basis=&#34;1304px&#34;
	
&gt;
继续发送数据，数据被 console1 接收
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-16.png&#34;
	width=&#34;734&#34;
	height=&#34;481&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-16_hu_27fec984d5ace5cf.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-16_hu_da10d12b697cf94.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;152&#34;
		data-flex-basis=&#34;366px&#34;
	
&gt;
console1 接收成功 。
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-17.png&#34;
	width=&#34;2424&#34;
	height=&#34;264&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-17_hu_f94472efee72010a.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-17_hu_a3d4cbf8982a213e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;918&#34;
		data-flex-basis=&#34;2203px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;负载均衡案例&#34;&gt;&lt;a href=&#34;#%e8%b4%9f%e8%bd%bd%e5%9d%87%e8%a1%a1%e6%a1%88%e4%be%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;负载均衡案例
&lt;/h2&gt;&lt;p&gt;尚硅谷 P25&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Name the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinkgroups = g1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks = k1 k2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.type = netcat
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.bind = localhost
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.port = 44444
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinkgroups.g1.processor.type = load_balance
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.hostname = linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.port = 4141
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.hostname = linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.port = 4142
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinkgroups.g1.sinks = k1 k2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;配置文件和故障转移案例一样，只有 flume-netcat-flume.conf 需要改。&lt;/p&gt;
&lt;h2 id=&#34;flume-聚合案例&#34;&gt;&lt;a href=&#34;#flume-%e8%81%9a%e5%90%88%e6%a1%88%e4%be%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Flume 聚合案例
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-18.png&#34;
	width=&#34;1401&#34;
	height=&#34;705&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-18_hu_b52e7eb81f2f0796.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-18_hu_2c464d839e46192e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;198&#34;
		data-flex-basis=&#34;476px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;三台服务器：linux01、linux02、linux03，监控 linux03 的 job/group.log 文件和 linux02 的 44444 端口，把监测到的数据传给 linux01，在 linux01 的控制台输出。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;linux03 的任务配置文件：flume3-logger-flume.conf&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Name the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks = k1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.type = exec
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.command = tail -F /export/server/flume/job/group.log
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.shell = /bin/bash -c
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.hostname = linux01
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.port = 4141
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;linux02 的任务配置文件：flume2-netcat-flume.conf&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Name the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks = k1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r1.type = netcat
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r1.bind = linux02
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r1.port = 44444
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.hostname = linux01
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.port = 4141
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Use a channel which buffers events in memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels.c1.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels.c1.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels.c1.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k1.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;linux01 的任务配置文件：flume1-flume-logger.conf&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Name the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks = k1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r1.bind = linux01
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r1.port = 4141
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k1.type = logger
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c1.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c1.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c1.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k1.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;自定义拦截器&#34;&gt;&lt;a href=&#34;#%e8%87%aa%e5%ae%9a%e4%b9%89%e6%8b%a6%e6%88%aa%e5%99%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;自定义拦截器
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;案例需求&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;使用 Flume 采集服务器本地日志，需要按照日志类型的不同，将不同种类的日志发往不 同的分析系统。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;需求分析&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;实际的开发中，一台服务器产生的日志类型可能有很多种，不同类型的日志可能需要 发送到不同的分析系统。此时会用到 Flume 拓扑结构中的 Multiplexing 结构，Multiplexing 的原理是，根据 event 中 Header 的某个 key 的值，将不同的 event 发送到不同的 Channel，所以我们需要自定义一个 Interceptor，为不同类型的 event 的 Header 中的 key 赋予不同的值。
在该案例中，我们以端口数据模拟日志，以是否包含”atguigu”模拟不同类型的日志， 我们需要自定义 interceptor 区分数据中是否包含”atguigu”，将其分别发往不同的分析 系统（Channel）。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-19.png&#34;
	width=&#34;1426&#34;
	height=&#34;584&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-19_hu_1bc3435833ccf53e.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-19_hu_b1cfcb02dd52d9e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;244&#34;
		data-flex-basis=&#34;586px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;自定义拦截器打成-jar-包&#34;&gt;&lt;a href=&#34;#%e8%87%aa%e5%ae%9a%e4%b9%89%e6%8b%a6%e6%88%aa%e5%99%a8%e6%89%93%e6%88%90-jar-%e5%8c%85&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;自定义拦截器打成 jar 包
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;77
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;78
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;79
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;org.apache.flume.Context&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;org.apache.flume.Event&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;org.apache.flume.interceptor.Interceptor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;java.util.ArrayList&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;java.util.List&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;java.util.Map&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;/**
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt; * @Author:懒大王Smile
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt; * @Date: 2024/4/28
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt; * @Time: 19:54
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt; * @Description:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt; */&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;TypeInterceptor&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;implements&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Interceptor&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//声明一个存放事件的集合&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;private&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;List&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Event&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;addHeaderEvents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Override&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;initialize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//初始化存放事件的集合&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;addHeaderEvents&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ArrayList&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//单个事件拦截&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Override&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Event&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;intercept&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Event&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;event&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//1.获取事件中的头信息&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Map&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;headers&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;event&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getHeaders&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//2.获取事件中的 body 信息&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;body&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;event&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getBody&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;());&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//3.根据 body 中是否有&amp;#34;atguigu&amp;#34;来决定添加怎样的头信息&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;body&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;contains&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;sereins&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//4.添加头信息&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;headers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;put&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;sereins&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//4.添加头信息&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;headers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;put&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;other&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;event&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//批量事件拦截&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Override&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;List&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Event&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;intercept&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;List&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Event&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;events&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//1.清空集合&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;addHeaderEvents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;clear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//2.遍历 events&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Event&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;event&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;events&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//3.给每一个事件添加头信息&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;addHeaderEvents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;add&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;intercept&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;event&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//4.返回结果&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;addHeaderEvents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Override&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;close&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//静态内部类&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;static&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Builder&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;implements&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Interceptor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;Builder&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Override&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Interceptor&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;build&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;TypeInterceptor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nd&#34;&gt;@Override&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;configure&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Context&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;context&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;所需依赖：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;project&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;xmlns=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;http://maven.apache.org/POM/4.0.0&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         &lt;span class=&#34;na&#34;&gt;xmlns:xsi=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;http://www.w3.org/2001/XMLSchema-instance&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         &lt;span class=&#34;na&#34;&gt;xsi:schemaLocation=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&amp;#34;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;modelVersion&amp;gt;&lt;/span&gt;4.0.0&lt;span class=&#34;nt&#34;&gt;&amp;lt;/modelVersion&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;com.smile&lt;span class=&#34;nt&#34;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;interceptor&lt;span class=&#34;nt&#34;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;1.0-SNAPSHOT&lt;span class=&#34;nt&#34;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;properties&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;maven.compiler.source&amp;gt;&lt;/span&gt;8&lt;span class=&#34;nt&#34;&gt;&amp;lt;/maven.compiler.source&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;maven.compiler.target&amp;gt;&lt;/span&gt;8&lt;span class=&#34;nt&#34;&gt;&amp;lt;/maven.compiler.target&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;project.build.sourceEncoding&amp;gt;&lt;/span&gt;UTF-8&lt;span class=&#34;nt&#34;&gt;&amp;lt;/project.build.sourceEncoding&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/properties&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;dependencies&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.apache.flume&lt;span class=&#34;nt&#34;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;flume-ng-core&lt;span class=&#34;nt&#34;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;1.9.0&lt;span class=&#34;nt&#34;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependencies&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;/project&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;jar 包打好放到 flume 的 lib 目录下，flume 启动时会加载 lib 的所有 jar 包。&lt;/p&gt;
&lt;p&gt;注意！！自定义拦截器的 jar 包源代码是定制的，里面的过滤拦截规则需要根据实际业务来编写，并且 jdk 最好是 1.8。&lt;/p&gt;
&lt;h3 id=&#34;任务配置文件&#34;&gt;&lt;a href=&#34;#%e4%bb%bb%e5%8a%a1%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;任务配置文件
&lt;/h3&gt;&lt;p&gt;inux01 服务器的 flume 配置文件 job/group4/interceptor-flume1.conf：&lt;/p&gt;
&lt;p&gt;1 配置 1 个 netcat source，1 个 sink group（2 个 avro sink）， 并配置相应的 ChannelSelector 和 interceptor。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Name the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks = k1 k2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels = c1 c2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.type = netcat
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.bind = localhost
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.port = 44444
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.interceptors = i1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.interceptors.i1.type = TypeInterceptor$Builder
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.selector.type = multiplexing
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.selector.header = type
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.selector.mapping.sereins = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.selector.mapping.other = c2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.hostname = linux02
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.port = 4141
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.type=avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.hostname = linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.port = 4242
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Use a channel which buffers events in memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Use a channel which buffers events in memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c2.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c2.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c2.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.channels = c1 c2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k2.channel = c2
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;linux02 服务器的 flume 配置文件 job/group4/interceptor-flume2.conf：&lt;/p&gt;
&lt;p&gt;配置一个 avro source 和一个 logger sink&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks = k1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.bind = linux02
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.port = 4141
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.type = logger
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;linux03 服务器的 flume 配置文件 job/group4/interceptor-flume3.conf：&lt;/p&gt;
&lt;p&gt;配置一个 avro source 和一个 logger sink&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources = r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks = k1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.type = avro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.bind = linux03
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.port = 4242
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.type = logger
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.channel = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;以上配置完后，在 linux01 nc localhost 44444,然而&lt;img src=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-20.png&#34;
	width=&#34;862&#34;
	height=&#34;94&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-20_hu_e70a91c1daa17f20.png 480w, /zh-cn/post/2024/04/flume%E8%BF%9B%E9%98%B6--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E8%80%81%E5%A4%A7%E7%88%B7%E4%B9%9F%E8%83%BD%E5%AD%A6%E4%BC%9A/image-20_hu_a03db1a18740a197.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;917&#34;
		data-flex-basis=&#34;2200px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;尚硅谷 Flume P33&lt;/strong&gt;
&lt;strong&gt;后面的以后再搞&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;自定义-source&#34;&gt;&lt;a href=&#34;#%e8%87%aa%e5%ae%9a%e4%b9%89-source&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;自定义 Source
&lt;/h2&gt;&lt;h2 id=&#34;自定义-sink&#34;&gt;&lt;a href=&#34;#%e8%87%aa%e5%ae%9a%e4%b9%89-sink&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;自定义 Sink
&lt;/h2&gt;&lt;h2 id=&#34;事务源码&#34;&gt;&lt;a href=&#34;#%e4%ba%8b%e5%8a%a1%e6%ba%90%e7%a0%81&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;事务源码
&lt;/h2&gt;</description>
        </item>
        <item>
        <title>Flume入门--万字详解</title>
        <link>/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/</link>
        <pubDate>Mon, 22 Apr 2024 15:22:55 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/</guid>
        <description>&lt;h2 id=&#34;概述&#34;&gt;&lt;a href=&#34;#%e6%a6%82%e8%bf%b0&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;概述
&lt;/h2&gt;&lt;p&gt;Flume 是 Cloudera 提供的一个高可用的，高可靠的，分布式的海量&lt;strong&gt;日志采集&lt;/strong&gt;、聚合和传 输的系统。Flume 基于流式架构，灵活简单。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image.png&#34;
	width=&#34;1218&#34;
	height=&#34;508&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image_hu_7fa87b03cd51f56f.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image_hu_86396d462a02f120.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;239&#34;
		data-flex-basis=&#34;575px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;基础架构&#34;&gt;&lt;a href=&#34;#%e5%9f%ba%e7%a1%80%e6%9e%b6%e6%9e%84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;基础架构
&lt;/h2&gt;&lt;p&gt;Flume 运行的核心是 Agent。Flume 是以 agent 为最小的独立运行单位。一个 agent 就是一个 JVM。它是 一个完整的数据收集工具，含有三个核心组件，分别是 source、 channel、 sink。通过这些组件， Event 可以从一个地方流向另一个地方。如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-1.png&#34;
	width=&#34;1210&#34;
	height=&#34;464&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-1_hu_8561a55c375264ae.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-1_hu_a84eee12f3e31d2f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;260&#34;
		data-flex-basis=&#34;625px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;agent&#34;&gt;&lt;a href=&#34;#agent&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Agent
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Agent 是一个 JVM 进程，它以事件的形式将数据从源头送至目的。&lt;/li&gt;
&lt;li&gt;Agent 主要有 3 个部分组成，Source、Channel、Sink。同一台服务器可以运行多个 Agent，每个 Agent 可以有多个 source、sink、channel。Agent 的名字可以相同但是不能同时启动任务，否则会出现冲突。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;source&#34;&gt;&lt;a href=&#34;#source&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Source
&lt;/h4&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Source 是负责接收数据到 Flume Agent 并传给 Channel 的组件。&lt;/li&gt;
&lt;li&gt;Source 组件可以处理各种类型、各种格式的日志数据，包括 avro、thrift、exec、jms、spooling directory、netcat、taildir、 sequence generator、syslog、http、legacy 这些不同的数据源。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;sink&#34;&gt;&lt;a href=&#34;#sink&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Sink
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Sink 不断地轮询 Channel 中的事件且批量地移除它们，并将这些事件批量写入到存储系统或索引系统、或者被发送到另一个 Flume Agent。&lt;/li&gt;
&lt;li&gt;Sink 组件目的地包括 hdfs、logger、avro、thrift、ipc、file、HBase、solr、自定义。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;channel&#34;&gt;&lt;a href=&#34;#channel&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Channel
&lt;/h4&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Channel 是位于 Source 和 Sink 之间的缓冲区。因此，Channel 允许 Source 和 Sink 运作在不同的速率上。&lt;/li&gt;
&lt;li&gt;Channel 是线程安全的，可以同时处理几个 Source 的写入操作和几个 Sink 的读取操作。&lt;/li&gt;
&lt;li&gt;Flume 自带两种 Channel：Memory Channel 和 File Channel。&lt;/li&gt;
&lt;li&gt;Memory Channel 是内存中的队列。Memory Channel 在不需要关心数据丢失的情景下适 用。如果需要关心数据丢失，那么 Memory Channel 就不应该使用，因为程序死亡、机器宕 机或者重启都会导致数据丢失。&lt;/li&gt;
&lt;li&gt;File Channel 将所有事件写到磁盘。因此在程序关闭或机器宕机的情况下不会丢失数 据。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;selector&#34;&gt;&lt;a href=&#34;#selector&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;selector
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;选择器，作用于 source 端，然后决定数据发往哪个目标。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;interceptor&#34;&gt;&lt;a href=&#34;#interceptor&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;interceptor
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;拦截器，flume 允许使用拦截器拦截数据。允许使用拦截器链，作用于 source 和 sink 阶段。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;event&#34;&gt;&lt;a href=&#34;#event&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Event
&lt;/h4&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;传输单元，Flume 数据传输的基本单元，以 Event 的形式将数据从源头送至目的地。&lt;/li&gt;
&lt;li&gt;Event 由 Header 和 Body 两部分组成，Header 用来存放该 event 的一些属性，为 K-V 结构， Body 用来存放该条数据，形式为字节数组。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-2.png&#34;
	width=&#34;816&#34;
	height=&#34;151&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-2_hu_3f35ec154b3b11eb.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-2_hu_10f158814c30aa1e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;540&#34;
		data-flex-basis=&#34;1296px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;安装部署&#34;&gt;&lt;a href=&#34;#%e5%ae%89%e8%a3%85%e9%83%a8%e7%bd%b2&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;安装部署
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;解压&lt;/p&gt;
&lt;p&gt;tar -zxvf /export/server/apache-flume-1.9.0-bin.tar.gz /export/server/&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;为了让 flume1.9 兼容 hadoop3.x，要删除 flume lib 包下的 guava-11.0.2.jar&lt;/p&gt;
&lt;p&gt;rm guava-11.0.2.jar&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;Netcat&#34;&gt;&lt;a href=&#34;#Netcat&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Netcat
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;安装&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;sudo yum install -y nc&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;简单案例&lt;/strong&gt;&lt;/p&gt;
&lt;br /&gt;
&lt;h2 id=&#34;flume-入门案例&#34;&gt;&lt;a href=&#34;#flume-%e5%85%a5%e9%97%a8%e6%a1%88%e4%be%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Flume 入门案例
&lt;/h2&gt;&lt;h3 id=&#34;netcat-本机端口监控&#34;&gt;&lt;a href=&#34;#netcat-%e6%9c%ac%e6%9c%ba%e7%ab%af%e5%8f%a3%e7%9b%91%e6%8e%a7&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;netcat 本机端口监控
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;在 flume 文件夹下创建工作目录 job&lt;/p&gt;
&lt;p&gt;mkdir job&lt;/p&gt;
&lt;p&gt;在 job 目录下建立任务配置文件，文件名任取，建议见名知意，net 表示数据源是端口，logger 表示数据是日志文件&lt;/p&gt;
&lt;p&gt;vim net-flume-logger.conf&lt;/p&gt;
&lt;p&gt;配置文件内容如下：&lt;/p&gt;&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Name the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources = r1 &lt;span class=&#34;ni&#34;&gt;#a1是该agent名&lt;/span&gt;，不可重复
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks = k1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels = c1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.type = netcat
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.bind = localhost
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sources.r1.port = 4444
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.sinks.k1.type = logger
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Use a channel which buffers events in memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.capacity = 1000 &lt;span class=&#34;ni&#34;&gt;#最多接收1000个event&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a1.channels.c1.transactionCapacity = 100 &lt;span class=&#34;ni&#34;&gt;#100个事务&lt;/span&gt;，一次最多发送100个event，事务失败会回滚。capacity应该 &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;transactionCapacity&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;Bind&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;source&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;sink&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;channel&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;na&#34;&gt;a1&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;sources&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;r1&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;channels &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;c1&lt;/span&gt; &lt;span class=&#34;ni&#34;&gt;#一个source可以绑定多个channel&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;na&#34;&gt;a1&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;sinks&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;k1&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;channel &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;c1&lt;/span&gt; &lt;span class=&#34;ni&#34;&gt;#一个sink只能绑定一个channel&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;启动两个终端，一个终端启动监听任务：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;在 flume 目录下运行：
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;flume-ng agent -c conf/ -n a1 -f job/flume-netcat-logger.conf -D flume.root.logger=INFO,console
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;参数说明：
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--conf/-c：表示配置文件存储在 conf/目录
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--name/-n：表示给 agent 起名为 a1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;--conf-file/-f：flume 本次启动读取的配置文件是在 job 文件夹下的 flume-telnet.conf 文件.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;-Dflume.root.logger=INFO,console ：-D 表示 flume 运行时动态修改 flume.root.logger 参数属性值，并将控制台日志打印级别设置为 INFO 级别。日志级别包括:log、info、warn、 error。
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-3.png&#34;
	width=&#34;1530&#34;
	height=&#34;653&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-3_hu_c99cca4dd73c04ee.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-3_hu_82ef1505922ff86c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;234&#34;
		data-flex-basis=&#34;562px&#34;
	
&gt;
另一个终端使用 netcat 向监听的端口发送内容：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;nc localhost 4444
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-4.png&#34;
	width=&#34;746&#34;
	height=&#34;258&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-4_hu_b88eeeed95de3eea.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-4_hu_76944ab34e474c55.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;289&#34;
		data-flex-basis=&#34;693px&#34;
	
&gt;
检查启动任务的端口是否收到。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;监控-hive-日志上传-hdfs&#34;&gt;&lt;a href=&#34;#%e7%9b%91%e6%8e%a7-hive-%e6%97%a5%e5%bf%97%e4%b8%8a%e4%bc%a0-hdfs&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;监控 hive 日志上传 hdfs
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-5.png&#34;
	width=&#34;1221&#34;
	height=&#34;507&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-5_hu_9d7ee6a4efc594d2.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-5_hu_d7e8bc859122f40b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;240&#34;
		data-flex-basis=&#34;577px&#34;
	
&gt;
在 job 目录下新建任务的配置文件 flume-file-hdfs.conf,内容如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Name the components on this agent
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources = r2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks = k2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels = c2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r2.type = exec
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r2.command = tail -F /export/server/hive/logs/metastore.log
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#这里我监控的是hive的元数据日志&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.type = hdfs
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.hdfs.path = hdfs://linux01:8020/flume/%Y%m%d/%H
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#8020端口不要搞错&lt;/span&gt;，具体查看hadoop的core-site.xml
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#上传文件的前缀&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.hdfs.filePrefix = logs-
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#是否按照时间滚动文件夹&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.hdfs.round = true
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#多少时间单位创建一个新的文件夹&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.hdfs.roundValue = 1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#重新定义时间单位&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.hdfs.roundUnit = hour
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#是否使用本地时间戳&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.hdfs.useLocalTimeStamp = true
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#注意&lt;/span&gt;：对于所有与时间相关的转义序列，Event Header 中必须存在以 “timestamp”的
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    key（除非 hdfs.useLocalTimeStamp 设置为 true，此方法会使用 TimestampInterceptor 自
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    动添加 timestamp）。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#积攒多少个&lt;/span&gt; Event 才 flush 到 HDFS 一次
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.hdfs.batchSize = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#设置文件类型&lt;/span&gt;，可支持压缩
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.hdfs.fileType = DataStream
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#多久生成一个新的文件&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.hdfs.rollInterval = 60
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#设置每个文件的滚动大小&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.hdfs.rollSize = 134217700
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#文件的滚动与&lt;/span&gt; Event 数量无关
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.hdfs.rollCount = 0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Use a channel which buffers events in memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels.c2.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels.c2.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.channels.c2.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sources.r2.channels = c2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a2.sinks.k2.channel = c2
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;先在 flume 文件夹下启动 flume 的监听任务：
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;bin/flume-ng agent -c conf/ -n a2 -f job/flume-file-hdfs.conf -D flume.root.logger=INFO,console
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;启动 hdfs 和 hive 的元数据服务
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;start-dfs.sh
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;start-hivemetastore.sh（自己写的脚本）
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;启动 hive 开始操作
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hive 会产生元数据记录在 metastore.log 中，然后就会被 flume 监听到，flume 就会把监听到的日志写到 hdfs 的 flume 文件夹中。浏览器打开 linux01:9870 查看 hdfs 的文件目录，发现新建了 flume 文件夹，表示操作成功。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;![alt text](image-6.png)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;注意！监听的 metastore.log 一定要是有效的，如果无效那么 hive 的日志就不会写到里面，flume 就检测不到，具体去看 hive 的日志配置教程。另外启动的 agent 的任务名字和配置文件不要搞错了，是 a2 和 flume-file-hdfs.conf。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;实时读取目录文件到-hdfs&#34;&gt;&lt;a href=&#34;#%e5%ae%9e%e6%97%b6%e8%af%bb%e5%8f%96%e7%9b%ae%e5%bd%95%e6%96%87%e4%bb%b6%e5%88%b0-hdfs&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;实时读取目录文件到 hdfs
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-7.png&#34;
	width=&#34;1209&#34;
	height=&#34;528&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-7_hu_c1105467385bcae8.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-7_hu_4fa73e60ceb8a8e2.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;228&#34;
		data-flex-basis=&#34;549px&#34;
	
&gt;
job 目录下编写 flume-dir-hdfs.conf 配置文件：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources = r3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks = k3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels = c3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # source类型是目录
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r3.type = spooldir
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#定义监控目录&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r3.spoolDir = /export/server/flume/upload
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#定义文件上传完后缀&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r3.fileSuffix = .COMPLETED
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#是否有文件头&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r3.fileHeader = true
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#忽略所有以&lt;/span&gt;.tmp 结尾的文件，不上传
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r3.ignorePattern = ([^ ]*\.tmp)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.type = hdfs
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.path = hdfs://linux01:8020/flume/upload/%Y%m%d/%H
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#hdfs的upload文件夹要提前手动创建好&lt;/span&gt;，flume不会自己创建，否则会报错。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#上传文件的前缀&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.filePrefix = upload-
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#是否按照时间滚动文件夹&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.round = true
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#多少时间单位创建一个新的文件夹&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.roundValue = 1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#重新定义时间单位&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.roundUnit = hour
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#是否使用本地时间戳&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.useLocalTimeStamp = true
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#积攒多少个&lt;/span&gt; Event 才 flush 到 HDFS 一次
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.batchSize = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#设置文件类型&lt;/span&gt;，可支持压缩
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.fileType = DataStream
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#多久生成一个新的文件&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.rollInterval = 60
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#设置每个文件的滚动大小大概是&lt;/span&gt; 128M
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.rollSize = 134217700
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#文件的滚动与&lt;/span&gt; Event 数量无关
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.rollCount = 0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Use a channel which buffers events in memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c3.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c3.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c3.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r3.channels = c3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.channel = c3
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;flume 目录下启动 agent 任务：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;bin/flume-ng agent -c conf/ -n a3 -f job/flume-dir-hdfs.conf&lt;/p&gt;
&lt;p&gt;注意不要有多余的空格或者不可见字符，启动失败就去 logs 文件夹看日志&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;任务启动后就往监控目录/flume/upload 文件夹里面放文件 ，放了 3 个不同的文件，其中 tmp 后缀的文件没有上传到 hdfs，因为在 conf 配置文件中把 tmp 后缀的排除了，其他两个上传完毕，并且文件后缀改成 COMPLETED：
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-8.png&#34;
	width=&#34;1132&#34;
	height=&#34;287&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-8_hu_119154576442338f.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-8_hu_638b356095ba52.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;394&#34;
		data-flex-basis=&#34;946px&#34;
	
&gt;
进入 linux01:9870 查看 hdfs 文件目录， 确实上传成功了。
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-9.png&#34;
	width=&#34;2437&#34;
	height=&#34;1006&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-9_hu_2110e997d452b344.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-9_hu_2c54946dfe69fec2.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;242&#34;
		data-flex-basis=&#34;581px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意！&lt;/strong&gt; 配置文件的 a3.sinks.k3.hdfs.path 指定了 linux01:8020，那么 flume 任务就得在 linux01 上启动，在 linux02 上启动不会生效。我的 linux01 是主机，linux02 和 03 是从机，就算在 linux02 上启动 flume 任务，把 a3.sinks.k3.hdfs.path 改成 linux02:8020 也不行，必须在 linux01 上启动。
&lt;strong&gt;注意！向/flume/upload 文件夹放的文件不能是以上传完成的后缀结尾，比如文件上传成功后缀是 COMPLETED，那么向里面放的文件后缀就不能是 COMPLETED。另外不能向 upload 里放文件名相同的文件，文件名相同的文件只有第一个会上传到 hdfs，之后的不会，因为 linux 同一目录不允许同名文件产生。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;实时监控目录下的多个追加文件&#34;&gt;&lt;a href=&#34;#%e5%ae%9e%e6%97%b6%e7%9b%91%e6%8e%a7%e7%9b%ae%e5%bd%95%e4%b8%8b%e7%9a%84%e5%a4%9a%e4%b8%aa%e8%bf%bd%e5%8a%a0%e6%96%87%e4%bb%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;实时监控目录下的多个追加文件
&lt;/h3&gt;&lt;p&gt;案例 2 的 exec source 适用于监控一个实时追加的文件，不能断点续传，案例 3 的 spooldir source 适用于同步新文件，但不适用于实时监听同步追加日志的文件，而该案例的 Taildir Source 就适合于监听多个实时追加的文件，并能实现断点续传。
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-10.png&#34;
	width=&#34;1447&#34;
	height=&#34;533&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-10_hu_3bb935b9cd6bd98f.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-10_hu_20ded4dc11c4bc23.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;271&#34;
		data-flex-basis=&#34;651px&#34;
	
&gt;
job 目录下新建 flume-dir-hdfs.conf 配置文件：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources = r3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks = k3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels = c3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe/configure the source
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#定义source类型&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r3.type = TAILDIR
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r3.positionFile = /export/server/apache-flume-1.9.0-bin/tail_dir.json
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#注意&lt;/span&gt;！！这里我把软链接flume换成了本来的真实目录apache-flume-1.9.0-bin，原因后面讲
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#文件组&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r3.filegroups = f1 f2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r3.filegroups.f1 = /export/server/flume/files/.*file.*
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r3.filegroups.f2 = /export/server/flume/files2/.*log.*
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Describe the sink
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.type = hdfs
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.path = hdfs://linux01:8020/flume/upload2/%Y%m%d/%H
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#上传文件的前缀&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.filePrefix = upload-
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#是否按照时间滚动文件夹&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.round = true
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#多少时间单位创建一个新的文件夹&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.roundValue = 1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#重新定义时间单位&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.roundUnit = hour
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#是否使用本地时间戳&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.useLocalTimeStamp = true
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#积攒多少个&lt;/span&gt; Event 才 flush 到 HDFS 一次
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.batchSize = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#设置文件类型&lt;/span&gt;，可支持压缩
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.fileType = DataStream
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#多久生成一个新的文件&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.rollInterval = 60
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#设置每个文件的滚动大小大概是&lt;/span&gt; 128M
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.rollSize = 134217700
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;ni&#34;&gt;#文件的滚动与&lt;/span&gt; Event 数量无关
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.hdfs.rollCount = 0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Use a channel which buffers events in memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c3.type = memory
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c3.capacity = 1000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.channels.c3.transactionCapacity = 100
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    # Bind the source and sink to the channel
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sources.r3.channels = c3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    a3.sinks.k3.channel = c3
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;hdfs 文件中提前创建好 upload2 文件夹：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;hdfs dfs -mkdir /flume/upload2
flume 文件夹中创建 files 和 files2 文件夹，分别在里面写 file1.txt 和 log1.log 用于追加内容让 flume 任务监控。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-11.png&#34;
	width=&#34;987&#34;
	height=&#34;232&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-11_hu_3d3be8253f4ea89.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-11_hu_35e2622993d720d4.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;425&#34;
		data-flex-basis=&#34;1021px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-12.png&#34;
	width=&#34;954&#34;
	height=&#34;188&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-12_hu_ff914089d72061b5.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-12_hu_8ba92ad258b85007.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;507&#34;
		data-flex-basis=&#34;1217px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;flume 文件下启动监控任务：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;bin/flume-ng agent -c conf/ -n a3 -f job/flume-taildir-hdfs.conf&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;用 echo 命令向 file1.txt 和 log1.log 追加内容，追加的内容就会被 flume 检测到，filume 就会把追加的新内容上传到 hdfs 的 upload2 文件夹。
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-13.png&#34;
	width=&#34;2338&#34;
	height=&#34;789&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-13_hu_496ca9bcf5e7b220.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-13_hu_a6a4961d82b88ca0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;296&#34;
		data-flex-basis=&#34;711px&#34;
	
&gt;
追加的内容被检测到，上传到 hdfs，案例成功！
&lt;strong&gt;注意！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;配置文件中，之前是 a3.sources.r3.positionFile = /export/server/flume/tail_dir.json，此时启动 flume 任务能成功，但是追加的内容不会上传到 hdfs，也就是该案例没有成功。去 logs 文件中查看 flume.log 日志，发现有一段报错如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;21&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;四月&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;2024&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;22&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;52&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;16&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;844&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ERROR&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;conf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;poller&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;org&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;apache&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;flume&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;AbstractConfigurationProvider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;loadSources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;355&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Source&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;r3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;has&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;been&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;removed&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;due&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;an&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;error&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;during&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;configuration&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;org&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;apache&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;flume&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;FlumeException&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Error&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;creating&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;positionFile&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;parent&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;directories&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;org&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;apache&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;flume&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;source&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;taildir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;TaildirSource&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;configure&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;TaildirSource&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;170&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;org&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;apache&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;flume&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;conf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;Configurables&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;configure&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Configurables&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;41&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;org&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;apache&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;flume&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;AbstractConfigurationProvider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;loadSources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;AbstractConfigurationProvider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;325&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;org&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;apache&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;flume&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;AbstractConfigurationProvider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getConfiguration&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;AbstractConfigurationProvider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;105&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;org&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;apache&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;flume&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;PollingPropertiesFileConfigurationProvider$FileWatcherRunnable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;run&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;PollingPropertiesFileConfigurationProvider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;145&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;util&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;concurrent&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;Executors$RunnableAdapter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;call&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Executors&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;511&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;util&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;concurrent&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;FutureTask&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;runAndReset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;FutureTask&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;308&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;util&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;concurrent&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;ScheduledThreadPoolExecutor$ScheduledFutureTask&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;access$301&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ScheduledThreadPoolExecutor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;180&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;util&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;concurrent&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;ScheduledThreadPoolExecutor$ScheduledFutureTask&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;run&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ScheduledThreadPoolExecutor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;294&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;util&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;concurrent&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;ThreadPoolExecutor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;runWorker&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ThreadPoolExecutor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;1149&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;util&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;concurrent&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;ThreadPoolExecutor$Worker&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;run&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ThreadPoolExecutor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;624&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;lang&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;Thread&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;run&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Thread&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;750&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Caused&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;by&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;nio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;FileAlreadyExistsException&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;export&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;server&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;flume&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;nio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;fs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;UnixException&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;translateToIOException&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UnixException&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;88&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;nio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;fs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;UnixException&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;rethrowAsIOException&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UnixException&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;102&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;nio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;fs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;UnixException&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;rethrowAsIOException&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UnixException&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;107&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;nio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;fs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;UnixFileSystemProvider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;createDirectory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UnixFileSystemProvider&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;384&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;nio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;Files&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;createDirectory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Files&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;674&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;nio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;Files&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;createAndCheckIsDirectory&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Files&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;781&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;nio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;Files&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;createDirectories&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Files&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;727&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;at&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;org&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;apache&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;flume&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;source&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;taildir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;TaildirSource&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;configure&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;TaildirSource&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;java&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;168&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;	&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;more&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;给 chatgpt 看看：
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-14.png&#34;
	width=&#34;2367&#34;
	height=&#34;575&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-14_hu_d8ff180d4f856e7e.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-14_hu_1b7cc2868b1adaee.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;411&#34;
		data-flex-basis=&#34;987px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;大概意思是 positionfile 文件创建失败，原因是出现命名冲突。因为我的 flume 是个软链接，类似于快捷方式，但是写到配置文件里面，flume 程序就会把配置文件的 flume 当成真实目录，进而就会尝试创建名为 flume 的目录并且去进到创建的 flume 目录创建 r3，然而我已经存在了名为 flume 的软链接，程序就会创建 flume 目录失败，进而无法创建 r3。所以把配置文件的 flume 换成真实的 apache-flume-1.9.0-bin 目录就可以了，这样就可以生成 r3，也就是 positionfile = tail_dir.json 文件。当然另一种解决方法就是把 positionfile 的位置放到 flume 软链接外面。&lt;/p&gt;
&lt;p&gt;tail_dir.json 文件内容如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;inode&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;83899573&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;pos&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;44&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;file&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/export/server/flume/files/file1.txt&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;inode是文件的唯一标识&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，即使文件重命名也不会变，除非文件删除&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pos表示读到哪里&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;：监控文件的绝对路径&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;json文件靠inode和file两个值表示pos位置信息&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;注意！ log4j 日志框架每天凌晨会自动把前一天的 hive.log 的文件改名，后缀加上日期，这点对我们监控空间极不友好，假如我们监控的是 hive.log，然而 hive.log 会自动更名 hive.log.2024-xx-xx,监测的文件名发生改变,而 inode 不变，然而 json 文件中记录的绝对路径仍然是 hive.log，此时的 hive.log 是新的文件，inode 变化，就无法实现断点续传。&lt;/p&gt;
&lt;p&gt;解决方案：1）不使用 log4j 2）修改 flume 源码包
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-15.png&#34;
	width=&#34;1254&#34;
	height=&#34;358&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-15_hu_ba0e6aa6ca72876.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-15_hu_7ea1071690105aa1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;350&#34;
		data-flex-basis=&#34;840px&#34;
	
&gt;
&lt;strong&gt;修改源码包的 TailFile 和 ReliableTaildirEventReader：&lt;/strong&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-16.png&#34;
	width=&#34;1832&#34;
	height=&#34;407&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-16_hu_8a8bb29403f12b75.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-16_hu_b5c7c5bcf5a462e7.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;450&#34;
		data-flex-basis=&#34;1080px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-17.png&#34;
	width=&#34;1728&#34;
	height=&#34;1402&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-17_hu_2651a7ca432bfddb.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-17_hu_f849167e43dfc987.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;123&#34;
		data-flex-basis=&#34;295px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-18.png&#34;
	width=&#34;1742&#34;
	height=&#34;1357&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-18_hu_41296967dda0ef4e.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-18_hu_b14b812135d32750.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;128&#34;
		data-flex-basis=&#34;308px&#34;
	
&gt;
修改后重新打包生成 flume-taildir-source-1.9.0.jar,进入 flume/lib 目录下，把原来的 jar 包替换掉：
&lt;img src=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-19.png&#34;
	width=&#34;1593&#34;
	height=&#34;96&#34;
	srcset=&#34;/zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-19_hu_9bc37188bd235dcd.png 480w, /zh-cn/post/2024/04/flume%E5%85%A5%E9%97%A8--%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3/image-19_hu_a5fd9ba123f64dc8.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;1659&#34;
		data-flex-basis=&#34;3982px&#34;
	
&gt;
把原来的后缀改成 bak。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>大数据—Zookeeper集群入门及使用</title>
        <link>/zh-cn/post/2024/04/%E5%A4%A7%E6%95%B0%E6%8D%AEzookeeper%E9%9B%86%E7%BE%A4%E5%85%A5%E9%97%A8%E5%8F%8A%E4%BD%BF%E7%94%A8/</link>
        <pubDate>Fri, 19 Apr 2024 16:43:51 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/04/%E5%A4%A7%E6%95%B0%E6%8D%AEzookeeper%E9%9B%86%E7%BE%A4%E5%85%A5%E9%97%A8%E5%8F%8A%E4%BD%BF%E7%94%A8/</guid>
        <description>&lt;h2 id=&#34;概述&#34;&gt;&lt;a href=&#34;#%e6%a6%82%e8%bf%b0&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;概述
&lt;/h2&gt;&lt;p&gt;ZooKeeper 是一个开源的&lt;strong&gt;分布式协调服务&lt;/strong&gt;，它的设计目标是&lt;strong&gt;为那些高吞吐的大型分布式系统提供一个高性能、高可用、且具有严格顺序访问控制 能力的分布式协调服务&lt;/strong&gt;，并以一系列简单易用的接口提供给用户使用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ZooKeeper 将数据存全量储在内存中以保持高性能&lt;/strong&gt;，并通过服务集群来实现高可用，由于 Zookeeper 的所有更新和删除都是&lt;strong&gt;基于事务&lt;/strong&gt;的，所以其在&lt;strong&gt;读多写少&lt;/strong&gt;的应用场景中有着很高的性能表现。&lt;/p&gt;
&lt;p&gt;简单来说 zookeeper 就是动物园管理者，管理协调大数据里面的一堆组件，比如 hadoop、hive、habse 等等。Zookeeper 可以用于实现分布 式系统中常见的发布/订阅、负载均衡、命令服务、分布式协调/通知、集群管理、Master 选举、分布式 锁和分布式队列等功能。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-07-55.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-07-55&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;特点&#34;&gt;&lt;a href=&#34;#%e7%89%b9%e7%82%b9&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;特点
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;-&lt;strong&gt;顺序一致性&lt;/strong&gt;：从一个客户端发起的事务请求，最终都会严格按照其发起顺序被应用到 Zookeeper 中； -&lt;strong&gt;原子性&lt;/strong&gt;：所有事务请求的处理结果在整个集群中所有机器上都是一致的；不存在部分机器应用了该事务，而另一部分没有应用的情况，一次数据更新要么成功要么失败。 -&lt;strong&gt;单一视图（全局数据一致）&lt;/strong&gt;：每个 server 保存相同的数据副本，无论 client 连接哪个 server，看到的数据一致； -&lt;strong&gt;可靠性&lt;/strong&gt;：一旦服务端成功应用了一个事务，则其引起的改变会一直保留，直到被另外一个事务所更改； -&lt;strong&gt;实时性&lt;/strong&gt;：一旦一个事务被成功应用后，在一定时间范围内，Zookeeper 可以保证客户端立即可以读取到这个事务变更后的最新状态的数据。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;集群中只要有&lt;strong&gt;半数以上节点存活&lt;/strong&gt;，zk 集群就可以正常服务，所以 zk 适合安装奇数台。&lt;/li&gt;
&lt;li&gt;一个 leader，多个 follower，&lt;strong&gt;leader 挂掉之后会从 follower 中重新选举&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;集群配置&#34;&gt;&lt;a href=&#34;#%e9%9b%86%e7%be%a4%e9%85%8d%e7%bd%ae&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;集群配置  
&lt;/h2&gt;&lt;p&gt;可以由一组 Zookeeper 服务构成 Zookeeper 集群，集群中每台机器都会单独在内存中维护自身的状 态，并且每台机器之间都保持着通讯，只要集群中有半数机器能够正常工作，那么整个集群就可以正常提供服务。对于来自客户端的每个更新请求，Zookeeper 都会分配一个全局唯一的递增 ID，这个 ID 反映了所有事 务请求的先后顺序。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-08-29.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-08-29&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;以下是集群环境搭建不是单机环境&#34;&gt;&lt;a href=&#34;#%e4%bb%a5%e4%b8%8b%e6%98%af%e9%9b%86%e7%be%a4%e7%8e%af%e5%a2%83%e6%90%ad%e5%bb%ba%e4%b8%8d%e6%98%af%e5%8d%95%e6%9c%ba%e7%8e%af%e5%a2%83&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;以下是集群环境搭建！！不是单机环境
&lt;/h3&gt;&lt;p&gt;解压、安装、配置环境变量并生效这三步省略，直接修改配置：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;进入 conf/目录下，拷贝配置样本并进行修改：&lt;/p&gt;
&lt;p&gt;cp zoo_sample.cfg zoo.cfg&lt;/p&gt;
&lt;p&gt;指定数据存储目录和日志文件目录（此时还没有目录，稍后手动创建），修改后完整配置如下：&lt;/p&gt;&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cobol&#34; data-lang=&#34;cobol&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c&#34;&gt;tickTi&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;me&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2000
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#用于计算的&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;基础时间单元。比如&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;session&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;超时：&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;tickTime&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;；
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;initLi&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;mit&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#用于集群，&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;允许从节点连接并同步到&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;master&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;节点的初始化连接时间，以&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;tickTime&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;的倍数来表示；
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;syncLi&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;mit&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#用于集群，&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;master&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;主节点与从节点之间发送消息，请求和应答时间长度（心&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;跳机制）；
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;dataDi&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=/&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;export&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;server&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;zookeeper&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;kr&#34;&gt;data
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kr&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#数据存储位&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;置；稍后手动创建
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;dataLo&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;gDir&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=/&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;export&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;server&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;zookeeper&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;logs&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#日志目录；&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;稍后手动创建
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;client&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;Port&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2181
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;#用于客户端&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;连接的端口，默认&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2181
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# serv&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;er&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1 &lt;/span&gt;&lt;span class=&#34;err&#34;&gt;这个&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;是服务器的标识，可以是任意有效数字，标识这是第几个服务器节点，这个标识要写到
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;dataDi&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;r目录下面myid&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;文件里，如果没有&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;myid&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;文件要自己创建
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# 指名集群&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;间通讯端口和选举端口
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;server&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;linux01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2888&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3888
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;server&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;linux02&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2888&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3888
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;mi&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;server&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;linux03&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2888&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3888
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;标识节点序号&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;分别在三台主机的 dataDir 目录下新建 myid 文件,并写入对应的节点标识。Zookeeper 集群通过 myid 文件识别集群节点，并通过上文配置的节点通信端口和选举端口来进行节点通信，选举出 Leader 节点。&lt;/p&gt;
&lt;p&gt;在&lt;strong&gt;每个服务器&lt;/strong&gt;上的/export/server/zookeeper/下创建 data 目录，在里面创建 myid 文件并写入各自序号，这个序号必须和 zoo.cfg 文件的序号相同。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;分别在三台主机上启动 ZK 集群&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;zkServer.sh start&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;集群验证&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;zkServer.sh status&lt;/p&gt;
&lt;p&gt;可以看到一个 leader，两个 follower，那么 zk 集群配置成功&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;启动客户端&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;zkCli.sh&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;集群角色&#34;&gt;&lt;a href=&#34;#%e9%9b%86%e7%be%a4%e8%a7%92%e8%89%b2&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;集群角色
&lt;/h2&gt;&lt;p&gt;ZK 集群有一个 leader 和多个 follower。&lt;/p&gt;
&lt;h3 id=&#34;leader&#34;&gt;&lt;a href=&#34;#leader&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Leader
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;为客户端提供读写服务，并维护集群状态，它是由集群选举所产生的；&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;follower&#34;&gt;&lt;a href=&#34;#follower&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Follower
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;为客户端提供读写服务，并定期向 Leader 汇报自己的节点状态。同时也参与写操作 “过半写成功”的策略和 Leader 的选举；&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;observer&#34;&gt;&lt;a href=&#34;#observer&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Observer
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;为客户端提供读写服务，并定期向 Leader 汇报自己的节点状态，但不参与写操作“过 半写成功”的策略和 Leader 的选举，因此 Observer 可以在不影响写性能的情况下提升集群的读性 能。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;会话&#34;&gt;&lt;a href=&#34;#%e4%bc%9a%e8%af%9d&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;会话
&lt;/h2&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Zookeeper 客户端通过 TCP 长连接连接到服务集群，会话 (Session) 从第一次连接开始就已经建立，之 后通过心跳检测机制来保持有效的会话状态。通过这个连接，客户端可以发送请求并接收响应，同时也 可以接收到 Watch 事件的通知。&lt;/li&gt;
&lt;li&gt;关于会话中另外一个核心的概念是&lt;strong&gt;sessionTimeOut(会话超时时间)&lt;/strong&gt;，当由于网络故障或者客户端主动 断开等原因，导致连接断开，此时只要在会话超时时间之内重新建立连接，则之前创建的会话依然有效。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;watcher&#34;&gt;&lt;a href=&#34;#watcher&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Watcher
&lt;/h2&gt;&lt;p&gt;Zookeeper 中一个常用的功能是 Watcher(事件监听器)，它允许用户在指定节点上针对感兴趣的事件注 册监听，当事件发生时，监听器会被触发，并将事件信息推送到客户端。该机制是 Zookeeper 实现分布式协调服务的重要特性。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-09-09.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-09-09&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;节点的值变化监听&#34;&gt;&lt;a href=&#34;#%e8%8a%82%e7%82%b9%e7%9a%84%e5%80%bc%e5%8f%98%e5%8c%96%e7%9b%91%e5%90%ac&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;节点的值变化监听  
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;1）在 linux01 主机上注册监听/sanguo 节点数据变化&lt;/p&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 26] get -w /sanguo&lt;/p&gt;
&lt;p&gt;2）在 linux02 主机上修改/sanguo 节点的数据&lt;/p&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 1] set /sanguo &amp;ldquo;xisi&amp;rdquo;&lt;/p&gt;
&lt;p&gt;3）观察 linux01 主机收到数据变化的监听&lt;/p&gt;
&lt;p&gt;WATCHER::&lt;/p&gt;
&lt;p&gt;WatchedEvent        state:SyncConnected         ype:NodeDataChanged&lt;/p&gt;
&lt;p&gt;path:/sanguo&lt;/p&gt;
&lt;p&gt;注意：在 linux02 再多次修改/sanguo 的值，linux01 上不会再收到监听。因为注册 一次，只能监听一次。想再次监听，需要再次注册。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;节点的子节点变化监听路径变化&#34;&gt;&lt;a href=&#34;#%e8%8a%82%e7%82%b9%e7%9a%84%e5%ad%90%e8%8a%82%e7%82%b9%e5%8f%98%e5%8c%96%e7%9b%91%e5%90%ac%e8%b7%af%e5%be%84%e5%8f%98%e5%8c%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;节点的子节点变化监听（路径变化）
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;1）在 linux01 主机上注册监听/sanguo 节点的子节点变化&lt;/p&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 1] ls -w /sanguo [shuguo, weiguo]&lt;/p&gt;
&lt;p&gt;2）在 linux02  主机/sanguo 节点上创建子节点&lt;/p&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 2] create /sanguo/jin &amp;ldquo;simayi&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Created /sanguo/jin&lt;/p&gt;
&lt;p&gt;3）观察  linux01 主机收到子节点变化的监听&lt;/p&gt;
&lt;p&gt;WATCHER::&lt;/p&gt;
&lt;p&gt;WatchedEvent        state:SyncConnected        type:NodeChildrenChanged&lt;/p&gt;
&lt;p&gt;path:/sanguo&lt;/p&gt;
&lt;p&gt;注意：节点的路径变化，也是注册一次，生效一次。想多次生效，就需要多次注册&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;工作机制&#34;&gt;&lt;a href=&#34;#%e5%b7%a5%e4%bd%9c%e6%9c%ba%e5%88%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;工作机制
&lt;/h2&gt;&lt;p&gt;从设计模式的角度来理解，zk 是基于观察者模式设计的分布式服务管理框架，它负责存储和管理大家都关心的数据，然后接受观察者的注册，一旦这些数据的状态发生变化，Zookeeper 就将负责通知已经在 Zookeeper 上注册的那些观察者做出相应的反应。&lt;/p&gt;
&lt;p&gt;集群中只要有半数以上节点存活，Zookeeper 集群就能正常服务。所以 Zookeeper 适合安装奇数台服务器。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-09-29.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-09-29&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;客户端向服务端写数据流程&#34;&gt;&lt;a href=&#34;#%e5%ae%a2%e6%88%b7%e7%ab%af%e5%90%91%e6%9c%8d%e5%8a%a1%e7%ab%af%e5%86%99%e6%95%b0%e6%8d%ae%e6%b5%81%e7%a8%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;客户端向服务端写数据流程
&lt;/h3&gt;&lt;h4 id=&#34;写请求发给-leader&#34;&gt;&lt;a href=&#34;#%e5%86%99%e8%af%b7%e6%b1%82%e5%8f%91%e7%bb%99-leader&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;写请求发给 leader
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-09-51.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-09-51&#34;
	
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;写请求发给-follower&#34;&gt;&lt;a href=&#34;#%e5%86%99%e8%af%b7%e6%b1%82%e5%8f%91%e7%bb%99-follower&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;写请求发给 follower
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-10-05.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-10-05&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;客户端向服务端读数据流程&#34;&gt;&lt;a href=&#34;#%e5%ae%a2%e6%88%b7%e7%ab%af%e5%90%91%e6%9c%8d%e5%8a%a1%e7%ab%af%e8%af%bb%e6%95%b0%e6%8d%ae%e6%b5%81%e7%a8%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;客户端向服务端读数据流程
&lt;/h3&gt;&lt;p&gt;由于 ZK 满足的是 CAP 中的 CP，，没有满足 Available，因此读出的数据可能是老数据。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-10-15.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-10-15&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;选举机制&#34;&gt;&lt;a href=&#34;#%e9%80%89%e4%b8%be%e6%9c%ba%e5%88%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;选举机制
&lt;/h2&gt;&lt;h3 id=&#34;初次启动&#34;&gt;&lt;a href=&#34;#%e5%88%9d%e6%ac%a1%e5%90%af%e5%8a%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;初次启动
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-10-26.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-10-26&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;非处次启动&#34;&gt;&lt;a href=&#34;#%e9%9d%9e%e5%a4%84%e6%ac%a1%e5%90%af%e5%8a%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;非处次启动
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-10-33.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-10-33&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;集群脑裂&#34;&gt;&lt;a href=&#34;#%e9%9b%86%e7%be%a4%e8%84%91%e8%a3%82&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;集群脑裂
&lt;/h3&gt;&lt;p&gt;对于一个集群，通常多台机器会部署在不同机房，来提高这个集群的可用性。保证可用性的同时，会发生一种机房间网络线路故障，导致机房间网络不通，而集群被割裂成几个小集群。这时候子集群各自选主导致“脑裂”的情况。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;过半机制是如何防止脑裂现象产生的？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;ZooKeeper 的过半机制导致不可能产生 2 个 leader，因为少于等于一半是不可能产生 leader 的，这就使得不论机房的机器如何分配都不可能发生脑裂。&lt;/p&gt;
&lt;h2 id=&#34;数据模型&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e6%8d%ae%e6%a8%a1%e5%9e%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;数据模型
&lt;/h2&gt;&lt;p&gt;Zookeeper 数据模型是由一系列基本数据单元 Znode (数据节点) 组成的节点树，其中根节点为 / ，每个节点上都会保存自己的数据和节点信息。不过和常见的文件系统不同，Zookeeper 将数据全量存储在内存中，以此来实现高吞吐，减少访 问延迟。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-10-44.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-10-44&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;节点类型&#34;&gt;&lt;a href=&#34;#%e8%8a%82%e7%82%b9%e7%b1%bb%e5%9e%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;节点类型
&lt;/h3&gt;&lt;p&gt;Zookeeper 中节点可以分为两大类：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;持久节点&lt;/strong&gt;：节点一旦创建，除非被主动删除，否则一直存在；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;临时节点&lt;/strong&gt;：一旦创建该节点的客户端会话失效，则所有该客户端创建的临时节点都会被删除。&lt;/p&gt;
&lt;p&gt;临时节点和持久节点都可以添加一个特殊的属性： SEQUENTIAL ，代表该节点是否具有递增属性。如果指定该属性，那么在这个节点创建时，Zookeeper 会自动在其节点名称后面追加一个由父节点维护的递增数字。这个递增数字可以被用于为所有的事件进行全局排序，这样客户端可以通过顺序号推断事件的顺序。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;节点信息&#34;&gt;&lt;a href=&#34;#%e8%8a%82%e7%82%b9%e4%bf%a1%e6%81%af&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;节点信息
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-10-57.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-10-57&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;集群操作&#34;&gt;&lt;a href=&#34;#%e9%9b%86%e7%be%a4%e6%93%8d%e4%bd%9c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;集群操作
&lt;/h2&gt;&lt;h3 id=&#34;创建节点&#34;&gt;&lt;a href=&#34;#%e5%88%9b%e5%bb%ba%e8%8a%82%e7%82%b9&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;创建节点
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;create [-s] [-e] path data acl   #其中-s 为有序节点，-e 临时节点&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;创建有序节点，此时创建的节点名为指定节点名 + 自增序号：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 23] create -s /a  &amp;ldquo;aaa&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Created /a0000000022&lt;/p&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 24] create -s /b  &amp;ldquo;bbb&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Created /b0000000023&lt;/p&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 25] create -s /c  &amp;ldquo;ccc&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Created /c0000000024&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;创建临时节点，临时节点会在会话过期后被删除：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 26] create -e /tmp  &amp;ldquo;tmp&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Created /tmp&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;查看节点&#34;&gt;&lt;a href=&#34;#%e6%9f%a5%e7%9c%8b%e8%8a%82%e7%82%b9&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;查看节点  
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;get path [watch]&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 31] get /hadoop&lt;/p&gt;
&lt;p&gt;123456   #节点数据&lt;/p&gt;
&lt;p&gt;cZxid = 0x14b&lt;/p&gt;
&lt;p&gt;ctime = Fri May 24 17:03:06 CST 2019&lt;/p&gt;
&lt;p&gt;mZxid = 0x14b&lt;/p&gt;
&lt;p&gt;mtime = Fri May 24 17:03:06 CST 2019&lt;/p&gt;
&lt;p&gt;pZxid = 0x14b&lt;/p&gt;
&lt;p&gt;cversion = 0&lt;/p&gt;
&lt;p&gt;dataVersion = 0&lt;/p&gt;
&lt;p&gt;aclVersion = 0&lt;/p&gt;
&lt;p&gt;ephemeralOwner = 0x0&lt;/p&gt;
&lt;p&gt;dataLength = 6&lt;/p&gt;
&lt;p&gt;numChildren = 0&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;节点各个属性如下表。其中一个重要的概念是 Zxid(ZooKeeper Transaction Id)，ZooKeeper 节点的 每一次更改都具有唯一的 Zxid，如果 Zxid1 小于 Zxid2，则 Zxid1 的更改发生在 Zxid2 更改之前。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-11-14.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-11-14&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;查看节点状态&#34;&gt;&lt;a href=&#34;#%e6%9f%a5%e7%9c%8b%e8%8a%82%e7%82%b9%e7%8a%b6%e6%80%81&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;查看节点状态  
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;stat path [watch]&lt;/p&gt;
&lt;p&gt;它和 get 类似，但不会返回节点数据内容&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;更新节点&#34;&gt;&lt;a href=&#34;#%e6%9b%b4%e6%96%b0%e8%8a%82%e7%82%b9&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;更新节点  
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 33] set /hadoop 345&lt;/p&gt;
&lt;p&gt;cZxid = 0x14b&lt;/p&gt;
&lt;p&gt;ctime = Fri May 24 17:03:06 CST 2019&lt;/p&gt;
&lt;p&gt;mZxid = 0x14c&lt;/p&gt;
&lt;p&gt;mtime = Fri May 24 17:13:05 CST 2019&lt;/p&gt;
&lt;p&gt;pZxid = 0x14b&lt;/p&gt;
&lt;p&gt;cversion = 0&lt;/p&gt;
&lt;p&gt;dataVersion = 1  # 注意更改后此时版本号为 1，默认创建时为 0&lt;/p&gt;
&lt;p&gt;aclVersion = 0&lt;/p&gt;
&lt;p&gt;ephemeralOwner = 0x0&lt;/p&gt;
&lt;p&gt;dataLength = 3&lt;/p&gt;
&lt;p&gt;numChildren = 0&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;也可以基于版本号进行更改，此时类似于乐观锁机制，当你传入的数据版本号 (dataVersion) 和当前节 点的数据版本号不符合时，zookeeper 会拒绝本次修改：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 34] set /hadoop 678 0&lt;/p&gt;
&lt;p&gt;version No is not valid : /hadoop    #无效的版本号&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;删除节点&#34;&gt;&lt;a href=&#34;#%e5%88%a0%e9%99%a4%e8%8a%82%e7%82%b9&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;删除节点
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;delete path [version]&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;和更新节点数据一样，也可以传入版本号，当你传入的数据版本号 (dataVersion) 和当前节点的数据版 本号不符合时，zookeeper 不会执行删除操作。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 36] delete /hadoop 0&lt;/p&gt;
&lt;p&gt;version No is not valid : /hadoop   #无效的版本号&lt;/p&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 37] delete /hadoop 1&lt;/p&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 38]&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;要想删除某个节点及其所有后代节点，可以使用递归删除，命令为&lt;strong&gt;rmr path&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;退出-zk&#34;&gt;&lt;a href=&#34;#%e9%80%80%e5%87%ba-zk&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;退出 ZK 
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;[zk: localhost:2181(CONNECTED) 12] quit&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;应用场景&#34;&gt;&lt;a href=&#34;#%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;应用场景
&lt;/h2&gt;&lt;h3 id=&#34;统一命名服务&#34;&gt;&lt;a href=&#34;#%e7%bb%9f%e4%b8%80%e5%91%bd%e5%90%8d%e6%9c%8d%e5%8a%a1&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;统一命名服务
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-11-27.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-11-27&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;统一配置管理&#34;&gt;&lt;a href=&#34;#%e7%bb%9f%e4%b8%80%e9%85%8d%e7%bd%ae%e7%ae%a1%e7%90%86&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;统一配置管理
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-11-36.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-11-36&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;统一集群管理&#34;&gt;&lt;a href=&#34;#%e7%bb%9f%e4%b8%80%e9%9b%86%e7%be%a4%e7%ae%a1%e7%90%86&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;统一集群管理
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-11-46.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-11-46&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;服务器动态上下线&#34;&gt;&lt;a href=&#34;#%e6%9c%8d%e5%8a%a1%e5%99%a8%e5%8a%a8%e6%80%81%e4%b8%8a%e4%b8%8b%e7%ba%bf&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;服务器动态上下线
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-11-56.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-11-56&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;软负载均衡&#34;&gt;&lt;a href=&#34;#%e8%bd%af%e8%b4%9f%e8%bd%bd%e5%9d%87%e8%a1%a1&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;软负载均衡
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-12-03.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-12-03&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;分布式锁&#34;&gt;&lt;a href=&#34;#%e5%88%86%e5%b8%83%e5%bc%8f%e9%94%81&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;分布式锁
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-12-10.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-12-10&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;拜占庭将军问题paxos-算法&#34;&gt;&lt;a href=&#34;#%e6%8b%9c%e5%8d%a0%e5%ba%ad%e5%b0%86%e5%86%9b%e9%97%ae%e9%a2%98paxos-%e7%ae%97%e6%b3%95&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;拜占庭将军问题（Paxos 算法）
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-12-20.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-12-20&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;Paxos 算法是一种基于消息传递且具有高度容错特性的一致性算法。解决如何快速正确的在一个分布式系统中对某个数据值达成一致，并且保证任何异常都不会破坏整个系统的一致性。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-12-34.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-12-34&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;算法描述&#34;&gt;&lt;a href=&#34;#%e7%ae%97%e6%b3%95%e6%8f%8f%e8%bf%b0&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;算法描述
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-12-42.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-12-42&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;算法流程&#34;&gt;&lt;a href=&#34;#%e7%ae%97%e6%b3%95%e6%b5%81%e7%a8%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;  算法流程
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-12-51.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-12-51&#34;
	
	
&gt;
&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-13-02.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-13-02&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;zab-协议&#34;&gt;&lt;a href=&#34;#zab-%e5%8d%8f%e8%ae%ae&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;ZAB 协议
&lt;/h2&gt;&lt;p&gt;ZAB 协议并不像 Paxos 算法那样是一种通用的分布式一致性算法，ZAB 是一种特别为 Zookeeper 设计的崩溃可恢复的原子消息广播算法。在 ZooKeeper 中，主要依赖 ZAB 协议来实现分布式数据一致性，基于该协议，ZooKeeper 实现了一种主备模式的系统架构来保持集群中各个副本之间的数据一致性。ZAB 包括以下两种模式:&lt;/p&gt;
&lt;h3 id=&#34;崩溃恢复&#34;&gt;&lt;a href=&#34;#%e5%b4%a9%e6%ba%83%e6%81%a2%e5%a4%8d&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;崩溃恢复
&lt;/h3&gt;&lt;p&gt;当整个服务框架在启动过程中，或是当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB 协议就会进入恢复模式并选举产生新的 Leader 服务器。当选举产生了新的 Leader 服务器，同时集群中已经有过半的机器与该 Leader 服务器完成了状态同步之后，ZAB 协议就会退出恢复模式。其中，&lt;strong&gt;所谓的状态同步是指数据同步，用来保证集群中存在过半的机器能够和 Leader 服务器的数据状态保持一致&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-13-26.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-13-26&#34;
	
	
&gt;
&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-13-54.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-13-54&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;消息广播&#34;&gt;&lt;a href=&#34;#%e6%b6%88%e6%81%af%e5%b9%bf%e6%92%ad&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;消息广播
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;当集群中已经有过半的 Follower 服务器完成了和 Leader 服务器的状态同步，那么整个服务框架就可以进入消息广播模式了。&lt;/strong&gt; 当一台同样遵守 ZAB 协议的服务器启动后加入到集群中时，如果此时集群中已经存在一个 Leader 服务器在负责进行消息广播，那么新加入的服务器就会自觉地进入数据恢复模式：找到 Leader 所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去。
&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-14-26.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-14-26&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-14-52.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-14-52&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;cap-理论&#34;&gt;&lt;a href=&#34;#cap-%e7%90%86%e8%ae%ba&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;CAP 理论
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-15-34.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-15-34&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;zk-源码图示&#34;&gt;&lt;a href=&#34;#zk-%e6%ba%90%e7%a0%81%e5%9b%be%e7%a4%ba&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;ZK 源码图示  
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-15-43.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-15-43&#34;
	
	
&gt;
&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-17-12.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-17-12&#34;
	
	
&gt;
&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-17-01.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-17-01&#34;
	
	
&gt;
&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-16-53.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-16-53&#34;
	
	
&gt;
&lt;img src=&#34;https://cdn.jsdelivr.net/gh/QingQiuGeek/imgRepo/picGo/2025-08-01-22-16-36.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;2025-08-01-22-16-36&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;小小面试题&#34;&gt;&lt;a href=&#34;#%e5%b0%8f%e5%b0%8f%e9%9d%a2%e8%af%95%e9%a2%98&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;小小面试题
&lt;/h2&gt;&lt;h3 id=&#34;选举机制-1&#34;&gt;&lt;a href=&#34;#%e9%80%89%e4%b8%be%e6%9c%ba%e5%88%b6-1&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;选举机制
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;半数机制，超过半数的投票通过，即通过。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;第一次启动选举规则： 投票过半数时，服务器 id 大的胜出&lt;/li&gt;
&lt;li&gt;第二次启动选举规则：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;EPOCH 大的直接胜出&lt;/p&gt;
&lt;p&gt;EPOCH 相同，事务 id 大的胜出&lt;/p&gt;
&lt;p&gt;事务 id 相同，服务器 id 大的胜出&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;生产集群安装多少-zk-合适&#34;&gt;&lt;a href=&#34;#%e7%94%9f%e4%ba%a7%e9%9b%86%e7%be%a4%e5%ae%89%e8%a3%85%e5%a4%9a%e5%b0%91-zk-%e5%90%88%e9%80%82&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;  生产集群安装多少 zk 合适？
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;安装奇数台。&lt;/p&gt;
&lt;p&gt;生产经验：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;10 台服务器：3 台 zk；&lt;/li&gt;
&lt;li&gt;20 台服务器：5 台 zk；&lt;/li&gt;
&lt;li&gt;100 台服务器：11 台 zk；&lt;/li&gt;
&lt;li&gt;200 台服务器：11 台 zk&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>HA—Hadoop高可用</title>
        <link>/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/</link>
        <pubDate>Mon, 15 Apr 2024 19:23:57 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/</guid>
        <description>&lt;h2 id=&#34;ha-概述&#34;&gt;&lt;a href=&#34;#ha-%e6%a6%82%e8%bf%b0&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HA 概述
&lt;/h2&gt;&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;1）所谓 HA（High Availablity），即高可用（7*24 小时不中断服务）。&lt;/p&gt;
&lt;p&gt;2）实现高可用最关键的策略是消除单点故障（传统的主从模式集群单个节点发生故障会影响整个集群）。HA 严格来说应该分成各个组件的 HA 机制：&lt;strong&gt;HDFS 的 HA 和 YARN 的 HA&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;3）NameNode 主要在以下两个方面影响 HDFS 集群&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NameNode 机器发生意外，如宕机，集群将无法使用，直到管理员重启&lt;/li&gt;
&lt;li&gt;NameNode 机器需要升级，包括软件、硬件升级，此时集群也将无法使用&lt;/li&gt;
&lt;li&gt;HDFS HA 功能通过配置多个 NameNode(Active/Standby)实现在集群中对 NameNode 的热备来解决上述问题。如果出现故障，如机器崩溃或机器需要升级维护，这时可以启动另一台机器上的 NameNode 继续维护整个集群的运行（&lt;strong&gt;集群中同时只能有一台 active 的 NN，其他 NN 处于 standby（备用）&lt;/strong&gt; ）。而这种启动方式&lt;strong&gt;分为手动和自动（推荐）&lt;/strong&gt;，但是在这之前，我们&lt;strong&gt;必须通过某种方式保证所有 NN 的元数据一致&lt;/strong&gt;，这样才能保证 active 状态的 NN 故障后，另一个处于 standby 状态的 NN 激活为 active 能够正常维持集群运行，类似于公司员工的任务的交接。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;hdfs-高可用&#34;&gt;&lt;a href=&#34;#hdfs-%e9%ab%98%e5%8f%af%e7%94%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HDFS 高可用
&lt;/h2&gt;&lt;hr&gt;
&lt;h3 id=&#34;保证所有-nn-的数据一致性&#34;&gt;&lt;a href=&#34;#%e4%bf%9d%e8%af%81%e6%89%80%e6%9c%89-nn-%e7%9a%84%e6%95%b0%e6%8d%ae%e4%b8%80%e8%87%b4%e6%80%a7&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;保证所有 NN 的数据一致性
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;在处于 active 的 NN 正常运行时，他会生成 Fsimage 文件，让其他处于 standby 的 NN 同步，同时引入 JournalNode 节点来保证 edits 文件数据的一致性&lt;/strong&gt;，JournalNode 作为 active 的 NN 和 standby 的 NN 的中间节点，activeNN 会把 edits 发送给 JournalNode，然后 standbyNN 从 JournalNode 获取 edits。同时为了保证 JournalNode 的可靠性，JournalNode 本身也是一个多节点的集群。&lt;/p&gt;
&lt;p&gt;JournalNode 节点会在集群自动的选择一个&amp;quot;主&amp;quot;节点出来，Active 节点会和 JournalNode 的主节点通信，然后 JournalNode 集群的主节点会将数据发送给其他的节点，只要有过半的节点完成了数据的存储（&lt;strong&gt;过半写成功&lt;/strong&gt;），JournalNode 集群的主节点，就会将成功信息返回给 Active 节点。当 JournalNode 集群的主节点挂掉，其他的 JournalNode 节点会快速选举出新的&amp;quot;主&amp;quot;节点来。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;同时在 HA 架构中，并没有 SecondaryNameNode&lt;/strong&gt;，那么定期合并 fsimage 的 eedits 的任务是由 standby 的 NN 来完成的。&lt;/p&gt;
&lt;h3 id=&#34;手动模式&#34;&gt;&lt;a href=&#34;#%e6%89%8b%e5%8a%a8%e6%a8%a1%e5%bc%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;手动模式
&lt;/h3&gt;&lt;p&gt;配置 core-site.xml&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定hdfs的nameservice为ns1 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;fs.defaultFS&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hdfs://mycluster/&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定hadoop临时目录 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.tmp.dir&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;配置 hdfs-site.xml&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;77
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!--指定hdfs的nameservice为mycluster，需要和core-site.xml中的保持一致 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.nameservices&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;mycluster&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- hadoop-ha下面有两个NameNode，分别是nn1，nn2 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.ha.namenodes.mycluster&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;nn1,nn2,nn3&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- nn1的RPC通信地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.rpc-address.mycluster.nn1&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux01:8020&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- nn1的http通信地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.http-address.mycluster.nn1&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux01:9870&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- nn2的RPC通信地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.rpc-address.mycluster.nn2&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux02:8020&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- nn2的http通信地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.http-address.mycluster.nn2&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux02:9870&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- nn3的RPC通信地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.rpc-address.mycluster.nn3&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux03:8020&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- nn3的http通信地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.http-address.mycluster.nn3&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux03:9870&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定NameNode的edits元数据在JournalNode上的存放位置 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.shared.edits.dir&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;qjournal://linux01:8485;linux02:8485;linux03:8485/mycluster&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- NameNode 数据存储目录 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;             &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.name.dir&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;             &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;file://${hadoop.tmp.dir}/name&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- DataNode 数据存储目录 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;             &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.data.dir&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;             &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;file://${hadoop.tmp.dir}/data&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- JournalNode数据存储目录 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.journalnode.edits.dir&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;${hadoop.tmp.dir}/data&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 配置失败自动切换实现方式 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.client.failover.proxy.provider.mycluster&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行--&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.ha.fencing.methods&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;sshfence&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 使用sshfence隔离机制时需要ssh免登陆 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.ha.fencing.ssh.private-key-files&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/root/.ssh/id_rsa&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;HA 集群的相关文件配置省略。以 3 台服务器的 HA 为例：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;在各个节点上，输入以下命令启动该节点的journalNode服务：
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hdfs --daemon start journalnode
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;在NN1上进行格式化并启动
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hdfs namenode -format
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hdfs --daemon start namenode
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;分别在NN2和NN3上运行如下命令，同步NN1的元数据信息
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hdfs namenode -bootstrapStandby
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;启动NN2，NN3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hdfs --daemon start namenode
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;此时所有NN处于standby，启动所有节点的datanode
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hdfs --daemon start datanode
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;切换NN1为active
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hdfs haadmin start -transitionToActive linux01
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;修改后重新分发文件！
&lt;img src=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image.png&#34;
	width=&#34;1326&#34;
	height=&#34;401&#34;
	srcset=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image_hu_c985863806ed0edc.png 480w, /zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image_hu_47a713227fbaa2e7.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;330&#34;
		data-flex-basis=&#34;793px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;自动模式&#34;&gt;&lt;a href=&#34;#%e8%87%aa%e5%8a%a8%e6%a8%a1%e5%bc%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;自动模式
&lt;/h3&gt;&lt;p&gt;自动模式需要引入 zookeeper 和 ZKFailoverController（ZKFC）&lt;/p&gt;
&lt;p&gt;配置 hdfs-site.xml&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 启用 nn 故障自动转移 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.ha.automatic-failover.enabled&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;配置 core-site.xml&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定 zkfc 要连接的 zkServer 地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ha.zookeeper.quorum&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux01:2181,linux02:2181,linux03:2181&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;修改后重新分发文件！&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;在每台服务器运行以下命令启动zookeeper集群：
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;zkServer.sh start
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;启动后初始化HA在zookeeper中的状态：
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hdfs zkfc -formatZK
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;杀死active namenode查看是否有standby namenode激活：
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kill -9 namenode的进程id
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;运行zkCli.sh查看namenode选举内容：
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;zkCli.sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-1.png&#34;
	width=&#34;1518&#34;
	height=&#34;847&#34;
	srcset=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-1_hu_3f372e4e88ec4427.png 480w, /zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-1_hu_fe1c88a95b8ebe06.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;179&#34;
		data-flex-basis=&#34;430px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;解决-nn-连接不上-jn-的问题&#34;&gt;&lt;a href=&#34;#%e8%a7%a3%e5%86%b3-nn-%e8%bf%9e%e6%8e%a5%e4%b8%8d%e4%b8%8a-jn-%e7%9a%84%e9%97%ae%e9%a2%98&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;解决 NN 连接不上 JN 的问题
&lt;/h4&gt;&lt;p&gt;自动故障转移配置好以后，然后使用 start-dfs.sh 群起脚本启动 hdfs 集群，有可能 会遇到 NameNode 起来一会后，进程自动关闭的问题。查看 NameNode 日志，报错信息如下：
&lt;img src=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-2.png&#34;
	width=&#34;1176&#34;
	height=&#34;767&#34;
	srcset=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-2_hu_3c6ab8b29a630e2.png 480w, /zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-2_hu_ebfdb8f34cef0750.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;153&#34;
		data-flex-basis=&#34;367px&#34;
	
&gt;
查看报错日志，可分析出报错原因是因为 NameNode 连接不上 JournalNode，而利 用 jps 命令查看到三台 JN 都已经正常启动，为什么 NN 还是无法正常连接到 JN 呢？这 是因为 start-dfs.sh 群起脚本默认的启动顺序是先启动 NN，再启动 DN，然后再启动 JN， 并且默认的 rpc 连接参数是重试次数为 10，每次重试的间隔是 1s，也就是说启动完 NN 以后的 10s 中内，JN 还启动不起来，NN 就会报错了。&lt;/p&gt;
&lt;p&gt;core-default.xml 里面有两个参数如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!--NN连接JN重试次数，默认10次--&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ipc.client.connect.max.retries&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;10&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!--重试时间间隔，默认1s--&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ipc.client.connect.retry.interval&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;1000&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;解决方案：可以先 JN 成功启动，然后启动三台 NN 或者 在 core-site.xml 调大上面的参数：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!--NN连接JN重试次数，默认10次--&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ipc.client.connect.max.retries&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;20&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!--重试时间间隔，默认1s--&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;ipc.client.connect.retry.interval&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;5000&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-3.png&#34;
	width=&#34;1318&#34;
	height=&#34;521&#34;
	srcset=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-3_hu_8de74b54e2c37152.png 480w, /zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-3_hu_f608aba8a29a6929.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;252&#34;
		data-flex-basis=&#34;607px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;yarn-高可用&#34;&gt;&lt;a href=&#34;#yarn-%e9%ab%98%e5%8f%af%e7%94%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Yarn 高可用
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-4.png&#34;
	width=&#34;876&#34;
	height=&#34;510&#34;
	srcset=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-4_hu_d1ccc4c7a5fe1c5a.png 480w, /zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-4_hu_193a236c9a33d153.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;171&#34;
		data-flex-basis=&#34;412px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-5.png&#34;
	width=&#34;1141&#34;
	height=&#34;273&#34;
	srcset=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-5_hu_9c0be25044f76717.png 480w, /zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-5_hu_ab9c930170399a7a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;417&#34;
		data-flex-basis=&#34;1003px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;核心问题&#34;&gt;&lt;a href=&#34;#%e6%a0%b8%e5%bf%83%e9%97%ae%e9%a2%98&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;核心问题
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;如果当前 active rm 挂了，其他 rm 怎么将其他 standby rm 上位
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;核心原理跟 hdfs 一样，利用了 zk 的临时节点
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;当前 rm 上有很多的计算程序在等待运行,其他的 rm 怎么将这些程序接手过来接着跑
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;rm会将当前的所有计算程序的状态存储在 zk 中,其他 rm 上位后会去读取，然后接着跑
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;配置 yarn-site.xml&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;  1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 77
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 78
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 79
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 80
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 81
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 82
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 83
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 84
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 85
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 86
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 87
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 88
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 89
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 90
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 91
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 92
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 93
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 94
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 95
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 96
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 97
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 98
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 99
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;100
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;101
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;102
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;103
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;104
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;105
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;106
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;107
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;108
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;109
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;110
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;111
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;112
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;113
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;114
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;115
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;116
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;117
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;118
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;119
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;120
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;121
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;122
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.nodemanager.aux-services&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;mapreduce_shuffle&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 启用 resourcemanager ha --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.ha.enabled&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 声明两台 resourcemanager 的地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.cluster-id&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;cluster-yarn1&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!--指定 resourcemanager 的逻辑列表--&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.ha.rm-ids&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;rm1,rm2,rm3&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- ========== rm1 的配置 ========== --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定 rm1 的主机名 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.hostname.rm1&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux01&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定 rm1 的 web 端地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.webapp.address.rm1&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux01:8088&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定 rm1 的内部通信地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.address.rm1&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux01:8032&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定 AM 向 rm1 申请资源的地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.scheduler.address.rm1&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux01:8030&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定供 NM 连接的地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.resource-tracker.address.rm1&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux01:8031&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- ========== rm2 的配置 ========== --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定 rm2 的主机名 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.hostname.rm2&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux02&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.webapp.address.rm2&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux02:8088&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.address.rm2&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux02:8032&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.scheduler.address.rm2&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux02:8030&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.resource-tracker.address.rm2&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux02:8031&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- ========== rm3 的配置 ========== --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定 rm3 的主机名 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.hostname.rm3&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux03&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定 rm3 的 web 端地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.webapp.address.rm3&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux03:8088&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定 rm3 的内部通信地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.address.rm3&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux03:8032&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定 AM 向 rm3 申请资源的地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.scheduler.address.rm3&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux03:8030&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定供 NM 连接的地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.resource-tracker.address.rm3&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux03:8031&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定 zookeeper 集群的地址 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.zk-address&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux01:2181,linux02:2181,linux03:2181&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 启用自动恢复 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.recovery.enabled&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 指定 resourcemanager 的状态信息存储在 zookeeper 集群 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.store.class&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateSt
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ore&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c&#34;&gt;&amp;lt;!-- 环境变量的继承 --&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.nodemanager.env-whitelist&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLAS
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    SPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;配置后重新分发配置文件！&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;启动Yarn
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;start-yarn.sh
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;查看服务状态
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;yarn rmadmin -getServiceState rm1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;运行zkCli.sh查看RM选举内容
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;zkCli.sh
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;可以通过8088端口查看Yarn状态
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;HA 最终规划
&lt;img src=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-6.png&#34;
	width=&#34;1131&#34;
	height=&#34;1058&#34;
	srcset=&#34;/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-6_hu_e606529a6d9b9fd8.png 480w, /zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/image-6_hu_c206762bb76f4e7c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;106&#34;
		data-flex-basis=&#34;256px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;以上来自尚硅谷 Hadoop HA 高可用&lt;/strong&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Hadoop入门—HDFS、MR、Yarn</title>
        <link>/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/</link>
        <pubDate>Mon, 15 Apr 2024 14:38:50 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/</guid>
        <description>&lt;h2 id=&#34;hadoop-简介&#34;&gt;&lt;a href=&#34;#hadoop-%e7%ae%80%e4%bb%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hadoop 简介
&lt;/h2&gt;&lt;hr&gt;
&lt;p&gt;狭义来说，hadoop 是 Apache 基金会开发的分布式系统基础架构，用来解决海量数据的存储和海量数据的分析计算问题。广义上来说，Hadoop 通常是指一个更广泛的概念 &amp;mdash;&amp;mdash; Hadoop 生态圈。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image.png&#34;
	width=&#34;849&#34;
	height=&#34;406&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image_hu_ae871aaf7cbe79af.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image_hu_abb20e2b328fbc6b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;209&#34;
		data-flex-basis=&#34;501px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;hadoop-三大发行版本&#34;&gt;&lt;a href=&#34;#hadoop-%e4%b8%89%e5%a4%a7%e5%8f%91%e8%a1%8c%e7%89%88%e6%9c%ac&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hadoop 三大发行版本
&lt;/h3&gt;&lt;p&gt;Apache、Cloudera、Hortonworks&lt;/p&gt;
&lt;p&gt;Apache 版本最原始（最基础）的版本，对于入门学习最好。&lt;/p&gt;
&lt;p&gt;Cloudera 在大型互联网企业中用的较多。其主要产品有 CDH、Cloudera Manager，Cloudera Support&lt;/p&gt;
&lt;h3 id=&#34;hadoop-优势&#34;&gt;&lt;a href=&#34;#hadoop-%e4%bc%98%e5%8a%bf&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hadoop 优势
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;高可靠性：&lt;/strong&gt; Hadoop 底层维护多个数据副本，所以即使 Hadoop 某个计算元素或存储出现故障，也不会导致数据的丢失。&lt;br&gt;
&lt;strong&gt;高扩展性：&lt;/strong&gt; 在集群间分配任务数据，可方便的扩展数以千计的节点。&lt;br&gt;
高效性： 在 MapReduce 的思想下，Hadoop 是并行工作的，以加快任务处理速度。&lt;br&gt;
&lt;strong&gt;高容错性：&lt;/strong&gt; 能够自动将失败的任务重新分配。&lt;/p&gt;
&lt;p&gt;**低成本：**Hadoop 不要求机器的配置达到极高的标准，大部分普通商用服务器即可满足要求，通过提供多个副本和容错机制提高集群的可靠性&lt;/p&gt;
&lt;h3 id=&#34;hadoop-基本组成&#34;&gt;&lt;a href=&#34;#hadoop-%e5%9f%ba%e6%9c%ac%e7%bb%84%e6%88%90&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hadoop 基本组成
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/fd575291df78b55069687df62b245798.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;常用-shell-命令&#34;&gt;&lt;a href=&#34;#%e5%b8%b8%e7%94%a8-shell-%e5%91%bd%e4%bb%a4&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;常用 Shell 命令
&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;hdfs dfs -ls &amp;lt;path&amp;gt;：列出指定 HDFS 路径下的文件和目录
hdfs dfs -mkdir &amp;lt;path&amp;gt;：在 HDFS 中创建新目录
hdfs dfs -put &amp;lt;localsrc&amp;gt; &amp;lt;dst&amp;gt;：将本地文件（或目录）复制到 HDFS
hdfs dfs -get &amp;lt;src&amp;gt; &amp;lt;localdst&amp;gt;：将 HDFS 上的文件（或目录）复制到本地
hdfs dfs -mv &amp;lt;src&amp;gt; &amp;lt;dst&amp;gt;：移动 HDFS 中的文件目录或重命名文件目录
hdfs dfs -cp &amp;lt;src&amp;gt; &amp;lt;dst&amp;gt;：复制 HDFS 中的文件或目录
hdfs dfs -rm &amp;lt;path&amp;gt;：删除 HDFS 中的文件
hdfs dfs -cat &amp;lt;path&amp;gt;：在控制台显示 HDFS 文件的内容
hdfs dfs -du &amp;lt;path&amp;gt;：显示 HDFS 文件或目录的大小
hdfs dfs -df &amp;lt;path&amp;gt;：显示 HDFS 的可用空间
hdfs fsck path [-files [-blocks [-location]]]
-files列出路径内的文件状态
-files -blocks输出文件块报告（几个块，几个副本）
-files -blocks -locations 输出每个block的详情
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;hdfs-分布存储&#34;&gt;&lt;a href=&#34;#hdfs-%e5%88%86%e5%b8%83%e5%ad%98%e5%82%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HDFS 分布存储
&lt;/h2&gt;&lt;hr&gt;
&lt;p&gt;HDFS 是一个分布式文件系统，具有高容错、高吞吐 量等特性，&lt;strong&gt;分布在多个集群节点上的文件系统。有 NN、DN、SNN 三种角色。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;hdfs-启停&#34;&gt;&lt;a href=&#34;#hdfs-%e5%90%af%e5%81%9c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HDFS 启停
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-1.png&#34;
	width=&#34;1296&#34;
	height=&#34;368&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-1_hu_9f50d72e4713275a.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-1_hu_e892968554c81460.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;352&#34;
		data-flex-basis=&#34;845px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;namenodenn&#34;&gt;&lt;a href=&#34;#namenodenn&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;NameNode（NN）
&lt;/h3&gt;&lt;p&gt;HDFS 的主角色，负责管理每个文件的块所在的 DataNode、整个 HDFS 文件系统、存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限）等。&lt;/p&gt;
&lt;h3 id=&#34;datanodedn&#34;&gt;&lt;a href=&#34;#datanodedn&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;DataNode（DN）
&lt;/h3&gt;&lt;p&gt;HDFS 从角色，负责处理客户端的读写请求，存储删除文件块，以及块数据校验和。&lt;/p&gt;
&lt;h3 id=&#34;secondarynamenodesnn&#34;&gt;&lt;a href=&#34;#secondarynamenodesnn&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;SecondaryNameNode（SNN）
&lt;/h3&gt;&lt;p&gt;NN 的辅助角色，帮 NN 打杂，监控 HDFS 状态的辅助后台程序，每隔一段时间获取 HDFS 元数据的快照。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可通过 9870 端口（默认 9870）访问 web 界面，查看集群各节点状态及信息&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-2.png&#34;
	width=&#34;2880&#34;
	height=&#34;1620&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-2_hu_57d3224414c2e837.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-2_hu_d5435fb5eaa6d337.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;文件写入流程&#34;&gt;&lt;a href=&#34;#%e6%96%87%e4%bb%b6%e5%86%99%e5%85%a5%e6%b5%81%e7%a8%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;文件写入流程
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-3.png&#34;
	width=&#34;1462&#34;
	height=&#34;644&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-3_hu_fbf8ea63e84c9d64.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-3_hu_cd5ef232b66b9c88.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;227&#34;
		data-flex-basis=&#34;544px&#34;
	
&gt;
发送的写入请求通过后，客户端会根据 NN 返回的信息自动把数据分块，向&lt;strong&gt;网络距离最近&lt;/strong&gt;的 DN 写入数据。同时，DN 会完成备份操作，把备份传到其他的 DN，然后由其他的 DN 再次做备份传播，直到满足设置的备份数量。当数据写入完成后，客户端会通知 NN，由 NN 完成元数据记录。
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-4.png&#34;
	width=&#34;1070&#34;
	height=&#34;1148&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-4_hu_493c72faaa0d005a.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-4_hu_ba3abf22a2a6c6b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;93&#34;
		data-flex-basis=&#34;223px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;hdfs-架构的稳定性&#34;&gt;&lt;a href=&#34;#hdfs-%e6%9e%b6%e6%9e%84%e7%9a%84%e7%a8%b3%e5%ae%9a%e6%80%a7&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HDFS 架构的稳定性
&lt;/h3&gt;&lt;h4 id=&#34;心跳机制和重新复制&#34;&gt;&lt;a href=&#34;#%e5%bf%83%e8%b7%b3%e6%9c%ba%e5%88%b6%e5%92%8c%e9%87%8d%e6%96%b0%e5%a4%8d%e5%88%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;心跳机制和重新复制
&lt;/h4&gt;&lt;p&gt;每个 DataNode 定期向 NameNode 发送心跳消息，如果超过指定时间没有收到心跳消息，则将 DataNode 标记为死亡。NameNode 不会将任何新的 IO 请求转发给标记为死亡的 DataNode，也不会 再使用这些 DataNode 上的数据。 由于数据不再可用，可能会导致某些块的复制因子小于其指定值， NameNode 会跟踪这些块，并在必要的时候进行重新复制。&lt;/p&gt;
&lt;h4 id=&#34;数据的完整性&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e6%8d%ae%e7%9a%84%e5%ae%8c%e6%95%b4%e6%80%a7&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;数据的完整性
&lt;/h4&gt;&lt;p&gt;由于存储设备故障等原因，存储在 DataNode 上的数据块也会发生损坏。为了避免读取到已经损坏的数 据而导致错误，HDFS 提供了数据完整性校验机制来保证数据的完整性，具体操作如下： 当客户端创建 HDFS 文件时，它会计算文件的每个块的 校验和 ，并将 校验和 存储在同一 HDFS 命名空 间下的单独的隐藏文件中。当客户端检索文件内容时，它会验证从每个 DataNode 接收的数据是否与存 储在关联校验和文件中的 校验和 匹配。如果匹配失败，则证明数据已经损坏，此时客户端会选择从其 他 DataNode 获取该块的其他可用副本。&lt;/p&gt;
&lt;h3 id=&#34;元数据的磁盘故障&#34;&gt;&lt;a href=&#34;#%e5%85%83%e6%95%b0%e6%8d%ae%e7%9a%84%e7%a3%81%e7%9b%98%e6%95%85%e9%9a%9c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;元数据的磁盘故障
&lt;/h3&gt;&lt;p&gt;FsImage 和 EditLog 是 HDFS 的核心数据，这些数据的意外丢失可能会导致整个 HDFS 服务不可 用。为了避免这个问题，可以配置 NameNode 使其支持 FsImage 和 EditLog 多副本同步，这样 FsImage 或 EditLog 的任何改变都会引起每个副本 FsImage 和 EditLog 的同步更新。&lt;/p&gt;
&lt;h4 id=&#34;支持快照&#34;&gt;&lt;a href=&#34;#%e6%94%af%e6%8c%81%e5%bf%ab%e7%85%a7&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;支持快照
&lt;/h4&gt;&lt;p&gt;快照支持在特定时刻存储数据副本，在数据意外损坏时，可以通过回滚操作恢复到健康的数据状态。&lt;/p&gt;
&lt;h3 id=&#34;文件读取流程&#34;&gt;&lt;a href=&#34;#%e6%96%87%e4%bb%b6%e8%af%bb%e5%8f%96%e6%b5%81%e7%a8%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;文件读取流程
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-5.png&#34;
	width=&#34;1920&#34;
	height=&#34;887&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-5_hu_4d4e26163a453731.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-5_hu_66e2c8639fa1ca70.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;216&#34;
		data-flex-basis=&#34;519px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;存储方式&#34;&gt;&lt;a href=&#34;#%e5%ad%98%e5%82%a8%e6%96%b9%e5%bc%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;存储方式
&lt;/h3&gt;&lt;h4 id=&#34;block-块和多副本&#34;&gt;&lt;a href=&#34;#block-%e5%9d%97%e5%92%8c%e5%a4%9a%e5%89%af%e6%9c%ac&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Block 块和多副本
&lt;/h4&gt;&lt;p&gt;由于文件大小不一，不利于统一管理，hdfs 设定了统一的存储单位 Block 块，Block 块是 hdfs 最小存储单位，通常每个 128MB（可修改 dfs.blocksize）。hdfs 会按照 Block 块大小把文件切分成多份存储在多个 datanode 上也就是多个服务器上，同时为了保证整个文件的完成性（防止 Block 块丢失或损坏），hdfs 会对每个 Block 块做多个备份存储在其他节点上，备份的数量默认是 3，可以在 hdfs-site.xml 中配置数量，修改后要重新分发该文件，保证每个服务器的配置文件相同！&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.replication&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;3&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;同时还可以&lt;strong&gt;临时决定&lt;/strong&gt;上传文件的副本数量：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;hdfs fs -D dfs.replication=5 -put test.tst /data/test&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;还可以修改已存在的 hdfs 文件的副本数量：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;hdfs fs -setrep [-R] 5 path
path 是指定文件路径，-R 表示对子目录也生效&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;edits-和-fsimage-文件&#34;&gt;&lt;a href=&#34;#edits-%e5%92%8c-fsimage-%e6%96%87%e4%bb%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;edits 和 fsimage 文件
&lt;/h4&gt;&lt;p&gt;hdfs 中文件被划分成一堆堆 block 块，为了方便整理记录文件和 block 的关系，namenode 基于一批 edits 文件和一个 fsimage 文件完成整个文件系统的维护管理。&lt;/p&gt;
&lt;p&gt;edits 文件是一个流水账文件，记录了 hdfs 的每一次操作以及该次操作影响的文件及其对应的 block。为了保证 edits 文件检索性能，会有多个 edits 文件，每一个 edits 文件存储到达一定数量会开启新的 edits，保证不出现超大的 edits 文件。最终所有 edits 文件会合并为一个 fsimage 文件，这个 fsimage 文件就记录了最终状态的文件操作信息。如果已经有了 fsimage，就会把全部的 edits 和已存在的 fsimage 进行新的合并，生成新的 fsimage。
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-6.png&#34;
	width=&#34;1296&#34;
	height=&#34;481&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-6_hu_52dfd5d1e1ebfb29.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-6_hu_11dd4332aaa90aaa.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;269&#34;
		data-flex-basis=&#34;646px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-7.png&#34;
	width=&#34;1069&#34;
	height=&#34;588&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-7_hu_2625dce4698b9464.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-7_hu_de1611f6402ed05e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;181&#34;
		data-flex-basis=&#34;436px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-8.png&#34;
	width=&#34;1891&#34;
	height=&#34;688&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-8_hu_52c0bd3ecacf8461.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-8_hu_cefe06dc3ddf1ff3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;274&#34;
		data-flex-basis=&#34;659px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;元数据合并及控制参数&#34;&gt;&lt;a href=&#34;#%e5%85%83%e6%95%b0%e6%8d%ae%e5%90%88%e5%b9%b6%e5%8f%8a%e6%8e%a7%e5%88%b6%e5%8f%82%e6%95%b0&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;元数据合并及控制参数
&lt;/h4&gt;&lt;p&gt;**注意！**元数据（eidts 和 fsimage）的合并不是由 NN 完成的，而是 SNN，NN 只是基于元数据对整个文件系统进行维护管理，负责元数据记录和权限审批，NN 是管理者，不是员工。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;SNN 会通过 http 从 NN 拉取 edits 和 fsimage 然后合并元数据并提供给 NN 使用&lt;/strong&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-9.png&#34;
	width=&#34;1322&#34;
	height=&#34;573&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-9_hu_fdcc81a3d0edfece.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-9_hu_c4d2baad5f67d482.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;230&#34;
		data-flex-basis=&#34;553px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;hdfs-漫画&#34;&gt;&lt;a href=&#34;#hdfs-%e6%bc%ab%e7%94%bb&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HDFS 漫画
&lt;/h3&gt;&lt;h4 id=&#34;读写数据&#34;&gt;&lt;a href=&#34;#%e8%af%bb%e5%86%99%e6%95%b0%e6%8d%ae&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;读写数据
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-10.png&#34;
	width=&#34;1121&#34;
	height=&#34;1256&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-10_hu_157753679e8ec94b.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-10_hu_128645316d4622f6.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;89&#34;
		data-flex-basis=&#34;214px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-11.png&#34;
	width=&#34;1134&#34;
	height=&#34;639&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-11_hu_5749475ab96244d1.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-11_hu_fdb712f4675e0e4c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;425px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-12.png&#34;
	width=&#34;1140&#34;
	height=&#34;696&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-12_hu_cbb94e5392c1e693.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-12_hu_3fa0523a2f6f2f2b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;163&#34;
		data-flex-basis=&#34;393px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;hdfs-故障类型和检测方法&#34;&gt;&lt;a href=&#34;#hdfs-%e6%95%85%e9%9a%9c%e7%b1%bb%e5%9e%8b%e5%92%8c%e6%a3%80%e6%b5%8b%e6%96%b9%e6%b3%95&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HDFS 故障类型和检测方法
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-13.png&#34;
	width=&#34;1194&#34;
	height=&#34;1261&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-13_hu_4b1cee605bbbf67f.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-13_hu_58e809ec424f960c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;94&#34;
		data-flex-basis=&#34;227px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-14.png&#34;
	width=&#34;1174&#34;
	height=&#34;781&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-14_hu_f1b4c4dcb189bb05.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-14_hu_ca4e5674b708f30f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;150&#34;
		data-flex-basis=&#34;360px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-15.png&#34;
	width=&#34;1032&#34;
	height=&#34;1308&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-15_hu_3c0d662c6bd6c4dc.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-15_hu_3c58c6056ad8f8ae.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;78&#34;
		data-flex-basis=&#34;189px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-16.png&#34;
	width=&#34;1032&#34;
	height=&#34;1308&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-16_hu_3c0d662c6bd6c4dc.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-16_hu_3c58c6056ad8f8ae.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;78&#34;
		data-flex-basis=&#34;189px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;mapreduce-分布式并行计算框架&#34;&gt;&lt;a href=&#34;#mapreduce-%e5%88%86%e5%b8%83%e5%bc%8f%e5%b9%b6%e8%a1%8c%e8%ae%a1%e7%ae%97%e6%a1%86%e6%9e%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;MapReduce 分布式并行计算框架
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;MapReduce 是基于 Yarn 运行的，没有 Yarn 就无法运行 MapReduce，MapReduce 有 RM、NM、AM 三种角色。&lt;/p&gt;
&lt;p&gt;MR 不适合实时计算，不适合流式计算，不适合有向图计算。&lt;/p&gt;
&lt;p&gt;可通过 8042 端口（默认 8042）访问 web 界面，查看 MR 任务的执行信息
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-17.png&#34;
	width=&#34;2880&#34;
	height=&#34;1620&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-17_hu_f4034a3b5f774256.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-17_hu_c2d144baf5c37545.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;计算模式&#34;&gt;&lt;a href=&#34;#%e8%ae%a1%e7%ae%97%e6%a8%a1%e5%bc%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;计算模式
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;MapReduce 属于分散汇总。spark、flink 属于中心调度.&lt;/strong&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-18.png&#34;
	width=&#34;2005&#34;
	height=&#34;844&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-18_hu_8fee4c51ba5bc4bc.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-18_hu_233fa6c8244e1f4c.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;237&#34;
		data-flex-basis=&#34;570px&#34;
	
&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-19.png&#34;
	width=&#34;1668&#34;
	height=&#34;955&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-19_hu_e796581b28647e17.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-19_hu_a7bfd4eb965f4d88.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;174&#34;
		data-flex-basis=&#34;419px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;map-和-reduce&#34;&gt;&lt;a href=&#34;#map-%e5%92%8c-reduce&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Map 和 Reduce
&lt;/h3&gt;&lt;p&gt;Map 接口提供“分散”功能，Reduce 提供“汇总聚合”功能，用户可以通过 Java、python 等编程调用 mapreduce 接口完成开发，不过现在已经有了 Hive on MR（稍微过时），sparkSQL 等客户端。不懂编程仅用 SQL 就能完成开发，使用更方便，逐渐成为主流。&lt;/p&gt;
&lt;h3 id=&#34;mr-执行原理&#34;&gt;&lt;a href=&#34;#mr-%e6%89%a7%e8%a1%8c%e5%8e%9f%e7%90%86&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;MR 执行原理
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-20.png&#34;
	width=&#34;1403&#34;
	height=&#34;1232&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-20_hu_68e96f09be2f3bc.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-20_hu_58f862bcd0565186.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;113&#34;
		data-flex-basis=&#34;273px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;yarn-作业调度资源管理&#34;&gt;&lt;a href=&#34;#yarn-%e4%bd%9c%e4%b8%9a%e8%b0%83%e5%ba%a6%e8%b5%84%e6%ba%90%e7%ae%a1%e7%90%86&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Yarn 作业调度、资源管理
&lt;/h2&gt;&lt;p&gt;Yarn 管控整个集群的资源调度，MR 程序运行时，是在 Yarn 的监督下运行的，MR 程序会把计算任务分成若干个 map 和 reduce，然后向 Yarn 申请资源并运行任务。Yarn 有四种角色：ResourceManager（RM）、NodeManager（NM）、ProxyServer（PS）、JobHistoryServer（JHS）
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-21.png&#34;
	width=&#34;889&#34;
	height=&#34;513&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-21_hu_54781fad034c5888.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-21_hu_c4ac2a9b591cc19d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;173&#34;
		data-flex-basis=&#34;415px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;yarn-启停&#34;&gt;&lt;a href=&#34;#yarn-%e5%90%af%e5%81%9c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Yarn 启停
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-22.png&#34;
	width=&#34;1253&#34;
	height=&#34;291&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-22_hu_7b46bce3de21f748.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-22_hu_775d8f0fe7403c04.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;430&#34;
		data-flex-basis=&#34;1033px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;resourcemanager&#34;&gt;&lt;a href=&#34;#resourcemanager&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;ResourceManager
&lt;/h3&gt;&lt;p&gt;集群资源总管家，整个集群资源调度者，负责协调调度各个程序所需资源。&lt;/p&gt;
&lt;h3 id=&#34;nodemanager&#34;&gt;&lt;a href=&#34;#nodemanager&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;NodeManager
&lt;/h3&gt;&lt;p&gt;单机资源管家，单个服务器的资源调度者，负责协调调度单个服务器的资源供程序使用。同时负责该节点内所有容器的生命周期的管 理，监视资源和跟踪节点健康。具体如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;启动时向 ResourceManager 注册并定时发送心跳消息，等待 ResourceManager 的指令；
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;维护 Container 的生命周期，监控 Container 的资源使用情况；
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;管理任务运行时的相关依赖，根据 ApplicationMaster 的需要，在启动 Container 之前将需 要的程序及其依赖拷贝到本地。
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;applicationmaster&#34;&gt;&lt;a href=&#34;#applicationmaster&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;ApplicationMaster
&lt;/h3&gt;&lt;p&gt;在用户提交一个应用程序时，YARN 会启动一个轻量级的进程 ApplicationMaster 。 ApplicationMaster 负责协调来自 ResourceManager 的资源，并通过 NodeManager 监视容器内资 源的使用情况，同时还负责任务的监控与容错。具体如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;根据应用的运行状态来决定动态计算资源需求；
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;向 ResourceManager 申请资源，监控申请的资源的使用情况；
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;跟踪任务状态和进度，报告资源的使用情况和应用的进度信息；
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;负责任务的容错。
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;运行时可通过服务器的 8088 端口（默认 8088）访问 web 界面&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;jobhistoryserver&#34;&gt;&lt;a href=&#34;#jobhistoryserver&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;JobHistoryServer
&lt;/h3&gt;&lt;p&gt;记录历史运行程序的信息及产生的日志，把每个程序的运行日志统一收集到 hdfs，可通过 19888 端口访问 web 界面
&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-23.png&#34;
	width=&#34;2880&#34;
	height=&#34;1620&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-23_hu_30a5329cc559fcde.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-23_hu_d5dd26fb9b003a81.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;container&#34;&gt;&lt;a href=&#34;#container&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Container
&lt;/h3&gt;&lt;p&gt;Container 是 Yarn 中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等。&lt;/p&gt;
&lt;h2 id=&#34;hadoop-一键启停&#34;&gt;&lt;a href=&#34;#hadoop-%e4%b8%80%e9%94%ae%e5%90%af%e5%81%9c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hadoop 一键启停
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-24.png&#34;
	width=&#34;1483&#34;
	height=&#34;658&#34;
	srcset=&#34;/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-24_hu_f5e5925f43b6c9ad.png 480w, /zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/image-24_hu_e523a5cfc8834ca0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;225&#34;
		data-flex-basis=&#34;540px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Hive本质、架构、玩法</title>
        <link>/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/</link>
        <pubDate>Sun, 14 Apr 2024 12:23:06 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/</guid>
        <description>&lt;h2 id=&#34;hive-本质&#34;&gt;&lt;a href=&#34;#hive-%e6%9c%ac%e8%b4%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;strong&gt;Hive 本质&lt;/strong&gt;
&lt;/h2&gt;&lt;p&gt;Hive 是构建在 hadoop 上的数据仓库，也可以说是一个&lt;strong&gt;操作 hdfs 文件&lt;/strong&gt; 的客户端，它&lt;strong&gt;可以将结构化的数据文件映射成表&lt;/strong&gt;，并提供类 SQL 查询功能，用于查询的 SQL 语句会被转化为 MapReduce 作业，然后提交到 Hadoop 上运行。&lt;strong&gt;Hive 执行引擎可以是 MapReduce、Spark、Tez，如果是 MR，Hive 就会把 HQL 翻译成 MR 进行数据计算。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;由于 Hive 是针对数据仓库应⽤设计的，⽽数据仓库的内容是读多写少的。因此，Hive 中不⽀持 对数据的改写和添加，所有的数据都是在加载的时候中确定好的。&lt;/p&gt;
&lt;p&gt;Hive 不适合⽤于联机事务处理(OLTP)，也不提供实时查询功能。它最适合应⽤在基于⼤量不可变数据的批处理 作业。Hive 的特点是可伸缩（在 Hadoop 的集群上动态的添加设备），可扩展、容错、输⼊格式的松散耦合。 Hive 的⼊⼝是 DRIVER ，执⾏的 SQL 语句⾸先提交到 DRIVER 驱动，然后调 COMPILER 解释驱动，最终解释成 MapReduce 任务执⾏，最后将结果返回。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;优点：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;简单、容易上手 (提供了类似 sql 的查询语言 hql)，使得精通 sql 但是不了解 Java 编程的人也能很 好地进行大数据分析；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;灵活性高，可以自定义用户函数 (UDF) 和存储格式；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;为超大的数据集设计的计算和存储能力，集群扩展容易;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;4.&lt;strong&gt;统一的元数据管理&lt;/strong&gt;，可与 presto／impala／sparksql 等共享数据；&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;执行延迟高，不适合做数据的实时处理，但适合做海量数据的离线处理。&lt;/li&gt;
&lt;/ol&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image.png&#34;
	width=&#34;1415&#34;
	height=&#34;997&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image_hu_56e46a4d2510f5d9.png 480w, /zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image_hu_8393fd4979f71c19.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;141&#34;
		data-flex-basis=&#34;340px&#34;
	
&gt;
&lt;br /&gt;&lt;/p&gt;
&lt;h2 id=&#34;hive-主要有以下-3-个模块&#34;&gt;&lt;a href=&#34;#hive-%e4%b8%bb%e8%a6%81%e6%9c%89%e4%bb%a5%e4%b8%8b-3-%e4%b8%aa%e6%a8%a1%e5%9d%97&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hive 主要有以下 3 个模块:
&lt;/h2&gt;&lt;h3 id=&#34;户接模块&#34;&gt;&lt;a href=&#34;#%e6%88%b7%e6%8e%a5%e6%a8%a1%e5%9d%97&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;⽤户接⼝模块
&lt;/h3&gt;&lt;p&gt;含 CLI、HWI、JDBC、Thrift Server 等，⽤来实现对 Hive 的访问。CLI 是 Hive ⾃带 的命令⾏界⾯；HWI 是 Hive 的⼀个简单⽹⻚界⾯；JDBC、ODBC 以及 Thrift Server 可向⽤户提供进 ⾏编程的接⼝，其中 Thrift Server 是基于 Thrift 软件框架开发的，提供&lt;/p&gt;
&lt;h3 id=&#34;hive-的-rpc-通信接&#34;&gt;&lt;a href=&#34;#hive-%e7%9a%84-rpc-%e9%80%9a%e4%bf%a1%e6%8e%a5&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hive 的 RPC 通信接⼝
&lt;/h3&gt;&lt;p&gt;驱动模块（Driver）：含编译器 compiler、优化器 optimizer、执⾏器 executor 等，负责把 HiveQL 语句转换成⼀系列 MR 作业， 所有命令和查询都会进⼊驱动模块，通过该模块的解析变异，对计算过程进⾏优化，然后按照指定 的步骤执⾏。&lt;/p&gt;
&lt;h3 id=&#34;元数据存储模块metastore&#34;&gt;&lt;a href=&#34;#%e5%85%83%e6%95%b0%e6%8d%ae%e5%ad%98%e5%82%a8%e6%a8%a1%e5%9d%97metastore&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;strong&gt;元数据存储模块（Metastore）&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;是⼀个独⽴的关系型数据库，通常与 MySQL 数据库连接后创建的 ⼀个 MySQL 实例，也可以是 Hive ⾃带的 Derby 数据库实例。此模块主要保存表模式和其他系统元数 据，如表的名称、表的列及其属性、表的分区及其属性、表的属性、表中数据所在位置信息等。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;metastore 是 Hive 最重要的部件，在 Hive 中，表名、表结构、字段名、字段类型、表的分隔符等统一被称为元数据。所有的元数据默认存储在 Hive 内置的 derby 数据库中，但由于 derby 只能有一个实例，也就是说不能有多个命令行客户端同时访问，所以在实际生产环境中，通常使用 MySQL 中的自建数据库代替 derby。Hive 进行的是统一的元数据管理，就是说你在 Hive 上创建了一张表，然后在 presto、impala、sparksql 中都是可以直接使用的，它们会从 Metastore 中获取统一的元数据信息，同样的你在 presto、impala、sparksql 中创建一张表，在 Hive 中也可以直接使用。
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;hive 创建的内部表，默认放在 hdfs 的/usr/hive/warehouse 文件夹下
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-1.png&#34;
	width=&#34;882&#34;
	height=&#34;902&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-1_hu_a450e0f272720c15.png 480w, /zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-1_hu_f2d454cd1d9857ac.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;97&#34;
		data-flex-basis=&#34;234px&#34;
	
&gt;
可以看到 db_msg.db、myhive.db 是数据库，其他的是表，而这些表创建时默认放在另一个 default 库中只是在 hdfs 中没有显示，在 hive 中才能显示出来。由此可见 hive 的表和库其实就是一个个 hdfs 文件夹，表和库可以是并列同级关系。表有内外之分，创建时默认是内部表，而 external_stu1 是外部表，外部表和内部表的区别就在于外部表只是把 hdfs 的文件数据和 hive 的表相关联，在 hive 中删除外部表，hdfs 的文件数据依然存在不会被删除，而删除内部表，表的文件数据和表本身会一同删除。
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-2.png&#34;
	width=&#34;931&#34;
	height=&#34;730&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-2_hu_b0464d693e7c6130.png 480w, /zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-2_hu_425bc9dbf21459fc.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;127&#34;
		data-flex-basis=&#34;306px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;架构&#34;&gt;&lt;a href=&#34;#%e6%9e%b6%e6%9e%84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;架构
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-3.png&#34;
	width=&#34;883&#34;
	height=&#34;449&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-3_hu_bf3e07e9994421d7.png 480w, /zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-3_hu_391526594d3c51ad.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;196&#34;
		data-flex-basis=&#34;471px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;hive-日志配置&#34;&gt;&lt;a href=&#34;#hive-%e6%97%a5%e5%bf%97%e9%85%8d%e7%bd%ae&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hive 日志配置
&lt;/h2&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;-- Hive中的日志分为两种
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;1. 系统日志，记录了hive的运行情况，错误状况。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;2. Job 日志，记录了Hive 中job的执行的历史过程。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;系统日志存储在什么地方呢 ？
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;在hive/conf/hive-log4j.properties 文件中记录了Hive日志的存储情况，
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;如果没有hive-log4j.properties。那么需要找到该文件夹下的hive-log4j.properties.templete,这个是模板文件，运行mv命令把templete重命名成properties文件即可。
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;properties文件默认的存储情况：
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;property.hive.root.logger=WARN,DRFA
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;property.hive.log.dir=/tmp/${user.name} # 默认的存储位置,一般是/tmp/root，此处改成hive/logs
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;property.hive.log.file=hive.log  # 默认的文件名
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Job日志又存储在什么地方呢 ？
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;//Location of Hive run time structured log file
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    HIVEHISTORYFILELOC(&amp;#34;hive.querylog.location&amp;#34;, &amp;#34;/tmp/&amp;#34; + System.getProperty(&amp;#34;user.name&amp;#34;)),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;默认存储与在/tmp/{user.name}目录下。但是我没找到。。。
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;properties 文件的日志存放目录修改之后如下：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-4.png&#34;
	width=&#34;837&#34;
	height=&#34;353&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-4_hu_4520e8acf4e7fef4.png 480w, /zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-4_hu_a65bc72b2afcc3fc.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;237&#34;
		data-flex-basis=&#34;569px&#34;
	
&gt;
日志目录是后来配置的，于是又把/tmp/root 目录下的 hive 日志手动移到了 hive/logs 下：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-5.png&#34;
	width=&#34;1274&#34;
	height=&#34;367&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-5_hu_172101a3a70a1991.png 480w, /zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-5_hu_9d8401827ae7467f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;347&#34;
		data-flex-basis=&#34;833px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;hql-执行过程&#34;&gt;&lt;a href=&#34;#hql-%e6%89%a7%e8%a1%8c%e8%bf%87%e7%a8%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HQL 执行过程
&lt;/h2&gt;&lt;p&gt;Hive 在执行一条 HQL 的时候，会经过以下步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;语法解析：Antlr 定义 SQL 的语法规则，完成 SQL 词法，语法解析，将 SQL 转化为抽象 语法树 AST Tree；&lt;/li&gt;
&lt;li&gt;语义解析：遍历 AST Tree，抽象出查询的基本组成单元 QueryBlock；&lt;/li&gt;
&lt;li&gt;生成逻辑执行计划：遍历 QueryBlock，翻译为执行操作树 OperatorTree；&lt;/li&gt;
&lt;li&gt;优化逻辑执行计划：逻辑层优化器进行 OperatorTree 变换，合并不必要的 * ReduceSinkOperator，减少 shuffle 数据量；&lt;/li&gt;
&lt;li&gt;生成物理执行计划：遍历 OperatorTree，翻译为 MapReduce 任务；&lt;/li&gt;
&lt;li&gt;优化物理执行计划：物理层优化器进行 MapReduce 任务的变换，生成最终的执行计划。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;hive-四种玩法&#34;&gt;&lt;a href=&#34;#hive-%e5%9b%9b%e7%a7%8d%e7%8e%a9%e6%b3%95&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hive 四种玩法：
&lt;/h2&gt;&lt;h3 id=&#34;cli&#34;&gt;&lt;a href=&#34;#cli&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;CLI
&lt;/h3&gt;&lt;p&gt;配置 hive 环境变量（通常是/etc/profile 文件）后，在任意目录下直接输入命令 hive 即可启动（或者 hive &amp;ndash;service cli），前提是要启动 hdfs（start-dfs.sh）和 hive 元数据服务（start-hivemetastore.sh 自己写的脚本配置到环境变量），因为 hive 就是操作 hdfs 的文件的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意！！！&lt;/strong&gt;
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-6.png&#34;
	width=&#34;1421&#34;
	height=&#34;191&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-6_hu_e8fcf768d70661e7.png 480w, /zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-6_hu_96ea3df9b92e66e2.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;743&#34;
		data-flex-basis=&#34;1785px&#34;
	
&gt;
注意第一行提到 Hive-on -MR is deprecated 在 2.x 版本已经废弃不推荐使用，后续都是 hive on spark （on Tez），但是 MapReduce 的 hive 优化还是建议学一下。
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-7.png&#34;
	width=&#34;1423&#34;
	height=&#34;150&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-7_hu_52aaf1bc603a5f5a.png 480w, /zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-7_hu_5454dee5108ecc8a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;948&#34;
		data-flex-basis=&#34;2276px&#34;
	
&gt;
上面这种情况可能就是没启动元数据服务。
hive 通常是在集群环境中使用的，如果只启动了一台服务器，那么在启动 hive 时会报错，如下：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-8.png&#34;
	width=&#34;1771&#34;
	height=&#34;235&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-8_hu_780d886e66dd009a.png 480w, /zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-8_hu_c5c8b2a013ac174e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;753&#34;
		data-flex-basis=&#34;1808px&#34;
	
&gt;
name node 处于安全模式，服务器数量少于最小要求数量，这种情况要么等 18s 后重新启动 cli，要么启动第二台服务器并启动上面的 hdfs。&lt;/p&gt;
&lt;h3 id=&#34;hiveserver2&#34;&gt;&lt;a href=&#34;#hiveserver2&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HiveServer2
&lt;/h3&gt;&lt;p&gt;启动 hiveserver2 服务，提供 thrift 端口供其他客户连接，启动之后就可以使用 hive 之外的其他工具操作 hdfs 文件，比如 DBserver，IDEA 的数据库插件&lt;/p&gt;
&lt;p&gt;需要在 hdfs 的 core-site.xml 文件中加如下配置：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.proxyuser.root.groups&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;*&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;允许root用户代理任何其他用户&lt;span class=&#34;nt&#34;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.proxyuser.root.hosts&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;*&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;nt&#34;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;允许代理任意服务器的请求&lt;span class=&#34;nt&#34;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    root也可以换成hadoop等其他用户，我这里设置成了超级用户root
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;任意目录下启动 hiveserver2（前台）或者切换到后台。
自己写的后台脚本，配置到环境变量中&lt;/p&gt;
&lt;p&gt;[root@linux01 bin]# cat start-hiveserver2.sh&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#!/bin/bash
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;nohup &lt;span class=&#34;nv&#34;&gt;$HIVE_HOME&lt;/span&gt;/bin/hive --service hiveserver2 &amp;gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;$HIVE_HOME&lt;/span&gt;/logs/hiveserver2.log 2&amp;gt;&lt;span class=&#34;p&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;amp;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#启动hiveserver2服务，提供thrift端口供其他客户连接&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;beeline&#34;&gt;&lt;a href=&#34;#beeline&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Beeline
&lt;/h3&gt;&lt;p&gt;启动 beeline 必须先启动 hiveserver2，启动 beeline 后，键入&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-md&#34; data-lang=&#34;md&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;!connect jdbc:hive2://linux01:10000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;并输入用户名密码即可，这里的登录用户可以是任意用户因为 hadoop 的 core-site.xml 设置了 root 用户可以代理任意用户。linux01 是我的服务器名。
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-9.png&#34;
	width=&#34;1089&#34;
	height=&#34;459&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-9_hu_2a432c89e502a252.png 480w, /zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/image-9_hu_a19ee912d4b86804.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;237&#34;
		data-flex-basis=&#34;569px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;web-ui&#34;&gt;&lt;a href=&#34;#web-ui&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Web UI
&lt;/h3&gt;&lt;p&gt;在 hive-site-xml 中添加 hive 配置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hive.server2.webui.host&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c&#34;&gt;&amp;lt;!--主机名或ip--&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;linux01&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hive.server2.webui.port&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;10002&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/propert&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;启动 hive，浏览器即可访问 10002 端口&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Hive调优</title>
        <link>/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/</link>
        <pubDate>Sat, 13 Apr 2024 20:49:38 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/</guid>
        <description>&lt;h2 id=&#34;yarn-和-mr-资源配置&#34;&gt;&lt;a href=&#34;#yarn-%e5%92%8c-mr-%e8%b5%84%e6%ba%90%e9%85%8d%e7%bd%ae&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Yarn 和 MR 资源配置
&lt;/h2&gt;&lt;p&gt;配置项参考官网：&lt;a class=&#34;link&#34; href=&#34;https://apache.github.io/hadoop/&#34;  title=&#34;https://apache.github.io/hadoop/&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://apache.github.io/hadoop/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;yarn-资源配置&#34;&gt;&lt;a href=&#34;#yarn-%e8%b5%84%e6%ba%90%e9%85%8d%e7%bd%ae&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Yarn 资源配置
&lt;/h3&gt;&lt;p&gt;修改 yarn-site.xml,调整的 Yarn 参数均与 CPU、内存等资源有关，配置如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.nodemanager.resource.memory-mb&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;65536&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;一个NodeManager节点分配给Container使用的内存。该参数的配置，取决于NodeManager所在节点的总内存容量和该节点运行的其他服务的数量&lt;span class=&#34;nt&#34;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.nodemanager.resource.cpu-vcores&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;16&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;一个NodeManager节点分配给Container使用的CPU核数。该参数的配置，同样取决于NodeManager所在节点的总CPU核数和该节点运行的其他服务。&lt;span class=&#34;nt&#34;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.scheduler.maximum-allocation-mb&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;16384&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;单个Container能够使用的最大内存。&lt;span class=&#34;nt&#34;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.scheduler.minimum-allocation-mb&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;512&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nt&#34;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;单个Container能够使用的最小内存。&lt;span class=&#34;nt&#34;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;修改后重新分发该配置文件并重启 Yarn&lt;/p&gt;
&lt;h3 id=&#34;mr-资源配置&#34;&gt;&lt;a href=&#34;#mr-%e8%b5%84%e6%ba%90%e9%85%8d%e7%bd%ae&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;MR 资源配置
&lt;/h3&gt;&lt;p&gt;MapReduce 资源配置主要包括 Map Task 的内存和 CPU 核数，以及 Reduce Task 的内存和 CPU 核数。核心配置参数如下：&lt;/p&gt;
&lt;h4 id=&#34;mapreducemapmemorymb&#34;&gt;&lt;a href=&#34;#mapreducemapmemorymb&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;strong&gt;mapreduce.map.memory.mb&lt;/strong&gt;
&lt;/h4&gt;&lt;p&gt;该参数的含义是，单个 Map Task 申请的 container 容器内存大小，其默认值为 1024。该值不能超出 yarn.scheduler.maximum-allocation-mb 和 yarn.scheduler.minimum-allocation-mb 规定的范围。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;该参数需要根据不同的计算任务单独进行配置，在 hive 中，可直接使用如下方式为每个 SQL 语句单独进行配置：set mapreduce.map.memory.mb=2048;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;mapreducemapcpuvcores&#34;&gt;&lt;a href=&#34;#mapreducemapcpuvcores&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;strong&gt;mapreduce.map.cpu.vcores&lt;/strong&gt;
&lt;/h4&gt;&lt;p&gt;该参数的含义是，单个 Map Task 申请的 container 容器 cpu 核数，其默认值为 1。该值一般无需调整。如需调整要修改 mapred-site.xml 文件（mapred-default.xml）&lt;/p&gt;
&lt;h4 id=&#34;mapreducereducecpuvcores&#34;&gt;&lt;a href=&#34;#mapreducereducecpuvcores&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;strong&gt;mapreduce.reduce.cpu.vcores&lt;/strong&gt;
&lt;/h4&gt;&lt;p&gt;该参数的含义是，单个 Reduce Task 申请的 container 容器 cpu 核数，其默认值为 1。该值一般无需调整。如需调整要修改 mapred-site.xml 文件（mapred-default.xml）&lt;/p&gt;
&lt;h4 id=&#34;mapreducereducememorymb&#34;&gt;&lt;a href=&#34;#mapreducereducememorymb&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;strong&gt;mapreduce.reduce.memory.mb&lt;/strong&gt;
&lt;/h4&gt;&lt;p&gt;该参数的含义是，单个 Reduce Task 申请的 container 容器内存大小，其默认值为 1024。该值同样不能超出 yarn.scheduler.maximum-allocation-mb 和 yarn.scheduler.minimum-allocation-mb 规定的范围。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;该参数需要根据不同的计算任务单独进行配置，在 hive 中，可直接使用如下方式为每个 SQL 语句单独进行配置：set mapreduce.reduce.memory.mb=2048;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;explain-查看执行计划&#34;&gt;&lt;a href=&#34;#explain-%e6%9f%a5%e7%9c%8b%e6%89%a7%e8%a1%8c%e8%ae%a1%e5%88%92&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Explain 查看执行计划
&lt;/h2&gt;&lt;p&gt;Explain 用于呈现 HQL 语句的详细执行步骤，由一系列 Stage 组成，简单的理解为 HQL 查询语句的不同执行阶段，这一系列 Stage 具有依赖关系，每个 Stage 对应一个 MapReduce Job 或一个文件系统操作等。&lt;/p&gt;
&lt;p&gt;若某个 Stage 对应的一个 MapReduce Job，则其 Map 端和 Reduce 端的计算逻辑分别由 Map Operator Tree 和 Reduce Operator Tree 进行描述，Operator Tree 由一系列的 Operator 组成，一个 Operator 代表在 Map 或 Reduce 阶段的一个单一的逻辑操作，例如 TableScan Operator，Select Operator，Join Operator 等。具体如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image.png&#34;
	width=&#34;213&#34;
	height=&#34;681&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image_hu_47b669486afcd8ad.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image_hu_6f7640515ae32138.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;31&#34;
		data-flex-basis=&#34;75px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;常见的 Operator 及其作用如下&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;TableScan：表扫描操作，通常 map 端第一个操作肯定是表扫描操作&lt;/p&gt;
&lt;p&gt;Select Operator：选取操作&lt;/p&gt;
&lt;p&gt;Group By Operator：map 端的分组聚合操作，在后面的分组聚合中会讲到&lt;/p&gt;
&lt;p&gt;Reduce Output Operator：输出到 reduce 操作&lt;/p&gt;
&lt;p&gt;Filter Operator：过滤操作&lt;/p&gt;
&lt;p&gt;Join Operator：join 操作&lt;/p&gt;
&lt;p&gt;File Output Operator：文件输出操作&lt;/p&gt;
&lt;p&gt;Fetch Operator 客户端获取数据操作&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Explain 语法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;EXPLAIN [FORMATTED | EXTENDED | DEPENDENCY]&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;FORMATTED：将执行计划以 JSON 字符串的形式输出&lt;/li&gt;
&lt;li&gt;EXTENDED：输出执行计划中的额外信息，通常是读写的文件名等信息&lt;/li&gt;
&lt;li&gt;DEPENDENCY：输出执行计划读取的表及分区&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;例：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;hive (default)&amp;gt;&lt;/p&gt;
&lt;p&gt;explain formatted&lt;/p&gt;
&lt;p&gt;select user_id,count(*) from order_detail group by user_id;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-1.png&#34;
	width=&#34;1435&#34;
	height=&#34;886&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-1_hu_df40e0082aa7426d.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-1_hu_38c1b7e1fc123ebc.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;161&#34;
		data-flex-basis=&#34;388px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;分组聚合优化&#34;&gt;&lt;a href=&#34;#%e5%88%86%e7%bb%84%e8%81%9a%e5%90%88%e4%bc%98%e5%8c%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;strong&gt;分组聚合优化&lt;/strong&gt;
&lt;/h2&gt;&lt;p&gt;分组聚合是通过 MR Job 实现的，map 端读取数据，并按照分组字段分区，通过 shuffle，把数据发到 reduce，各组数据在 reduce 端完成最终的聚合运算。&lt;/p&gt;
&lt;p&gt;分组聚合的优化主要围绕减少 shuffle 数据量进行，具体做法是 map-side 聚合。map-side 聚合是在 map 端维护一个 hash table，先利用其完成数据的部分聚合，再把聚合的结果按照分组字段分区，发到 reduce 端完成最终聚合，以此提高分组聚合运算效率。简而言之就是增加了一个 map 端的部分聚合过程，以减少 shuffle 的工作量，进而减少 reduce 端的聚合工作量。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;map-side 聚合相关参数如下&lt;/p&gt;
&lt;p&gt;&amp;ndash;启用 map-side 聚合，默认是 true&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;set hive.map.aggr=true;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&amp;ndash;用于检测源表数据是否适合进行 map-side 聚合。检测的方法是：系统自动先对若干条数据进行 map-side 聚合，若聚合后的条数和聚合前的条数比值小于该值，则认为该表适合进行 map-side 聚合；否则，认为该表数据不适合进行 map-side 聚合，后续数据便不再进行 map-side 聚合。0.5 意味着平均有 2 条数据可以聚合成 1 条，1 意味着没有出现任何的聚合&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;set hive.map.aggr.hash.min.reduction=0.5;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&amp;ndash;用于&lt;strong&gt;hive.map.aggr.hash.min.reduction=0.5&lt;/strong&gt; 检测源表是否适合 map-side 聚合的条数。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;set hive.groupby.mapaggr.checkinterval=100000;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&amp;ndash;map-side 聚合所用的 hash table 占用 map task 堆内存的最大比例，若超出该值，则会对 hash table 进行一次 flush。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;set hive.map.aggr.hash.force.flush.memory.threshold=0.7;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;优化前-vs-优化后&#34;&gt;&lt;a href=&#34;#%e4%bc%98%e5%8c%96%e5%89%8d-vs-%e4%bc%98%e5%8c%96%e5%90%8e&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;优化前 VS 优化后
&lt;/h3&gt;&lt;p&gt;set hive.map.aggr=false 关闭分组聚合优化，查看执行效果，在 Map 端没有了 Group By Operator&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-2.png&#34;
	width=&#34;538&#34;
	height=&#34;871&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-2_hu_d4e494b7ea248a44.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-2_hu_c61e4d2575f0ab2a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;61&#34;
		data-flex-basis=&#34;148px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;set hive.map.aggr=true 开启分组聚合优化，查看执行效果，在 Map 端有了 Group By Operator，&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-3.png&#34;
	width=&#34;493&#34;
	height=&#34;888&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-3_hu_53044b8f5a377993.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-3_hu_ae68419ad1ada840.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;55&#34;
		data-flex-basis=&#34;133px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;若发生 map-side 优化，优化后比优化前的 HQL 执行耗时应该有所减少，且 map 的 output 数量明显小于 input 数量。&lt;/p&gt;
&lt;p&gt;若没有触发 map-side，则 map 的 output 数量虽然比 input 数量有所减少但可以忽略不计。具体有没有触发 map-side 可以去 web UI 界面查看 map 日志。&lt;/p&gt;
&lt;p&gt;注意！！map-side 聚合不够智能，即 map 端的分组聚合是否执行一定程度上会受到分组字段在表中存储的位置和分布的影响，这是底层存储问题，未必是因为数据真的不适合分组聚合。要解决此问题可以提前对数据&lt;strong&gt;分区分桶&lt;/strong&gt;，使用分区分桶表，使得同一区域存储的数据分布具有一定的相似性，这样聚合结果会有所提升。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;例：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1）select province_id,count(*) from order_detail group by province_id;&lt;/p&gt;
&lt;p&gt;该语句查询所有订单，根据省份 id 分组聚合，省份只有 34 个，这样 map 后的数据应该只有 34 条，所以聚合结果是应该是比较可观的。所以 group by 的基数越小，一般越适合聚合。&lt;/p&gt;
&lt;p&gt;2）select product_id,count(*) from order_detail group by product_id;&lt;/p&gt;
&lt;p&gt;若 product_id 这一分组字段在 order_detail 表中分布比较散，那么可能会导致 hive 在表中切片抽样进行 map-side 检测的时候测试聚合结果&amp;gt;0.5，那么最终就没有使用 map-side 聚合。所以说如果能保证抽样数据的测试结果&amp;lt;=0.5，就会实现分组聚合，当然也可以调整&lt;strong&gt;hive.map.aggr.hash.min.reduction&lt;/strong&gt; 的值以提高 map-side 的命中率。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;若 100w 的数据集分组聚合之后的输出&amp;gt;100w,可能的原因是多次触发了 hash table 的 flush&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;join-优化&#34;&gt;&lt;a href=&#34;#join-%e4%bc%98%e5%8c%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Join 优化
&lt;/h2&gt;&lt;p&gt;Join 优化就是控制 HQL 语句走哪种 join 算法，这些 join 算法有的快，有的慢，有的激进，有的保守。我们要做的就是让 HQL 走最适合自己的 join 算法。&lt;/p&gt;
&lt;h3 id=&#34;common-join普通-join&#34;&gt;&lt;a href=&#34;#common-join%e6%99%ae%e9%80%9a-join&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Common Join(普通 join)
&lt;/h3&gt;&lt;h4 id=&#34;原理&#34;&gt;&lt;a href=&#34;#%e5%8e%9f%e7%90%86&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;原理
&lt;/h4&gt;&lt;p&gt;hive 中最稳定的 join 算法，其通过一个 MapReduce Job 完成一个 join 操作。Map 端负责读取 join 操作所需表的数据，并按照关联字段进行分区，通过 Shuffle，将其发送到 Reduce 端，相同 key 的数据在 Reduce 端完成最终的 Join 操作。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-4.png&#34;
	width=&#34;641&#34;
	height=&#34;479&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-4_hu_d8fba809e1779fb4.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-4_hu_d946e815b71cef4d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;321px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;需要注意的是，HQL 语句中的 join 操作和执行计划中的 Common Join 任务并非一对一的关系，即 HQL 中的 A 表 join B 表 join C 表在 common join 中未必也是两个 join 操作，一个 HQL 语句中的相邻的且关联字段相同的多个 join 操作可以合并为一个 Common Join 任务。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;例：
1）hive (default)&lt;/p&gt;
&lt;p&gt;select a.val, b.val, c.val from&lt;/p&gt;
&lt;p&gt;a join b on (a.key = b.key1) join c on (c.key = b.key1)&lt;/p&gt;
&lt;p&gt;上述 sql 语句中两个 join 操作的关联字段均为 b 表的 key1 字段，则该语句中的两个 join 操作可由一个 Common Join 任务实现，也就是可通过 1 个 Map Reduce 任务实现。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;2）hive (default)&amp;gt; select a.val, b.val, c.val from&lt;/p&gt;
&lt;p&gt;a join b on (a.key = b.key1) join c on (c.key = b.key2)&lt;/p&gt;
&lt;p&gt;上述 sql 语句中的两个 join 操作关联字段各不相同，则该语句的两个 join 操作需要各自通过一个 Common Join 任务实现，也就是通过 2 个 Map Reduce 任务实现。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;map-join&#34;&gt;&lt;a href=&#34;#map-join&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Map Join
&lt;/h3&gt;&lt;h4 id=&#34;原理-1&#34;&gt;&lt;a href=&#34;#%e5%8e%9f%e7%90%86-1&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;原理
&lt;/h4&gt;&lt;p&gt;Map Join 算法可以通过一个 MR 和一个 MapJoin 阶段完成一个 join 操作，省去了 shuffle 和 reduce，在第二个 map 阶段进行表的 join，不需要进入 reduce 阶段。其适用场景为大表 join 小表。第一个 Job 会读取小表数据，将其制作为 hash table，并上传至 Hadoop 分布式缓存（本质上是上传至 HDFS）。第二个 Job 会先从分布式缓存中读取小表数据，并缓存在 Map Task 的内存中，然后扫描大表数据，这样在 map 端即可完成关联操作。如下图所示：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-5.png&#34;
	width=&#34;865&#34;
	height=&#34;514&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-5_hu_c9f21c1f5ca0940b.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-5_hu_1529fb5d47ecf2d4.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;168&#34;
		data-flex-basis=&#34;403px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;mapreduce local task 是本地任务，读取小表数据，因为小表数据占用内存资源少，所以不上传到 yarn，直接在本地读取效率更高 ，读取后序列化生成 hash table 并上传到 hdfs 的 cache 中。&lt;/p&gt;
&lt;p&gt;其中 Mapper 是实现 Map 阶段功能的代码组件。它接受原始数据作为输入，执行某种转换操作，然后输出一组键值对。这些键值对会作为 Reduce 阶段的输入。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;例：SELECT a.key, a.value FROM a JOIN b ON a.key = b.key&lt;/p&gt;
&lt;p&gt;前提 b 表是一张小表，具体小表有多小，由参数 hive.mapjoin.smalltable.filesize 来决定，默认值是 25M。&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;参数列表：&lt;/p&gt;
&lt;p&gt;1）小表自动选择 Mapjoin&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join=true;&lt;/p&gt;
&lt;p&gt;默认值：false。该参数为 true 时，Hive 自动对左边的表统计量，若是小表就加入内存，即对小表使用 Map join
2）小表阀值
set hive.mapjoin.smalltable.filesize=25000000;
?默认值：25M&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;优化&#34;&gt;&lt;a href=&#34;#%e4%bc%98%e5%8c%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;优化
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;法一：hint 提示&lt;/strong&gt;
手动指定通过 map join 算法，该方式已经过时，不推荐使用。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;hive (default)&amp;gt; select /_+ map join(ta) _/&lt;/p&gt;
&lt;p&gt;ta.id, tb.id from table_a ta join table_b tb on ta.id=tb.id;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;法二：自动触发&lt;/strong&gt;
Hive 在编译 HQL 语句阶段，起初所有的 join 操作均采用 Common Join 算法实现。&lt;/p&gt;
&lt;p&gt;之后在物理优化阶段，Hive 会根据每个 Common Join 任务所需表的大小判断该 Common Join 任务是否能够转换为 Map Join 任务，若满足要求（小表大小&amp;lt;指定的阈值），便将 Common Join 任务自动转换为 Map Join 任务。&lt;/p&gt;
&lt;p&gt;但有些 Common Join 任务所需的表大小，在 HQL 的编译阶段是未知的（例如对子查询进行 join 操作），所以这种 Common Join 任务是否能转换成 Map Join 任务在编译阶是无法确定的。&lt;/p&gt;
&lt;p&gt;针对这种情况，Hive 会在编译阶段生成一个条件任务（Conditional Task），其下会包含一个计划列表，计划列表中包含转换后的 Map Join 任务以及原有的 Common Join 任务。最终具体采用哪个计划，是在运行时决定的。大致思路如下图所示：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-6.png&#34;
	width=&#34;865&#34;
	height=&#34;609&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-6_hu_9b1e73b062f06732.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-6_hu_ba70a549f87b60b1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;142&#34;
		data-flex-basis=&#34;340px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;Map join 自动转换的具体判断逻辑如下图所示：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-7.png&#34;
	width=&#34;863&#34;
	height=&#34;680&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-7_hu_ab3561a231e66273.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-7_hu_122f568ab470925a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;126&#34;
		data-flex-basis=&#34;304px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;图片详情看尚硅谷 P135&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;寻找大表候选人时还不知道每张表的大小&lt;/strong&gt;，那么选择规则是看 join 方式，有 innner join、left join、right join 等等。&lt;/p&gt;
&lt;p&gt;inner join：每个表都可能是大表候选人。&lt;/p&gt;
&lt;p&gt;left join：默认左表为大表候选人，右表当作小表，这样小表会缓存到内存中，以大表为主，从大表中一条条 join 内存中的小表，如果反过来把大表缓存到内存中，以小表为主，从小表中一条条 join 内存中的大表，若出现大表有该字段而小表没有的情况，这种情况下就会出现大量数据 join 失败，小表数据少，大表数据多，那么会因为小表浪费很多数据，所以通常是左表为大表，右表为小表。&lt;/p&gt;
&lt;p&gt;right join：左表当作小表，右表为大表候选人。&lt;/p&gt;
&lt;p&gt;full outer join：找不到大表候选人，因为全外联要返回两个表的全部数据，两个表都要去遍历，就无法 map join 优化。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;涉及参数：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&amp;ndash;启动 Map Join 自动转换&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join=true;&lt;/p&gt;
&lt;p&gt;&amp;ndash;一个 Common Join operator 转为 Map Join operator 的判断条件：若该 Common Join 相关的表中,把每一个表都当作大表候选人，若除大表之外的任意一张已知大小的表的大小&amp;gt;大表候选人，则该组合不成立，不生成 map join，反之生成一个 Map Join 计划。此时可能存在多种组合均满足该条件,则 hive 会为每种满足条件的组合均生成一个 Map Join 计划,同时还会保留原有的 Common Join 计划作为后备(back up)计划,实际运行时,优先执行 Map Join 计划，若不能执行成功，则启动 Common Join 后备计划。&lt;/p&gt;
&lt;p&gt;set hive.mapjoin.smalltable.filesize=250000;&lt;/p&gt;
&lt;p&gt;&amp;ndash;开启无条件转 Map Join&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join.noconditionaltask=true; -无条件转 Map Join 时的小表之和阈值,若一个 Common Join operator 相关的表中，存在 n-1 张表的大小总和&amp;lt;=该值,此时 hive 便不会再为每种 n-1 张表的组合均生成 Map Join 计划,同时也不会保留 Common Join 作为后备计划。而是只生成一个最优的 Map Join 计划。
set hive.auto.convert.join.noconditionaltask.size=10000000;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;优化案例&#34;&gt;&lt;a href=&#34;#%e4%bc%98%e5%8c%96%e6%a1%88%e4%be%8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;strong&gt;优化案例&lt;/strong&gt;
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;hive (default)&amp;gt; select * from order_detail od&lt;/p&gt;
&lt;p&gt;join product_info product on od.product_id = product.id&lt;/p&gt;
&lt;p&gt;join province_info province on od.province_id = province.id;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;优化前&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;上述 SQL 语句共有三张表进行两次 join 操作，且两次 join 操作的关联字段不同。故优化前的执行计划应该包含两个 Common Join operator，也就是由两个 MapReduce 任务实现。执行计划如下图所示：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-8.png&#34;
	width=&#34;445&#34;
	height=&#34;1391&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-8_hu_3e6bbe204819d3d6.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-8_hu_63b78982ef539f4b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;31&#34;
		data-flex-basis=&#34;76px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;优化思路&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;使用如下语句获取表/分区的大小信息：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;hive (default)&amp;gt;&lt;/p&gt;
&lt;p&gt;desc formatted table_name partition(partition_col=&amp;lsquo;partition&amp;rsquo;);&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;经分析，参与 join 的三张表，数据量如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-9.png&#34;
	width=&#34;1474&#34;
	height=&#34;371&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-9_hu_53b2492ddd32221d.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-9_hu_a661e9dca70d29c4.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;397&#34;
		data-flex-basis=&#34;953px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;方案一：&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;启用 Map Join 自动转换。&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join=true;&lt;/p&gt;
&lt;p&gt;不使用无条件转 Map Join。&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join.noconditionaltask=false;&lt;/p&gt;
&lt;p&gt;调整 hive.mapjoin.smalltable.filesize 参数，使其大于等于 product_info。&lt;/p&gt;
&lt;p&gt;set hive.mapjoin.smalltable.filesize=25285707;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;这样可保证将两个 Common Join operator 均可转为 Map Join operator，并保留 Common Join 作为后备计划，保证计算任务的稳定。调整完的执行计划如下图：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-10.png&#34;
	width=&#34;541&#34;
	height=&#34;1422&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-10_hu_4df7790955068a83.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-10_hu_75b79a59c50968c3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;38&#34;
		data-flex-basis=&#34;91px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;方案二：&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;启用 Map Join 自动转换。&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join=true;&lt;/p&gt;
&lt;p&gt;使用无条件转 Map Join。&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join.noconditionaltask=true;&lt;/p&gt;
&lt;p&gt;调整 hive.auto.convert.join.noconditionaltask.size 参数，使其大于等于 product_info 和 province_info 之和。&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join.noconditionaltask.size=25286076;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;这样可直接将两个 Common Join operator 转为两个 Map Join operator，并且由于两个 Map Join operator 的小表大小之和小于等于 hive.auto.convert.join.noconditionaltask.size，故两个 Map Join operator 任务可合并为同一个。这个方案计算效率最高，但需要的内存也是最多的。&lt;/p&gt;
&lt;p&gt;调整完的执行计划如下图：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-11.png&#34;
	width=&#34;334&#34;
	height=&#34;805&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-11_hu_d1095692a79431fe.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-11_hu_7607218a1c33454a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;41&#34;
		data-flex-basis=&#34;99px&#34;
	
&gt;
&lt;strong&gt;方案三：&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;启用 Map Join 自动转换。&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join=true;&lt;/p&gt;
&lt;p&gt;使用无条件转 Map Join。&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join.noconditionaltask=true;&lt;/p&gt;
&lt;p&gt;调整 hive.auto.convert.join.noconditionaltask.size 参数，使其等于 product_info。&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join.noconditionaltask.size=25285707;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;这样可直接将两个 Common Join operator 转为 Map Join operator，但不会将两个 Map Join 的任务合并。该方案计算效率比方案二低，但需要的内存也更少。
调整完的执行计划如下图：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-12.png&#34;
	width=&#34;191&#34;
	height=&#34;1408&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-12_hu_c31777942e896c7e.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-12_hu_10df58072d93e378.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;13&#34;
		data-flex-basis=&#34;32px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;bucket-map-join&#34;&gt;&lt;a href=&#34;#bucket-map-join&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Bucket Map Join
&lt;/h3&gt;&lt;h4 id=&#34;原理-2&#34;&gt;&lt;a href=&#34;#%e5%8e%9f%e7%90%86-2&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;原理
&lt;/h4&gt;&lt;p&gt;Bucket Map Join 是对 Map Join 算法的改进，其打破了 Map Join 只适用于大表 join 小表的限制，可用于大表 join 大表的场景。分桶其实就是把大表化成了“小表”，然后 Map-Side Join 解决。&lt;/p&gt;
&lt;p&gt;Bucket Map Join 的核心思想是：若能保证参与 join 的表均为分桶表，且关联字段为分桶字段，且其中一张表的分桶数量是另外一张表分桶数量的整数倍，就能保证参与 join 的两张表的分桶之间具有明确的关联关系，所以就可以在两表的分桶间进行 Map Join 操作了。这样一来，第二个 Job 的 Map 端就无需再缓存小表的全表数据了，而只需缓存其所需的分桶即可。其原理如图所示：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-13.png&#34;
	width=&#34;1235&#34;
	height=&#34;705&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-13_hu_cb5f7dc2b3847456.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-13_hu_f86c97fcd542db0d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;175&#34;
		data-flex-basis=&#34;420px&#34;
	
&gt;
第一个 map 对较小的表 tableB 的每个 bucket 序列化成 hash table，上传到 hdfs cache 中，第二个 map 对较大的表 tableA 的每个桶单独切片，有几个桶就有几个 mapper&lt;/p&gt;
&lt;h4 id=&#34;优化-1&#34;&gt;&lt;a href=&#34;#%e4%bc%98%e5%8c%96-1&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;优化
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;hint 提示&lt;/strong&gt;
Bucket Map Join 不支持自动转换，啊！原来是 hive 团队在 hive2.x 已经放弃维护 MR 计算引擎，建议使用 spark 等计算引擎（看到这乐死我了 tmd 白学了）。
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-14.png&#34;
	width=&#34;2160&#34;
	height=&#34;190&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-14_hu_aa3268172124e9c2.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-14_hu_ef09d34419541475.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;1136&#34;
		data-flex-basis=&#34;2728px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;参数：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&amp;ndash;关闭 cbo 优化，cbo 会导致 hint 信息被忽略&lt;/p&gt;
&lt;p&gt;set hive.cbo.enable=false;&lt;/p&gt;
&lt;p&gt;&amp;ndash;map join hint 默认会被忽略(因为已经过时)，需将如下参数设置为 false&lt;/p&gt;
&lt;p&gt;set hive.ignore.mapjoin.hint=false;&lt;/p&gt;
&lt;p&gt;&amp;ndash;启用 bucket map join 优化功能&lt;/p&gt;
&lt;p&gt;set hive.optimize.bucketmapjoin = true;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;优化案例-1&#34;&gt;&lt;a href=&#34;#%e4%bc%98%e5%8c%96%e6%a1%88%e4%be%8b-1&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;strong&gt;优化案例&lt;/strong&gt;
&lt;/h4&gt;&lt;p&gt;hive (default)&amp;gt; select _ from( select _ from order_detail where dt=&amp;lsquo;2020-06-14&amp;rsquo;) od&lt;/p&gt;
&lt;p&gt;join( select * from payment_detail where dt=&amp;lsquo;2020-06-14&amp;rsquo;) pd on od.id=pd.order_detail_id;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;优化前&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;上述 SQL 语句共有两张表一次 join 操作，故优化前的执行计划应包含一个 Common Join 任务，通过一个 MapReduce Job 实现。执行计划如下图所示：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-15.png&#34;
	width=&#34;556&#34;
	height=&#34;1002&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-15_hu_d6b5c402d156a695.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-15_hu_3ccb68d6dbe1bffb.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;55&#34;
		data-flex-basis=&#34;133px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;优化思路&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;经分析，参与 join 的两张表，数据量如下。
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-16.png&#34;
	width=&#34;1467&#34;
	height=&#34;301&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-16_hu_86b016ba9c62bbb1.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-16_hu_b55ec376440037ac.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;487&#34;
		data-flex-basis=&#34;1169px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;两张表都相对较大，若采用普通的 Map Join 算法，则 Map 端需要较多的内存来缓存数据，可以选择为 Map 段分配更多的内存，来保证任务运行成功。但是，Map 端的内存不可能无上限的分配，所以当参与 Join 的表数据量均过大时，可以考虑采用 Bucket Map Join 算法。&lt;/p&gt;
&lt;p&gt;创建两个分桶表，order_detail 建议分 16 个 bucket，payment_detail 建议分 8 个 bucket,注意分桶个数的倍数关系以及分桶字段。然后向其中导入数据。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;设置优化参数：&lt;/p&gt;
&lt;p&gt;&amp;ndash;关闭 cbo 优化，cbo 会导致 hint 信息被忽略，需将如下参数修改为 false&lt;/p&gt;
&lt;p&gt;set hive.cbo.enable=false;&lt;/p&gt;
&lt;p&gt;&amp;ndash;map join hint 默认会被忽略(因为已经过时)，需将如下参数修改为 false&lt;/p&gt;
&lt;p&gt;set hive.ignore.mapjoin.hint=false;&lt;/p&gt;
&lt;p&gt;&amp;ndash;启用 bucket map join 优化功能,默认不启用，需将如下参数修改为 true&lt;/p&gt;
&lt;p&gt;set hive.optimize.bucketmapjoin = true;&lt;/p&gt;
&lt;p&gt;重写 SQL 语句：&lt;/p&gt;
&lt;p&gt;hive (default)&amp;gt;&lt;/p&gt;
&lt;p&gt;select /_+ mapjoin(pd) _/ * from order_detail_bucketed od&lt;/p&gt;
&lt;p&gt;join payment_detail_bucketed pd on od.id = pd.order_detail_id;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;执行结果如下：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-17.png&#34;
	width=&#34;256&#34;
	height=&#34;1015&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-17_hu_2ff263283659683b.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-17_hu_557c941ca036804f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;25&#34;
		data-flex-basis=&#34;60px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;使用&lt;/p&gt;
&lt;p&gt;hive (default)&amp;gt;&lt;/p&gt;
&lt;p&gt;explain extended select /_+ mapjoin(pd) _/ *&lt;/p&gt;
&lt;p&gt;from order_detail_bucketed od&lt;/p&gt;
&lt;p&gt;join payment_detail_bucketed pd on od.id = pd.order_detail_id;查看执行计划，在 Map Join Operator 中看到 “BucketMapJoin: true”&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;sort-merge-bucket-map-joinsmb-map-join&#34;&gt;&lt;a href=&#34;#sort-merge-bucket-map-joinsmb-map-join&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Sort Merge Bucket Map Join(SMB map join)
&lt;/h3&gt;&lt;h4 id=&#34;原理-3&#34;&gt;&lt;a href=&#34;#%e5%8e%9f%e7%90%86-3&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;原理
&lt;/h4&gt;&lt;p&gt;SMB Map Join 基于 Bucket Map Join。SMB Map Join 要求，参与 join 的表均为分桶表，且需保证分桶内的数据是有序的，且分桶字段、排序字段和关联字段为相同字段，且其中一张表的分桶数量是另外一张表分桶数量的整数倍。&lt;/p&gt;
&lt;p&gt;SMB Map Join 同 Bucket Join 一样，同样是利用两表各分桶之间的关联关系，在分桶之间进行 join 操作，不同的是，分桶之间的 join 操作的实现原理。Bucket Map Join，两个分桶之间的 join 实现原理为 Hash Join 算法；而 SMB Map Join，两个分桶之间的 join 实现原理为 Sort Merge Join 算法。&lt;/p&gt;
&lt;p&gt;Hash Join 和 Sort Merge Join 均为关系型数据库中常见的 Join 实现算法。Hash Join 的原理相对简单，就是对参与 join 的一张表构建 hash table，然后扫描另外一张表，然后进行逐行匹配。Sort Merge Join 需要在两张按照关联字段排好序的表中进行，其原理如图所示：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-18.png&#34;
	width=&#34;1234&#34;
	height=&#34;709&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-18_hu_cd814555b30c2367.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-18_hu_7676e8dcb67afaab.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;174&#34;
		data-flex-basis=&#34;417px&#34;
	
&gt;
Hive 中的 SMB Map Join 就是对两个分桶的数据按照上述思路进行 Join 操作。可以看出，SMB Map Join 与 Bucket Map Join 相比，在进行 Join 操作时，Map 端是无需对整个 Bucket 构建 hash table，也无需在 Map 端缓存整个 Bucket 数据的，每个 Mapper 只需按顺序逐个 key 读取两个分桶的数据进行 join 即可。&lt;/p&gt;
&lt;h4 id=&#34;优化-2&#34;&gt;&lt;a href=&#34;#%e4%bc%98%e5%8c%96-2&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;优化
&lt;/h4&gt;&lt;p&gt;Sort Merge Bucket Map Join 有两种触发方式，包括 Hint 提示和自动转换。Hint 提示已过时，不推荐使用。下面是自动转换的相关参数：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ndash;启动 Sort Merge Bucket Map Join 优化&lt;/p&gt;
&lt;p&gt;set hive.optimize.bucketmapjoin.sortedmerge=true;&lt;/p&gt;
&lt;p&gt;&amp;ndash;使用自动转换 SMB Join&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.sortmerge.join=true;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;和 bucket map join 一样，创建分桶表并导入数据 ，设置参数，运行 HQL，结果如下：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-19.png&#34;
	width=&#34;317&#34;
	height=&#34;654&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-19_hu_9e5a0b4b5771431a.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-19_hu_a812c6d9b6d4878f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;48&#34;
		data-flex-basis=&#34;116px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;数据倾斜优化&#34;&gt;&lt;a href=&#34;#%e6%95%b0%e6%8d%ae%e5%80%be%e6%96%9c%e4%bc%98%e5%8c%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;数据倾斜优化
&lt;/h2&gt;&lt;p&gt;数据倾斜问题，通常是指参与计算的数据分布不均，即某个 key 或者某些 key 的数据量远超其他 key，导致在 shuffle 阶段，大量相同 key 的数据被发往同一个 Reduce，进而导致该 Reduce 所需的时间远超其他 Reduce，成为整个任务的瓶颈。&lt;/p&gt;
&lt;p&gt;Hive 中的数据倾斜常出现在分组聚合和 join 操作的场景中，下面分别介绍在上述两种场景下的优化思路。&lt;/p&gt;
&lt;h3 id=&#34;分组聚合导致的数据倾斜&#34;&gt;&lt;a href=&#34;#%e5%88%86%e7%bb%84%e8%81%9a%e5%90%88%e5%af%bc%e8%87%b4%e7%9a%84%e6%95%b0%e6%8d%ae%e5%80%be%e6%96%9c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;分组聚合导致的数据倾斜
&lt;/h3&gt;&lt;p&gt;Hive 中未经优化的分组聚合，是通过一个 MapReduce Job 实现的。Map 端负责读取数据，并按照分组字段分区，通过 Shuffle，将数据发往 Reduce 端，各组数据在 Reduce 端完成最终的聚合运算。&lt;/p&gt;
&lt;p&gt;如果 group by 分组字段的值分布不均，就可能导致大量相同的 key 进入同一 Reduce，从而导致数据倾斜问题。&lt;/p&gt;
&lt;p&gt;由分组聚合导致的数据倾斜问题，有以下两种解决思路：&lt;/p&gt;
&lt;h4 id=&#34;map-side-聚合&#34;&gt;&lt;a href=&#34;#map-side-%e8%81%9a%e5%90%88&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Map-Side 聚合
&lt;/h4&gt;&lt;p&gt;前文提过，此处略过&lt;/p&gt;
&lt;h4 id=&#34;skew-groupby-优化&#34;&gt;&lt;a href=&#34;#skew-groupby-%e4%bc%98%e5%8c%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Skew-GroupBy 优化
&lt;/h4&gt;&lt;p&gt;原理是启动两个 MR 任务，第一个 MR 按照随机数分区，将数据分散发送到 Reduce，完成部分聚合，第二个 MR 把打散的数据按照分组字段分区，完成最终聚合。&lt;/p&gt;
&lt;h5 id=&#34;优化前&#34;&gt;&lt;a href=&#34;#%e4%bc%98%e5%8c%96%e5%89%8d&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;优化前
&lt;/h5&gt;&lt;p&gt;该表数据中的 province_id 字段是存在倾斜的，若不经过优化，通过观察任务的执行过程，是能够看出数据倾斜现象的。
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-20.png&#34;
	width=&#34;869&#34;
	height=&#34;245&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-20_hu_4c7b5ee5d955b18c.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-20_hu_4bd4157092ae801d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;354&#34;
		data-flex-basis=&#34;851px&#34;
	
&gt;&lt;/p&gt;
&lt;h5 id=&#34;优化后&#34;&gt;&lt;a href=&#34;#%e4%bc%98%e5%8c%96%e5%90%8e&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;优化后
&lt;/h5&gt;&lt;blockquote&gt;
&lt;p&gt;&amp;ndash;启用 skew-groupby&lt;/p&gt;
&lt;p&gt;set hive.groupby.skewindata=true;&lt;/p&gt;
&lt;p&gt;&amp;ndash;关闭 map-side 聚合（map side 聚合默认是开启的）&lt;/p&gt;
&lt;p&gt;set hive.map.aggr=false;&lt;/p&gt;
&lt;p&gt;开启 Skew-GroupBy 优化后，可以很明显看到该 sql 执行在 yarn 上启动了两个 mr 任务，第一个 mr 打散数据，第二个 mr 把打散后的数据进行分组聚合。
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-21.png&#34;
	width=&#34;869&#34;
	height=&#34;204&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-21_hu_a9f85e157a440921.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-21_hu_41134c8a7aa5bf1f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;425&#34;
		data-flex-basis=&#34;1022px&#34;
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;join-导致的数据倾斜&#34;&gt;&lt;a href=&#34;#join-%e5%af%bc%e8%87%b4%e7%9a%84%e6%95%b0%e6%8d%ae%e5%80%be%e6%96%9c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Join 导致的数据倾斜
&lt;/h3&gt;&lt;p&gt;未经优化的 join 操作，默认是使用 common join 算法，也就是通过一个 MapReduce Job 完成计算。Map 端负责读取 join 操作所需表的数据，并按照关联字段进行分区，通过 Shuffle，将其发送到 Reduce 端，相同 key 的数据在 Reduce 端完成最终的 Join 操作。&lt;/p&gt;
&lt;p&gt;如果关联字段的值分布不均，就可能导致大量相同的 key 进入同一 Reduce，从而导致数据倾斜问题。由 join 导致的数据倾斜问题，有如下三种解决方案：&lt;/p&gt;
&lt;h4 id=&#34;map-join-1&#34;&gt;&lt;a href=&#34;#map-join-1&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;map join
&lt;/h4&gt;&lt;p&gt;略过&lt;/p&gt;
&lt;h4 id=&#34;skew-join&#34;&gt;&lt;a href=&#34;#skew-join&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;skew join
&lt;/h4&gt;&lt;p&gt;原理是为倾斜的大 key 单独启动一个 map join 任务进行计算，其余 key 进行正常的 common join。原理图如下：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-22.png&#34;
	width=&#34;865&#34;
	height=&#34;453&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-22_hu_56fdabed3e095d99.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-22_hu_ce6b8a273fee43e9.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;190&#34;
		data-flex-basis=&#34;458px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ndash;启用 skew join 优化&lt;/p&gt;
&lt;p&gt;set hive.optimize.skewjoin=true;&lt;/p&gt;
&lt;p&gt;&amp;ndash;触发 skew join 的阈值，若某个 key 的行数超过该参数值，则触发&lt;/p&gt;
&lt;p&gt;set hive.skewjoin.key=100000;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;这种方案对参与 join 的源表大小没有要求，但是对两表中倾斜的 key 的数据量有要求，要求一张表中的倾斜 key 的数据量比较小（方便走 map join）。&lt;/p&gt;
&lt;h2 id=&#34;任务并行度优化&#34;&gt;&lt;a href=&#34;#%e4%bb%bb%e5%8a%a1%e5%b9%b6%e8%a1%8c%e5%ba%a6%e4%bc%98%e5%8c%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;任务并行度优化
&lt;/h2&gt;&lt;p&gt;Hive 的计算任务由 MapReduce 完成，故并行度的调整需要分为 Map 端和 Reduce 端。&lt;/p&gt;
&lt;h3 id=&#34;map-端并行度&#34;&gt;&lt;a href=&#34;#map-%e7%ab%af%e5%b9%b6%e8%a1%8c%e5%ba%a6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Map 端并行度
&lt;/h3&gt;&lt;p&gt;Map 端的并行度，也就是 Map 的个数。是由输入文件的切片数决定的。一般情况下，Map 端的并行度无需手动调整。&lt;/p&gt;
&lt;p&gt;以下特殊情况可考虑调整 map 端并行度：
&lt;strong&gt;1）查询的表中存在大量小文件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;按照 Hadoop 默认的切片策略，一个小文件会单独启动一个 map task 负责计算。若查询的表中存在大量小文件，则会启动大量 map task，造成计算资源的浪费。这种情况下，可以使用 Hive 提供的 CombineHiveInputFormat，多个小文件合并为一个切片，从而控制 map task 个数。相关参数如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;2）map 端有复杂的查询逻辑&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;若 SQL 语句中有正则替换、json 解析等复杂耗时的查询逻辑时，map 端的计算会相对慢一些。若想加快计算速度，在计算资源充足的情况下，可考虑增大 map 端的并行度，令 map task 多一些，每个 map task 计算的数据少一些。相关参数如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ndash;一个切片的最大值&lt;/p&gt;
&lt;p&gt;set mapreduce.input.fileinputformat.split.maxsize=256000000;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;reduce-端并行度&#34;&gt;&lt;a href=&#34;#reduce-%e7%ab%af%e5%b9%b6%e8%a1%8c%e5%ba%a6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Reduce 端并行度
&lt;/h3&gt;&lt;p&gt;Reduce 端的并行度，可由用户自己指定，也可由 Hive 自行根据该 MR Job 输入的文件大小进行估算。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Reduce 端的并行度的相关参数如下：&lt;/p&gt;
&lt;p&gt;&amp;ndash;指定 Reduce 端并行度，默认值为-1，表示用户未指定&lt;/p&gt;
&lt;p&gt;set mapreduce.job.reduces;&lt;/p&gt;
&lt;p&gt;&amp;ndash;Reduce 端并行度最大值&lt;/p&gt;
&lt;p&gt;set hive.exec.reducers.max;&lt;/p&gt;
&lt;p&gt;&amp;ndash;单个 Reduce Task 计算的数据量，用于估算 Reduce 并行度&lt;/p&gt;
&lt;p&gt;set hive.exec.reducers.bytes.per.reducer;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Reduce 端并行度的确定逻辑如下：&lt;/p&gt;
&lt;p&gt;若指定参数 mapreduce.job.reduces 的值为一个非负整数，则 Reduce 并行度为指定值。否则，Hive 自行估算 Reduce 并行度，估算逻辑如下：&lt;/p&gt;
&lt;p&gt;假设 Job 输入的文件大小为 totalInputBytes&lt;/p&gt;
&lt;p&gt;参数 hive.exec.reducers.bytes.per.reducer 的值为 bytesPerReducer。&lt;/p&gt;
&lt;p&gt;参数 hive.exec.reducers.max 的值为 maxReducers。&lt;/p&gt;
&lt;p&gt;则 Reduce 端的并行度为：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-23.png&#34;
	width=&#34;638&#34;
	height=&#34;98&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-23_hu_21010bf6e8750fb7.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-23_hu_4938c6195bbe484e.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;651&#34;
		data-flex-basis=&#34;1562px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;根据上述描述，可以看出，Hive 自行估算 Reduce 并行度时，是以整个 MR Job 输入的文件大小作为依据的。因此，在某些情况下其估计的并行度很可能并不准确，此时就需要用户根据实际情况来指定 Reduce 并行度了。&lt;/p&gt;
&lt;p&gt;在默认情况下，是会进行 map-side 聚合的，也就是 Reduce 端接收的数据，实际上是 map 端完成聚合之后的结果。观察任务的执行过程，会发现，每个 map 端输出的数据只有 34 条记录，共有 5 个 map task。
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-24.png&#34;
	width=&#34;869&#34;
	height=&#34;374&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-24_hu_f3c3a8909f90ec92.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-24_hu_8d200be734c58711.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;232&#34;
		data-flex-basis=&#34;557px&#34;
	
&gt;
也就是说 Reduce 端实际只会接收 170（34*5）条记录，故理论上 Reduce 端并行度设置为 1 就足够了。这种情况下，用户可通过以下参数，自行设置 Reduce 端并行度为 1，这样把 5 个文件合并为只输出 1 个文件。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ndash;指定 Reduce 端并行度，默认值为-1，表示用户未指定&lt;/p&gt;
&lt;p&gt;set mapreduce.job.reduces=1;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;小文件合并优化&#34;&gt;&lt;a href=&#34;#%e5%b0%8f%e6%96%87%e4%bb%b6%e5%90%88%e5%b9%b6%e4%bc%98%e5%8c%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;小文件合并优化
&lt;/h2&gt;&lt;p&gt;Map 端输入的小文件合并，和 Reduce 端输出的小文件合并。&lt;/p&gt;
&lt;h3 id=&#34;合并-map-端输入的小文件&#34;&gt;&lt;a href=&#34;#%e5%90%88%e5%b9%b6-map-%e7%ab%af%e8%be%93%e5%85%a5%e7%9a%84%e5%b0%8f%e6%96%87%e4%bb%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;合并 Map 端输入的小文件
&lt;/h3&gt;&lt;p&gt;将多个小文件划分到一个切片中，进而由一个 Map Task 去处理。目的是防止为单个小文件启动一个 Map Task，浪费计算资源。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;相关参数为：&lt;/p&gt;
&lt;p&gt;&amp;ndash;可将多个小文件切片，合并为一个切片，进而由一个 map 任务处理（默认）
set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;合并-reduce-端输出的小文件&#34;&gt;&lt;a href=&#34;#%e5%90%88%e5%b9%b6-reduce-%e7%ab%af%e8%be%93%e5%87%ba%e7%9a%84%e5%b0%8f%e6%96%87%e4%bb%b6&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;合并 Reduce 端输出的小文件
&lt;/h3&gt;&lt;p&gt;将多个小文件合并成大文件。目的是减少 HDFS 小文件数量。其原理是根据计算任务输出文件的平均大小进行判断，若符合条件，则单独启动 1 个额外的任务进行合并。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;相关参数为：&lt;/p&gt;
&lt;p&gt;&amp;ndash;开启合并 map only 任务输出的小文件，默认 false&lt;/p&gt;
&lt;p&gt;set hive.merge.mapfiles=true;&lt;/p&gt;
&lt;p&gt;&amp;ndash;开启合并 map reduce 任务输出的小文件，默认 false&lt;/p&gt;
&lt;p&gt;set hive.merge.mapredfiles=true;&lt;/p&gt;
&lt;p&gt;&amp;ndash;合并后的文件大小&lt;/p&gt;
&lt;p&gt;set hive.merge.size.per.task=256000000;&lt;/p&gt;
&lt;p&gt;&amp;ndash;触发小文件合并任务的阈值，若某计算任务输出的文件平均大小低于该值，则触发合并&lt;/p&gt;
&lt;p&gt;set hive.merge.smallfiles.avgsize=16000000;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;若 reduce 端设置并行度为 5，则输出 5 个文件。下图为输出文件，可以看出，5 个均为小文件：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-25.png&#34;
	width=&#34;869&#34;
	height=&#34;379&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-25_hu_87c8501899639239.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-25_hu_19398f78240c4efd.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;229&#34;
		data-flex-basis=&#34;550px&#34;
	
&gt;
要避免 5 个小文件产生，可以设置 reduce 端并行度为 1，有几个 reduce 并行就有几个文件产生，保证其输出结果只有一个文件或启用 hive 合并小文件优化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;启用 Hive 合并小文件优化&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;设置以下参数：&lt;/p&gt;
&lt;p&gt;&amp;ndash;开启合并 map reduce 任务输出的小文件&lt;/p&gt;
&lt;p&gt;set hive.merge.mapredfiles=true;&lt;/p&gt;
&lt;p&gt;&amp;ndash;合并后的文件大小&lt;/p&gt;
&lt;p&gt;set hive.merge.size.per.task=256000000;&lt;/p&gt;
&lt;p&gt;&amp;ndash;触发小文件合并任务的阈值，若某计算任务输出的文件平均大小低于该值，则触发合并&lt;/p&gt;
&lt;p&gt;set hive.merge.smallfiles.avgsize=16000000;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;这样输出文件就合并为一个了
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-26.png&#34;
	width=&#34;869&#34;
	height=&#34;303&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-26_hu_7e0b9aa0a00b8312.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-26_hu_3d9e91230e8317b1.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;286&#34;
		data-flex-basis=&#34;688px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;其他优化&#34;&gt;&lt;a href=&#34;#%e5%85%b6%e4%bb%96%e4%bc%98%e5%8c%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;其他优化
&lt;/h2&gt;&lt;h3 id=&#34;cbo-优化&#34;&gt;&lt;a href=&#34;#cbo-%e4%bc%98%e5%8c%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;CBO 优化
&lt;/h3&gt;&lt;p&gt;CBO 是指 Cost based Optimizer，即基于计算成本的优化。&lt;/p&gt;
&lt;p&gt;在 Hive 中，计算成本模型考虑到了：数据的行数、CPU、本地 IO、HDFS IO、网络 IO 等方面。Hive 会计算同一 SQL 语句的不同执行计划的计算成本，并选出成本最低的执行计划。目前 CBO 在 hive 的 MR 引擎下主要用于 join 的优化，例如多表 join 的 join 顺序。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;相关参数为：&lt;/p&gt;
&lt;p&gt;&amp;ndash;是否启用 cbo 优化&lt;/p&gt;
&lt;p&gt;set hive.cbo.enable=true;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;1）示例 HQL&lt;/p&gt;
&lt;p&gt;hive (default)&amp;gt; select * from order_detail od&lt;/p&gt;
&lt;p&gt;join product_info product on od.product_id=product.id&lt;/p&gt;
&lt;p&gt;join province_info province on od.province_id=province.id;&lt;/p&gt;
&lt;p&gt;2）关闭 CBO 优化&lt;/p&gt;
&lt;p&gt;&amp;ndash;关闭 cbo 优化&lt;/p&gt;
&lt;p&gt;set hive.cbo.enable=false;&lt;/p&gt;
&lt;p&gt;&amp;ndash;为了测试效果更加直观，关闭 map join 自动转换&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join=false;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;根据执行计划，可以看出，三张表的 join 顺序如下：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-27.png&#34;
	width=&#34;660&#34;
	height=&#34;294&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-27_hu_40e2f0ee95980f6.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-27_hu_1e3b627e737906da.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;224&#34;
		data-flex-basis=&#34;538px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;3）开启 CBO 优化&lt;/p&gt;
&lt;p&gt;&amp;ndash;开启 cbo 优化&lt;/p&gt;
&lt;p&gt;set hive.cbo.enable=true;&lt;/p&gt;
&lt;p&gt;&amp;ndash;为了测试效果更加直观，关闭 map join 自动转换&lt;/p&gt;
&lt;p&gt;set hive.auto.convert.join=false;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;根据执行计划，可以看出，三张表的 join 顺序如下：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-28.png&#34;
	width=&#34;669&#34;
	height=&#34;298&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-28_hu_7ceeab9ab8aa26e.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-28_hu_45dd3c1250222a77.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;224&#34;
		data-flex-basis=&#34;538px&#34;
	
&gt;
CBO 优化对于执行计划中 join 顺序是有影响的，其之所以会将 province_info 的 join 顺序提前，是因为 province info 的数据量较小，将其提前，会有更大的概率使得中间结果的数据量变小，从而使整个计算任务的数据量减小，也就是使计算成本变小。&lt;/p&gt;
&lt;h3 id=&#34;谓词下推&#34;&gt;&lt;a href=&#34;#%e8%b0%93%e8%af%8d%e4%b8%8b%e6%8e%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;谓词下推
&lt;/h3&gt;&lt;p&gt;谓词下推（predicate pushdown）是指，尽量将过滤操作前移，以减少后续计算步骤的数据量。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;相关参数为：&lt;/p&gt;
&lt;p&gt;&amp;ndash;是否启动谓词下推（predicate pushdown）优化&lt;/p&gt;
&lt;p&gt;set hive.optimize.ppd = true;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;需要注意的是：CBO 优化也会完成一部分的谓词下推优化工作，因为在执行计划中，谓词越靠前，整个计划的计算成本就会越低。
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-29.png&#34;
	width=&#34;684&#34;
	height=&#34;568&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-29_hu_e70a14f380e3cc42.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-29_hu_87d64db6b104c96b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;120&#34;
		data-flex-basis=&#34;289px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;矢量化查询&#34;&gt;&lt;a href=&#34;#%e7%9f%a2%e9%87%8f%e5%8c%96%e6%9f%a5%e8%af%a2&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;矢量化查询
&lt;/h3&gt;&lt;p&gt;Hive 的矢量化查询优化，依赖于 CPU 的矢量化计算，CPU 的矢量化计算的基本原理如下图：
&lt;img src=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-30.png&#34;
	width=&#34;960&#34;
	height=&#34;540&#34;
	srcset=&#34;/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-30_hu_e362fffa2298c231.png 480w, /zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/image-30_hu_aeb22a57936a7ac0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;相关参数如下：&lt;/p&gt;
&lt;p&gt;set hive.vectorized.execution.enabled=true;&lt;/p&gt;
&lt;p&gt;若执行计划中，出现“Execution mode: vectorized”字样，即表明使用了矢量化计算。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;fetch-抓取&#34;&gt;&lt;a href=&#34;#fetch-%e6%8a%93%e5%8f%96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Fetch 抓取
&lt;/h3&gt;&lt;p&gt;Fetch 抓取是指，Hive 中对某些情况的查询可以不必使用 MapReduce 计算。例如：select * from emp;在这种情况下，Hive 可以简单地读取 emp 对应的存储目录下的文件，然后输出查询结果到控制台。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;相关参数如下：&lt;/p&gt;
&lt;p&gt;&amp;ndash;是否在特定场景转换为 fetch 任务&lt;/p&gt;
&lt;p&gt;&amp;ndash;设置为 none 表示不转换&lt;/p&gt;
&lt;p&gt;&amp;ndash;设置为 minimal 表示支持 select *，分区字段过滤，Limit 等&lt;/p&gt;
&lt;p&gt;&amp;ndash;设置为 more 表示支持 select 任意字段,包括函数，过滤，和 limit 等&lt;/p&gt;
&lt;p&gt;set hive.fetch.task.conversion=more;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;本地模式&#34;&gt;&lt;a href=&#34;#%e6%9c%ac%e5%9c%b0%e6%a8%a1%e5%bc%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;本地模式
&lt;/h3&gt;&lt;p&gt;大多数的 Hadoop Job 是需要 Hadoop 提供的完整的可扩展性来处理大数据集的。不过，有时 Hive 的输入数据量是非常小的。在这种情况下，为查询触发执行任务消耗的时间可能会比实际 job 的执行时间要多的多。对于大多数这种情况，Hive 可以通过本地模式在单台机器上处理所有的任务，不必提交到 Yarn。对于小数据集，执行时间可以明显被缩短。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;相关参数如下：&lt;/p&gt;
&lt;p&gt;&amp;ndash;开启自动转换为本地模式&lt;/p&gt;
&lt;p&gt;set hive.exec.mode.local.auto=true;&lt;/p&gt;
&lt;p&gt;&amp;ndash;设置 local MapReduce 的最大输入数据量，当输入数据量小于这个值时采用 local MapReduce 的方式，默认为 134217728，即 128M&lt;/p&gt;
&lt;p&gt;set hive.exec.mode.local.auto.inputbytes.max=50000000;&lt;/p&gt;
&lt;p&gt;&amp;ndash;设置 local MapReduce 的最大输入文件个数，当输入文件个数小于这个值时采用 local MapReduce 的方式，默认为 4&lt;/p&gt;
&lt;p&gt;set hive.exec.mode.local.auto.input.files.max=10;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;并行执行&#34;&gt;&lt;a href=&#34;#%e5%b9%b6%e8%a1%8c%e6%89%a7%e8%a1%8c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;并行执行
&lt;/h3&gt;&lt;p&gt;Hive 会将一个 SQL 语句转化成一个或者多个 Stage，每个 Stage 对应一个 MR Job。默认情况下，Hive 同时只会执行一个 Stage。但是某 SQL 语句可能会包含多个 Stage，但这多个 Stage 可能并非完全互相依赖，也就是说有些 Stage 是可以并行执行的。此处提到的并行执行就是指这些 Stage 的并行执行。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;相关参数如下：&lt;/p&gt;
&lt;p&gt;&amp;ndash;启用并行执行优化&lt;/p&gt;
&lt;p&gt;set hive.exec.parallel=true;&lt;/p&gt;
&lt;p&gt;&amp;ndash;同一个 sql 允许最大并行度，默认为 8&lt;/p&gt;
&lt;p&gt;set hive.exec.parallel.thread.number=8;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;严格模式&#34;&gt;&lt;a href=&#34;#%e4%b8%a5%e6%a0%bc%e6%a8%a1%e5%bc%8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;严格模式
&lt;/h3&gt;&lt;p&gt;Hive 可以通过设置某些参数防止危险操作：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1）分区表不使用分区过滤&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;将 hive.strict.checks.no.partition.filter 设置为 true 时，对于分区表，除非 where 语句中含有分区字段过滤条件来限制范围，否则不允许执行。换句话说，就是用户不允许扫描所有分区。进行这个限制的原因是，通常分区表都拥有非常大的数据集，而且数据增加迅速。没有进行分区限制的查询可能会消耗令人不可接受的巨大资源来处理这个表。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2）使用 order by 没有 limit 过滤&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;将 hive.strict.checks.orderby.no.limit 设置为 true 时，对于使用了 order by 语句的查询，要求必须使用 limit 语句。因为 order by 为了执行排序过程会将所有的结果数据分发到同一个 Reduce 中进行处理，强制要求用户增加这个 limit 语句可以防止 Reduce 额外执行很长一段时间（开启了 limit 可以在数据进入到 Reduce 之前就减少一部分数据）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3）笛卡尔积&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;将 hive.strict.checks.cartesian.product 设置为 true 时，会限制笛卡尔积的查询。对关系型数据库非常了解的用户可能期望在执行 JOIN 查询的时候不使用 ON 语句而是使用 where 语句，这样关系数据库的执行优化器就可以高效地将 WHERE 语句转化成那个 ON 语句。不幸的是，Hive 并不会执行这种优化，因此，如果表足够大，那么这个查询就会出现不可控的情况。&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
