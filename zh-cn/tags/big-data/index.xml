<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Big Data on 青秋博客</title>
        <link>/zh-cn/tags/big-data/</link>
        <description>Recent content in Big Data on 青秋博客</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>青秋博客</copyright>
        <lastBuildDate>Sun, 05 May 2024 17:42:50 +0000</lastBuildDate><atom:link href="/zh-cn/tags/big-data/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Kafka入门到入土——万字详解，图文并茂</title>
        <link>/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/</link>
        <pubDate>Sun, 05 May 2024 17:42:50 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/05/kafka%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F%E4%B8%87%E5%AD%97%E8%AF%A6%E8%A7%A3%E5%9B%BE%E6%96%87%E5%B9%B6%E8%8C%82/</guid>
        <description>&lt;p&gt;&lt;strong&gt;目录&lt;/strong&gt;{#main-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%EF%BC%88MQ%EF%BC%89&#34; &gt;消息队列（MQ）&lt;/a&gt;{#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%EF%BC%88MQ%EF%BC%89-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%80%E8%88%AC%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF&#34; &gt;消息队列一般应用场景&lt;/a&gt;{#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%80%E8%88%AC%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#JMS&#34; &gt;JMS&lt;/a&gt;{#JMS-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%C2%A0JMS%E6%A8%A1%E5%9E%8B&#34; &gt;JMS模型&lt;/a&gt;{#%C2%A0JMS%E6%A8%A1%E5%9E%8B-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E7%82%B9%E5%AF%B9%E7%82%B9%E6%A8%A1%E5%9E%8B%EF%BC%88peer%20to%20peer%EF%BC%89&#34; &gt;点对点模型（peer to peer）&lt;/a&gt;{#%E7%82%B9%E5%AF%B9%E7%82%B9%E6%A8%A1%E5%9E%8B%EF%BC%88peer%20to%20peer%EF%BC%89-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%A8%A1%E5%9E%8B&#34; &gt;发布订阅模型&lt;/a&gt;{#%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%A8%A1%E5%9E%8B-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Kafka%E6%9E%B6%E6%9E%84&#34; &gt;Kafka架构&lt;/a&gt;{#Kafka%E6%9E%B6%E6%9E%84-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Broker&#34; &gt;Broker&lt;/a&gt;{#Broker-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Controller%E9%80%89%E4%B8%BE&#34; &gt;Controller选举&lt;/a&gt;{#Controller%E9%80%89%E4%B8%BE-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Broker%E4%B8%8A%E4%B8%8B%E7%BA%BF%C2%A0&#34; &gt;Broker上下线&lt;/a&gt;{#Broker%E4%B8%8A%E4%B8%8B%E7%BA%BF%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Broker%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B&#34; &gt;Broker工作流程&lt;/a&gt;{#Broker%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Producer&#34; &gt;Producer&lt;/a&gt;{#Producer-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Consumer&#34; &gt;Consumer&lt;/a&gt;{#Consumer-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Consumer%20Group&#34; &gt;Consumer Group&lt;/a&gt;{#Consumer%20Group-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Topic&#34; &gt;Topic&lt;/a&gt;{#Topic-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Partition%E5%88%86%E5%8C%BA&#34; &gt;Partition分区&lt;/a&gt;{#Partition%E5%88%86%E5%8C%BA-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%88%86%E5%8C%BA%E5%A5%BD%E5%A4%84%C2%A0&#34; &gt;分区好处&lt;/a&gt;{#%E5%88%86%E5%8C%BA%E5%A5%BD%E5%A4%84%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%C2%A0%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E7%9A%84%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5&#34; &gt;生产者发送消息的分区策略&lt;/a&gt;{#%C2%A0%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E7%9A%84%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8Segment&#34; &gt;文件存储Segment&lt;/a&gt;{#%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8Segment-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%88%86%E5%8C%BA%E7%9A%84%E5%89%AF%E6%9C%AC&#34; &gt;分区的副本&lt;/a&gt;{#%E5%88%86%E5%8C%BA%E7%9A%84%E5%89%AF%E6%9C%AC-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Why%E5%88%86%E5%8C%BA%E5%89%AF%E6%9C%AC&#34; &gt;Why分区副本&lt;/a&gt;{#Why%E5%88%86%E5%8C%BA%E5%89%AF%E6%9C%AC-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%89%8B%E5%8A%A8%E8%B0%83%E6%95%B4%E5%88%86%E5%8C%BA%E5%89%AF%E6%9C%AC%E5%AD%98%E5%82%A8%E2%80%8B%E7%BC%96%E8%BE%91&#34; &gt;手动调整分区副本存储​编辑&lt;/a&gt;{#%E6%89%8B%E5%8A%A8%E8%B0%83%E6%95%B4%E5%88%86%E5%8C%BA%E5%89%AF%E6%9C%AC%E5%AD%98%E5%82%A8%E2%80%8B%E7%BC%96%E8%BE%91-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%89%AF%E6%9C%ACLeader%E5%88%86%E5%8C%BA%E8%87%AA%E5%8A%A8%E5%B9%B3%E8%A1%A1&#34; &gt;副本Leader分区自动平衡&lt;/a&gt;{#%E5%89%AF%E6%9C%ACLeader%E5%88%86%E5%8C%BA%E8%87%AA%E5%8A%A8%E5%B9%B3%E8%A1%A1-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%A2%9E%E5%8A%A0%E5%89%AF%E6%9C%AC%E6%95%B0%E9%87%8F%C2%A0&#34; &gt;增加副本数量&lt;/a&gt;{#%E5%A2%9E%E5%8A%A0%E5%89%AF%E6%9C%AC%E6%95%B0%E9%87%8F%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%89%AF%E6%9C%ACLeader%E9%80%89%E4%B8%BE&#34; &gt;副本Leader选举&lt;/a&gt;{#%E5%89%AF%E6%9C%ACLeader%E9%80%89%E4%B8%BE-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%89%AF%E6%9C%ACLeader%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D&#34; &gt;副本Leader故障恢复&lt;/a&gt;{#%E5%89%AF%E6%9C%ACLeader%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%89%AF%E6%9C%ACFollower%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D%C2%A0&#34; &gt;副本Follower故障恢复&lt;/a&gt;{#%E5%89%AF%E6%9C%ACFollower%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%C2%A0ISR%E6%9C%BA%E5%88%B6&#34; &gt;ISR机制&lt;/a&gt;{#%C2%A0ISR%E6%9C%BA%E5%88%B6-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E4%B8%8D%E5%AE%8C%E5%85%A8%E9%A6%96%E9%A2%86%E9%80%89%E4%B8%BE&#34; &gt;不完全首领选举&lt;/a&gt;{#%E4%B8%8D%E5%AE%8C%E5%85%A8%E9%A6%96%E9%A2%86%E9%80%89%E4%B8%BE-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%9C%80%E5%B0%91%E5%90%8C%E6%AD%A5%E5%89%AF%E6%9C%AC&#34; &gt;最少同步副本&lt;/a&gt;{#%E6%9C%80%E5%B0%91%E5%90%8C%E6%AD%A5%E5%89%AF%E6%9C%AC-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%95%B0%E6%8D%AE%E8%AF%B7%E6%B1%82%C2%A0&#34; &gt;数据请求&lt;/a&gt;{#%E6%95%B0%E6%8D%AE%E8%AF%B7%E6%B1%82%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E8%AF%B7%E6%B1%82%E6%9C%BA%E5%88%B6&#34; &gt;请求机制&lt;/a&gt;{#%E8%AF%B7%E6%B1%82%E6%9C%BA%E5%88%B6-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E7%94%9F%E4%BA%A7%E8%80%85%E8%AF%A6%E8%A7%A3&#34; &gt;生产者详解&lt;/a&gt;{#%E7%94%9F%E4%BA%A7%E8%80%85%E8%AF%A6%E8%A7%A3-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E7%9A%84%E8%BF%87%E7%A8%8B&#34; &gt;生产者发送消息的过程&lt;/a&gt;{#%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E7%9A%84%E8%BF%87%E7%A8%8B-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%B6%88%E6%81%AF%E5%8F%AF%E9%9D%A0%E6%80%A7%C2%A0&#34; &gt;消息可靠性&lt;/a&gt;{#%E6%B6%88%E6%81%AF%E5%8F%AF%E9%9D%A0%E6%80%A7%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#ACK%E5%BA%94%E7%AD%94%C2%A0&#34; &gt;ACK应答&lt;/a&gt;{#ACK%E5%BA%94%E7%AD%94%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%C2%A0%E6%95%B0%E6%8D%AE%E9%87%8D%E8%AF%95&#34; &gt;数据重试&lt;/a&gt;{#%C2%A0%E6%95%B0%E6%8D%AE%E9%87%8D%E8%AF%95-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%95%B0%E6%8D%AE%E4%B9%B1%E5%BA%8F%C2%A0&#34; &gt;数据乱序&lt;/a&gt;{#%E6%95%B0%E6%8D%AE%E4%B9%B1%E5%BA%8F%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%90%8C%E6%AD%A5%E5%8F%91%E9%80%81&#34; &gt;同步发送&lt;/a&gt;{#%E5%90%8C%E6%AD%A5%E5%8F%91%E9%80%81-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%BC%82%E6%AD%A5%E5%8F%91%E9%80%81&#34; &gt;异步发送&lt;/a&gt;{#%E5%BC%82%E6%AD%A5%E5%8F%91%E9%80%81-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E7%94%9F%E4%BA%A7%E8%80%85%E6%8F%90%E9%AB%98%E5%90%9E%E5%90%90%E9%87%8F&#34; &gt;生产者提高吞吐量&lt;/a&gt;{#%E7%94%9F%E4%BA%A7%E8%80%85%E6%8F%90%E9%AB%98%E5%90%9E%E5%90%90%E9%87%8F-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95%C2%A0&#34; &gt;压缩算法&lt;/a&gt;{#%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%B6%88%E8%B4%B9%E8%80%85%E8%AF%A6%E8%A7%A3&#34; &gt;消费者详解&lt;/a&gt;{#%E6%B6%88%E8%B4%B9%E8%80%85%E8%AF%A6%E8%A7%A3-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#push%26pull&#34; &gt;push&amp;amp;pull&lt;/a&gt;{#push%26pull-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E8%B0%83%E5%BA%A6%E5%99%A8%C2%A0&#34; &gt;消费者组调度器&lt;/a&gt;{#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E8%B0%83%E5%BA%A6%E5%99%A8%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%B6%88%E8%B4%B9%E8%80%85%E5%88%86%E9%85%8D%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5%C2%A0&#34; &gt;消费者分配分区策略&lt;/a&gt;{#%E6%B6%88%E8%B4%B9%E8%80%85%E5%88%86%E9%85%8D%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%B6%88%E8%B4%B9%E8%80%85Leader%C2%A0&#34; &gt;消费者Leader&lt;/a&gt;{#%E6%B6%88%E8%B4%B9%E8%80%85Leader%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%88%86%E5%8C%BA%E5%86%8D%E5%9D%87%E8%A1%A1&#34; &gt;分区再均衡&lt;/a&gt;{#%E5%88%86%E5%8C%BA%E5%86%8D%E5%9D%87%E8%A1%A1-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E7%9B%91%E5%90%AC%E5%88%86%E5%8C%BA%E5%86%8D%E5%9D%87%E8%A1%A1%C2%A0&#34; &gt;监听分区再均衡&lt;/a&gt;{#%E7%9B%91%E5%90%AC%E5%88%86%E5%8C%BA%E5%86%8D%E5%9D%87%E8%A1%A1%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%81%8F%E7%A7%BB%E9%87%8FOffset&#34; &gt;偏移量Offset&lt;/a&gt;{#%E5%81%8F%E7%A7%BB%E9%87%8FOffset-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#LSO&#34; &gt;LSO&lt;/a&gt;{#LSO-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#LEO&#34; &gt;LEO&lt;/a&gt;{#LEO-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#HW&#34; &gt;HW&lt;/a&gt;{#HW-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%89%8B%E5%8A%A8%E6%8F%90%E4%BA%A4%E5%81%8F%E7%A7%BB%E9%87%8F&#34; &gt;手动提交偏移量&lt;/a&gt;{#%E6%89%8B%E5%8A%A8%E6%8F%90%E4%BA%A4%E5%81%8F%E7%A7%BB%E9%87%8F-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%90%8C%E6%AD%A5%E6%8F%90%E4%BA%A4&#34; &gt;同步提交&lt;/a&gt;{#%E5%90%8C%E6%AD%A5%E6%8F%90%E4%BA%A4-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%BC%82%E6%AD%A5%E6%8F%90%E4%BA%A4&#34; &gt;异步提交&lt;/a&gt;{#%E5%BC%82%E6%AD%A5%E6%8F%90%E4%BA%A4-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E8%87%AA%E5%8A%A8%E6%8F%90%E4%BA%A4%E5%81%8F%E7%A7%BB%E9%87%8F&#34; &gt;自动提交偏移量&lt;/a&gt;{#%E8%87%AA%E5%8A%A8%E6%8F%90%E4%BA%A4%E5%81%8F%E7%A7%BB%E9%87%8F-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%88%AA%E8%87%B3%20%E5%B0%9A%E7%A1%85%E8%B0%B7kafka3.x%20P39&#34; &gt;截至 尚硅谷kafka3.x P39&lt;/a&gt;{#%E6%88%AA%E8%87%B3%20%E5%B0%9A%E7%A1%85%E8%B0%B7kafka3.x%20P39-toc}&lt;/p&gt;
&lt;hr&gt;
&lt;br /&gt;
&lt;p&gt;Kafka是一个由Scala和Java语言开发的，经典高吞吐量的分布式消息发布和订阅系统，也是大数据技术领域中用作数据交换的核心组件之一。它具有以下特点：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;支持消息的发布和订阅，类似于 RabbtMQ、ActiveMQ 等消息队列；&lt;/li&gt;
&lt;li&gt;支持数据实时处理；&lt;/li&gt;
&lt;li&gt;能保证消息的可靠性投递；&lt;/li&gt;
&lt;li&gt;支持消息的持久化存储，并通过多副本分布式的存储方案来保证消息的容错；&lt;/li&gt;
&lt;li&gt;高吞吐率，单 Broker 可以轻松处理数千个分区以及每秒百万级的消息量；&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;消息队列mq-e6b688e681afe9989fe58897efbc88mqefbc89&#34;&gt;&lt;a href=&#34;#%e6%b6%88%e6%81%af%e9%98%9f%e5%88%97mq-e6b688e681afe9989fe58897efbc88mqefbc89&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;消息队列（MQ） {#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%EF%BC%88MQ%EF%BC%89}
&lt;/h2&gt;&lt;p&gt;Kafka软件最初的设计就是专门用于数据传输的消息系统，类似功能的软件有RabbitMQ、ActiveMQ、RocketMQ等，这些软件的核心功能是传输数据，而Java中如果想要实现数据传输功能，那么这个软件一般需要遵循Java消息服务技术规范JMS。前面提到的ActiveMQ软件就完全遵循了JMS技术规范，而RabbitMQ是遵循了类似JMS规范并兼容JMS规范的跨平台的AMQP规范。除了上面描述的JMS，AMQP外，还有一种用于物联网小型设备之间传输消息的MQTT通讯协议。&lt;/p&gt;
&lt;p&gt;Kafka拥有作为一个消息系统应该具备的功能，但是却有着独特的设计。&lt;strong&gt;Kafka借鉴了JMS规范的思想，但是却并没有完全遵循JMS规范&lt;/strong&gt;。这也恰恰是软件名称为Kafka，而不是KafkaMQ的原因。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/9fb6defea02f0b37752ca1c4782231e4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;消息队列一般应用场景-e6b688e681afe9989fe58897e4b880e888ace5ba94e794a8e59cbae699af&#34;&gt;&lt;a href=&#34;#%e6%b6%88%e6%81%af%e9%98%9f%e5%88%97%e4%b8%80%e8%88%ac%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af-e6b688e681afe9989fe58897e4b880e888ace5ba94e794a8e59cbae699af&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;消息队列一般应用场景 {#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%80%E8%88%AC%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF}
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;**应用耦合：**多应用间通过消息队列对同一消息进行处理，避免调用接口失败导致整个过程失败。&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/2f16f6101cd2b4bb63436228734e155b.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/li&gt;
&lt;li&gt;**异步处理：**多应用对消息队列中同一消息进行处理，应用间并发处理消息，相比串行处理，减少处理时间&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/a55ab7be057ab04a981105f917581112.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;限流削峰：&lt;/strong&gt; 广泛应用于秒杀或抢购活动中，避免流量过大导致应用系统挂掉的情况。该方法有如下优点：
&lt;ul&gt;
&lt;li&gt;1.请求先入消息队列，而不是由业务处理系统直接处理，做了一次缓冲,极 大地减少了业务处理系统的压力；&lt;/li&gt;
&lt;li&gt;2.队列长度可以做限制，事实上，秒杀时，后入队列的用户无法秒杀到商品，这些请求可以直接被抛弃，返回活动已结束或商品已售完信息；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/257e558241daec39757876a0891b6458.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;消息驱动的系统：&lt;/strong&gt; 系统分为消息队列、消息生产者、消息消费者，生产者 负责产生消息，消费者(可能有多个)负责对消息进行处理。&lt;strong&gt;具体场景&lt;/strong&gt;：用户新上传了一批照片，人脸识别系统需要对这个用户的所有照片进行聚类，聚类完成后由对账系统重新生成用户的人脸索引(加快查询)。这三个子 系统间由消息队列连接起来，前一个阶段的处理结果放入队列中，后一个阶段从 队列中获取消息继续处理。&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/e7a0846fd5fe97485958c48ddb466a5d.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/li&gt;
&lt;li&gt;该方法有如下优点：1.避免了直接调用下一个系统导致当前系统失败； 2.每个子系统对于消息的处理方式可以更为灵活，可以选择收到消息时就处理，可以选择定时处理，也可以划分时间段按不同处理速度处理；&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;JMS&#34;&gt;&lt;a href=&#34;#JMS&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;JMS
&lt;/h3&gt;&lt;p&gt;JMS类似于JDBC，是java平台的消息中间件通用规范，定义了系统和系统之间传输消息的接口。&lt;/p&gt;
&lt;p&gt;为了实现系统和系统之间的数据传输，JMS规范中定义很多用于通信的组件：&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/285ce9d7a2a8f1e6ac77037c2f05e82b.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;JMS Producer&lt;/strong&gt; **：**JMS消息生产者。所谓的生产者，就是生产数据的客户端应用程序，这些应用通过JMS接口发送JMS消息。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JMS Provider&lt;/strong&gt;：JMS消息提供者。其实就是实现JMS接口和规范的消息中间件，也就是我们提供消息服务的软件系统，比如RabbitMQ、ActiveMQ、Kafka。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JMS Message&lt;/strong&gt;：JMS消息。这里的消息指的就是数据。一般采用Java数据模型进行封装，其中包含消息头，消息属性和消息主体内容。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JMS Consumer&lt;/strong&gt;：JMS消息消费者。所谓的消费者，就是从消息提供者中获取数据的客户端应用程序，这些应用通过JMS接口接收JMS消息。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;jms模型-c2a0jmse6a8a1e59e8b&#34;&gt;&lt;a href=&#34;#jms%e6%a8%a1%e5%9e%8b-c2a0jmse6a8a1e59e8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;JMS模型 {#%C2%A0JMS%E6%A8%A1%E5%9E%8B}
&lt;/h4&gt;&lt;h5 id=&#34;点对点模型peer-to-peer-e782b9e5afb9e782b9e6a8a1e59e8befbc88peer20to20peerefbc89&#34;&gt;&lt;a href=&#34;#%e7%82%b9%e5%af%b9%e7%82%b9%e6%a8%a1%e5%9e%8bpeer-to-peer-e782b9e5afb9e782b9e6a8a1e59e8befbc88peer20to20peerefbc89&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;点对点模型（peer to peer） {#%E7%82%B9%E5%AF%B9%E7%82%B9%E6%A8%A1%E5%9E%8B%EF%BC%88peer%20to%20peer%EF%BC%89}
&lt;/h5&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/fd0746d5877a27d6ecaa045fee8dc601.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特点：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个消息只有一个接收者（Consumer）(即一旦被消费，就会被删除)；&lt;/li&gt;
&lt;li&gt;发送者和接发收者间没有依赖性，发送者发送消息之后，不管有没有接收者在运行，都不会影响到发送者下次发送消息；&lt;/li&gt;
&lt;li&gt;接收者在成功接收消息之后需向队列应答成功，以便消息队列删除当前接 收的消息&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h5 id=&#34;发布订阅模型-e58f91e5b883e8aea2e99885e6a8a1e59e8b&#34;&gt;&lt;a href=&#34;#%e5%8f%91%e5%b8%83%e8%ae%a2%e9%98%85%e6%a8%a1%e5%9e%8b-e58f91e5b883e8aea2e99885e6a8a1e59e8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;发布订阅模型 {#%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%A8%A1%E5%9E%8B}
&lt;/h5&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/0bdabc2f116a00b4e787472f14c7c820.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特点：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个消息可以有多个订阅者，但是订阅者必须来自不同的消费者组；&lt;/li&gt;
&lt;li&gt;针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息。&lt;/li&gt;
&lt;li&gt;为了消费消息，订阅者需要提前订阅该角色主题，并保持在线运行；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Kafka采用就是这种模型。&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;kafka架构-kafkae69eb6e69e84&#34;&gt;&lt;a href=&#34;#kafka%e6%9e%b6%e6%9e%84-kafkae69eb6e69e84&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Kafka架构 {#Kafka%E6%9E%B6%E6%9E%84}
&lt;/h2&gt;&lt;p&gt;在 Kafka 2.8.0 版本，移除了对 Zookeeper 的依赖，通过&lt;strong&gt;Kraft模式&lt;/strong&gt; 进行自己的集群管理，使用 Kafka&lt;strong&gt;内部的 Quorum 控制器&lt;/strong&gt;来取代 ZooKeeper管理元数据，这样我们无需维护zk集群，只要维护Kafka集群就可以了，节省运算资源。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;kafka基本数据单元被称为 message(消息)&lt;/strong&gt;，为减少网络开销，提高效率，多个消息会被放入同一批次(Batch) 中后再写入。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/f0678a5c5c02bd632d1b71553fd9fa4c.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;Broker&#34;&gt;&lt;a href=&#34;#Broker&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Broker
&lt;/h3&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;kafka 集群中包含多个服务实例（节点），这种服务实例被称为 broker（一个 broker 就是一个节点/一个服务器），每个 broker 都有一个唯一标识 broker.id，用于标识自己在集群中的身份，可以在配置文件 server.properties 中进行配置，或由程序自动生成。&lt;/li&gt;
&lt;li&gt;Broker 接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。Broker 为消费者提供服务，对读取分区的请求做出响应，返回已经提交到磁盘的消息。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;controller选举-controllere98089e4b8be&#34;&gt;&lt;a href=&#34;#controller%e9%80%89%e4%b8%be-controllere98089e4b8be&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Controller选举 {#Controller%E9%80%89%E4%B8%BE}
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;每一个集群都会选举出一个 Broker作为&lt;strong&gt;集群控制器&lt;/strong&gt; **(Controller)，它负责分区 Leader 选举，还负责管理主题分区及其副本的状态、元数据管理。**如果在运行过程中，Controller节点出现了故障，那么Kafka会依托于ZooKeeper软件选举其他的节点作为新的Controller，让Kafka集群实现高可用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特殊情况&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Controller节点并没有宕掉，而是因为网络的抖动，不稳定，导致和ZooKeeper之间的会话超时，那么此时，整个Kafka集群就会认为之前的Controller已经下线（退出）从而选举出新的Controller，而之前的Controller的网络又恢复了，以为自己还是Controller了，继续管理整个集群，那么此时，整个Kafka集群就有两个controller进行管理，那么其他的broker就懵了，不知道听谁的了，这种情况，我们称之为脑裂现象，为了解决这个问题，Kafka通过一个任期（epoch:纪元）的概念来解决，也就是说，每一个Broker当选Controller时，会告诉当前Broker是第几任Controller，一旦重新选举时，这个任期会自动增1，那么不同任期的Controller的epoch值是不同的，那么旧的controller一旦发现集群中有新任controller的时候，那么它就会完成退出操作（清空缓存，中断和broker的连接，并重新加载最新的缓存），让自己重新变成一个普通的Broker。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;broker上下线-brokere4b88ae4b88be7babfc2a0&#34;&gt;&lt;a href=&#34;#broker%e4%b8%8a%e4%b8%8b%e7%ba%bf-brokere4b88ae4b88be7babfc2a0&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Broker上下线 {#Broker%E4%B8%8A%E4%B8%8B%E7%BA%BF%C2%A0}
&lt;/h4&gt;&lt;p&gt;Controller 在初始化时，会利用 ZK 的 watch 机制注册很多不同类型的监听器，当监听的事件被触发时，Controller 就会触发相应的操作。Controller 在初始化时，会注册多种类型的监听器，主要有以下几种：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;/kafka/admin/reassign_partitions 节点，用于分区副本迁移的监听&lt;/li&gt;
&lt;li&gt;/kafka/isr_change_notification 节点，用于 Partition ISR 变动的监听&lt;/li&gt;
&lt;li&gt;/kafka/admin/preferred_replica_election 节点，用于需要进行 Partition 最优 leader 选举的监听&lt;/li&gt;
&lt;li&gt;/kafka/brokers/topics 节点，用于 Topic 新建的监听&lt;/li&gt;
&lt;li&gt;/kafka/brokers/topics/TOPIC_NAME 节点，用于 Topic Partition 扩容的监听&lt;/li&gt;
&lt;li&gt;/kafka/admin/delete_topics 节点，用于 Topic 删除的监听&lt;/li&gt;
&lt;li&gt;/kafka/brokers/ids 节点，用于 Broker 上下线的监听，记录有哪些kafka服务器在线。&lt;/li&gt;
&lt;li&gt;/kafka/controller节点，辅助选举leader&lt;/li&gt;
&lt;li&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/6eacf94f1216ffd1894cad366ae0a0ca.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;每台 Broker 在上线时，都会与ZK建立一个建立一个session，并在 /brokers/ids下注册一个节点，节点名字就是broker id，这个节点是临时节点，该节点内部会有这个 Broker 的详细节点信息。Controller会监听/brokers/ids这个路径下的所有子节点，如果有新的节点出现，那么就代表有新的Broker上线，如果有节点消失，就代表有broker下线，Controller会进行相应的处理，Kafka就是利用ZK的这种watch机制及临时节点的特性来完成集群 Broker的上下线。无论Controller监听到的哪一种节点的变化，都会进行相应的处理，同步整个集群元数据。&lt;/p&gt;
&lt;h4 id=&#34;broker工作流程-brokere5b7a5e4bd9ce6b581e7a88b&#34;&gt;&lt;a href=&#34;#broker%e5%b7%a5%e4%bd%9c%e6%b5%81%e7%a8%8b-brokere5b7a5e4bd9ce6b581e7a88b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Broker工作流程 {#Broker%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B}
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/afd0a4e19e5449dd0cfa84fe3c8213ed.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;Producer&#34;&gt;&lt;a href=&#34;#Producer&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Producer
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;一般情况下，生产者在把消息均衡地分布到在主题的所有分区上，而并不关心消息会被写到哪个分区。如果我们想要把消息写到指定的分区，可以通过&lt;strong&gt;自定义分区器&lt;/strong&gt;来实现。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;Consumer&#34;&gt;&lt;a href=&#34;#Consumer&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Consumer
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;消费者一定是归属于某个消费组中的&lt;/strong&gt;，消费者可以订阅一或多个主题，并按照分区中消息的顺序来读取。消费者通过检查消息的偏移量 (offset) 来区分读取过的消息。偏移量是一个不 断递增的数值，在创建消息时，Kafka 会把它添加到其中，在给定的分区里，每个消息的偏移量都是唯一的。消费者把每个分区最后读取的偏移量保存在 Zookeeper 或 Kafka 上，如果消费者关闭或者重启，它还可以重新获取该偏移量，以保证读取状态不会丢失。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;consumer-group-consumer20group&#34;&gt;&lt;a href=&#34;#consumer-group-consumer20group&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Consumer Group {#Consumer%20Group}
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;消费者组由一个或者多个消费者组成，&lt;strong&gt;同一个组中的消费者对于同一条消息只消费一次。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;每个消费者组都有一个 ID，即 group ID。组内的所有消费者协调在一起来消费 一个订阅主题的所有分区。当然，&lt;strong&gt;每个分区只能由同一个消费组内的一个消费者来消费，但可以由不同的消费组来消费。partition 数量决定了每个 consumer group 中并发消费者的最大数。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;因此要合理设置消费者组中的消费者数量，避免出现消费者闲置。&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;Topic&#34;&gt;&lt;a href=&#34;#Topic&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Topic
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;Kafka 的消息通过 Topics(主题) 进行分类，Kafka中有两个固定的，用于记录消费者偏移量和事务处理的主题，一个主题可以被分为若干个 Partitions(分区)，一个分区就是 一个提交日志 (commit log)。消息以追加的方式写入分区，然后以先入先出的顺序读取。&lt;strong&gt;Kafka 通过分区来实现数据的冗余和伸缩性，分区可以分布在不同的服务器上，这意味着一个 Topic 可以横跨多个服务器，以提供比单个服务器更强大的性能&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;由于一个 Topic 包含多个分区，因此无法在整个 Topic 范围内保证消息的顺序性，但可以保证消息在单个分区内的顺序性。&lt;/strong&gt;&lt;/p&gt;
&lt;br /&gt;&lt;/blockquote&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>HA—Hadoop高可用</title>
        <link>/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/</link>
        <pubDate>Mon, 15 Apr 2024 19:23:57 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/04/hahadoop%E9%AB%98%E5%8F%AF%E7%94%A8/</guid>
        <description>&lt;p&gt;&lt;strong&gt;目录&lt;/strong&gt;{#main-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#HA%20%E6%A6%82%E8%BF%B0&#34; &gt;HA 概述&lt;/a&gt;{#HA%20%E6%A6%82%E8%BF%B0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#HDFS%E9%AB%98%E5%8F%AF%E7%94%A8&#34; &gt;HDFS高可用&lt;/a&gt;{#HDFS%E9%AB%98%E5%8F%AF%E7%94%A8-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E4%BF%9D%E8%AF%81%E6%89%80%E6%9C%89NN%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%C2%A0&#34; &gt;保证所有NN的数据一致性&lt;/a&gt;{#%E4%BF%9D%E8%AF%81%E6%89%80%E6%9C%89NN%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%89%8B%E5%8A%A8%E6%A8%A1%E5%BC%8F&#34; &gt;手动模式&lt;/a&gt;{#%E6%89%8B%E5%8A%A8%E6%A8%A1%E5%BC%8F-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E8%87%AA%E5%8A%A8%E6%A8%A1%E5%BC%8F&#34; &gt;自动模式&lt;/a&gt;{#%E8%87%AA%E5%8A%A8%E6%A8%A1%E5%BC%8F-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E8%A7%A3%E5%86%B3NN%E8%BF%9E%E6%8E%A5%E4%B8%8D%E4%B8%8AJN%E7%9A%84%E9%97%AE%E9%A2%98&#34; &gt;解决NN连接不上JN的问题&lt;/a&gt;{#%E8%A7%A3%E5%86%B3NN%E8%BF%9E%E6%8E%A5%E4%B8%8D%E4%B8%8AJN%E7%9A%84%E9%97%AE%E9%A2%98-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%C2%A0Yarn%E9%AB%98%E5%8F%AF%E7%94%A8&#34; &gt;Yarn高可用&lt;/a&gt;{#%C2%A0Yarn%E9%AB%98%E5%8F%AF%E7%94%A8-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%A0%B8%E5%BF%83%E9%97%AE%E9%A2%98&#34; &gt;核心问题&lt;/a&gt;{#%E6%A0%B8%E5%BF%83%E9%97%AE%E9%A2%98-toc}&lt;/p&gt;
&lt;hr&gt;
&lt;br /&gt;
&lt;h2 id=&#34;ha-概述-ha20e6a682e8bfb0&#34;&gt;&lt;a href=&#34;#ha-%e6%a6%82%e8%bf%b0-ha20e6a682e8bfb0&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HA 概述 {#HA%20%E6%A6%82%E8%BF%B0}
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;1）所谓 HA（High Availablity），即高可用（7*24 小时不中断服务）。&lt;/p&gt;
&lt;p&gt;2）实现高可用最关键的策略是消除单点故障（传统的主从模式集群单个节点发生故障会影响整个集群）。HA 严格来说应该分成各个组件的 HA 机制：&lt;strong&gt;HDFS 的 HA 和 YARN 的 HA&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;3）NameNode 主要在以下两个方面影响 HDFS 集群&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NameNode 机器发生意外，如宕机，集群将无法使用，直到管理员重启&lt;/li&gt;
&lt;li&gt;NameNode 机器需要升级，包括软件、硬件升级，此时集群也将无法使用&lt;/li&gt;
&lt;li&gt;HDFS HA 功能通过配置多个 NameNode(Active/Standby)实现在集群中对 NameNode 的热备来解决上述问题。如果出现故障，如机器崩溃或机器需要升级维护，这时可以启动另一台机器上的NameNode继续维护整个集群的运行（&lt;strong&gt;集群中同时只能有一台active的NN，其他NN处于standby（备用）&lt;/strong&gt; ）。而这种启动方式&lt;strong&gt;分为手动和自动（推荐）&lt;/strong&gt;，但是在这之前，我们&lt;strong&gt;必须通过某种方式保证所有NN的元数据一致&lt;/strong&gt;，这样才能保证active状态的NN故障后，另一个处于standby状态的NN激活为active能够正常维持集群运行，类似于公司员工的任务的交接。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;hdfs高可用-hdfse9ab98e58fafe794a8&#34;&gt;&lt;a href=&#34;#hdfs%e9%ab%98%e5%8f%af%e7%94%a8-hdfse9ab98e58fafe794a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HDFS高可用 {#HDFS%E9%AB%98%E5%8F%AF%E7%94%A8}
&lt;/h2&gt;&lt;h3 id=&#34;保证所有nn的数据一致性-e4bf9de8af81e68980e69c89nne79a84e695b0e68daee4b880e887b4e680a7c2a0&#34;&gt;&lt;a href=&#34;#%e4%bf%9d%e8%af%81%e6%89%80%e6%9c%89nn%e7%9a%84%e6%95%b0%e6%8d%ae%e4%b8%80%e8%87%b4%e6%80%a7-e4bf9de8af81e68980e69c89nne79a84e695b0e68daee4b880e887b4e680a7c2a0&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;保证所有NN的数据一致性 {#%E4%BF%9D%E8%AF%81%E6%89%80%E6%9C%89NN%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%C2%A0}
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;在处于active的NN正常运行时，他会生成Fsimage文件，让其他处于standby的NN同步，同时引入JournalNode节点来保证edits文件数据的一致性&lt;/strong&gt;，JournalNode作为active的NN和standby的NN的中间节点，activeNN会把edits发送给JournalNode，然后standbyNN从JournalNode获取edits。同时为了保证JournalNode的可靠性，JournalNode本身也是一个多节点的集群。&lt;/p&gt;
&lt;p&gt;JournalNode 节点会在集群自动的选择一个&amp;quot;主&amp;quot;节点出来，Active 节点会和 JournalNode 的主节点通信，然后 JournalNode 集群的主节点会将数据发送给其他的节点，只要有过半的节点完成了数据的存储（&lt;strong&gt;过半写成功&lt;/strong&gt;），JournalNode 集群的主节点，就会将成功信息返回给 Active 节点。当 JournalNode 集群的主节点挂掉，其他的 JournalNode 节点会快速选举出新的&amp;quot;主&amp;quot;节点来。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;同时在HA架构中，并没有SecondaryNameNode&lt;/strong&gt;，那么定期合并fsimage的eedits的任务是由standby的NN来完成的。&lt;/p&gt;
&lt;h3 id=&#34;手动模式-e6898be58aa8e6a8a1e5bc8f&#34;&gt;&lt;a href=&#34;#%e6%89%8b%e5%8a%a8%e6%a8%a1%e5%bc%8f-e6898be58aa8e6a8a1e5bc8f&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;手动模式 {#%E6%89%8B%E5%8A%A8%E6%A8%A1%E5%BC%8F}
&lt;/h3&gt;&lt;p&gt;配置core-site.xml&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;!-- 指定hdfs的nameservice为ns1 --&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hdfs://mycluster/&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;!-- 指定hadoop临时目录 --&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;hadoop.tmp.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;配置hdfs-site.xml&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;!--指定hdfs的nameservice为mycluster，需要和core-site.xml中的保持一致 --&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.nameservices&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;mycluster&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;!-- hadoop-ha下面有两个NameNode，分别是nn1，nn2 --&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.ha.namenodes.mycluster&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;nn1,nn2,nn3&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;!-- nn1的RPC通信地址 --&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.namenode.rpc-address.mycluster.nn1&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;linux01:8020&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;!-- nn1的http通信地址 --&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.namenode.http-address.mycluster.nn1&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;linux01:9870&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;!-- nn2的RPC通信地址 --&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.namenode.rpc-address.mycluster.nn2&amp;amp;
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>Hadoop入门—HDFS、MR、Yarn</title>
        <link>/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/</link>
        <pubDate>Mon, 15 Apr 2024 14:38:50 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/04/hadoop%E5%85%A5%E9%97%A8hdfsmryarn/</guid>
        <description>&lt;p&gt;&lt;strong&gt;目录&lt;/strong&gt;{#main-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Hadoop%E7%AE%80%E4%BB%8B&#34; &gt;Hadoop简介&lt;/a&gt;{#Hadoop%E7%AE%80%E4%BB%8B-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Hadoop%20%E4%B8%89%E5%A4%A7%E5%8F%91%E8%A1%8C%E7%89%88%E6%9C%AC&#34; &gt;Hadoop 三大发行版本&lt;/a&gt;{#Hadoop%20%E4%B8%89%E5%A4%A7%E5%8F%91%E8%A1%8C%E7%89%88%E6%9C%AC-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Hadoop%E4%BC%98%E5%8A%BF&#34; &gt;Hadoop优势&lt;/a&gt;{#Hadoop%E4%BC%98%E5%8A%BF-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Hadoop%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90&#34; &gt;Hadoop基本组成&lt;/a&gt;{#Hadoop%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%B8%B8%E7%94%A8Shell%E5%91%BD%E4%BB%A4&#34; &gt;常用Shell命令&lt;/a&gt;{#%E5%B8%B8%E7%94%A8Shell%E5%91%BD%E4%BB%A4-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#HDFS%E5%88%86%E5%B8%83%E5%AD%98%E5%82%A8&#34; &gt;HDFS分布存储&lt;/a&gt;{#HDFS%E5%88%86%E5%B8%83%E5%AD%98%E5%82%A8-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#HDFS%E5%90%AF%E5%81%9C&#34; &gt;HDFS启停&lt;/a&gt;{#HDFS%E5%90%AF%E5%81%9C-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#NameNode%EF%BC%88NN%EF%BC%89&#34; &gt;NameNode（NN）&lt;/a&gt;{#NameNode%EF%BC%88NN%EF%BC%89-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#DataNode%EF%BC%88DN%EF%BC%89&#34; &gt;DataNode（DN）&lt;/a&gt;{#DataNode%EF%BC%88DN%EF%BC%89-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#SecondaryNameNode%EF%BC%88SNN%EF%BC%89&#34; &gt;SecondaryNameNode（SNN）&lt;/a&gt;{#SecondaryNameNode%EF%BC%88SNN%EF%BC%89-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%96%87%E4%BB%B6%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B&#34; &gt;文件写入流程&lt;/a&gt;{#%E6%96%87%E4%BB%B6%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#HDFS%E6%9E%B6%E6%9E%84%E7%9A%84%E7%A8%B3%E5%AE%9A%E6%80%A7&#34; &gt;HDFS架构的稳定性&lt;/a&gt;{#HDFS%E6%9E%B6%E6%9E%84%E7%9A%84%E7%A8%B3%E5%AE%9A%E6%80%A7-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%C2%A0%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%B5%81%E7%A8%8B&#34; &gt;文件读取流程&lt;/a&gt;{#%C2%A0%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%B5%81%E7%A8%8B-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%AD%98%E5%82%A8%E6%96%B9%E5%BC%8F&#34; &gt;存储方式&lt;/a&gt;{#%E5%AD%98%E5%82%A8%E6%96%B9%E5%BC%8F-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Block%E5%9D%97%E5%92%8C%E5%A4%9A%E5%89%AF%E6%9C%AC&#34; &gt;Block块和多副本&lt;/a&gt;{#Block%E5%9D%97%E5%92%8C%E5%A4%9A%E5%89%AF%E6%9C%AC-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#edits%E5%92%8Cfsimage%E6%96%87%E4%BB%B6&#34; &gt;edits和fsimage文件&lt;/a&gt;{#edits%E5%92%8Cfsimage%E6%96%87%E4%BB%B6-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%C2%A0%E5%85%83%E6%95%B0%E6%8D%AE%E5%90%88%E5%B9%B6%E5%8F%8A%E6%8E%A7%E5%88%B6%E5%8F%82%E6%95%B0&#34; &gt;元数据合并及控制参数&lt;/a&gt;{#%C2%A0%E5%85%83%E6%95%B0%E6%8D%AE%E5%90%88%E5%B9%B6%E5%8F%8A%E6%8E%A7%E5%88%B6%E5%8F%82%E6%95%B0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#HDFS%E6%BC%AB%E7%94%BB&#34; &gt;HDFS漫画&lt;/a&gt;{#HDFS%E6%BC%AB%E7%94%BB-toc}&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Mapreduce%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6&#34; &gt;Mapreduce分布式并行计算框架&lt;/a&gt;{#Mapreduce%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E8%AE%A1%E7%AE%97%E6%A8%A1%E5%BC%8F&#34; &gt;计算模式&lt;/a&gt;{#%E8%AE%A1%E7%AE%97%E6%A8%A1%E5%BC%8F-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Map%E5%92%8CReduce&#34; &gt;Map和Reduce&lt;/a&gt;{#Map%E5%92%8CReduce-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#MR%E6%89%A7%E8%A1%8C%E5%8E%9F%E7%90%86&#34; &gt;MR执行原理&lt;/a&gt;{#MR%E6%89%A7%E8%A1%8C%E5%8E%9F%E7%90%86-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Yarn%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6%E3%80%81%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86&#34; &gt;Yarn作业调度、资源管理&lt;/a&gt;{#Yarn%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6%E3%80%81%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Yarn%E5%90%AF%E5%81%9C%C2%A0&#34; &gt;Yarn启停&lt;/a&gt;{#Yarn%E5%90%AF%E5%81%9C%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#ResourceManager&#34; &gt;ResourceManager&lt;/a&gt;{#ResourceManager-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#NodeManager%C2%A0&#34; &gt;NodeManager&lt;/a&gt;{#NodeManager%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#ApplicationMaster&#34; &gt;ApplicationMaster&lt;/a&gt;{#ApplicationMaster-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#JobHistoryServer&#34; &gt;JobHistoryServer&lt;/a&gt;{#JobHistoryServer-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Container&#34; &gt;Container&lt;/a&gt;{#Container-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Hadoop%E4%B8%80%E9%94%AE%E5%90%AF%E5%81%9C%C2%A0&#34; &gt;Hadoop一键启停&lt;/a&gt;{#Hadoop%E4%B8%80%E9%94%AE%E5%90%AF%E5%81%9C%C2%A0-toc}&lt;/p&gt;
&lt;hr&gt;
&lt;br /&gt;
&lt;h2 id=&#34;hadoop简介-hadoope7ae80e4bb8b&#34;&gt;&lt;a href=&#34;#hadoop%e7%ae%80%e4%bb%8b-hadoope7ae80e4bb8b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hadoop简介 {#Hadoop%E7%AE%80%E4%BB%8B}
&lt;/h2&gt;&lt;p&gt;狭义来说，hadoop是Apache基金会开发的分布式系统基础架构，用来解决海量数据的存储和海量数据的分析计算问题。广义上来说，Hadoop 通常是指一个更广泛的概念 &amp;mdash;&amp;mdash; Hadoop 生态圈。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/0fd7c932e8ae6ff521f32eee46cd8663.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;hadoop-三大发行版本-hadoop20e4b889e5a4a7e58f91e8a18ce78988e69cac&#34;&gt;&lt;a href=&#34;#hadoop-%e4%b8%89%e5%a4%a7%e5%8f%91%e8%a1%8c%e7%89%88%e6%9c%ac-hadoop20e4b889e5a4a7e58f91e8a18ce78988e69cac&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hadoop 三大发行版本 {#Hadoop%20%E4%B8%89%E5%A4%A7%E5%8F%91%E8%A1%8C%E7%89%88%E6%9C%AC}
&lt;/h3&gt;&lt;p&gt;Apache、Cloudera、Hortonworks&lt;/p&gt;
&lt;p&gt;Apache 版本最原始（最基础）的版本，对于入门学习最好。&lt;/p&gt;
&lt;p&gt;Cloudera在大型互联网企业中用的较多。其主要产品有CDH、Cloudera Manager，Cloudera Support&lt;/p&gt;
&lt;h3 id=&#34;hadoop优势-hadoope4bc98e58abf&#34;&gt;&lt;a href=&#34;#hadoop%e4%bc%98%e5%8a%bf-hadoope4bc98e58abf&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hadoop优势 {#Hadoop%E4%BC%98%E5%8A%BF}
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;高可靠性：&lt;/strong&gt; Hadoop 底层维护多个数据副本，所以即使 Hadoop 某个计算元素或存储出现故障，也不会导致数据的丢失。&lt;br&gt;
&lt;strong&gt;高扩展性：&lt;/strong&gt; 在集群间分配任务数据，可方便的扩展数以千计的节点。&lt;br&gt;
高效性： 在 MapReduce 的思想下，Hadoop 是并行工作的，以加快任务处理速度。&lt;br&gt;
&lt;strong&gt;高容错性：&lt;/strong&gt; 能够自动将失败的任务重新分配。&lt;/p&gt;
&lt;p&gt;**低成本：**Hadoop不要求机器的配置达到极高的标准，大部分普通商用服务器即可满足要求，通过提供多个副本和容错机制提高集群的可靠性&lt;/p&gt;
&lt;h3 id=&#34;hadoop基本组成-hadoope59fbae69cace7bb84e68890&#34;&gt;&lt;a href=&#34;#hadoop%e5%9f%ba%e6%9c%ac%e7%bb%84%e6%88%90-hadoope59fbae69cace7bb84e68890&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hadoop基本组成 {#Hadoop%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90}
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/fd575291df78b55069687df62b245798.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;常用shell命令-e5b8b8e794a8shelle591bde4bba4&#34;&gt;&lt;a href=&#34;#%e5%b8%b8%e7%94%a8shell%e5%91%bd%e4%bb%a4-e5b8b8e794a8shelle591bde4bba4&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;常用Shell命令 {#%E5%B8%B8%E7%94%A8Shell%E5%91%BD%E4%BB%A4}
&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;hdfs dfs -ls &amp;lt;path&amp;gt;：列出指定 HDFS 路径下的文件和目录
hdfs dfs -mkdir &amp;lt;path&amp;gt;：在 HDFS 中创建新目录
hdfs dfs -put &amp;lt;localsrc&amp;gt; &amp;lt;dst&amp;gt;：将本地文件（或目录）复制到 HDFS
hdfs dfs -get &amp;lt;src&amp;gt; &amp;lt;localdst&amp;gt;：将 HDFS 上的文件（或目录）复制到本地
hdfs dfs -mv &amp;lt;src&amp;gt; &amp;lt;dst&amp;gt;：移动 HDFS 中的文件目录或重命名文件目录
hdfs dfs -cp &amp;lt;src&amp;gt; &amp;lt;dst&amp;gt;：复制 HDFS 中的文件或目录
hdfs dfs -rm &amp;lt;path&amp;gt;：删除 HDFS 中的文件
hdfs dfs -cat &amp;lt;path&amp;gt;：在控制台显示 HDFS 文件的内容
hdfs dfs -du &amp;lt;path&amp;gt;：显示 HDFS 文件或目录的大小
hdfs dfs -df &amp;lt;path&amp;gt;：显示 HDFS 的可用空间
hdfs fsck path [-files [-blocks [-location]]]
-files列出路径内的文件状态
-files -blocks输出文件块报告（几个块，几个副本）
-files -blocks -locations 输出每个block的详情
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;hdfs分布存储-hdfse58886e5b883e5ad98e582a8&#34;&gt;&lt;a href=&#34;#hdfs%e5%88%86%e5%b8%83%e5%ad%98%e5%82%a8-hdfse58886e5b883e5ad98e582a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;HDFS分布存储 {#HDFS%E5%88%86%E5%B8%83%E5%AD%98%E5%82%A8}
&lt;/h2&gt;&lt;p&gt;HDFS是一个分布式文件系统，具有高容错、高吞吐 量等特性，&lt;strong&gt;分布在多个集群节点上的文件系统。有NN、DN、SNN三种角色。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;hdfs启停-hdfse590afe5819c&#34;&gt;&lt;a href=&#34;#hdfs%e5%90%af%e5%81%9c-hdfse590afe5819c&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;strong&gt;HDFS启停&lt;/strong&gt; {#HDFS%E5%90%AF%E5%81%9C}
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/307c647c8aa7e460c1ae34a79304e357.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;namenodenn-namenodeefbc88nnefbc89&#34;&gt;&lt;a href=&#34;#namenodenn-namenodeefbc88nnefbc89&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;NameNode（NN） {#NameNode%EF%BC%88NN%EF%BC%89}
&lt;/h3&gt;&lt;p&gt;HDFS的主角色，负责管理每个文件的块所在的 DataNode、整个HDFS文件系统、存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限）等。&lt;/p&gt;
&lt;h3 id=&#34;datanodedn-datanodeefbc88dnefbc89&#34;&gt;&lt;a href=&#34;#datanodedn-datanodeefbc88dnefbc89&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;DataNode（DN） {#DataNode%EF%BC%88DN%EF%BC%89}
&lt;/h3&gt;&lt;p&gt;HDFS从角色，负责处理客户端的读写请求，存储删除文件块，以及块数据校验和。&lt;/p&gt;
&lt;h3 id=&#34;secondarynamenodesnn-secondarynamenodeefbc88snnefbc89&#34;&gt;&lt;a href=&#34;#secondarynamenodesnn-secondarynamenodeefbc88snnefbc89&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;SecondaryNameNode（SNN） {#SecondaryNameNode%EF%BC%88SNN%EF%BC%89}
&lt;/h3&gt;&lt;p&gt;NN的辅助角色，帮NN打杂，监控 HDFS 状态的辅助后台程序，每隔一段时间获取 HDFS 元数据的快照。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可通过9870端口（默认9870）访问web界面，查看集群各节点状态及信息&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/06b13a99d15316eb579548d13d808452.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;文件写入流程-e69687e4bbb6e58699e585a5e6b581e7a88b&#34;&gt;&lt;a href=&#34;#%e6%96%87%e4%bb%b6%e5%86%99%e5%85%a5%e6%b5%81%e7%a8%8b-e69687e4bbb6e58699e585a5e6b581e7a88b&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;文件写入流程 {#%E6%96%87%E4%BB%B6%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B}
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/15300fba96e9072b20673cad977f7de1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;发送的写入请求通过后客户端会根据nn返回的信息自动把数据分块向网络距离最近的dn写入数据同时dn会完成备份操作把备份传到其他的dn然后由其他的dn再次做备份传播直到满足设置的备份数量nb&#34;&gt;&lt;a href=&#34;#%e5%8f%91%e9%80%81%e7%9a%84%e5%86%99%e5%85%a5%e8%af%b7%e6%b1%82%e9%80%9a%e8%bf%87%e5%90%8e%e5%ae%a2%e6%88%b7%e7%ab%af%e4%bc%9a%e6%a0%b9%e6%8d%aenn%e8%bf%94%e5%9b%9e%e7%9a%84%e4%bf%a1%e6%81%af%e8%87%aa%e5%8a%a8%e6%8a%8a%e6%95%b0%e6%8d%ae%e5%88%86%e5%9d%97%e5%90%91%e7%bd%91%e7%bb%9c%e8%b7%9d%e7%a6%bb%e6%9c%80%e8%bf%91%e7%9a%84dn%e5%86%99%e5%85%a5%e6%95%b0%e6%8d%ae%e5%90%8c%e6%97%b6dn%e4%bc%9a%e5%ae%8c%e6%88%90%e5%a4%87%e4%bb%bd%e6%93%8d%e4%bd%9c%e6%8a%8a%e5%a4%87%e4%bb%bd%e4%bc%a0%e5%88%b0%e5%85%b6%e4%bb%96%e7%9a%84dn%e7%84%b6%e5%90%8e%e7%94%b1%e5%85%b6%e4%bb%96%e7%9a%84dn%e5%86%8d%e6%ac%a1%e5%81%9a%e5%a4%87%e4%bb%bd%e4%bc%a0%e6%92%ad%e7%9b%b4%e5%88%b0%e6%bb%a1%e8%b6%b3%e8%ae%be%e7%bd%ae%e7%9a%84%e5%a4%87%e4%bb%bd%e6%95%b0%e9%87%8fnb&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;发送的写入请求通过后，客户端会根据NN返回的信息自动把数据分块，向&lt;strong&gt;网络距离最近&lt;/strong&gt;的DN写入数据。同时，DN会完成备份操作，把备份传到其他的DN，然后由其他的DN再次做备份传播，直到满足设置的备份数量&amp;amp;nb
&lt;/h2&gt;</description>
        </item>
        <item>
        <title>Hive本质、架构、玩法</title>
        <link>/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/</link>
        <pubDate>Sun, 14 Apr 2024 12:23:06 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/04/hive%E6%9C%AC%E8%B4%A8%E6%9E%B6%E6%9E%84%E7%8E%A9%E6%B3%95/</guid>
        <description>&lt;p&gt;&lt;strong&gt;目录&lt;/strong&gt;{#main-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Hive%E6%9C%AC%E8%B4%A8&#34; &gt;Hive本质&lt;/a&gt;{#Hive%E6%9C%AC%E8%B4%A8-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Hive%E4%B8%BB%E8%A6%81%E6%9C%89%E4%BB%A5%E4%B8%8B3%E4%B8%AA%E6%A8%A1%E5%9D%97&#34; &gt;Hive主要有以下3个模块&lt;/a&gt;{#Hive%E4%B8%BB%E8%A6%81%E6%9C%89%E4%BB%A5%E4%B8%8B3%E4%B8%AA%E6%A8%A1%E5%9D%97-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Metastore&#34; &gt;Metastore&lt;/a&gt;{#Metastore-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%9E%B6%E6%9E%84%C2%A0&#34; &gt;架构&lt;/a&gt;{#%E6%9E%B6%E6%9E%84%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Hive%E6%97%A5%E5%BF%97%E9%85%8D%E7%BD%AE&#34; &gt;Hive日志配置&lt;/a&gt;{#Hive%E6%97%A5%E5%BF%97%E9%85%8D%E7%BD%AE-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#HQL%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B&#34; &gt;HQL执行过程&lt;/a&gt;{#HQL%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Hive%E5%9B%9B%E7%A7%8D%E7%8E%A9%E6%B3%95%EF%BC%9A&#34; &gt;Hive四种玩法：&lt;/a&gt;{#Hive%E5%9B%9B%E7%A7%8D%E7%8E%A9%E6%B3%95%EF%BC%9A-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#1%EF%BC%89CLI&#34; &gt;1）CLI&lt;/a&gt;{#1%EF%BC%89CLI-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#2%EF%BC%89HiveServer2&#34; &gt;2）HiveServer2&lt;/a&gt;{#2%EF%BC%89HiveServer2-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#3%EF%BC%89Beeline&#34; &gt;3）Beeline&lt;/a&gt;{#3%EF%BC%89Beeline-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#4%EF%BC%89Web%20UI&#34; &gt;4）Web UI&lt;/a&gt;{#4%EF%BC%89Web%20UI-toc}&lt;/p&gt;
&lt;hr&gt;
&lt;br /&gt;
&lt;h2 id=&#34;hive-本质-hivee69cace8b4a8&#34;&gt;&lt;a href=&#34;#hive-%e6%9c%ac%e8%b4%a8-hivee69cace8b4a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;strong&gt;Hive&lt;/strong&gt; &lt;strong&gt;本质&lt;/strong&gt; {#Hive%E6%9C%AC%E8%B4%A8}
&lt;/h2&gt;&lt;p&gt;Hive是构建在hadoop上的数据仓库，也可以说是一个&lt;strong&gt;操作hdfs文件&lt;/strong&gt; 的客户端，它&lt;strong&gt;可以将结构化的数据文件映射成表&lt;/strong&gt;，并提供类 SQL查询功能，用于查询的 SQL 语句会被转化为 MapReduce 作业，然后提交到 Hadoop 上运行。&lt;strong&gt;Hive执行引擎可以是MapReduce、Spark、Tez，如果是MR，Hive就会把HQL翻译成MR进行数据计算。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;由于Hive是针对数据仓库应⽤设计的，⽽数据仓库的内容是读多写少的。因此，Hive中不⽀持 对数据的改写和添加，所有的数据都是在加载的时候中确定好的。&lt;/p&gt;
&lt;p&gt;Hive不适合⽤于联机事务处理(OLTP)，也不提供实时查询功能。它最适合应⽤在基于⼤量不可变数据的批处理 作业。Hive 的特点是可伸缩（在Hadoop 的集群上动态的添加设备），可扩展、容错、输⼊格式的松散耦合。 Hive 的⼊⼝是DRIVER ，执⾏的SQL语句⾸先提交到DRIVER驱动，然后调COMPILER解释驱动，最终解释成 MapReduce 任务执⾏，最后将结果返回。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;优点：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;简单、容易上手 (提供了类似 sql 的查询语言 hql)，使得精通 sql 但是不了解 Java 编程的人也能很 好地进行大数据分析；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;灵活性高，可以自定义用户函数 (UDF) 和存储格式；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;为超大的数据集设计的计算和存储能力，集群扩展容易;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;4.&lt;strong&gt;统一的元数据管理&lt;/strong&gt;，可与 presto／impala／sparksql 等共享数据；&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;执行延迟高，不适合做数据的实时处理，但适合做海量数据的离线处理。&lt;/li&gt;
&lt;/ol&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/9785a8b5d20da5ab15eb5cf746fa5288.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;br /&gt;
&lt;h2 id=&#34;hive主要有以下3个模块-hivee4b8bbe8a681e69c89e4bba5e4b88b3e4b8aae6a8a1e59d97&#34;&gt;&lt;a href=&#34;#hive%e4%b8%bb%e8%a6%81%e6%9c%89%e4%bb%a5%e4%b8%8b3%e4%b8%aa%e6%a8%a1%e5%9d%97-hivee4b8bbe8a681e69c89e4bba5e4b88b3e4b8aae6a8a1e59d97&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Hive主要有以下3个模块 {#Hive%E4%B8%BB%E8%A6%81%E6%9C%89%E4%BB%A5%E4%B8%8B3%E4%B8%AA%E6%A8%A1%E5%9D%97}
&lt;/h2&gt;&lt;h2 id=&#34;户接模块含clihwijdbcthrift-server等来实现对hive的访问cli是hive带-的命令界hwi是hive的个简单界jdbcodbc以及thrift-server可向户提供进-编程的接其中thrift-server是基于thrift软件框架开发的提供hi&#34;&gt;&lt;a href=&#34;#%e6%88%b7%e6%8e%a5%e6%a8%a1%e5%9d%97%e5%90%abclihwijdbcthrift-server%e7%ad%89%e6%9d%a5%e5%ae%9e%e7%8e%b0%e5%af%b9hive%e7%9a%84%e8%ae%bf%e9%97%aecli%e6%98%afhive%e5%b8%a6-%e7%9a%84%e5%91%bd%e4%bb%a4%e7%95%8chwi%e6%98%afhive%e7%9a%84%e4%b8%aa%e7%ae%80%e5%8d%95%e7%95%8cjdbcodbc%e4%bb%a5%e5%8f%8athrift-server%e5%8f%af%e5%90%91%e6%88%b7%e6%8f%90%e4%be%9b%e8%bf%9b-%e7%bc%96%e7%a8%8b%e7%9a%84%e6%8e%a5%e5%85%b6%e4%b8%adthrift-server%e6%98%af%e5%9f%ba%e4%ba%8ethrift%e8%bd%af%e4%bb%b6%e6%a1%86%e6%9e%b6%e5%bc%80%e5%8f%91%e7%9a%84%e6%8f%90%e4%be%9bhi&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;**⽤户接⼝模块：**含CLI、HWI、JDBC、Thrift Server等，⽤来实现对Hive的访问。CLI是Hive⾃带 的命令⾏界⾯；HWI是Hive的⼀个简单⽹⻚界⾯；JDBC、ODBC以及Thrift Server可向⽤户提供进 ⾏编程的接⼝，其中Thrift Server是基于Thrift软件框架开发的，提供Hi
&lt;/h2&gt;</description>
        </item>
        <item>
        <title>Hive调优</title>
        <link>/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/</link>
        <pubDate>Sat, 13 Apr 2024 20:49:38 +0000</pubDate>
        
        <guid>/zh-cn/post/2024/04/hive%E8%B0%83%E4%BC%98/</guid>
        <description>&lt;p&gt;&lt;strong&gt;目录&lt;/strong&gt;{#main-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Yarn%E5%92%8CMR%E8%B5%84%E6%BA%90%E9%85%8D%E7%BD%AE&#34; &gt;Yarn和MR资源配置&lt;/a&gt;{#Yarn%E5%92%8CMR%E8%B5%84%E6%BA%90%E9%85%8D%E7%BD%AE-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Yarn%E8%B5%84%E6%BA%90%E9%85%8D%E7%BD%AE&#34; &gt;Yarn资源配置&lt;/a&gt;{#Yarn%E8%B5%84%E6%BA%90%E9%85%8D%E7%BD%AE-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#MR%E8%B5%84%E6%BA%90%E9%85%8D%E7%BD%AE&#34; &gt;MR资源配置&lt;/a&gt;{#MR%E8%B5%84%E6%BA%90%E9%85%8D%E7%BD%AE-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Explain%E6%9F%A5%E7%9C%8B%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92&#34; &gt;Explain查看执行计划&lt;/a&gt;{#Explain%E6%9F%A5%E7%9C%8B%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%88%86%E7%BB%84%E8%81%9A%E5%90%88%E4%BC%98%E5%8C%96&#34; &gt;分组聚合优化&lt;/a&gt;{#%E5%88%86%E7%BB%84%E8%81%9A%E5%90%88%E4%BC%98%E5%8C%96-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E4%BC%98%E5%8C%96%E5%89%8DVS%E4%BC%98%E5%8C%96%E5%90%8E&#34; &gt;优化前VS优化后&lt;/a&gt;{#%E4%BC%98%E5%8C%96%E5%89%8DVS%E4%BC%98%E5%8C%96%E5%90%8E-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Join%E4%BC%98%E5%8C%96&#34; &gt;Join优化&lt;/a&gt;{#Join%E4%BC%98%E5%8C%96-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Common%20Join%EF%BC%88%E6%99%AE%E9%80%9Ajoin%EF%BC%89&#34; &gt;Common Join（普通join）&lt;/a&gt;{#Common%20Join%EF%BC%88%E6%99%AE%E9%80%9Ajoin%EF%BC%89-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%8E%9F%E7%90%86&#34; &gt;原理&lt;/a&gt;{#%E5%8E%9F%E7%90%86-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Map%20Join&#34; &gt;Map Join&lt;/a&gt;{#Map%20Join-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%8E%9F%E7%90%86&#34; &gt;原理&lt;/a&gt;{#%E5%8E%9F%E7%90%86-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E4%BC%98%E5%8C%96%C2%A0&#34; &gt;优化&lt;/a&gt;{#%E4%BC%98%E5%8C%96%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%B3%95%E4%B8%80%EF%BC%9Ahint%E6%8F%90%E7%A4%BA&#34; &gt;法一：hint提示&lt;/a&gt;{#%E6%B3%95%E4%B8%80%EF%BC%9Ahint%E6%8F%90%E7%A4%BA-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%B3%95%E4%BA%8C%EF%BC%9A%E8%87%AA%E5%8A%A8%E8%A7%A6%E5%8F%91&#34; &gt;法二：自动触发&lt;/a&gt;{#%E6%B3%95%E4%BA%8C%EF%BC%9A%E8%87%AA%E5%8A%A8%E8%A7%A6%E5%8F%91-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%C2%A0%E4%BC%98%E5%8C%96%E6%A1%88%E4%BE%8B&#34; &gt;优化案例&lt;/a&gt;{#%C2%A0%E4%BC%98%E5%8C%96%E6%A1%88%E4%BE%8B-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Bucket%20Map%20Join&#34; &gt;Bucket Map Join&lt;/a&gt;{#Bucket%20Map%20Join-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%8E%9F%E7%90%86&#34; &gt;原理&lt;/a&gt;{#%E5%8E%9F%E7%90%86-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E4%BC%98%E5%8C%96&#34; &gt;优化&lt;/a&gt;{#%E4%BC%98%E5%8C%96-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#hint%E6%8F%90%E7%A4%BA%C2%A0&#34; &gt;hint提示&lt;/a&gt;{#hint%E6%8F%90%E7%A4%BA%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%C2%A0%E4%BC%98%E5%8C%96%E6%A1%88%E4%BE%8B&#34; &gt;优化案例&lt;/a&gt;{#%C2%A0%E4%BC%98%E5%8C%96%E6%A1%88%E4%BE%8B-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Sort%20Merge%20Bucket%20Map%20Join%28SMB%20map%20join%29&#34; &gt;Sort Merge Bucket Map Join(SMB map join)&lt;/a&gt;{#Sort%20Merge%20Bucket%20Map%20Join(SMB%20map%20join)-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%8E%9F%E7%90%86&#34; &gt;原理&lt;/a&gt;{#%E5%8E%9F%E7%90%86-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E4%BC%98%E5%8C%96&#34; &gt;优化&lt;/a&gt;{#%E4%BC%98%E5%8C%96-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E4%BC%98%E5%8C%96&#34; &gt;数据倾斜优化&lt;/a&gt;{#%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E4%BC%98%E5%8C%96-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%88%86%E7%BB%84%E8%81%9A%E5%90%88%E5%AF%BC%E8%87%B4%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C&#34; &gt;分组聚合导致的数据倾斜&lt;/a&gt;{#%E5%88%86%E7%BB%84%E8%81%9A%E5%90%88%E5%AF%BC%E8%87%B4%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Map-Side%E8%81%9A%E5%90%88&#34; &gt;Map-Side聚合&lt;/a&gt;{#Map-Side%E8%81%9A%E5%90%88-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Skew-GroupBy%E4%BC%98%E5%8C%96&#34; &gt;Skew-GroupBy优化&lt;/a&gt;{#Skew-GroupBy%E4%BC%98%E5%8C%96-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E4%BC%98%E5%8C%96%E5%89%8D&#34; &gt;优化前&lt;/a&gt;{#%E4%BC%98%E5%8C%96%E5%89%8D-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E4%BC%98%E5%8C%96%E5%90%8E%C2%A0&#34; &gt;优化后&lt;/a&gt;{#%E4%BC%98%E5%8C%96%E5%90%8E%C2%A0-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Join%E5%AF%BC%E8%87%B4%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C&#34; &gt;Join导致的数据倾斜&lt;/a&gt;{#Join%E5%AF%BC%E8%87%B4%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#map%20join&#34; &gt;map join&lt;/a&gt;{#map%20join-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#skew%20join&#34; &gt;skew join&lt;/a&gt;{#skew%20join-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E4%BB%BB%E5%8A%A1%E5%B9%B6%E8%A1%8C%E5%BA%A6%E4%BC%98%E5%8C%96&#34; &gt;任务并行度优化&lt;/a&gt;{#%E4%BB%BB%E5%8A%A1%E5%B9%B6%E8%A1%8C%E5%BA%A6%E4%BC%98%E5%8C%96-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Map%E7%AB%AF%E5%B9%B6%E8%A1%8C%E5%BA%A6&#34; &gt;Map端并行度&lt;/a&gt;{#Map%E7%AB%AF%E5%B9%B6%E8%A1%8C%E5%BA%A6-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Reduce%E7%AB%AF%E5%B9%B6%E8%A1%8C%E5%BA%A6&#34; &gt;Reduce端并行度&lt;/a&gt;{#Reduce%E7%AB%AF%E5%B9%B6%E8%A1%8C%E5%BA%A6-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%B0%8F%E6%96%87%E4%BB%B6%E5%90%88%E5%B9%B6%E4%BC%98%E5%8C%96&#34; &gt;小文件合并优化&lt;/a&gt;{#%E5%B0%8F%E6%96%87%E4%BB%B6%E5%90%88%E5%B9%B6%E4%BC%98%E5%8C%96-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%90%88%E5%B9%B6Map%E7%AB%AF%E8%BE%93%E5%85%A5%E7%9A%84%E5%B0%8F%E6%96%87%E4%BB%B6&#34; &gt;合并Map端输入的小文件&lt;/a&gt;{#%E5%90%88%E5%B9%B6Map%E7%AB%AF%E8%BE%93%E5%85%A5%E7%9A%84%E5%B0%8F%E6%96%87%E4%BB%B6-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%90%88%E5%B9%B6Reduce%E7%AB%AF%E8%BE%93%E5%87%BA%E7%9A%84%E5%B0%8F%E6%96%87%E4%BB%B6&#34; &gt;合并Reduce端输出的小文件&lt;/a&gt;{#%E5%90%88%E5%B9%B6Reduce%E7%AB%AF%E8%BE%93%E5%87%BA%E7%9A%84%E5%B0%8F%E6%96%87%E4%BB%B6-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%85%B6%E4%BB%96%E4%BC%98%E5%8C%96&#34; &gt;其他优化&lt;/a&gt;{#%E5%85%B6%E4%BB%96%E4%BC%98%E5%8C%96-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#CBO%E4%BC%98%E5%8C%96&#34; &gt;CBO优化&lt;/a&gt;{#CBO%E4%BC%98%E5%8C%96-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E8%B0%93%E8%AF%8D%E4%B8%8B%E6%8E%A8&#34; &gt;谓词下推&lt;/a&gt;{#%E8%B0%93%E8%AF%8D%E4%B8%8B%E6%8E%A8-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E7%9F%A2%E9%87%8F%E5%8C%96%E6%9F%A5%E8%AF%A2&#34; &gt;矢量化查询&lt;/a&gt;{#%E7%9F%A2%E9%87%8F%E5%8C%96%E6%9F%A5%E8%AF%A2-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#Fetch%E6%8A%93%E5%8F%96&#34; &gt;Fetch抓取&lt;/a&gt;{#Fetch%E6%8A%93%E5%8F%96-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%BC%8F&#34; &gt;本地模式&lt;/a&gt;{#%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%BC%8F-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%B9%B6%E8%A1%8C%E6%89%A7%E8%A1%8C&#34; &gt;并行执行&lt;/a&gt;{#%E5%B9%B6%E8%A1%8C%E6%89%A7%E8%A1%8C-toc}&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;#%E4%B8%A5%E6%A0%BC%E6%A8%A1%E5%BC%8F&#34; &gt;严格模式&lt;/a&gt;{#%E4%B8%A5%E6%A0%BC%E6%A8%A1%E5%BC%8F-toc}&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;yarn和mr资源配置-yarne5928cmre8b584e6ba90e9858de7bdae&#34;&gt;&lt;a href=&#34;#yarn%e5%92%8cmr%e8%b5%84%e6%ba%90%e9%85%8d%e7%bd%ae-yarne5928cmre8b584e6ba90e9858de7bdae&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Yarn和MR资源配置 {#Yarn%E5%92%8CMR%E8%B5%84%E6%BA%90%E9%85%8D%E7%BD%AE}
&lt;/h2&gt;&lt;p&gt;配置项参考官网：&lt;a class=&#34;link&#34; href=&#34;https://apache.github.io/hadoop/&#34;  title=&#34;https://apache.github.io/hadoop/&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://apache.github.io/hadoop/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;yarn资源配置-yarne8b584e6ba90e9858de7bdae&#34;&gt;&lt;a href=&#34;#yarn%e8%b5%84%e6%ba%90%e9%85%8d%e7%bd%ae-yarne8b584e6ba90e9858de7bdae&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Yarn资源配置 {#Yarn%E8%B5%84%E6%BA%90%E9%85%8D%E7%BD%AE}
&lt;/h3&gt;&lt;p&gt;修改yarn-site.xml,调整的Yarn参数均与CPU、内存等资源有关，配置如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;lt;property&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;name&amp;gt;yarn.nodemanager.resource.memory-mb&amp;lt;/name&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;value&amp;gt;65536&amp;lt;/value&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;description&amp;gt;一个NodeManager节点分配给Container使用的内存。该参数的配置，取决于NodeManager所在节点的总内存容量和该节点运行的其他服务的数量&amp;lt;/description&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;/property&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;property&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;name&amp;gt;yarn.nodemanager.resource.cpu-vcores&amp;lt;/name&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;value&amp;gt;16&amp;lt;/value&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;description&amp;gt;一个NodeManager节点分配给Container使用的CPU核数。该参数的配置，同样取决于NodeManager所在节点的总CPU核数和该节点运行的其他服务。&amp;lt;/description&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;/property&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;property&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;name&amp;gt;yarn.scheduler.maximum-allocation-mb&amp;lt;/name&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;value&amp;gt;16384&amp;lt;/value&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;description&amp;gt;单个Container能够使用的最大内存。&amp;lt;/description&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;/property&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;property&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;name&amp;gt;yarn.scheduler.minimum-allocation-mb&amp;lt;/name&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;value&amp;gt;512&amp;lt;/value&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;description&amp;gt;单个Container能够使用的最小内存。&amp;lt;/description&amp;gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;/property&amp;gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;修改后重新分发该配置文件并重启Yarn&lt;/p&gt;
&lt;h3 id=&#34;mr资源配置-mre8b584e6ba90e9858de7bdae&#34;&gt;&lt;a href=&#34;#mr%e8%b5%84%e6%ba%90%e9%85%8d%e7%bd%ae-mre8b584e6ba90e9858de7bdae&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;MR资源配置 {#MR%E8%B5%84%E6%BA%90%E9%85%8D%E7%BD%AE}
&lt;/h3&gt;&lt;p&gt;MapReduce资源配置主要包括Map Task的内存和CPU核数，以及Reduce Task的内存和CPU核数。核心配置参数如下：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt;{#_Hlk110418691}&lt;strong&gt;）&lt;/strong&gt; &lt;strong&gt;mapreduce.map.memory.mb&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;该参数的含义是，单个Map Task申请的container容器内存大小，其默认值为1024。该值不能超出yarn.scheduler.maximum-allocation-mb和yarn.scheduler.minimum-allocation-mb规定的范围。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;该参数需要根据不同的计算任务单独进行配置，在hive中，可直接使用如下方式为每个SQL语句单独进行配置：set mapreduce.map.memory.mb=2048;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;）&lt;/strong&gt; &lt;strong&gt;mapreduce.map.cpu.vcores&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;该参数的含义是，单个Map Task申请的container容器cpu核数，其默认值为1。该值一般无需调整。如需调整要修改mapred-site.xml文件（mapred-default.xml）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3）&lt;/strong&gt; &lt;strong&gt;mapreduce.reduce.cpu.vcores&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;该参数的含义是，单个Reduce Task申请的container容器cpu核数，其默认值为1。该值一般无需调整。如需调整要修改mapred-site.xml文件（mapred-default.xml）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4）mapreduce.reduce.memory.mb&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;该参数的含义是，单个Reduce Task申请的container容器内存大小，其默认值为1024。该值同样不能超出yarn.scheduler.maximum-allocation-mb和yarn.scheduler.minimum-allocation-mb规定的范围。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;该参数需要根据不同的计算任务单独进行配置，在hive中，可直接使用如下方式为每个SQL语句单独进行配置：set mapreduce.reduce.memory.mb=2048;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;explain查看执行计划-explaine69fa5e79c8be689a7e8a18ce8aea1e58892&#34;&gt;&lt;a href=&#34;#explain%e6%9f%a5%e7%9c%8b%e6%89%a7%e8%a1%8c%e8%ae%a1%e5%88%92-explaine69fa5e79c8be689a7e8a18ce8aea1e58892&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Explain查看执行计划 {#Explain%E6%9F%A5%E7%9C%8B%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92}
&lt;/h2&gt;&lt;p&gt;Explain用于呈现HQL语句的详细执行步骤，由一系列Stage组成，简单的理解为HQL查询语句的不同执行阶段，这一系列Stage具有依赖关系，每个Stage对应一个MapReduce Job或一个文件系统操作等。&lt;/p&gt;
&lt;p&gt;若某个Stage对应的一个MapReduce Job，则其Map端和Reduce端的计算逻辑分别由Map Operator Tree和Reduce Operator Tree进行描述，Operator Tree由一系列的Operator组成，一个Operator代表在Map或Reduce阶段的一个单一的逻辑操作，例如TableScan Operator，Select Operator，Join Operator等。具体如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/4da9891258984bbe1a892f0ccafcb92b.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;常见的Operator及其作用如下&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;TableScan：表扫描操作，通常map端第一个操作肯定是表扫描操作&lt;/p&gt;
&lt;p&gt;Select Operator：选取操作&lt;/p&gt;
&lt;p&gt;Group By Operator：map端的分组聚合操作，在后面的分组聚合中会讲到&lt;/p&gt;
&lt;p&gt;Reduce Output Operator：输出到 reduce 操作&lt;/p&gt;
&lt;p&gt;Filter Operator：过滤操作&lt;/p&gt;
&lt;p&gt;Join Operator：join 操作&lt;/p&gt;
&lt;p&gt;File Output Operator：文件输出操作&lt;/p&gt;
&lt;p&gt;Fetch Operator 客户端获取数据操作
&lt;strong&gt;Explain语法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;EXPLAIN &lt;/p&gt;
\[FORMATTED \| EXTENDED \| DEPENDENCY\]&lt;p&gt; query-sql&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;FORMATTED：将执行计划以JSON字符串的形式输出&lt;/li&gt;
&lt;li&gt;EXTENDED：输出执行计划中的额外信息，通常是读写的文件名等信息&lt;/li&gt;
&lt;li&gt;DEPENDENCY：输出执行计划读取的表及分区&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;例：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;hive (default)&amp;gt;&lt;/p&gt;
&lt;p&gt;explain formatted&lt;/p&gt;
&lt;p&gt;select user_id,count(*) from order_detail group by user_id;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/d475c4d504540aaa12554c7c9480202c.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;分组聚合优化-e58886e7bb84e8819ae59088e4bc98e58c96&#34;&gt;&lt;a href=&#34;#%e5%88%86%e7%bb%84%e8%81%9a%e5%90%88%e4%bc%98%e5%8c%96-e58886e7bb84e8819ae59088e4bc98e58c96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;&lt;strong&gt;分组聚合优化&lt;/strong&gt; {#%E5%88%86%E7%BB%84%E8%81%9A%E5%90%88%E4%BC%98%E5%8C%96}
&lt;/h2&gt;&lt;p&gt;分组聚合是通过MR Job实现的，map端读取数据，并按照分组字段分区，通过shuffle，把数据发到reduce，各组数据在reduce端完成最终的聚合运算。&lt;/p&gt;
&lt;p&gt;分组聚合的优化主要围绕减少shuffle数据量进行，具体做法是map-side聚合。map-side聚合是在map端维护一个hash table，先利用其完成数据的部分聚合，再把聚合的结果按照分组字段分区，发到reduce端完成最终聚合，以此提高分组聚合运算效率。简而言之就是增加了一个map端的部分聚合过程，以减少shuffle的工作量，进而减少reduce端的聚合工作量。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;map-side聚合相关参数如下&lt;/p&gt;
&lt;p&gt;&amp;ndash;启用map-side聚合，默认是true&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;set hive.map.aggr=true;&lt;/strong&gt;&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;&amp;ndash;用于检测源表数据是否适合进行map-side聚合。检测的方法是：系统自动先对若干条数据进行map-side聚合，若聚合后的条数和聚合前的条数比值小于该值，则认为该表适合进行map-side聚合；否则，认为该表数据不适合进行map-side聚合，后续数据便不再进行map-side聚合。0.5意味着平均有2条数据可以聚合成1条，1意味着没有出现任何的聚合&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;set hive.map.aggr.hash.min.reduction=0.5;&lt;/strong&gt;&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;&amp;ndash;用于&lt;strong&gt;hive.map.aggr.hash.min.reduction=0.5&lt;/strong&gt; 检测源表是否适合map-side聚合的条数。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;set hive.groupby.mapaggr.checkinterval=100000;&lt;/strong&gt;&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;&amp;ndash;map-side聚合所用的hash table占用map task堆内存的最大比例，若超出该值，则会对hash table进行一次flush。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;set hive.map.aggr.hash.force.flush.memory.threshold=0.7;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;优化前vs优化后-e4bc98e58c96e5898dvse4bc98e58c96e5908e&#34;&gt;&lt;a href=&#34;#%e4%bc%98%e5%8c%96%e5%89%8dvs%e4%bc%98%e5%8c%96%e5%90%8e-e4bc98e58c96e5898dvse4bc98e58c96e5908e&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;优化前VS优化后 {#%E4%BC%98%E5%8C%96%E5%89%8DVS%E4%BC%98%E5%8C%96%E5%90%8E}
&lt;/h3&gt;&lt;p&gt;set hive.map.aggr=false关闭分组聚合优化，查看执行效果，在Map端没有了Group By Operator&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/bef7cc2560feaf0c03af5c376dadbac4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;set hive.map.aggr=true开启分组聚合优化，查看执行效果，在Map端有了Group By Operator，&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/fd582dc168193eedd0302e6cdccc7d17.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;若发生map-side优化，优化后比优化前的HQL执行耗时应该有所减少，且map的output数量明显小于input数量。&lt;/p&gt;
&lt;p&gt;若没有触发map-side，则map的output数量虽然比input数量有所减少但可以忽略不计。具体有没有触发map-side可以去web UI界面查看map日志。&lt;/p&gt;
&lt;p&gt;注意！！map-side聚合不够智能，即map端的分组聚合是否执行一定程度上会受到分组字段在表中存储的位置和分布的影响，这是底层存储问题，未必是因为数据真的不适合分组聚合。要解决此问题可以提前对数据&lt;strong&gt;分区分桶&lt;/strong&gt;，使用分区分桶表，使得同一区域存储的数据分布具有一定的相似性，这样聚合结果会有所提升。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;例：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1）select province_id,count(*) from order_detail group by province_id;&lt;/p&gt;
&lt;p&gt;该语句查询所有订单，根据省份id分组聚合，省份只有34个，这样map后的数据应该只有34条，所以聚合结果是应该是比较可观的。所以group by 的基数越小，一般越适合聚合。&lt;/p&gt;
&lt;p&gt;2）select product_id,count(*) from order_detail group by product_id;&lt;/p&gt;
&lt;p&gt;若product_id这一分组字段在order_detail表中分布比较散，那么可能会导致hive在表中切片抽样进行map-side检测的时候测试聚合结果&amp;gt;0.5，那么最终就没有使用map-side聚合。所以说如果能保证抽样数据的测试结果&amp;lt;=0.5，就会实现分组聚合，当然也可以调整&lt;strong&gt;hive.map.aggr.hash.min.reduction&lt;/strong&gt; 的值以提高map-side的命中率。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;若100w&lt;/strong&gt; &lt;strong&gt;的数据集分组聚合之后的输出&lt;/strong&gt; &lt;strong&gt;&amp;gt;100w,&lt;/strong&gt; &lt;strong&gt;可能的原因是多次触发了&lt;/strong&gt; &lt;strong&gt;hash table&lt;/strong&gt; &lt;strong&gt;的&lt;/strong&gt; &lt;strong&gt;flush&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;join优化-joine4bc98e58c96&#34;&gt;&lt;a href=&#34;#join%e4%bc%98%e5%8c%96-joine4bc98e58c96&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Join优化 {#Join%E4%BC%98%E5%8C%96}
&lt;/h2&gt;&lt;p&gt;Join优化就是控制HQL语句走哪种join算法，这些join算法有的快，有的慢，有的激进，有的保守。我们要做的就是让HQL走最适合自己的join算法。&lt;/p&gt;
&lt;h3 id=&#34;common-join普通join-common20joinefbc88e699aee9809ajoinefbc89&#34;&gt;&lt;a href=&#34;#common-join%e6%99%ae%e9%80%9ajoin-common20joinefbc88e699aee9809ajoinefbc89&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Common Join（普通join） {#Common%20Join%EF%BC%88%E6%99%AE%E9%80%9Ajoin%EF%BC%89}
&lt;/h3&gt;&lt;h4 id=&#34;原理-e58e9fe79086&#34;&gt;&lt;a href=&#34;#%e5%8e%9f%e7%90%86-e58e9fe79086&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;原理 {#%E5%8E%9F%E7%90%86}
&lt;/h4&gt;&lt;p&gt;hive中最稳定的join算法，其通过一个MapReduce Job完成一个join操作。Map端负责读取join操作所需表的数据，并按照关联字段进行分区，通过Shuffle，将其发送到Reduce端，相同key的数据在Reduce端完成最终的Join操作。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i-blog.csdnimg.cn/blog_migrate/c93be2b01fce05ed73c439a062480a2f.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;需要注意-的是hql语句中的join操作和执行计划中的common-join任务并非一对一的关系即hql中的a表&#34;&gt;&lt;a href=&#34;#%e9%9c%80%e8%a6%81%e6%b3%a8%e6%84%8f-%e7%9a%84%e6%98%afhql%e8%af%ad%e5%8f%a5%e4%b8%ad%e7%9a%84join%e6%93%8d%e4%bd%9c%e5%92%8c%e6%89%a7%e8%a1%8c%e8%ae%a1%e5%88%92%e4%b8%ad%e7%9a%84common-join%e4%bb%bb%e5%8a%a1%e5%b9%b6%e9%9d%9e%e4%b8%80%e5%af%b9%e4%b8%80%e7%9a%84%e5%85%b3%e7%b3%bb%e5%8d%b3hql%e4%b8%ad%e7%9a%84a%e8%a1%a8&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;需要&lt;strong&gt;注意&lt;/strong&gt; 的是，&lt;strong&gt;HQL语句中的join操作和执行计划中的Common Join任务并非一对一的关系&lt;/strong&gt;，即HQL中的A&lt;strong&gt;表&lt;/strong&gt;
&lt;/h2&gt;</description>
        </item>
        
    </channel>
</rss>
